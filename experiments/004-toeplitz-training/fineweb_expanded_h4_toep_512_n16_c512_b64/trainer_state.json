{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.320988639689254,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013302471599223136,
      "grad_norm": 2.667436361312866,
      "learning_rate": 0.000499,
      "loss": 10.3411,
      "step": 500
    },
    {
      "epoch": 0.026604943198446272,
      "grad_norm": 1.6333435773849487,
      "learning_rate": 0.0004987493734335839,
      "loss": 5.5183,
      "step": 1000
    },
    {
      "epoch": 0.039907414797669405,
      "grad_norm": 0.7628523707389832,
      "learning_rate": 0.0004974962406015038,
      "loss": 5.1157,
      "step": 1500
    },
    {
      "epoch": 0.053209886396892545,
      "grad_norm": 0.6750486493110657,
      "learning_rate": 0.0004962431077694235,
      "loss": 4.8508,
      "step": 2000
    },
    {
      "epoch": 0.06651235799611568,
      "grad_norm": 0.6765925884246826,
      "learning_rate": 0.0004949899749373434,
      "loss": 4.6555,
      "step": 2500
    },
    {
      "epoch": 0.07981482959533881,
      "grad_norm": 0.5951440334320068,
      "learning_rate": 0.0004937368421052632,
      "loss": 4.4927,
      "step": 3000
    },
    {
      "epoch": 0.09311730119456195,
      "grad_norm": 0.6644490957260132,
      "learning_rate": 0.000492483709273183,
      "loss": 4.3677,
      "step": 3500
    },
    {
      "epoch": 0.10641977279378509,
      "grad_norm": 0.7323002815246582,
      "learning_rate": 0.0004912305764411028,
      "loss": 4.2714,
      "step": 4000
    },
    {
      "epoch": 0.10641977279378509,
      "eval_loss": 4.118514060974121,
      "eval_runtime": 27.1503,
      "eval_samples_per_second": 1841.601,
      "eval_steps_per_second": 7.219,
      "step": 4000
    },
    {
      "epoch": 0.11972224439300821,
      "grad_norm": 0.6630799770355225,
      "learning_rate": 0.0004899774436090226,
      "loss": 4.197,
      "step": 4500
    },
    {
      "epoch": 0.13302471599223137,
      "grad_norm": 0.6862923502922058,
      "learning_rate": 0.0004887243107769423,
      "loss": 4.1329,
      "step": 5000
    },
    {
      "epoch": 0.1463271875914545,
      "grad_norm": 0.6832886338233948,
      "learning_rate": 0.0004874711779448622,
      "loss": 4.0815,
      "step": 5500
    },
    {
      "epoch": 0.15962965919067762,
      "grad_norm": 0.47924715280532837,
      "learning_rate": 0.00048621804511278196,
      "loss": 4.0348,
      "step": 6000
    },
    {
      "epoch": 0.17293213078990077,
      "grad_norm": 0.5361506342887878,
      "learning_rate": 0.0004849649122807018,
      "loss": 3.9968,
      "step": 6500
    },
    {
      "epoch": 0.1862346023891239,
      "grad_norm": 0.5885820388793945,
      "learning_rate": 0.00048371177944862154,
      "loss": 3.9584,
      "step": 7000
    },
    {
      "epoch": 0.19953707398834702,
      "grad_norm": 0.5530357360839844,
      "learning_rate": 0.00048245864661654135,
      "loss": 3.9276,
      "step": 7500
    },
    {
      "epoch": 0.21283954558757018,
      "grad_norm": 0.5487329959869385,
      "learning_rate": 0.0004812080200501253,
      "loss": 3.9,
      "step": 8000
    },
    {
      "epoch": 0.21283954558757018,
      "eval_loss": 3.7773711681365967,
      "eval_runtime": 27.1551,
      "eval_samples_per_second": 1841.274,
      "eval_steps_per_second": 7.218,
      "step": 8000
    },
    {
      "epoch": 0.2261420171867933,
      "grad_norm": 0.5054848790168762,
      "learning_rate": 0.0004799548872180451,
      "loss": 3.8744,
      "step": 8500
    },
    {
      "epoch": 0.23944448878601643,
      "grad_norm": 0.5311636328697205,
      "learning_rate": 0.00047870426065162907,
      "loss": 3.8499,
      "step": 9000
    },
    {
      "epoch": 0.2527469603852396,
      "grad_norm": 0.403477281332016,
      "learning_rate": 0.0004774511278195489,
      "loss": 3.8308,
      "step": 9500
    },
    {
      "epoch": 0.26604943198446274,
      "grad_norm": 0.38660749793052673,
      "learning_rate": 0.0004761979949874687,
      "loss": 3.8075,
      "step": 10000
    },
    {
      "epoch": 0.27935190358368583,
      "grad_norm": 0.43414732813835144,
      "learning_rate": 0.00047494486215538846,
      "loss": 3.7919,
      "step": 10500
    },
    {
      "epoch": 0.292654375182909,
      "grad_norm": 0.4243447780609131,
      "learning_rate": 0.00047369423558897247,
      "loss": 3.7774,
      "step": 11000
    },
    {
      "epoch": 0.30595684678213214,
      "grad_norm": 0.5905536413192749,
      "learning_rate": 0.00047244110275689223,
      "loss": 3.7618,
      "step": 11500
    },
    {
      "epoch": 0.31925931838135524,
      "grad_norm": 0.5407343506813049,
      "learning_rate": 0.00047119047619047623,
      "loss": 3.7464,
      "step": 12000
    },
    {
      "epoch": 0.31925931838135524,
      "eval_loss": 3.635023355484009,
      "eval_runtime": 27.1525,
      "eval_samples_per_second": 1841.454,
      "eval_steps_per_second": 7.219,
      "step": 12000
    },
    {
      "epoch": 0.3325617899805784,
      "grad_norm": 0.5802879929542542,
      "learning_rate": 0.000469937343358396,
      "loss": 3.7334,
      "step": 12500
    },
    {
      "epoch": 0.34586426157980155,
      "grad_norm": 0.8227988481521606,
      "learning_rate": 0.0004686842105263158,
      "loss": 3.7184,
      "step": 13000
    },
    {
      "epoch": 0.35916673317902464,
      "grad_norm": 0.7912476658821106,
      "learning_rate": 0.00046743107769423557,
      "loss": 3.706,
      "step": 13500
    },
    {
      "epoch": 0.3724692047782478,
      "grad_norm": 0.5883572101593018,
      "learning_rate": 0.00046617794486215544,
      "loss": 3.6953,
      "step": 14000
    },
    {
      "epoch": 0.38577167637747095,
      "grad_norm": 0.6100011467933655,
      "learning_rate": 0.0004649248120300752,
      "loss": 3.6858,
      "step": 14500
    },
    {
      "epoch": 0.39907414797669405,
      "grad_norm": 0.6509743928909302,
      "learning_rate": 0.000463671679197995,
      "loss": 3.6749,
      "step": 15000
    },
    {
      "epoch": 0.4123766195759172,
      "grad_norm": 0.6133148074150085,
      "learning_rate": 0.00046242105263157897,
      "loss": 3.6637,
      "step": 15500
    },
    {
      "epoch": 0.42567909117514036,
      "grad_norm": 0.7763041257858276,
      "learning_rate": 0.00046116791979949873,
      "loss": 3.6553,
      "step": 16000
    },
    {
      "epoch": 0.42567909117514036,
      "eval_loss": 3.5460283756256104,
      "eval_runtime": 27.1635,
      "eval_samples_per_second": 1840.706,
      "eval_steps_per_second": 7.216,
      "step": 16000
    },
    {
      "epoch": 0.43898156277436345,
      "grad_norm": 0.859032392501831,
      "learning_rate": 0.00045991478696741855,
      "loss": 3.6459,
      "step": 16500
    },
    {
      "epoch": 0.4522840343735866,
      "grad_norm": 0.49188709259033203,
      "learning_rate": 0.0004586616541353383,
      "loss": 3.6358,
      "step": 17000
    },
    {
      "epoch": 0.46558650597280976,
      "grad_norm": 0.4221230149269104,
      "learning_rate": 0.0004574085213032582,
      "loss": 3.6295,
      "step": 17500
    },
    {
      "epoch": 0.47888897757203286,
      "grad_norm": 0.49653804302215576,
      "learning_rate": 0.00045616040100250626,
      "loss": 3.6259,
      "step": 18000
    },
    {
      "epoch": 0.492191449171256,
      "grad_norm": 0.4079008400440216,
      "learning_rate": 0.000454907268170426,
      "loss": 3.6137,
      "step": 18500
    },
    {
      "epoch": 0.5054939207704792,
      "grad_norm": 0.4494672119617462,
      "learning_rate": 0.0004536541353383459,
      "loss": 3.6069,
      "step": 19000
    },
    {
      "epoch": 0.5187963923697023,
      "grad_norm": 0.424685537815094,
      "learning_rate": 0.00045240100250626566,
      "loss": 3.6007,
      "step": 19500
    },
    {
      "epoch": 0.5320988639689255,
      "grad_norm": 0.4963476359844208,
      "learning_rate": 0.00045114786967418547,
      "loss": 3.5944,
      "step": 20000
    },
    {
      "epoch": 0.5320988639689255,
      "eval_loss": 3.4858362674713135,
      "eval_runtime": 27.1351,
      "eval_samples_per_second": 1842.635,
      "eval_steps_per_second": 7.223,
      "step": 20000
    },
    {
      "epoch": 0.5454013355681485,
      "grad_norm": 0.451934278011322,
      "learning_rate": 0.00044989473684210523,
      "loss": 3.5857,
      "step": 20500
    },
    {
      "epoch": 0.5587038071673717,
      "grad_norm": 0.6090632677078247,
      "learning_rate": 0.00044864160401002505,
      "loss": 3.5802,
      "step": 21000
    },
    {
      "epoch": 0.5720062787665948,
      "grad_norm": 0.6218973398208618,
      "learning_rate": 0.00044738847117794487,
      "loss": 3.5757,
      "step": 21500
    },
    {
      "epoch": 0.585308750365818,
      "grad_norm": 1.1202036142349243,
      "learning_rate": 0.0004461378446115288,
      "loss": 3.5724,
      "step": 22000
    },
    {
      "epoch": 0.5986112219650411,
      "grad_norm": 0.44989070296287537,
      "learning_rate": 0.00044488471177944863,
      "loss": 3.5657,
      "step": 22500
    },
    {
      "epoch": 0.6119136935642643,
      "grad_norm": 0.557341992855072,
      "learning_rate": 0.00044363157894736845,
      "loss": 3.5565,
      "step": 23000
    },
    {
      "epoch": 0.6252161651634873,
      "grad_norm": 0.5099391937255859,
      "learning_rate": 0.0004423809523809524,
      "loss": 3.5493,
      "step": 23500
    },
    {
      "epoch": 0.6385186367627105,
      "grad_norm": 0.5098186731338501,
      "learning_rate": 0.0004411278195488722,
      "loss": 3.5454,
      "step": 24000
    },
    {
      "epoch": 0.6385186367627105,
      "eval_loss": 3.4403536319732666,
      "eval_runtime": 27.1577,
      "eval_samples_per_second": 1841.096,
      "eval_steps_per_second": 7.217,
      "step": 24000
    },
    {
      "epoch": 0.6518211083619336,
      "grad_norm": 0.417726993560791,
      "learning_rate": 0.000439874686716792,
      "loss": 3.54,
      "step": 24500
    },
    {
      "epoch": 0.6651235799611568,
      "grad_norm": 0.42544087767601013,
      "learning_rate": 0.0004386215538847118,
      "loss": 3.5356,
      "step": 25000
    },
    {
      "epoch": 0.6784260515603799,
      "grad_norm": 0.41293472051620483,
      "learning_rate": 0.0004373684210526316,
      "loss": 3.5289,
      "step": 25500
    },
    {
      "epoch": 0.6917285231596031,
      "grad_norm": 0.5762995481491089,
      "learning_rate": 0.0004361152882205514,
      "loss": 3.5295,
      "step": 26000
    },
    {
      "epoch": 0.7050309947588261,
      "grad_norm": 0.48341846466064453,
      "learning_rate": 0.0004348621553884712,
      "loss": 3.5196,
      "step": 26500
    },
    {
      "epoch": 0.7183334663580493,
      "grad_norm": 0.5399007201194763,
      "learning_rate": 0.000433609022556391,
      "loss": 3.5166,
      "step": 27000
    },
    {
      "epoch": 0.7316359379572724,
      "grad_norm": 0.46773937344551086,
      "learning_rate": 0.00043235588972431076,
      "loss": 3.5124,
      "step": 27500
    },
    {
      "epoch": 0.7449384095564956,
      "grad_norm": 0.6584270596504211,
      "learning_rate": 0.00043110275689223063,
      "loss": 3.5079,
      "step": 28000
    },
    {
      "epoch": 0.7449384095564956,
      "eval_loss": 3.4039089679718018,
      "eval_runtime": 27.1724,
      "eval_samples_per_second": 1840.1,
      "eval_steps_per_second": 7.213,
      "step": 28000
    },
    {
      "epoch": 0.7582408811557187,
      "grad_norm": 0.43309667706489563,
      "learning_rate": 0.0004298496240601504,
      "loss": 3.5046,
      "step": 28500
    },
    {
      "epoch": 0.7715433527549419,
      "grad_norm": 0.7291338443756104,
      "learning_rate": 0.0004285964912280702,
      "loss": 3.4982,
      "step": 29000
    },
    {
      "epoch": 0.7848458243541651,
      "grad_norm": 0.5387976765632629,
      "learning_rate": 0.00042734586466165416,
      "loss": 3.4973,
      "step": 29500
    },
    {
      "epoch": 0.7981482959533881,
      "grad_norm": 0.6515381336212158,
      "learning_rate": 0.00042609774436090224,
      "loss": 3.4959,
      "step": 30000
    },
    {
      "epoch": 0.8114507675526113,
      "grad_norm": 0.5760719776153564,
      "learning_rate": 0.0004248496240601504,
      "loss": 3.5086,
      "step": 30500
    },
    {
      "epoch": 0.8247532391518344,
      "grad_norm": 0.4715568423271179,
      "learning_rate": 0.00042359899749373433,
      "loss": 3.4944,
      "step": 31000
    },
    {
      "epoch": 0.8380557107510576,
      "grad_norm": 0.559729278087616,
      "learning_rate": 0.00042234586466165415,
      "loss": 3.4825,
      "step": 31500
    },
    {
      "epoch": 0.8513581823502807,
      "grad_norm": 0.4946298599243164,
      "learning_rate": 0.0004210927318295739,
      "loss": 3.4804,
      "step": 32000
    },
    {
      "epoch": 0.8513581823502807,
      "eval_loss": 3.3817033767700195,
      "eval_runtime": 28.0714,
      "eval_samples_per_second": 1781.175,
      "eval_steps_per_second": 6.982,
      "step": 32000
    },
    {
      "epoch": 0.8646606539495039,
      "grad_norm": 0.41861966252326965,
      "learning_rate": 0.0004198395989974937,
      "loss": 3.4764,
      "step": 32500
    },
    {
      "epoch": 0.8779631255487269,
      "grad_norm": 0.5426784157752991,
      "learning_rate": 0.00041858646616541354,
      "loss": 3.4725,
      "step": 33000
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.6744776368141174,
      "learning_rate": 0.00041733333333333336,
      "loss": 3.4683,
      "step": 33500
    },
    {
      "epoch": 0.9045680687471732,
      "grad_norm": 0.40163853764533997,
      "learning_rate": 0.0004160802005012531,
      "loss": 3.4653,
      "step": 34000
    },
    {
      "epoch": 0.9178705403463964,
      "grad_norm": 0.5588751435279846,
      "learning_rate": 0.00041482706766917294,
      "loss": 3.4644,
      "step": 34500
    },
    {
      "epoch": 0.9311730119456195,
      "grad_norm": 0.43456581234931946,
      "learning_rate": 0.0004135739348370927,
      "loss": 3.4622,
      "step": 35000
    },
    {
      "epoch": 0.9444754835448427,
      "grad_norm": 0.39412403106689453,
      "learning_rate": 0.0004123208020050125,
      "loss": 3.4583,
      "step": 35500
    },
    {
      "epoch": 0.9577779551440657,
      "grad_norm": 0.40832415223121643,
      "learning_rate": 0.00041107017543859646,
      "loss": 3.4606,
      "step": 36000
    },
    {
      "epoch": 0.9577779551440657,
      "eval_loss": 3.3548827171325684,
      "eval_runtime": 27.4914,
      "eval_samples_per_second": 1818.748,
      "eval_steps_per_second": 7.129,
      "step": 36000
    },
    {
      "epoch": 0.9710804267432889,
      "grad_norm": 0.5555247068405151,
      "learning_rate": 0.00040981704260651633,
      "loss": 3.454,
      "step": 36500
    },
    {
      "epoch": 0.984382898342512,
      "grad_norm": 0.4962080419063568,
      "learning_rate": 0.0004085639097744361,
      "loss": 3.4479,
      "step": 37000
    },
    {
      "epoch": 0.9976853699417352,
      "grad_norm": 0.5921329259872437,
      "learning_rate": 0.0004073107769423559,
      "loss": 3.4442,
      "step": 37500
    },
    {
      "epoch": 1.0109878415409583,
      "grad_norm": 0.3988755941390991,
      "learning_rate": 0.0004060576441102757,
      "loss": 3.4396,
      "step": 38000
    },
    {
      "epoch": 1.0242903131401815,
      "grad_norm": 0.4586036801338196,
      "learning_rate": 0.0004048045112781955,
      "loss": 3.4367,
      "step": 38500
    },
    {
      "epoch": 1.0375927847394046,
      "grad_norm": 0.46856603026390076,
      "learning_rate": 0.0004035513784461153,
      "loss": 3.4335,
      "step": 39000
    },
    {
      "epoch": 1.0508952563386278,
      "grad_norm": 0.4884733259677887,
      "learning_rate": 0.0004022982456140351,
      "loss": 3.4318,
      "step": 39500
    },
    {
      "epoch": 1.064197727937851,
      "grad_norm": 0.4241534471511841,
      "learning_rate": 0.0004010451127819549,
      "loss": 3.431,
      "step": 40000
    },
    {
      "epoch": 1.064197727937851,
      "eval_loss": 3.3274881839752197,
      "eval_runtime": 27.1764,
      "eval_samples_per_second": 1839.832,
      "eval_steps_per_second": 7.212,
      "step": 40000
    },
    {
      "epoch": 1.077500199537074,
      "grad_norm": 0.43964746594429016,
      "learning_rate": 0.0003997919799498747,
      "loss": 3.4278,
      "step": 40500
    },
    {
      "epoch": 1.090802671136297,
      "grad_norm": 0.7205533981323242,
      "learning_rate": 0.00039853884711779446,
      "loss": 3.4243,
      "step": 41000
    },
    {
      "epoch": 1.1041051427355202,
      "grad_norm": 0.6690815091133118,
      "learning_rate": 0.00039728571428571433,
      "loss": 3.4243,
      "step": 41500
    },
    {
      "epoch": 1.1174076143347433,
      "grad_norm": 0.5864388942718506,
      "learning_rate": 0.0003960325814536341,
      "loss": 3.4222,
      "step": 42000
    },
    {
      "epoch": 1.1307100859339665,
      "grad_norm": 0.541922390460968,
      "learning_rate": 0.0003947819548872181,
      "loss": 3.4205,
      "step": 42500
    },
    {
      "epoch": 1.1440125575331896,
      "grad_norm": 0.47454530000686646,
      "learning_rate": 0.00039352882205513786,
      "loss": 3.4184,
      "step": 43000
    },
    {
      "epoch": 1.1573150291324128,
      "grad_norm": 0.5601059198379517,
      "learning_rate": 0.0003922756892230577,
      "loss": 3.4147,
      "step": 43500
    },
    {
      "epoch": 1.170617500731636,
      "grad_norm": 0.71876460313797,
      "learning_rate": 0.00039102255639097744,
      "loss": 3.4118,
      "step": 44000
    },
    {
      "epoch": 1.170617500731636,
      "eval_loss": 3.308527708053589,
      "eval_runtime": 27.1838,
      "eval_samples_per_second": 1839.332,
      "eval_steps_per_second": 7.21,
      "step": 44000
    },
    {
      "epoch": 1.183919972330859,
      "grad_norm": 0.524050235748291,
      "learning_rate": 0.00038976942355889725,
      "loss": 3.4106,
      "step": 44500
    },
    {
      "epoch": 1.1972224439300823,
      "grad_norm": 0.6193998456001282,
      "learning_rate": 0.00038851629072681707,
      "loss": 3.4089,
      "step": 45000
    },
    {
      "epoch": 1.2105249155293054,
      "grad_norm": 0.48831450939178467,
      "learning_rate": 0.0003872631578947369,
      "loss": 3.4055,
      "step": 45500
    },
    {
      "epoch": 1.2238273871285286,
      "grad_norm": 0.6643530130386353,
      "learning_rate": 0.00038601253132832084,
      "loss": 3.4051,
      "step": 46000
    },
    {
      "epoch": 1.2371298587277515,
      "grad_norm": 0.552052915096283,
      "learning_rate": 0.00038476190476190473,
      "loss": 3.4069,
      "step": 46500
    },
    {
      "epoch": 1.2504323303269747,
      "grad_norm": 0.3944990038871765,
      "learning_rate": 0.00038351127819548873,
      "loss": 3.4066,
      "step": 47000
    },
    {
      "epoch": 1.2637348019261978,
      "grad_norm": 0.439698725938797,
      "learning_rate": 0.00038225814536340855,
      "loss": 3.3986,
      "step": 47500
    },
    {
      "epoch": 1.277037273525421,
      "grad_norm": 0.46354109048843384,
      "learning_rate": 0.00038100751879699245,
      "loss": 3.3994,
      "step": 48000
    },
    {
      "epoch": 1.277037273525421,
      "eval_loss": 3.2943756580352783,
      "eval_runtime": 27.1927,
      "eval_samples_per_second": 1838.726,
      "eval_steps_per_second": 7.208,
      "step": 48000
    },
    {
      "epoch": 1.290339745124644,
      "grad_norm": 0.40206533670425415,
      "learning_rate": 0.0003797543859649123,
      "loss": 3.3953,
      "step": 48500
    },
    {
      "epoch": 1.3036422167238673,
      "grad_norm": 0.6067354083061218,
      "learning_rate": 0.0003785012531328321,
      "loss": 3.3974,
      "step": 49000
    },
    {
      "epoch": 1.3169446883230904,
      "grad_norm": 0.5470119118690491,
      "learning_rate": 0.0003772481203007519,
      "loss": 3.3926,
      "step": 49500
    },
    {
      "epoch": 1.3302471599223136,
      "grad_norm": 0.5007860064506531,
      "learning_rate": 0.00037599749373433584,
      "loss": 3.3901,
      "step": 50000
    },
    {
      "epoch": 1.3435496315215367,
      "grad_norm": 0.5245732069015503,
      "learning_rate": 0.00037474436090225566,
      "loss": 3.3857,
      "step": 50500
    },
    {
      "epoch": 1.3568521031207599,
      "grad_norm": 0.5673564076423645,
      "learning_rate": 0.0003734912280701754,
      "loss": 3.3857,
      "step": 51000
    },
    {
      "epoch": 1.370154574719983,
      "grad_norm": 0.5307412147521973,
      "learning_rate": 0.00037223809523809524,
      "loss": 3.3835,
      "step": 51500
    },
    {
      "epoch": 1.3834570463192062,
      "grad_norm": 0.40981507301330566,
      "learning_rate": 0.00037098496240601505,
      "loss": 3.3828,
      "step": 52000
    },
    {
      "epoch": 1.3834570463192062,
      "eval_loss": 3.28011417388916,
      "eval_runtime": 27.6232,
      "eval_samples_per_second": 1810.07,
      "eval_steps_per_second": 7.095,
      "step": 52000
    },
    {
      "epoch": 1.3967595179184293,
      "grad_norm": 0.5434794425964355,
      "learning_rate": 0.00036973182957393487,
      "loss": 3.38,
      "step": 52500
    },
    {
      "epoch": 1.4100619895176525,
      "grad_norm": 0.4699205160140991,
      "learning_rate": 0.00036847869674185463,
      "loss": 3.3819,
      "step": 53000
    },
    {
      "epoch": 1.4233644611168756,
      "grad_norm": 0.6839460134506226,
      "learning_rate": 0.00036722556390977445,
      "loss": 3.3774,
      "step": 53500
    },
    {
      "epoch": 1.4366669327160986,
      "grad_norm": 0.6602123379707336,
      "learning_rate": 0.0003659724310776942,
      "loss": 3.3752,
      "step": 54000
    },
    {
      "epoch": 1.4499694043153217,
      "grad_norm": 0.4443703889846802,
      "learning_rate": 0.0003647192982456141,
      "loss": 3.3756,
      "step": 54500
    },
    {
      "epoch": 1.4632718759145449,
      "grad_norm": 0.6381964087486267,
      "learning_rate": 0.00036346616541353384,
      "loss": 3.3713,
      "step": 55000
    },
    {
      "epoch": 1.476574347513768,
      "grad_norm": 0.49229204654693604,
      "learning_rate": 0.00036221303258145366,
      "loss": 3.371,
      "step": 55500
    },
    {
      "epoch": 1.4898768191129912,
      "grad_norm": 0.3732621371746063,
      "learning_rate": 0.0003609598997493734,
      "loss": 3.3699,
      "step": 56000
    },
    {
      "epoch": 1.4898768191129912,
      "eval_loss": 3.266118049621582,
      "eval_runtime": 27.1573,
      "eval_samples_per_second": 1841.125,
      "eval_steps_per_second": 7.217,
      "step": 56000
    },
    {
      "epoch": 1.5031792907122143,
      "grad_norm": 0.5090251564979553,
      "learning_rate": 0.00035970676691729324,
      "loss": 3.3678,
      "step": 56500
    },
    {
      "epoch": 1.5164817623114375,
      "grad_norm": 0.5744776725769043,
      "learning_rate": 0.00035845363408521305,
      "loss": 3.3671,
      "step": 57000
    },
    {
      "epoch": 1.5297842339106607,
      "grad_norm": 0.5948556065559387,
      "learning_rate": 0.00035720300751879695,
      "loss": 3.3702,
      "step": 57500
    },
    {
      "epoch": 1.5430867055098836,
      "grad_norm": 0.6759040951728821,
      "learning_rate": 0.0003559498746867168,
      "loss": 3.3645,
      "step": 58000
    },
    {
      "epoch": 1.5563891771091067,
      "grad_norm": 0.5225825905799866,
      "learning_rate": 0.0003546967418546366,
      "loss": 3.3636,
      "step": 58500
    },
    {
      "epoch": 1.56969164870833,
      "grad_norm": 0.7031965851783752,
      "learning_rate": 0.0003534461152882206,
      "loss": 3.3623,
      "step": 59000
    },
    {
      "epoch": 1.582994120307553,
      "grad_norm": 0.6900858283042908,
      "learning_rate": 0.00035219298245614035,
      "loss": 3.3615,
      "step": 59500
    },
    {
      "epoch": 1.5962965919067762,
      "grad_norm": 0.44843199849128723,
      "learning_rate": 0.00035093984962406016,
      "loss": 3.3592,
      "step": 60000
    },
    {
      "epoch": 1.5962965919067762,
      "eval_loss": 3.2550737857818604,
      "eval_runtime": 27.1801,
      "eval_samples_per_second": 1839.578,
      "eval_steps_per_second": 7.211,
      "step": 60000
    },
    {
      "epoch": 1.6095990635059994,
      "grad_norm": 0.49657008051872253,
      "learning_rate": 0.0003496867167919799,
      "loss": 3.3572,
      "step": 60500
    },
    {
      "epoch": 1.6229015351052225,
      "grad_norm": 0.5058820843696594,
      "learning_rate": 0.0003484335839598998,
      "loss": 3.3561,
      "step": 61000
    },
    {
      "epoch": 1.6362040067044457,
      "grad_norm": 0.533944845199585,
      "learning_rate": 0.00034718045112781956,
      "loss": 3.3559,
      "step": 61500
    },
    {
      "epoch": 1.6495064783036688,
      "grad_norm": 0.5166232585906982,
      "learning_rate": 0.00034592731829573937,
      "loss": 3.3543,
      "step": 62000
    },
    {
      "epoch": 1.662808949902892,
      "grad_norm": 0.5151689648628235,
      "learning_rate": 0.00034467418546365913,
      "loss": 3.3523,
      "step": 62500
    },
    {
      "epoch": 1.6761114215021151,
      "grad_norm": 0.45806068181991577,
      "learning_rate": 0.00034342105263157895,
      "loss": 3.3507,
      "step": 63000
    },
    {
      "epoch": 1.6894138931013383,
      "grad_norm": 0.45488226413726807,
      "learning_rate": 0.00034216791979949877,
      "loss": 3.3486,
      "step": 63500
    },
    {
      "epoch": 1.7027163647005614,
      "grad_norm": 0.3460201621055603,
      "learning_rate": 0.0003409147869674186,
      "loss": 3.3473,
      "step": 64000
    },
    {
      "epoch": 1.7027163647005614,
      "eval_loss": 3.2445497512817383,
      "eval_runtime": 27.1833,
      "eval_samples_per_second": 1839.368,
      "eval_steps_per_second": 7.21,
      "step": 64000
    },
    {
      "epoch": 1.7160188362997846,
      "grad_norm": 0.445976585149765,
      "learning_rate": 0.00033966165413533834,
      "loss": 3.3472,
      "step": 64500
    },
    {
      "epoch": 1.7293213078990077,
      "grad_norm": 0.5720549821853638,
      "learning_rate": 0.00033840852130325816,
      "loss": 3.3466,
      "step": 65000
    },
    {
      "epoch": 1.7426237794982309,
      "grad_norm": 0.5288912653923035,
      "learning_rate": 0.0003371553884711779,
      "loss": 3.3418,
      "step": 65500
    },
    {
      "epoch": 1.755926251097454,
      "grad_norm": 0.6777865290641785,
      "learning_rate": 0.0003359022556390978,
      "loss": 3.3424,
      "step": 66000
    },
    {
      "epoch": 1.7692287226966772,
      "grad_norm": 0.5375733375549316,
      "learning_rate": 0.00033464912280701755,
      "loss": 3.34,
      "step": 66500
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 0.38474756479263306,
      "learning_rate": 0.00033339598997493737,
      "loss": 3.3406,
      "step": 67000
    },
    {
      "epoch": 1.7958336658951233,
      "grad_norm": 0.39952439069747925,
      "learning_rate": 0.00033214285714285713,
      "loss": 3.3405,
      "step": 67500
    },
    {
      "epoch": 1.8091361374943464,
      "grad_norm": 0.6566779017448425,
      "learning_rate": 0.00033089223057644114,
      "loss": 3.3384,
      "step": 68000
    },
    {
      "epoch": 1.8091361374943464,
      "eval_loss": 3.2342612743377686,
      "eval_runtime": 27.2576,
      "eval_samples_per_second": 1834.352,
      "eval_steps_per_second": 7.191,
      "step": 68000
    },
    {
      "epoch": 1.8224386090935696,
      "grad_norm": 0.5768113136291504,
      "learning_rate": 0.0003296390977443609,
      "loss": 3.3368,
      "step": 68500
    },
    {
      "epoch": 1.8357410806927927,
      "grad_norm": 0.36756792664527893,
      "learning_rate": 0.00032838847117794485,
      "loss": 3.336,
      "step": 69000
    },
    {
      "epoch": 1.849043552292016,
      "grad_norm": 0.3980279564857483,
      "learning_rate": 0.00032713533834586466,
      "loss": 3.3354,
      "step": 69500
    },
    {
      "epoch": 1.862346023891239,
      "grad_norm": 0.39134764671325684,
      "learning_rate": 0.0003258822055137844,
      "loss": 3.3327,
      "step": 70000
    },
    {
      "epoch": 1.875648495490462,
      "grad_norm": 0.47198331356048584,
      "learning_rate": 0.0003246290726817043,
      "loss": 3.3328,
      "step": 70500
    },
    {
      "epoch": 1.8889509670896851,
      "grad_norm": 0.46254071593284607,
      "learning_rate": 0.00032337593984962406,
      "loss": 3.3302,
      "step": 71000
    },
    {
      "epoch": 1.9022534386889083,
      "grad_norm": 0.4995776116847992,
      "learning_rate": 0.0003221328320802005,
      "loss": 3.3375,
      "step": 71500
    },
    {
      "epoch": 1.9155559102881314,
      "grad_norm": 0.46819761395454407,
      "learning_rate": 0.00032088220551378447,
      "loss": 3.3287,
      "step": 72000
    },
    {
      "epoch": 1.9155559102881314,
      "eval_loss": 3.2264950275421143,
      "eval_runtime": 27.2067,
      "eval_samples_per_second": 1837.784,
      "eval_steps_per_second": 7.204,
      "step": 72000
    },
    {
      "epoch": 1.9288583818873546,
      "grad_norm": 0.5892652273178101,
      "learning_rate": 0.0003196290726817043,
      "loss": 3.3295,
      "step": 72500
    },
    {
      "epoch": 1.9421608534865777,
      "grad_norm": 0.4682302474975586,
      "learning_rate": 0.00031837593984962404,
      "loss": 3.3316,
      "step": 73000
    },
    {
      "epoch": 1.955463325085801,
      "grad_norm": 0.4112544357776642,
      "learning_rate": 0.00031712280701754386,
      "loss": 3.3259,
      "step": 73500
    },
    {
      "epoch": 1.968765796685024,
      "grad_norm": 0.5110191106796265,
      "learning_rate": 0.0003158696741854636,
      "loss": 3.3264,
      "step": 74000
    },
    {
      "epoch": 1.9820682682842472,
      "grad_norm": 0.6020995378494263,
      "learning_rate": 0.0003146165413533835,
      "loss": 3.3233,
      "step": 74500
    },
    {
      "epoch": 1.9953707398834704,
      "grad_norm": 0.4737228751182556,
      "learning_rate": 0.00031336340852130325,
      "loss": 3.3221,
      "step": 75000
    },
    {
      "epoch": 2.0086732114826935,
      "grad_norm": 0.44325533509254456,
      "learning_rate": 0.00031211027568922307,
      "loss": 3.3201,
      "step": 75500
    },
    {
      "epoch": 2.0219756830819167,
      "grad_norm": 0.35524091124534607,
      "learning_rate": 0.00031085714285714283,
      "loss": 3.3176,
      "step": 76000
    },
    {
      "epoch": 2.0219756830819167,
      "eval_loss": 3.2171847820281982,
      "eval_runtime": 27.1833,
      "eval_samples_per_second": 1839.366,
      "eval_steps_per_second": 7.21,
      "step": 76000
    },
    {
      "epoch": 2.03527815468114,
      "grad_norm": 0.542904794216156,
      "learning_rate": 0.00030960651629072684,
      "loss": 3.3322,
      "step": 76500
    },
    {
      "epoch": 2.048580626280363,
      "grad_norm": 0.48643115162849426,
      "learning_rate": 0.0003083533834586466,
      "loss": 3.3214,
      "step": 77000
    },
    {
      "epoch": 2.061883097879586,
      "grad_norm": 0.5075219869613647,
      "learning_rate": 0.0003071002506265664,
      "loss": 3.3165,
      "step": 77500
    },
    {
      "epoch": 2.0751855694788093,
      "grad_norm": 0.5345073938369751,
      "learning_rate": 0.00030584711779448623,
      "loss": 3.3154,
      "step": 78000
    },
    {
      "epoch": 2.0884880410780324,
      "grad_norm": 0.45017513632774353,
      "learning_rate": 0.00030459398496240605,
      "loss": 3.3142,
      "step": 78500
    },
    {
      "epoch": 2.1017905126772556,
      "grad_norm": 0.4704497158527374,
      "learning_rate": 0.0003033408521303258,
      "loss": 3.314,
      "step": 79000
    },
    {
      "epoch": 2.1150929842764787,
      "grad_norm": 0.5591506958007812,
      "learning_rate": 0.0003020877192982456,
      "loss": 3.3114,
      "step": 79500
    },
    {
      "epoch": 2.128395455875702,
      "grad_norm": 0.4871775209903717,
      "learning_rate": 0.0003008345864661654,
      "loss": 3.3123,
      "step": 80000
    },
    {
      "epoch": 2.128395455875702,
      "eval_loss": 3.2092859745025635,
      "eval_runtime": 27.1655,
      "eval_samples_per_second": 1840.571,
      "eval_steps_per_second": 7.215,
      "step": 80000
    },
    {
      "epoch": 2.141697927474925,
      "grad_norm": 0.5315726399421692,
      "learning_rate": 0.00029958145363408526,
      "loss": 3.3112,
      "step": 80500
    },
    {
      "epoch": 2.155000399074148,
      "grad_norm": 0.5529385209083557,
      "learning_rate": 0.000298328320802005,
      "loss": 3.3101,
      "step": 81000
    },
    {
      "epoch": 2.168302870673371,
      "grad_norm": 0.5462661981582642,
      "learning_rate": 0.00029707518796992483,
      "loss": 3.3084,
      "step": 81500
    },
    {
      "epoch": 2.181605342272594,
      "grad_norm": 0.3769354224205017,
      "learning_rate": 0.0002958220551378446,
      "loss": 3.3072,
      "step": 82000
    },
    {
      "epoch": 2.194907813871817,
      "grad_norm": 0.4202004373073578,
      "learning_rate": 0.0002945714285714286,
      "loss": 3.3072,
      "step": 82500
    },
    {
      "epoch": 2.2082102854710404,
      "grad_norm": 0.4462929666042328,
      "learning_rate": 0.00029331829573934836,
      "loss": 3.3059,
      "step": 83000
    },
    {
      "epoch": 2.2215127570702635,
      "grad_norm": 0.48758816719055176,
      "learning_rate": 0.0002920651629072682,
      "loss": 3.3064,
      "step": 83500
    },
    {
      "epoch": 2.2348152286694867,
      "grad_norm": 0.44739076495170593,
      "learning_rate": 0.000290812030075188,
      "loss": 3.3056,
      "step": 84000
    },
    {
      "epoch": 2.2348152286694867,
      "eval_loss": 3.2041409015655518,
      "eval_runtime": 27.1952,
      "eval_samples_per_second": 1838.559,
      "eval_steps_per_second": 7.207,
      "step": 84000
    },
    {
      "epoch": 2.24811770026871,
      "grad_norm": 0.5228930711746216,
      "learning_rate": 0.0002895588972431078,
      "loss": 3.3045,
      "step": 84500
    },
    {
      "epoch": 2.261420171867933,
      "grad_norm": 0.44699519872665405,
      "learning_rate": 0.00028830576441102757,
      "loss": 3.3043,
      "step": 85000
    },
    {
      "epoch": 2.274722643467156,
      "grad_norm": 0.4110918641090393,
      "learning_rate": 0.0002870526315789474,
      "loss": 3.3017,
      "step": 85500
    },
    {
      "epoch": 2.2880251150663793,
      "grad_norm": 0.46606364846229553,
      "learning_rate": 0.0002858045112781955,
      "loss": 3.3116,
      "step": 86000
    },
    {
      "epoch": 2.3013275866656024,
      "grad_norm": 0.4697859585285187,
      "learning_rate": 0.0002845513784461153,
      "loss": 3.302,
      "step": 86500
    },
    {
      "epoch": 2.3146300582648256,
      "grad_norm": 0.39274629950523376,
      "learning_rate": 0.0002832982456140351,
      "loss": 3.3019,
      "step": 87000
    },
    {
      "epoch": 2.3279325298640487,
      "grad_norm": 0.3398069441318512,
      "learning_rate": 0.00028204511278195486,
      "loss": 3.2993,
      "step": 87500
    },
    {
      "epoch": 2.341235001463272,
      "grad_norm": 0.41502711176872253,
      "learning_rate": 0.00028079197994987473,
      "loss": 3.3048,
      "step": 88000
    },
    {
      "epoch": 2.341235001463272,
      "eval_loss": 3.199005603790283,
      "eval_runtime": 27.1726,
      "eval_samples_per_second": 1840.091,
      "eval_steps_per_second": 7.213,
      "step": 88000
    },
    {
      "epoch": 2.354537473062495,
      "grad_norm": 0.4920514225959778,
      "learning_rate": 0.00027954135338345863,
      "loss": 3.3047,
      "step": 88500
    },
    {
      "epoch": 2.367839944661718,
      "grad_norm": 0.5229268670082092,
      "learning_rate": 0.0002782907268170426,
      "loss": 3.299,
      "step": 89000
    },
    {
      "epoch": 2.3811424162609414,
      "grad_norm": 0.46220067143440247,
      "learning_rate": 0.0002770375939849624,
      "loss": 3.2984,
      "step": 89500
    },
    {
      "epoch": 2.3944448878601645,
      "grad_norm": 0.36779388785362244,
      "learning_rate": 0.0002757844611528822,
      "loss": 3.299,
      "step": 90000
    },
    {
      "epoch": 2.4077473594593877,
      "grad_norm": 0.3717319965362549,
      "learning_rate": 0.0002745338345864662,
      "loss": 3.3212,
      "step": 90500
    },
    {
      "epoch": 2.421049831058611,
      "grad_norm": 0.4933376610279083,
      "learning_rate": 0.000273280701754386,
      "loss": 3.3017,
      "step": 91000
    },
    {
      "epoch": 2.434352302657834,
      "grad_norm": 0.4952901601791382,
      "learning_rate": 0.0002720275689223058,
      "loss": 3.2925,
      "step": 91500
    },
    {
      "epoch": 2.447654774257057,
      "grad_norm": 0.4006173312664032,
      "learning_rate": 0.00027077443609022556,
      "loss": 3.3007,
      "step": 92000
    },
    {
      "epoch": 2.447654774257057,
      "eval_loss": 3.1911728382110596,
      "eval_runtime": 27.1723,
      "eval_samples_per_second": 1840.109,
      "eval_steps_per_second": 7.213,
      "step": 92000
    },
    {
      "epoch": 2.4609572458562803,
      "grad_norm": 0.459710031747818,
      "learning_rate": 0.00026952130325814537,
      "loss": 3.2936,
      "step": 92500
    },
    {
      "epoch": 2.474259717455503,
      "grad_norm": 0.5211644768714905,
      "learning_rate": 0.0002682681704260652,
      "loss": 3.2908,
      "step": 93000
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.535473108291626,
      "learning_rate": 0.000267015037593985,
      "loss": 3.2902,
      "step": 93500
    },
    {
      "epoch": 2.5008646606539493,
      "grad_norm": 0.37169280648231506,
      "learning_rate": 0.00026576190476190477,
      "loss": 3.2908,
      "step": 94000
    },
    {
      "epoch": 2.5141671322531725,
      "grad_norm": 0.4562361538410187,
      "learning_rate": 0.0002645087719298246,
      "loss": 3.2887,
      "step": 94500
    },
    {
      "epoch": 2.5274696038523956,
      "grad_norm": 0.48053014278411865,
      "learning_rate": 0.00026325563909774434,
      "loss": 3.2887,
      "step": 95000
    },
    {
      "epoch": 2.5407720754516188,
      "grad_norm": 0.4860774278640747,
      "learning_rate": 0.0002620025062656642,
      "loss": 3.2875,
      "step": 95500
    },
    {
      "epoch": 2.554074547050842,
      "grad_norm": 0.4234567880630493,
      "learning_rate": 0.000260749373433584,
      "loss": 3.2848,
      "step": 96000
    },
    {
      "epoch": 2.554074547050842,
      "eval_loss": 3.1834487915039062,
      "eval_runtime": 27.4885,
      "eval_samples_per_second": 1818.943,
      "eval_steps_per_second": 7.13,
      "step": 96000
    },
    {
      "epoch": 2.567377018650065,
      "grad_norm": 0.3976267874240875,
      "learning_rate": 0.0002594987468671679,
      "loss": 3.2877,
      "step": 96500
    },
    {
      "epoch": 2.580679490249288,
      "grad_norm": 0.4676811695098877,
      "learning_rate": 0.00025824561403508774,
      "loss": 3.2845,
      "step": 97000
    },
    {
      "epoch": 2.5939819618485114,
      "grad_norm": 0.4392540752887726,
      "learning_rate": 0.0002569924812030075,
      "loss": 3.2864,
      "step": 97500
    },
    {
      "epoch": 2.6072844334477345,
      "grad_norm": 0.406595915555954,
      "learning_rate": 0.0002557418546365915,
      "loss": 3.286,
      "step": 98000
    },
    {
      "epoch": 2.6205869050469577,
      "grad_norm": 0.40177762508392334,
      "learning_rate": 0.00025448872180451127,
      "loss": 3.2864,
      "step": 98500
    },
    {
      "epoch": 2.633889376646181,
      "grad_norm": 0.6198639869689941,
      "learning_rate": 0.0002532355889724311,
      "loss": 3.2987,
      "step": 99000
    },
    {
      "epoch": 2.647191848245404,
      "grad_norm": 0.43352431058883667,
      "learning_rate": 0.00025198245614035085,
      "loss": 3.3071,
      "step": 99500
    },
    {
      "epoch": 2.660494319844627,
      "grad_norm": 0.561125636100769,
      "learning_rate": 0.0002507293233082707,
      "loss": 3.2872,
      "step": 100000
    },
    {
      "epoch": 2.660494319844627,
      "eval_loss": 3.1800343990325928,
      "eval_runtime": 27.1314,
      "eval_samples_per_second": 1842.886,
      "eval_steps_per_second": 7.224,
      "step": 100000
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 0.5859033465385437,
      "learning_rate": 0.0002494761904761905,
      "loss": 3.2795,
      "step": 100500
    },
    {
      "epoch": 2.6870992630430734,
      "grad_norm": 0.4176803231239319,
      "learning_rate": 0.00024822305764411024,
      "loss": 3.2804,
      "step": 101000
    },
    {
      "epoch": 2.7004017346422966,
      "grad_norm": 0.49887239933013916,
      "learning_rate": 0.00024696992481203006,
      "loss": 3.2793,
      "step": 101500
    },
    {
      "epoch": 2.7137042062415198,
      "grad_norm": 0.37129077315330505,
      "learning_rate": 0.0002457167919799499,
      "loss": 3.2786,
      "step": 102000
    },
    {
      "epoch": 2.727006677840743,
      "grad_norm": 0.48081153631210327,
      "learning_rate": 0.0002444636591478697,
      "loss": 3.2787,
      "step": 102500
    },
    {
      "epoch": 2.740309149439966,
      "grad_norm": 0.3816072344779968,
      "learning_rate": 0.00024321052631578948,
      "loss": 3.2764,
      "step": 103000
    },
    {
      "epoch": 2.753611621039189,
      "grad_norm": 0.5537930130958557,
      "learning_rate": 0.00024195739348370927,
      "loss": 3.2801,
      "step": 103500
    },
    {
      "epoch": 2.7669140926384124,
      "grad_norm": 0.44269636273384094,
      "learning_rate": 0.00024070426065162906,
      "loss": 3.2762,
      "step": 104000
    },
    {
      "epoch": 2.7669140926384124,
      "eval_loss": 3.173548460006714,
      "eval_runtime": 27.1524,
      "eval_samples_per_second": 1841.455,
      "eval_steps_per_second": 7.219,
      "step": 104000
    },
    {
      "epoch": 2.7802165642376355,
      "grad_norm": 0.5237007737159729,
      "learning_rate": 0.00023945112781954887,
      "loss": 3.2752,
      "step": 104500
    },
    {
      "epoch": 2.7935190358368587,
      "grad_norm": 0.4218149781227112,
      "learning_rate": 0.00023819799498746866,
      "loss": 3.2731,
      "step": 105000
    },
    {
      "epoch": 2.806821507436082,
      "grad_norm": 0.5408462285995483,
      "learning_rate": 0.00023694486215538845,
      "loss": 3.2742,
      "step": 105500
    },
    {
      "epoch": 2.820123979035305,
      "grad_norm": 0.4614938199520111,
      "learning_rate": 0.00023569172932330827,
      "loss": 3.2727,
      "step": 106000
    },
    {
      "epoch": 2.833426450634528,
      "grad_norm": 0.4157836437225342,
      "learning_rate": 0.00023443859649122805,
      "loss": 3.2735,
      "step": 106500
    },
    {
      "epoch": 2.8467289222337513,
      "grad_norm": 0.4579694867134094,
      "learning_rate": 0.00023318546365914787,
      "loss": 3.2742,
      "step": 107000
    },
    {
      "epoch": 2.860031393832974,
      "grad_norm": 0.43438151478767395,
      "learning_rate": 0.00023193233082706766,
      "loss": 3.2715,
      "step": 107500
    },
    {
      "epoch": 2.873333865432197,
      "grad_norm": 0.394849956035614,
      "learning_rate": 0.00023067919799498745,
      "loss": 3.2731,
      "step": 108000
    },
    {
      "epoch": 2.873333865432197,
      "eval_loss": 3.1744892597198486,
      "eval_runtime": 27.1633,
      "eval_samples_per_second": 1840.719,
      "eval_steps_per_second": 7.216,
      "step": 108000
    },
    {
      "epoch": 2.8866363370314203,
      "grad_norm": 0.6257174611091614,
      "learning_rate": 0.00022942857142857143,
      "loss": 3.2737,
      "step": 108500
    },
    {
      "epoch": 2.8999388086306435,
      "grad_norm": 0.5187649726867676,
      "learning_rate": 0.00022817543859649124,
      "loss": 3.2695,
      "step": 109000
    },
    {
      "epoch": 2.9132412802298666,
      "grad_norm": 0.4735715687274933,
      "learning_rate": 0.00022692230576441103,
      "loss": 3.2703,
      "step": 109500
    },
    {
      "epoch": 2.9265437518290898,
      "grad_norm": 0.43575164675712585,
      "learning_rate": 0.00022566917293233082,
      "loss": 3.2686,
      "step": 110000
    },
    {
      "epoch": 2.939846223428313,
      "grad_norm": 0.4100079834461212,
      "learning_rate": 0.0002244185463659148,
      "loss": 3.268,
      "step": 110500
    },
    {
      "epoch": 2.953148695027536,
      "grad_norm": 0.4575628340244293,
      "learning_rate": 0.0002231654135338346,
      "loss": 3.2676,
      "step": 111000
    },
    {
      "epoch": 2.9664511666267592,
      "grad_norm": 0.4328841269016266,
      "learning_rate": 0.0002219122807017544,
      "loss": 3.2664,
      "step": 111500
    },
    {
      "epoch": 2.9797536382259824,
      "grad_norm": 0.507824182510376,
      "learning_rate": 0.0002206591478696742,
      "loss": 3.2662,
      "step": 112000
    },
    {
      "epoch": 2.9797536382259824,
      "eval_loss": 3.1629602909088135,
      "eval_runtime": 27.6185,
      "eval_samples_per_second": 1810.379,
      "eval_steps_per_second": 7.097,
      "step": 112000
    },
    {
      "epoch": 2.9930561098252055,
      "grad_norm": 0.4820820093154907,
      "learning_rate": 0.000219406015037594,
      "loss": 3.2649,
      "step": 112500
    },
    {
      "epoch": 3.0063585814244287,
      "grad_norm": 0.45125043392181396,
      "learning_rate": 0.0002181528822055138,
      "loss": 3.2635,
      "step": 113000
    },
    {
      "epoch": 3.019661053023652,
      "grad_norm": 0.5080246329307556,
      "learning_rate": 0.00021689974937343358,
      "loss": 3.2607,
      "step": 113500
    },
    {
      "epoch": 3.032963524622875,
      "grad_norm": 0.39998018741607666,
      "learning_rate": 0.0002156466165413534,
      "loss": 3.2607,
      "step": 114000
    },
    {
      "epoch": 3.046265996222098,
      "grad_norm": 0.4598545730113983,
      "learning_rate": 0.0002143934837092732,
      "loss": 3.2597,
      "step": 114500
    },
    {
      "epoch": 3.0595684678213213,
      "grad_norm": 0.39985328912734985,
      "learning_rate": 0.00021314285714285714,
      "loss": 3.2607,
      "step": 115000
    },
    {
      "epoch": 3.0728709394205445,
      "grad_norm": 0.3773278594017029,
      "learning_rate": 0.00021188972431077693,
      "loss": 3.2591,
      "step": 115500
    },
    {
      "epoch": 3.0861734110197676,
      "grad_norm": 0.38897570967674255,
      "learning_rate": 0.00021063659147869674,
      "loss": 3.261,
      "step": 116000
    },
    {
      "epoch": 3.0861734110197676,
      "eval_loss": 3.1586315631866455,
      "eval_runtime": 27.1486,
      "eval_samples_per_second": 1841.713,
      "eval_steps_per_second": 7.22,
      "step": 116000
    },
    {
      "epoch": 3.0994758826189908,
      "grad_norm": 0.45912811160087585,
      "learning_rate": 0.00020938345864661653,
      "loss": 3.261,
      "step": 116500
    },
    {
      "epoch": 3.112778354218214,
      "grad_norm": 0.4349292814731598,
      "learning_rate": 0.00020813032581453635,
      "loss": 3.2594,
      "step": 117000
    },
    {
      "epoch": 3.126080825817437,
      "grad_norm": 0.3970211446285248,
      "learning_rate": 0.00020687719298245614,
      "loss": 3.2584,
      "step": 117500
    },
    {
      "epoch": 3.1393832974166602,
      "grad_norm": 0.47834038734436035,
      "learning_rate": 0.00020562406015037593,
      "loss": 3.2574,
      "step": 118000
    },
    {
      "epoch": 3.152685769015883,
      "grad_norm": 0.5185514688491821,
      "learning_rate": 0.00020437092731829574,
      "loss": 3.2555,
      "step": 118500
    },
    {
      "epoch": 3.165988240615106,
      "grad_norm": 0.5180524587631226,
      "learning_rate": 0.00020311779448621553,
      "loss": 3.2568,
      "step": 119000
    },
    {
      "epoch": 3.1792907122143292,
      "grad_norm": 0.5638203620910645,
      "learning_rate": 0.00020186466165413532,
      "loss": 3.2553,
      "step": 119500
    },
    {
      "epoch": 3.1925931838135524,
      "grad_norm": 0.5015814900398254,
      "learning_rate": 0.00020061152882205514,
      "loss": 3.2547,
      "step": 120000
    },
    {
      "epoch": 3.1925931838135524,
      "eval_loss": 3.1544787883758545,
      "eval_runtime": 27.1263,
      "eval_samples_per_second": 1843.233,
      "eval_steps_per_second": 7.225,
      "step": 120000
    },
    {
      "epoch": 3.2058956554127755,
      "grad_norm": 0.4181402325630188,
      "learning_rate": 0.00019935839598997493,
      "loss": 3.2542,
      "step": 120500
    },
    {
      "epoch": 3.2191981270119987,
      "grad_norm": 0.5227533578872681,
      "learning_rate": 0.00019810526315789474,
      "loss": 3.2536,
      "step": 121000
    },
    {
      "epoch": 3.232500598611222,
      "grad_norm": 0.43460792303085327,
      "learning_rate": 0.00019685213032581453,
      "loss": 3.254,
      "step": 121500
    },
    {
      "epoch": 3.245803070210445,
      "grad_norm": 0.48146897554397583,
      "learning_rate": 0.00019559899749373432,
      "loss": 3.2554,
      "step": 122000
    },
    {
      "epoch": 3.259105541809668,
      "grad_norm": 0.504737913608551,
      "learning_rate": 0.00019434586466165414,
      "loss": 3.2542,
      "step": 122500
    },
    {
      "epoch": 3.2724080134088913,
      "grad_norm": 0.428771048784256,
      "learning_rate": 0.00019309273182957392,
      "loss": 3.2521,
      "step": 123000
    },
    {
      "epoch": 3.2857104850081145,
      "grad_norm": 0.5187606811523438,
      "learning_rate": 0.00019183959899749374,
      "loss": 3.2526,
      "step": 123500
    },
    {
      "epoch": 3.2990129566073376,
      "grad_norm": 0.46049508452415466,
      "learning_rate": 0.00019059147869674188,
      "loss": 3.252,
      "step": 124000
    },
    {
      "epoch": 3.2990129566073376,
      "eval_loss": 3.1505367755889893,
      "eval_runtime": 27.9978,
      "eval_samples_per_second": 1785.857,
      "eval_steps_per_second": 7.001,
      "step": 124000
    },
    {
      "epoch": 3.3123154282065608,
      "grad_norm": 0.4825071692466736,
      "learning_rate": 0.00018933834586466167,
      "loss": 3.2522,
      "step": 124500
    },
    {
      "epoch": 3.325617899805784,
      "grad_norm": 0.4551273286342621,
      "learning_rate": 0.00018808521303258148,
      "loss": 3.2498,
      "step": 125000
    },
    {
      "epoch": 3.338920371405007,
      "grad_norm": 0.4011402726173401,
      "learning_rate": 0.00018683208020050127,
      "loss": 3.2508,
      "step": 125500
    },
    {
      "epoch": 3.3522228430042302,
      "grad_norm": 0.40147340297698975,
      "learning_rate": 0.00018557894736842106,
      "loss": 3.2499,
      "step": 126000
    },
    {
      "epoch": 3.3655253146034534,
      "grad_norm": 0.4022288918495178,
      "learning_rate": 0.000184328320802005,
      "loss": 3.2475,
      "step": 126500
    },
    {
      "epoch": 3.3788277862026765,
      "grad_norm": 0.3925893306732178,
      "learning_rate": 0.0001830751879699248,
      "loss": 3.2467,
      "step": 127000
    },
    {
      "epoch": 3.3921302578018997,
      "grad_norm": 0.3795579969882965,
      "learning_rate": 0.00018182205513784462,
      "loss": 3.249,
      "step": 127500
    },
    {
      "epoch": 3.405432729401123,
      "grad_norm": 0.392520934343338,
      "learning_rate": 0.0001805689223057644,
      "loss": 3.251,
      "step": 128000
    },
    {
      "epoch": 3.405432729401123,
      "eval_loss": 3.145681619644165,
      "eval_runtime": 27.3282,
      "eval_samples_per_second": 1829.613,
      "eval_steps_per_second": 7.172,
      "step": 128000
    },
    {
      "epoch": 3.418735201000346,
      "grad_norm": 0.41625142097473145,
      "learning_rate": 0.00017931578947368422,
      "loss": 3.247,
      "step": 128500
    },
    {
      "epoch": 3.432037672599569,
      "grad_norm": 0.37713301181793213,
      "learning_rate": 0.000178062656641604,
      "loss": 3.2469,
      "step": 129000
    },
    {
      "epoch": 3.4453401441987923,
      "grad_norm": 0.47815096378326416,
      "learning_rate": 0.000176812030075188,
      "loss": 3.2461,
      "step": 129500
    },
    {
      "epoch": 3.4586426157980155,
      "grad_norm": 0.46166184544563293,
      "learning_rate": 0.00017555889724310778,
      "loss": 3.2462,
      "step": 130000
    },
    {
      "epoch": 3.4719450873972386,
      "grad_norm": 0.4913821816444397,
      "learning_rate": 0.0001743057644110276,
      "loss": 3.2464,
      "step": 130500
    },
    {
      "epoch": 3.4852475589964618,
      "grad_norm": 0.4470365047454834,
      "learning_rate": 0.00017305263157894738,
      "loss": 3.2447,
      "step": 131000
    },
    {
      "epoch": 3.498550030595685,
      "grad_norm": 0.4462797939777374,
      "learning_rate": 0.00017179949874686717,
      "loss": 3.2455,
      "step": 131500
    },
    {
      "epoch": 3.511852502194908,
      "grad_norm": 0.5959962010383606,
      "learning_rate": 0.00017054636591478699,
      "loss": 3.2449,
      "step": 132000
    },
    {
      "epoch": 3.511852502194908,
      "eval_loss": 3.1433331966400146,
      "eval_runtime": 27.1397,
      "eval_samples_per_second": 1842.317,
      "eval_steps_per_second": 7.222,
      "step": 132000
    },
    {
      "epoch": 3.525154973794131,
      "grad_norm": 0.378966361284256,
      "learning_rate": 0.0001692957393483709,
      "loss": 3.2412,
      "step": 132500
    },
    {
      "epoch": 3.538457445393354,
      "grad_norm": 0.584739625453949,
      "learning_rate": 0.00016804260651629072,
      "loss": 3.2438,
      "step": 133000
    },
    {
      "epoch": 3.551759916992577,
      "grad_norm": 0.41701316833496094,
      "learning_rate": 0.0001667894736842105,
      "loss": 3.2425,
      "step": 133500
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.40733230113983154,
      "learning_rate": 0.00016553634085213033,
      "loss": 3.2446,
      "step": 134000
    },
    {
      "epoch": 3.5783648601910234,
      "grad_norm": 0.4318430721759796,
      "learning_rate": 0.00016428320802005012,
      "loss": 3.2438,
      "step": 134500
    },
    {
      "epoch": 3.5916673317902466,
      "grad_norm": 0.591431200504303,
      "learning_rate": 0.0001630300751879699,
      "loss": 3.2401,
      "step": 135000
    },
    {
      "epoch": 3.6049698033894697,
      "grad_norm": 0.37140408158302307,
      "learning_rate": 0.00016177694235588972,
      "loss": 3.2416,
      "step": 135500
    },
    {
      "epoch": 3.618272274988693,
      "grad_norm": 0.3778288960456848,
      "learning_rate": 0.0001605238095238095,
      "loss": 3.2412,
      "step": 136000
    },
    {
      "epoch": 3.618272274988693,
      "eval_loss": 3.1379096508026123,
      "eval_runtime": 27.1876,
      "eval_samples_per_second": 1839.075,
      "eval_steps_per_second": 7.209,
      "step": 136000
    },
    {
      "epoch": 3.631574746587916,
      "grad_norm": 0.44359901547431946,
      "learning_rate": 0.00015927067669172933,
      "loss": 3.2401,
      "step": 136500
    },
    {
      "epoch": 3.644877218187139,
      "grad_norm": 0.34987717866897583,
      "learning_rate": 0.00015802005012531328,
      "loss": 3.2397,
      "step": 137000
    },
    {
      "epoch": 3.6581796897863623,
      "grad_norm": 0.34184521436691284,
      "learning_rate": 0.00015676942355889725,
      "loss": 3.2396,
      "step": 137500
    },
    {
      "epoch": 3.6714821613855855,
      "grad_norm": 0.38604289293289185,
      "learning_rate": 0.00015551629072681704,
      "loss": 3.2387,
      "step": 138000
    },
    {
      "epoch": 3.6847846329848086,
      "grad_norm": 0.6059139966964722,
      "learning_rate": 0.000154265664160401,
      "loss": 3.2387,
      "step": 138500
    },
    {
      "epoch": 3.698087104584032,
      "grad_norm": 0.4484976828098297,
      "learning_rate": 0.00015301503759398497,
      "loss": 3.2378,
      "step": 139000
    },
    {
      "epoch": 3.711389576183255,
      "grad_norm": 0.40182533860206604,
      "learning_rate": 0.00015176190476190476,
      "loss": 3.2372,
      "step": 139500
    },
    {
      "epoch": 3.724692047782478,
      "grad_norm": 0.4901478886604309,
      "learning_rate": 0.00015050877192982458,
      "loss": 3.2362,
      "step": 140000
    },
    {
      "epoch": 3.724692047782478,
      "eval_loss": 3.1349775791168213,
      "eval_runtime": 27.5703,
      "eval_samples_per_second": 1813.545,
      "eval_steps_per_second": 7.109,
      "step": 140000
    },
    {
      "epoch": 3.7379945193817012,
      "grad_norm": 0.37324297428131104,
      "learning_rate": 0.00014925563909774436,
      "loss": 3.2373,
      "step": 140500
    },
    {
      "epoch": 3.7512969909809244,
      "grad_norm": 0.4539564847946167,
      "learning_rate": 0.00014800250626566415,
      "loss": 3.2371,
      "step": 141000
    },
    {
      "epoch": 3.7645994625801475,
      "grad_norm": 0.40002650022506714,
      "learning_rate": 0.0001467543859649123,
      "loss": 3.2424,
      "step": 141500
    },
    {
      "epoch": 3.7779019341793703,
      "grad_norm": 0.4375636577606201,
      "learning_rate": 0.00014550125313283208,
      "loss": 3.2366,
      "step": 142000
    },
    {
      "epoch": 3.7912044057785934,
      "grad_norm": 0.3486834466457367,
      "learning_rate": 0.00014425062656641606,
      "loss": 3.2348,
      "step": 142500
    },
    {
      "epoch": 3.8045068773778166,
      "grad_norm": 0.4147860109806061,
      "learning_rate": 0.00014299749373433585,
      "loss": 3.2339,
      "step": 143000
    },
    {
      "epoch": 3.8178093489770397,
      "grad_norm": 0.46270111203193665,
      "learning_rate": 0.00014174436090225563,
      "loss": 3.2424,
      "step": 143500
    },
    {
      "epoch": 3.831111820576263,
      "grad_norm": 0.35574403405189514,
      "learning_rate": 0.00014049122807017545,
      "loss": 3.2351,
      "step": 144000
    },
    {
      "epoch": 3.831111820576263,
      "eval_loss": 3.131566286087036,
      "eval_runtime": 27.1301,
      "eval_samples_per_second": 1842.973,
      "eval_steps_per_second": 7.224,
      "step": 144000
    },
    {
      "epoch": 3.844414292175486,
      "grad_norm": 0.4074110984802246,
      "learning_rate": 0.00013923809523809524,
      "loss": 3.2353,
      "step": 144500
    },
    {
      "epoch": 3.857716763774709,
      "grad_norm": 0.34621289372444153,
      "learning_rate": 0.00013798496240601506,
      "loss": 3.2313,
      "step": 145000
    },
    {
      "epoch": 3.8710192353739323,
      "grad_norm": 0.4810634255409241,
      "learning_rate": 0.00013673182957393484,
      "loss": 3.2331,
      "step": 145500
    },
    {
      "epoch": 3.8843217069731555,
      "grad_norm": 0.36471498012542725,
      "learning_rate": 0.00013547869674185463,
      "loss": 3.232,
      "step": 146000
    },
    {
      "epoch": 3.8976241785723786,
      "grad_norm": 0.4709288477897644,
      "learning_rate": 0.00013422556390977445,
      "loss": 3.2311,
      "step": 146500
    },
    {
      "epoch": 3.910926650171602,
      "grad_norm": 0.5525557398796082,
      "learning_rate": 0.00013297243107769424,
      "loss": 3.2321,
      "step": 147000
    },
    {
      "epoch": 3.924229121770825,
      "grad_norm": 0.32841944694519043,
      "learning_rate": 0.00013171929824561405,
      "loss": 3.2308,
      "step": 147500
    },
    {
      "epoch": 3.937531593370048,
      "grad_norm": 0.38491496443748474,
      "learning_rate": 0.00013046616541353384,
      "loss": 3.2293,
      "step": 148000
    },
    {
      "epoch": 3.937531593370048,
      "eval_loss": 3.1280713081359863,
      "eval_runtime": 27.1316,
      "eval_samples_per_second": 1842.868,
      "eval_steps_per_second": 7.224,
      "step": 148000
    },
    {
      "epoch": 3.9508340649692713,
      "grad_norm": 0.429764986038208,
      "learning_rate": 0.00012921303258145363,
      "loss": 3.2286,
      "step": 148500
    },
    {
      "epoch": 3.9641365365684944,
      "grad_norm": 0.3834453225135803,
      "learning_rate": 0.00012795989974937345,
      "loss": 3.2317,
      "step": 149000
    },
    {
      "epoch": 3.9774390081677176,
      "grad_norm": 0.3826310932636261,
      "learning_rate": 0.00012670676691729324,
      "loss": 3.2291,
      "step": 149500
    },
    {
      "epoch": 3.9907414797669407,
      "grad_norm": 0.4409639835357666,
      "learning_rate": 0.00012545363408521305,
      "loss": 3.2283,
      "step": 150000
    },
    {
      "epoch": 4.004043951366164,
      "grad_norm": 0.4133812487125397,
      "learning_rate": 0.00012420050125313284,
      "loss": 3.226,
      "step": 150500
    },
    {
      "epoch": 4.017346422965387,
      "grad_norm": 0.33227822184562683,
      "learning_rate": 0.00012294736842105263,
      "loss": 3.2243,
      "step": 151000
    },
    {
      "epoch": 4.03064889456461,
      "grad_norm": 0.43526461720466614,
      "learning_rate": 0.00012169423558897242,
      "loss": 3.2237,
      "step": 151500
    },
    {
      "epoch": 4.043951366163833,
      "grad_norm": 0.43446773290634155,
      "learning_rate": 0.00012044110275689222,
      "loss": 3.2242,
      "step": 152000
    },
    {
      "epoch": 4.043951366163833,
      "eval_loss": 3.1253814697265625,
      "eval_runtime": 27.1229,
      "eval_samples_per_second": 1843.458,
      "eval_steps_per_second": 7.226,
      "step": 152000
    },
    {
      "epoch": 4.0572538377630565,
      "grad_norm": 0.4444161057472229,
      "learning_rate": 0.00011918796992481203,
      "loss": 3.2248,
      "step": 152500
    },
    {
      "epoch": 4.07055630936228,
      "grad_norm": 0.43414145708084106,
      "learning_rate": 0.00011793483709273183,
      "loss": 3.2233,
      "step": 153000
    },
    {
      "epoch": 4.083858780961503,
      "grad_norm": 0.3258025646209717,
      "learning_rate": 0.00011668170426065163,
      "loss": 3.223,
      "step": 153500
    },
    {
      "epoch": 4.097161252560726,
      "grad_norm": 0.5506508946418762,
      "learning_rate": 0.00011542857142857142,
      "loss": 3.2251,
      "step": 154000
    },
    {
      "epoch": 4.110463724159949,
      "grad_norm": 0.4262111485004425,
      "learning_rate": 0.00011417543859649122,
      "loss": 3.2243,
      "step": 154500
    },
    {
      "epoch": 4.123766195759172,
      "grad_norm": 0.4131987988948822,
      "learning_rate": 0.00011292230576441102,
      "loss": 3.224,
      "step": 155000
    },
    {
      "epoch": 4.137068667358395,
      "grad_norm": 0.4600571095943451,
      "learning_rate": 0.00011167418546365915,
      "loss": 3.2265,
      "step": 155500
    },
    {
      "epoch": 4.1503711389576186,
      "grad_norm": 0.43095651268959045,
      "learning_rate": 0.00011042105263157895,
      "loss": 3.2199,
      "step": 156000
    },
    {
      "epoch": 4.1503711389576186,
      "eval_loss": 3.1221225261688232,
      "eval_runtime": 27.1382,
      "eval_samples_per_second": 1842.42,
      "eval_steps_per_second": 7.222,
      "step": 156000
    },
    {
      "epoch": 4.163673610556842,
      "grad_norm": 0.4623009264469147,
      "learning_rate": 0.0001091704260651629,
      "loss": 3.2302,
      "step": 156500
    },
    {
      "epoch": 4.176976082156065,
      "grad_norm": 0.42513611912727356,
      "learning_rate": 0.0001079172932330827,
      "loss": 3.2208,
      "step": 157000
    },
    {
      "epoch": 4.190278553755288,
      "grad_norm": 0.4146079421043396,
      "learning_rate": 0.0001066641604010025,
      "loss": 3.2208,
      "step": 157500
    },
    {
      "epoch": 4.203581025354511,
      "grad_norm": 0.4210008382797241,
      "learning_rate": 0.00010541102756892231,
      "loss": 3.2222,
      "step": 158000
    },
    {
      "epoch": 4.216883496953734,
      "grad_norm": 0.45566433668136597,
      "learning_rate": 0.00010415789473684211,
      "loss": 3.2192,
      "step": 158500
    },
    {
      "epoch": 4.2301859685529575,
      "grad_norm": 0.4675600826740265,
      "learning_rate": 0.00010290726817042606,
      "loss": 3.2203,
      "step": 159000
    },
    {
      "epoch": 4.243488440152181,
      "grad_norm": 0.34709200263023376,
      "learning_rate": 0.00010165413533834586,
      "loss": 3.2197,
      "step": 159500
    },
    {
      "epoch": 4.256790911751404,
      "grad_norm": 0.35094940662384033,
      "learning_rate": 0.00010040100250626567,
      "loss": 3.2203,
      "step": 160000
    },
    {
      "epoch": 4.256790911751404,
      "eval_loss": 3.1187069416046143,
      "eval_runtime": 27.5825,
      "eval_samples_per_second": 1812.743,
      "eval_steps_per_second": 7.106,
      "step": 160000
    },
    {
      "epoch": 4.270093383350627,
      "grad_norm": 0.39697521924972534,
      "learning_rate": 9.914786967418545e-05,
      "loss": 3.2192,
      "step": 160500
    },
    {
      "epoch": 4.28339585494985,
      "grad_norm": 0.4224788546562195,
      "learning_rate": 9.789473684210526e-05,
      "loss": 3.2186,
      "step": 161000
    },
    {
      "epoch": 4.296698326549073,
      "grad_norm": 0.31755638122558594,
      "learning_rate": 9.664411027568923e-05,
      "loss": 3.2188,
      "step": 161500
    },
    {
      "epoch": 4.310000798148296,
      "grad_norm": 0.4394413232803345,
      "learning_rate": 9.539097744360902e-05,
      "loss": 3.2183,
      "step": 162000
    },
    {
      "epoch": 4.3233032697475196,
      "grad_norm": 0.3505682051181793,
      "learning_rate": 9.413784461152883e-05,
      "loss": 3.2183,
      "step": 162500
    },
    {
      "epoch": 4.336605741346742,
      "grad_norm": 0.34492701292037964,
      "learning_rate": 9.288471177944863e-05,
      "loss": 3.2186,
      "step": 163000
    },
    {
      "epoch": 4.349908212945965,
      "grad_norm": 0.3565775454044342,
      "learning_rate": 9.163157894736843e-05,
      "loss": 3.2192,
      "step": 163500
    },
    {
      "epoch": 4.363210684545188,
      "grad_norm": 0.46883267164230347,
      "learning_rate": 9.037844611528823e-05,
      "loss": 3.2166,
      "step": 164000
    },
    {
      "epoch": 4.363210684545188,
      "eval_loss": 3.11631178855896,
      "eval_runtime": 27.1658,
      "eval_samples_per_second": 1840.548,
      "eval_steps_per_second": 7.215,
      "step": 164000
    },
    {
      "epoch": 4.376513156144411,
      "grad_norm": 0.44639116525650024,
      "learning_rate": 8.912531328320802e-05,
      "loss": 3.2157,
      "step": 164500
    },
    {
      "epoch": 4.389815627743634,
      "grad_norm": 0.32703572511672974,
      "learning_rate": 8.787468671679198e-05,
      "loss": 3.2166,
      "step": 165000
    },
    {
      "epoch": 4.403118099342858,
      "grad_norm": 0.3402850031852722,
      "learning_rate": 8.662155388471179e-05,
      "loss": 3.2163,
      "step": 165500
    },
    {
      "epoch": 4.416420570942081,
      "grad_norm": 0.3589324951171875,
      "learning_rate": 8.536842105263158e-05,
      "loss": 3.2163,
      "step": 166000
    },
    {
      "epoch": 4.429723042541304,
      "grad_norm": 0.30613166093826294,
      "learning_rate": 8.411528822055138e-05,
      "loss": 3.2157,
      "step": 166500
    },
    {
      "epoch": 4.443025514140527,
      "grad_norm": 0.33605363965034485,
      "learning_rate": 8.286215538847118e-05,
      "loss": 3.2159,
      "step": 167000
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.33522340655326843,
      "learning_rate": 8.160902255639098e-05,
      "loss": 3.2126,
      "step": 167500
    },
    {
      "epoch": 4.469630457338973,
      "grad_norm": 0.37431812286376953,
      "learning_rate": 8.035588972431079e-05,
      "loss": 3.2145,
      "step": 168000
    },
    {
      "epoch": 4.469630457338973,
      "eval_loss": 3.1132562160491943,
      "eval_runtime": 27.592,
      "eval_samples_per_second": 1812.12,
      "eval_steps_per_second": 7.104,
      "step": 168000
    },
    {
      "epoch": 4.4829329289381965,
      "grad_norm": 0.4261336922645569,
      "learning_rate": 7.910275689223058e-05,
      "loss": 3.2129,
      "step": 168500
    },
    {
      "epoch": 4.49623540053742,
      "grad_norm": 0.413906455039978,
      "learning_rate": 7.784962406015038e-05,
      "loss": 3.2144,
      "step": 169000
    },
    {
      "epoch": 4.509537872136643,
      "grad_norm": 0.35231488943099976,
      "learning_rate": 7.659899749373434e-05,
      "loss": 3.2143,
      "step": 169500
    },
    {
      "epoch": 4.522840343735866,
      "grad_norm": 0.3179995119571686,
      "learning_rate": 7.534586466165413e-05,
      "loss": 3.2132,
      "step": 170000
    },
    {
      "epoch": 4.536142815335089,
      "grad_norm": 0.3546539545059204,
      "learning_rate": 7.409273182957393e-05,
      "loss": 3.2129,
      "step": 170500
    },
    {
      "epoch": 4.549445286934312,
      "grad_norm": 0.45516782999038696,
      "learning_rate": 7.28421052631579e-05,
      "loss": 3.2129,
      "step": 171000
    },
    {
      "epoch": 4.562747758533535,
      "grad_norm": 0.34697043895721436,
      "learning_rate": 7.158897243107768e-05,
      "loss": 3.211,
      "step": 171500
    },
    {
      "epoch": 4.576050230132759,
      "grad_norm": 0.31378787755966187,
      "learning_rate": 7.033583959899749e-05,
      "loss": 3.2126,
      "step": 172000
    },
    {
      "epoch": 4.576050230132759,
      "eval_loss": 3.1104891300201416,
      "eval_runtime": 27.1005,
      "eval_samples_per_second": 1844.984,
      "eval_steps_per_second": 7.232,
      "step": 172000
    },
    {
      "epoch": 4.589352701731982,
      "grad_norm": 0.3922683298587799,
      "learning_rate": 6.908270676691729e-05,
      "loss": 3.2131,
      "step": 172500
    },
    {
      "epoch": 4.602655173331205,
      "grad_norm": 0.34696346521377563,
      "learning_rate": 6.782957393483709e-05,
      "loss": 3.2094,
      "step": 173000
    },
    {
      "epoch": 4.615957644930428,
      "grad_norm": 0.3154340386390686,
      "learning_rate": 6.65764411027569e-05,
      "loss": 3.2108,
      "step": 173500
    },
    {
      "epoch": 4.629260116529651,
      "grad_norm": 0.37236252427101135,
      "learning_rate": 6.532330827067668e-05,
      "loss": 3.2092,
      "step": 174000
    },
    {
      "epoch": 4.642562588128874,
      "grad_norm": 0.43917208909988403,
      "learning_rate": 6.407268170426066e-05,
      "loss": 3.2132,
      "step": 174500
    },
    {
      "epoch": 4.6558650597280975,
      "grad_norm": 0.3819872736930847,
      "learning_rate": 6.282205513784461e-05,
      "loss": 3.21,
      "step": 175000
    },
    {
      "epoch": 4.669167531327321,
      "grad_norm": 0.36325958371162415,
      "learning_rate": 6.156892230576441e-05,
      "loss": 3.209,
      "step": 175500
    },
    {
      "epoch": 4.682470002926544,
      "grad_norm": 0.3765188157558441,
      "learning_rate": 6.0315789473684215e-05,
      "loss": 3.2105,
      "step": 176000
    },
    {
      "epoch": 4.682470002926544,
      "eval_loss": 3.108011245727539,
      "eval_runtime": 27.1756,
      "eval_samples_per_second": 1839.883,
      "eval_steps_per_second": 7.212,
      "step": 176000
    },
    {
      "epoch": 4.695772474525767,
      "grad_norm": 0.38570329546928406,
      "learning_rate": 5.906265664160401e-05,
      "loss": 3.2101,
      "step": 176500
    },
    {
      "epoch": 4.70907494612499,
      "grad_norm": 0.3072173297405243,
      "learning_rate": 5.780952380952381e-05,
      "loss": 3.2089,
      "step": 177000
    },
    {
      "epoch": 4.722377417724213,
      "grad_norm": 0.31837838888168335,
      "learning_rate": 5.655639097744361e-05,
      "loss": 3.2077,
      "step": 177500
    },
    {
      "epoch": 4.735679889323436,
      "grad_norm": 0.4747929275035858,
      "learning_rate": 5.530325814536341e-05,
      "loss": 3.2067,
      "step": 178000
    },
    {
      "epoch": 4.74898236092266,
      "grad_norm": 0.4266558885574341,
      "learning_rate": 5.405012531328321e-05,
      "loss": 3.2047,
      "step": 178500
    },
    {
      "epoch": 4.762284832521883,
      "grad_norm": 0.36798930168151855,
      "learning_rate": 5.279699248120301e-05,
      "loss": 3.2069,
      "step": 179000
    },
    {
      "epoch": 4.775587304121106,
      "grad_norm": 0.45573440194129944,
      "learning_rate": 5.154385964912281e-05,
      "loss": 3.2067,
      "step": 179500
    },
    {
      "epoch": 4.788889775720329,
      "grad_norm": 0.40253037214279175,
      "learning_rate": 5.029072681704261e-05,
      "loss": 3.2073,
      "step": 180000
    },
    {
      "epoch": 4.788889775720329,
      "eval_loss": 3.1057772636413574,
      "eval_runtime": 27.1786,
      "eval_samples_per_second": 1839.681,
      "eval_steps_per_second": 7.212,
      "step": 180000
    },
    {
      "epoch": 4.802192247319552,
      "grad_norm": 0.41078007221221924,
      "learning_rate": 4.903759398496241e-05,
      "loss": 3.2065,
      "step": 180500
    },
    {
      "epoch": 4.815494718918775,
      "grad_norm": 0.3486778140068054,
      "learning_rate": 4.778947368421053e-05,
      "loss": 3.208,
      "step": 181000
    },
    {
      "epoch": 4.8287971905179985,
      "grad_norm": 0.35594621300697327,
      "learning_rate": 4.6538847117794484e-05,
      "loss": 3.2074,
      "step": 181500
    },
    {
      "epoch": 4.842099662117222,
      "grad_norm": 0.3107937276363373,
      "learning_rate": 4.528571428571429e-05,
      "loss": 3.2062,
      "step": 182000
    },
    {
      "epoch": 4.855402133716445,
      "grad_norm": 0.4046947956085205,
      "learning_rate": 4.403508771929825e-05,
      "loss": 3.208,
      "step": 182500
    },
    {
      "epoch": 4.868704605315668,
      "grad_norm": 0.322572261095047,
      "learning_rate": 4.2781954887218046e-05,
      "loss": 3.2053,
      "step": 183000
    },
    {
      "epoch": 4.882007076914891,
      "grad_norm": 0.317634254693985,
      "learning_rate": 4.152882205513785e-05,
      "loss": 3.2069,
      "step": 183500
    },
    {
      "epoch": 4.895309548514114,
      "grad_norm": 0.3808601498603821,
      "learning_rate": 4.0275689223057644e-05,
      "loss": 3.2048,
      "step": 184000
    },
    {
      "epoch": 4.895309548514114,
      "eval_loss": 3.1033475399017334,
      "eval_runtime": 27.2408,
      "eval_samples_per_second": 1835.484,
      "eval_steps_per_second": 7.195,
      "step": 184000
    },
    {
      "epoch": 4.908612020113337,
      "grad_norm": 0.4422445595264435,
      "learning_rate": 3.9022556390977447e-05,
      "loss": 3.2054,
      "step": 184500
    },
    {
      "epoch": 4.921914491712561,
      "grad_norm": 0.3883807063102722,
      "learning_rate": 3.776942355889724e-05,
      "loss": 3.2048,
      "step": 185000
    },
    {
      "epoch": 4.935216963311783,
      "grad_norm": 0.38038763403892517,
      "learning_rate": 3.6516290726817045e-05,
      "loss": 3.2032,
      "step": 185500
    },
    {
      "epoch": 4.948519434911006,
      "grad_norm": 0.3312079906463623,
      "learning_rate": 3.526315789473685e-05,
      "loss": 3.2052,
      "step": 186000
    },
    {
      "epoch": 4.961821906510229,
      "grad_norm": 0.4302058815956116,
      "learning_rate": 3.401002506265664e-05,
      "loss": 3.2039,
      "step": 186500
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.3535769581794739,
      "learning_rate": 3.2756892230576445e-05,
      "loss": 3.2041,
      "step": 187000
    },
    {
      "epoch": 4.9884268497086754,
      "grad_norm": 0.32106703519821167,
      "learning_rate": 3.150375939849624e-05,
      "loss": 3.2026,
      "step": 187500
    },
    {
      "epoch": 5.001729321307899,
      "grad_norm": 0.3086095452308655,
      "learning_rate": 3.0250626566416044e-05,
      "loss": 3.2037,
      "step": 188000
    },
    {
      "epoch": 5.001729321307899,
      "eval_loss": 3.101155996322632,
      "eval_runtime": 27.1387,
      "eval_samples_per_second": 1842.385,
      "eval_steps_per_second": 7.222,
      "step": 188000
    },
    {
      "epoch": 5.015031792907122,
      "grad_norm": 0.31678327918052673,
      "learning_rate": 2.8997493734335843e-05,
      "loss": 3.1998,
      "step": 188500
    },
    {
      "epoch": 5.028334264506345,
      "grad_norm": 0.3371265232563019,
      "learning_rate": 2.774436090225564e-05,
      "loss": 3.1991,
      "step": 189000
    },
    {
      "epoch": 5.041636736105568,
      "grad_norm": 0.3609102666378021,
      "learning_rate": 2.6491228070175438e-05,
      "loss": 3.199,
      "step": 189500
    },
    {
      "epoch": 5.054939207704791,
      "grad_norm": 0.3912805914878845,
      "learning_rate": 2.52406015037594e-05,
      "loss": 3.2016,
      "step": 190000
    },
    {
      "epoch": 5.068241679304014,
      "grad_norm": 0.3151344060897827,
      "learning_rate": 2.3987468671679197e-05,
      "loss": 3.1991,
      "step": 190500
    },
    {
      "epoch": 5.0815441509032375,
      "grad_norm": 0.4069143831729889,
      "learning_rate": 2.2734335839598996e-05,
      "loss": 3.1987,
      "step": 191000
    },
    {
      "epoch": 5.094846622502461,
      "grad_norm": 0.35487642884254456,
      "learning_rate": 2.1481203007518795e-05,
      "loss": 3.1975,
      "step": 191500
    },
    {
      "epoch": 5.108149094101684,
      "grad_norm": 0.34860044717788696,
      "learning_rate": 2.0228070175438594e-05,
      "loss": 3.1976,
      "step": 192000
    },
    {
      "epoch": 5.108149094101684,
      "eval_loss": 3.09965181350708,
      "eval_runtime": 27.1477,
      "eval_samples_per_second": 1841.78,
      "eval_steps_per_second": 7.22,
      "step": 192000
    },
    {
      "epoch": 5.121451565700907,
      "grad_norm": 0.30724889039993286,
      "learning_rate": 1.8974937343358396e-05,
      "loss": 3.1983,
      "step": 192500
    },
    {
      "epoch": 5.13475403730013,
      "grad_norm": 0.3529643416404724,
      "learning_rate": 1.7721804511278196e-05,
      "loss": 3.2007,
      "step": 193000
    },
    {
      "epoch": 5.148056508899353,
      "grad_norm": 0.3843773305416107,
      "learning_rate": 1.6468671679197995e-05,
      "loss": 3.197,
      "step": 193500
    },
    {
      "epoch": 5.161358980498576,
      "grad_norm": 0.31653454899787903,
      "learning_rate": 1.5218045112781956e-05,
      "loss": 3.1993,
      "step": 194000
    },
    {
      "epoch": 5.1746614520978,
      "grad_norm": 0.29352712631225586,
      "learning_rate": 1.3967418546365914e-05,
      "loss": 3.2076,
      "step": 194500
    },
    {
      "epoch": 5.187963923697023,
      "grad_norm": 0.3236948847770691,
      "learning_rate": 1.2714285714285715e-05,
      "loss": 3.1957,
      "step": 195000
    },
    {
      "epoch": 5.201266395296246,
      "grad_norm": 0.33547693490982056,
      "learning_rate": 1.1461152882205514e-05,
      "loss": 3.1985,
      "step": 195500
    },
    {
      "epoch": 5.214568866895469,
      "grad_norm": 0.3218807578086853,
      "learning_rate": 1.0208020050125313e-05,
      "loss": 3.1963,
      "step": 196000
    },
    {
      "epoch": 5.214568866895469,
      "eval_loss": 3.097806930541992,
      "eval_runtime": 27.1468,
      "eval_samples_per_second": 1841.837,
      "eval_steps_per_second": 7.22,
      "step": 196000
    },
    {
      "epoch": 5.227871338494692,
      "grad_norm": 0.3274977505207062,
      "learning_rate": 8.954887218045113e-06,
      "loss": 3.1966,
      "step": 196500
    },
    {
      "epoch": 5.241173810093915,
      "grad_norm": 0.29856619238853455,
      "learning_rate": 7.701754385964913e-06,
      "loss": 3.1981,
      "step": 197000
    },
    {
      "epoch": 5.2544762816931385,
      "grad_norm": 0.3004787862300873,
      "learning_rate": 6.448621553884712e-06,
      "loss": 3.1961,
      "step": 197500
    },
    {
      "epoch": 5.267778753292362,
      "grad_norm": 0.3132115602493286,
      "learning_rate": 5.195488721804511e-06,
      "loss": 3.1965,
      "step": 198000
    },
    {
      "epoch": 5.281081224891585,
      "grad_norm": 0.3155243694782257,
      "learning_rate": 3.942355889724311e-06,
      "loss": 3.1978,
      "step": 198500
    },
    {
      "epoch": 5.294383696490808,
      "grad_norm": 0.30173754692077637,
      "learning_rate": 2.6892230576441102e-06,
      "loss": 3.1966,
      "step": 199000
    },
    {
      "epoch": 5.307686168090031,
      "grad_norm": 0.3556678891181946,
      "learning_rate": 1.4385964912280704e-06,
      "loss": 3.2019,
      "step": 199500
    },
    {
      "epoch": 5.320988639689254,
      "grad_norm": 0.2932811379432678,
      "learning_rate": 1.8546365914786967e-07,
      "loss": 3.1964,
      "step": 200000
    },
    {
      "epoch": 5.320988639689254,
      "eval_loss": 3.096881151199341,
      "eval_runtime": 27.1187,
      "eval_samples_per_second": 1843.748,
      "eval_steps_per_second": 7.227,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
