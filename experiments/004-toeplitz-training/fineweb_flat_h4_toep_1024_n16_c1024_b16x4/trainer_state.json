{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.3302648557327763,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003325662139331941,
      "grad_norm": 18.08835792541504,
      "learning_rate": 0.000495,
      "loss": 17.0522,
      "step": 500
    },
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 2.7506420612335205,
      "learning_rate": 0.0004987593984962407,
      "loss": 6.6283,
      "step": 1000
    },
    {
      "epoch": 0.009976986417995822,
      "grad_norm": 2.129786729812622,
      "learning_rate": 0.0004975062656641604,
      "loss": 5.4724,
      "step": 1500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 1.9486875534057617,
      "learning_rate": 0.0004962531328320802,
      "loss": 5.0584,
      "step": 2000
    },
    {
      "epoch": 0.016628310696659706,
      "grad_norm": 1.2977862358093262,
      "learning_rate": 0.000495,
      "loss": 4.7634,
      "step": 2500
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 1.451637864112854,
      "learning_rate": 0.0004937468671679198,
      "loss": 4.5231,
      "step": 3000
    },
    {
      "epoch": 0.023279634975323586,
      "grad_norm": 1.1155755519866943,
      "learning_rate": 0.0004924937343358396,
      "loss": 4.3344,
      "step": 3500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 1.0200659036636353,
      "learning_rate": 0.0004912406015037594,
      "loss": 4.1875,
      "step": 4000
    },
    {
      "epoch": 0.026605297114655528,
      "eval_loss": 4.128506183624268,
      "eval_runtime": 135.4013,
      "eval_samples_per_second": 369.273,
      "eval_steps_per_second": 5.775,
      "step": 4000
    },
    {
      "epoch": 0.02993095925398747,
      "grad_norm": 0.8132773041725159,
      "learning_rate": 0.0004899874686716792,
      "loss": 4.0813,
      "step": 4500
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.8180035948753357,
      "learning_rate": 0.0004887343358395991,
      "loss": 3.992,
      "step": 5000
    },
    {
      "epoch": 0.036582283532651354,
      "grad_norm": 0.9729020595550537,
      "learning_rate": 0.0004874812030075188,
      "loss": 3.9233,
      "step": 5500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.8523889780044556,
      "learning_rate": 0.00048622807017543866,
      "loss": 3.8674,
      "step": 6000
    },
    {
      "epoch": 0.04323360781131523,
      "grad_norm": 0.740610659122467,
      "learning_rate": 0.00048497994987468674,
      "loss": 3.8216,
      "step": 6500
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 1.035994291305542,
      "learning_rate": 0.0004837268170426065,
      "loss": 3.7815,
      "step": 7000
    },
    {
      "epoch": 0.049884932089979114,
      "grad_norm": 0.8973346948623657,
      "learning_rate": 0.0004824736842105263,
      "loss": 3.7544,
      "step": 7500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.8888710141181946,
      "learning_rate": 0.00048122055137844613,
      "loss": 3.7216,
      "step": 8000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.70975399017334,
      "eval_runtime": 135.4045,
      "eval_samples_per_second": 369.264,
      "eval_steps_per_second": 5.775,
      "step": 8000
    },
    {
      "epoch": 0.056536256368643,
      "grad_norm": 0.6682837009429932,
      "learning_rate": 0.00047996741854636595,
      "loss": 3.6979,
      "step": 8500
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.6481870412826538,
      "learning_rate": 0.0004787142857142857,
      "loss": 3.6688,
      "step": 9000
    },
    {
      "epoch": 0.06318758064730688,
      "grad_norm": 1.2349473237991333,
      "learning_rate": 0.0004774761904761905,
      "loss": 3.7174,
      "step": 9500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 3.2395286560058594,
      "learning_rate": 0.0004762330827067669,
      "loss": 4.8658,
      "step": 10000
    },
    {
      "epoch": 0.06983890492597077,
      "grad_norm": 28.703466415405273,
      "learning_rate": 0.0004749799498746867,
      "loss": 4.2892,
      "step": 10500
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 42.49644088745117,
      "learning_rate": 0.00047372681704260653,
      "loss": 4.9038,
      "step": 11000
    },
    {
      "epoch": 0.07649022920463465,
      "grad_norm": 77.38860321044922,
      "learning_rate": 0.00047247368421052634,
      "loss": 5.4858,
      "step": 11500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 60.2841682434082,
      "learning_rate": 0.0004712205513784461,
      "loss": 4.5343,
      "step": 12000
    },
    {
      "epoch": 0.07981589134396658,
      "eval_loss": 4.729492664337158,
      "eval_runtime": 135.5839,
      "eval_samples_per_second": 368.775,
      "eval_steps_per_second": 5.768,
      "step": 12000
    },
    {
      "epoch": 0.08314155348329852,
      "grad_norm": 123.45989990234375,
      "learning_rate": 0.0004699674185463659,
      "loss": 4.6129,
      "step": 12500
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 58.6734619140625,
      "learning_rate": 0.0004687142857142857,
      "loss": 4.7508,
      "step": 13000
    },
    {
      "epoch": 0.0897928777619624,
      "grad_norm": 55.22932434082031,
      "learning_rate": 0.00046746115288220555,
      "loss": 4.832,
      "step": 13500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 52.763694763183594,
      "learning_rate": 0.0004662080200501253,
      "loss": 4.0848,
      "step": 14000
    },
    {
      "epoch": 0.09644420204062629,
      "grad_norm": 36.19338607788086,
      "learning_rate": 0.00046495488721804513,
      "loss": 4.0362,
      "step": 14500
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 11.889057159423828,
      "learning_rate": 0.0004637017543859649,
      "loss": 8.3272,
      "step": 15000
    },
    {
      "epoch": 0.10309552631929017,
      "grad_norm": 35.861236572265625,
      "learning_rate": 0.0004624486215538847,
      "loss": 4.1349,
      "step": 15500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 14.845090866088867,
      "learning_rate": 0.0004611954887218045,
      "loss": 3.7795,
      "step": 16000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.7091152667999268,
      "eval_runtime": 135.5105,
      "eval_samples_per_second": 368.975,
      "eval_steps_per_second": 5.771,
      "step": 16000
    },
    {
      "epoch": 0.10974685059795405,
      "grad_norm": 18.482023239135742,
      "learning_rate": 0.00045994235588972434,
      "loss": 3.7302,
      "step": 16500
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 19.1699161529541,
      "learning_rate": 0.0004586892230576441,
      "loss": 3.7277,
      "step": 17000
    },
    {
      "epoch": 0.11639817487661794,
      "grad_norm": 18.107181549072266,
      "learning_rate": 0.0004574360902255639,
      "loss": 3.7281,
      "step": 17500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 1.5723371505737305,
      "learning_rate": 0.0004561829573934837,
      "loss": 3.8542,
      "step": 18000
    },
    {
      "epoch": 0.12304949915528182,
      "grad_norm": 1.3046311140060425,
      "learning_rate": 0.00045492982456140355,
      "loss": 3.6841,
      "step": 18500
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 2.265974521636963,
      "learning_rate": 0.0004536766917293233,
      "loss": 3.6137,
      "step": 19000
    },
    {
      "epoch": 0.1297008234339457,
      "grad_norm": 1.4687892198562622,
      "learning_rate": 0.00045242355889724313,
      "loss": 3.5647,
      "step": 19500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 1.05413019657135,
      "learning_rate": 0.0004511704260651629,
      "loss": 3.5744,
      "step": 20000
    },
    {
      "epoch": 0.13302648557327765,
      "eval_loss": 3.551231622695923,
      "eval_runtime": 135.5918,
      "eval_samples_per_second": 368.754,
      "eval_steps_per_second": 5.767,
      "step": 20000
    },
    {
      "epoch": 0.1363521477126096,
      "grad_norm": 0.7613028287887573,
      "learning_rate": 0.0004499172932330827,
      "loss": 3.5368,
      "step": 20500
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.6895266175270081,
      "learning_rate": 0.00044866416040100247,
      "loss": 3.5077,
      "step": 21000
    },
    {
      "epoch": 0.14300347199127347,
      "grad_norm": 1.2077078819274902,
      "learning_rate": 0.00044741102756892234,
      "loss": 3.4876,
      "step": 21500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.5919422507286072,
      "learning_rate": 0.0004461578947368421,
      "loss": 3.4668,
      "step": 22000
    },
    {
      "epoch": 0.14965479626993736,
      "grad_norm": 0.5595279932022095,
      "learning_rate": 0.0004449047619047619,
      "loss": 3.4495,
      "step": 22500
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.6449010372161865,
      "learning_rate": 0.0004436516290726817,
      "loss": 3.4414,
      "step": 23000
    },
    {
      "epoch": 0.1563061205486012,
      "grad_norm": 1.1180583238601685,
      "learning_rate": 0.0004423984962406015,
      "loss": 3.4293,
      "step": 23500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.6200860738754272,
      "learning_rate": 0.0004411453634085213,
      "loss": 3.419,
      "step": 24000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.4123990535736084,
      "eval_runtime": 135.6081,
      "eval_samples_per_second": 368.71,
      "eval_steps_per_second": 5.767,
      "step": 24000
    },
    {
      "epoch": 0.1629574448272651,
      "grad_norm": 1.0363249778747559,
      "learning_rate": 0.00043989223057644113,
      "loss": 3.4133,
      "step": 24500
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.5639841556549072,
      "learning_rate": 0.0004386390977443609,
      "loss": 3.4017,
      "step": 25000
    },
    {
      "epoch": 0.16960876910592898,
      "grad_norm": 0.6146987080574036,
      "learning_rate": 0.0004373859649122807,
      "loss": 3.3963,
      "step": 25500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.7569714188575745,
      "learning_rate": 0.00043613283208020047,
      "loss": 3.3901,
      "step": 26000
    },
    {
      "epoch": 0.17626009338459286,
      "grad_norm": 1.1271774768829346,
      "learning_rate": 0.00043487969924812034,
      "loss": 3.3727,
      "step": 26500
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.5985541939735413,
      "learning_rate": 0.0004336265664160401,
      "loss": 3.3721,
      "step": 27000
    },
    {
      "epoch": 0.18291141766325675,
      "grad_norm": 0.7450999617576599,
      "learning_rate": 0.0004323734335839599,
      "loss": 3.3647,
      "step": 27500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.6578332781791687,
      "learning_rate": 0.0004311203007518797,
      "loss": 3.36,
      "step": 28000
    },
    {
      "epoch": 0.1862370798025887,
      "eval_loss": 3.3543503284454346,
      "eval_runtime": 135.7558,
      "eval_samples_per_second": 368.308,
      "eval_steps_per_second": 5.76,
      "step": 28000
    },
    {
      "epoch": 0.18956274194192063,
      "grad_norm": 0.5502318739891052,
      "learning_rate": 0.0004298671679197995,
      "loss": 3.3495,
      "step": 28500
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.7196609973907471,
      "learning_rate": 0.0004286140350877193,
      "loss": 3.3508,
      "step": 29000
    },
    {
      "epoch": 0.19621406622058452,
      "grad_norm": 0.5373541712760925,
      "learning_rate": 0.0004273609022556391,
      "loss": 3.34,
      "step": 29500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.7134045362472534,
      "learning_rate": 0.0004261077694235589,
      "loss": 3.3365,
      "step": 30000
    },
    {
      "epoch": 0.2028653904992484,
      "grad_norm": 0.5442966222763062,
      "learning_rate": 0.0004248546365914787,
      "loss": 3.3289,
      "step": 30500
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.5896552801132202,
      "learning_rate": 0.00042360150375939847,
      "loss": 3.3223,
      "step": 31000
    },
    {
      "epoch": 0.20951671477791228,
      "grad_norm": 0.5500332713127136,
      "learning_rate": 0.00042234837092731834,
      "loss": 3.3196,
      "step": 31500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.5223756432533264,
      "learning_rate": 0.0004210952380952381,
      "loss": 3.3169,
      "step": 32000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.3131983280181885,
      "eval_runtime": 135.819,
      "eval_samples_per_second": 368.137,
      "eval_steps_per_second": 5.758,
      "step": 32000
    },
    {
      "epoch": 0.21616803905657617,
      "grad_norm": 0.7134462594985962,
      "learning_rate": 0.0004198421052631579,
      "loss": 3.3068,
      "step": 32500
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.8896155953407288,
      "learning_rate": 0.0004185889724310777,
      "loss": 3.3059,
      "step": 33000
    },
    {
      "epoch": 0.22281936333524005,
      "grad_norm": 0.7771251201629639,
      "learning_rate": 0.0004173358395989975,
      "loss": 3.2968,
      "step": 33500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.5678886771202087,
      "learning_rate": 0.00041608521303258144,
      "loss": 3.297,
      "step": 34000
    },
    {
      "epoch": 0.22947068761390393,
      "grad_norm": 0.5830522775650024,
      "learning_rate": 0.0004148395989974937,
      "loss": 3.2926,
      "step": 34500
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.5319101810455322,
      "learning_rate": 0.0004135864661654136,
      "loss": 3.291,
      "step": 35000
    },
    {
      "epoch": 0.23612201189256782,
      "grad_norm": 1.064479947090149,
      "learning_rate": 0.00041233333333333335,
      "loss": 3.2767,
      "step": 35500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.581251323223114,
      "learning_rate": 0.00041108020050125316,
      "loss": 3.276,
      "step": 36000
    },
    {
      "epoch": 0.23944767403189976,
      "eval_loss": 3.2746987342834473,
      "eval_runtime": 135.4925,
      "eval_samples_per_second": 369.024,
      "eval_steps_per_second": 5.772,
      "step": 36000
    },
    {
      "epoch": 0.2427733361712317,
      "grad_norm": 0.8562107682228088,
      "learning_rate": 0.0004098270676691729,
      "loss": 3.2732,
      "step": 36500
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.6025232076644897,
      "learning_rate": 0.00040857393483709274,
      "loss": 3.2717,
      "step": 37000
    },
    {
      "epoch": 0.24942466044989559,
      "grad_norm": 0.9583590030670166,
      "learning_rate": 0.00040732080200501256,
      "loss": 3.2677,
      "step": 37500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.5320245027542114,
      "learning_rate": 0.00040606766917293237,
      "loss": 3.2653,
      "step": 38000
    },
    {
      "epoch": 0.25607598472855947,
      "grad_norm": 0.7827557325363159,
      "learning_rate": 0.00040481453634085213,
      "loss": 3.2553,
      "step": 38500
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.5491990447044373,
      "learning_rate": 0.00040356140350877195,
      "loss": 3.2501,
      "step": 39000
    },
    {
      "epoch": 0.26272730900722335,
      "grad_norm": 0.6467874050140381,
      "learning_rate": 0.0004023082706766917,
      "loss": 3.25,
      "step": 39500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.5180622935295105,
      "learning_rate": 0.0004010551378446116,
      "loss": 3.2478,
      "step": 40000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.2445380687713623,
      "eval_runtime": 135.4117,
      "eval_samples_per_second": 369.244,
      "eval_steps_per_second": 5.775,
      "step": 40000
    },
    {
      "epoch": 0.26937863328588724,
      "grad_norm": 0.8558171987533569,
      "learning_rate": 0.00039980200501253134,
      "loss": 3.2409,
      "step": 40500
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.7236514091491699,
      "learning_rate": 0.00039854887218045116,
      "loss": 3.2404,
      "step": 41000
    },
    {
      "epoch": 0.2760299575645511,
      "grad_norm": 0.5130232572555542,
      "learning_rate": 0.0003972957393483709,
      "loss": 3.2372,
      "step": 41500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 1.0736019611358643,
      "learning_rate": 0.00039604260651629074,
      "loss": 3.2362,
      "step": 42000
    },
    {
      "epoch": 0.282681281843215,
      "grad_norm": 0.6965305209159851,
      "learning_rate": 0.00039478947368421055,
      "loss": 3.2325,
      "step": 42500
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 1.5416265726089478,
      "learning_rate": 0.00039353884711779445,
      "loss": 3.2272,
      "step": 43000
    },
    {
      "epoch": 0.2893326061218789,
      "grad_norm": 0.5608951449394226,
      "learning_rate": 0.00039228822055137845,
      "loss": 3.226,
      "step": 43500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.9075213074684143,
      "learning_rate": 0.00039103508771929827,
      "loss": 3.2188,
      "step": 44000
    },
    {
      "epoch": 0.29265826826121083,
      "eval_loss": 3.2170372009277344,
      "eval_runtime": 135.4921,
      "eval_samples_per_second": 369.025,
      "eval_steps_per_second": 5.772,
      "step": 44000
    },
    {
      "epoch": 0.29598393040054277,
      "grad_norm": 0.4879620671272278,
      "learning_rate": 0.0003897819548872181,
      "loss": 3.2175,
      "step": 44500
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.5808523893356323,
      "learning_rate": 0.00038852882205513785,
      "loss": 3.2188,
      "step": 45000
    },
    {
      "epoch": 0.30263525467920666,
      "grad_norm": 0.5532805919647217,
      "learning_rate": 0.00038727568922305766,
      "loss": 3.2143,
      "step": 45500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 1.0286520719528198,
      "learning_rate": 0.0003860225563909774,
      "loss": 3.2077,
      "step": 46000
    },
    {
      "epoch": 0.30928657895787054,
      "grad_norm": 0.6443065404891968,
      "learning_rate": 0.0003847694235588973,
      "loss": 3.2058,
      "step": 46500
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.47806498408317566,
      "learning_rate": 0.00038351629072681706,
      "loss": 3.202,
      "step": 47000
    },
    {
      "epoch": 0.31593790323653437,
      "grad_norm": 0.7785501480102539,
      "learning_rate": 0.00038226315789473687,
      "loss": 3.1978,
      "step": 47500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.4946920871734619,
      "learning_rate": 0.00038101002506265663,
      "loss": 3.1986,
      "step": 48000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.1950693130493164,
      "eval_runtime": 135.6445,
      "eval_samples_per_second": 368.611,
      "eval_steps_per_second": 5.765,
      "step": 48000
    },
    {
      "epoch": 0.32258922751519825,
      "grad_norm": 0.5906003713607788,
      "learning_rate": 0.00037975689223057645,
      "loss": 3.199,
      "step": 48500
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.9678395390510559,
      "learning_rate": 0.0003785037593984962,
      "loss": 3.192,
      "step": 49000
    },
    {
      "epoch": 0.32924055179386214,
      "grad_norm": 0.527747631072998,
      "learning_rate": 0.00037725313283208016,
      "loss": 3.1876,
      "step": 49500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.7089765071868896,
      "learning_rate": 0.00037600000000000003,
      "loss": 3.1902,
      "step": 50000
    },
    {
      "epoch": 0.335891876072526,
      "grad_norm": 0.5336205959320068,
      "learning_rate": 0.0003747468671679198,
      "loss": 3.1827,
      "step": 50500
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.8674543499946594,
      "learning_rate": 0.0003734962406015038,
      "loss": 3.1828,
      "step": 51000
    },
    {
      "epoch": 0.3425432003511899,
      "grad_norm": 0.527754008769989,
      "learning_rate": 0.00037224310776942356,
      "loss": 3.1813,
      "step": 51500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.775619626045227,
      "learning_rate": 0.0003709899749373434,
      "loss": 3.1749,
      "step": 52000
    },
    {
      "epoch": 0.34586886249052184,
      "eval_loss": 3.1741390228271484,
      "eval_runtime": 135.5954,
      "eval_samples_per_second": 368.744,
      "eval_steps_per_second": 5.767,
      "step": 52000
    },
    {
      "epoch": 0.3491945246298538,
      "grad_norm": 1.4127137660980225,
      "learning_rate": 0.00036973684210526314,
      "loss": 3.1742,
      "step": 52500
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.6934494972229004,
      "learning_rate": 0.00036848370927318295,
      "loss": 3.1755,
      "step": 53000
    },
    {
      "epoch": 0.35584584890851767,
      "grad_norm": 0.9334360361099243,
      "learning_rate": 0.00036723057644110277,
      "loss": 3.1671,
      "step": 53500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.47914808988571167,
      "learning_rate": 0.0003659799498746867,
      "loss": 3.1684,
      "step": 54000
    },
    {
      "epoch": 0.36249717318718155,
      "grad_norm": 0.5372723340988159,
      "learning_rate": 0.00036472681704260654,
      "loss": 3.1668,
      "step": 54500
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.5444692969322205,
      "learning_rate": 0.00036347368421052635,
      "loss": 3.1657,
      "step": 55000
    },
    {
      "epoch": 0.36914849746584544,
      "grad_norm": 0.5437084436416626,
      "learning_rate": 0.0003622205513784461,
      "loss": 3.1601,
      "step": 55500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.4884639084339142,
      "learning_rate": 0.00036096741854636593,
      "loss": 3.1584,
      "step": 56000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.1577401161193848,
      "eval_runtime": 135.7813,
      "eval_samples_per_second": 368.239,
      "eval_steps_per_second": 5.759,
      "step": 56000
    },
    {
      "epoch": 0.3757998217445093,
      "grad_norm": 0.47808215022087097,
      "learning_rate": 0.0003597142857142857,
      "loss": 3.1572,
      "step": 56500
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.540707528591156,
      "learning_rate": 0.00035846115288220556,
      "loss": 3.1591,
      "step": 57000
    },
    {
      "epoch": 0.3824511460231732,
      "grad_norm": 0.642117440700531,
      "learning_rate": 0.0003572080200501253,
      "loss": 3.1516,
      "step": 57500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.5220913887023926,
      "learning_rate": 0.0003559573934837093,
      "loss": 3.1524,
      "step": 58000
    },
    {
      "epoch": 0.3891024703018371,
      "grad_norm": 0.6135008931159973,
      "learning_rate": 0.0003547042606516291,
      "loss": 3.1549,
      "step": 58500
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.881693422794342,
      "learning_rate": 0.00035345363408521304,
      "loss": 3.1477,
      "step": 59000
    },
    {
      "epoch": 0.395753794580501,
      "grad_norm": 0.5017749667167664,
      "learning_rate": 0.00035220050125313285,
      "loss": 3.1418,
      "step": 59500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.5734116435050964,
      "learning_rate": 0.0003509473684210526,
      "loss": 3.1454,
      "step": 60000
    },
    {
      "epoch": 0.3990794567198329,
      "eval_loss": 3.1441268920898438,
      "eval_runtime": 135.6999,
      "eval_samples_per_second": 368.46,
      "eval_steps_per_second": 5.763,
      "step": 60000
    },
    {
      "epoch": 0.40240511885916486,
      "grad_norm": 0.7243313193321228,
      "learning_rate": 0.00034969423558897243,
      "loss": 3.1366,
      "step": 60500
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.793127179145813,
      "learning_rate": 0.00034844110275689225,
      "loss": 3.1399,
      "step": 61000
    },
    {
      "epoch": 0.40905644313782874,
      "grad_norm": 0.4741256535053253,
      "learning_rate": 0.00034718796992481206,
      "loss": 3.1368,
      "step": 61500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.6108814477920532,
      "learning_rate": 0.0003459348370927318,
      "loss": 3.1295,
      "step": 62000
    },
    {
      "epoch": 0.4157077674164926,
      "grad_norm": 0.6753247976303101,
      "learning_rate": 0.00034468170426065164,
      "loss": 3.133,
      "step": 62500
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.459094375371933,
      "learning_rate": 0.0003434285714285714,
      "loss": 3.1288,
      "step": 63000
    },
    {
      "epoch": 0.4223590916951565,
      "grad_norm": 0.48037147521972656,
      "learning_rate": 0.0003421779448621554,
      "loss": 3.13,
      "step": 63500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.6082454919815063,
      "learning_rate": 0.00034092481203007517,
      "loss": 3.128,
      "step": 64000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.1231043338775635,
      "eval_runtime": 135.4382,
      "eval_samples_per_second": 369.172,
      "eval_steps_per_second": 5.774,
      "step": 64000
    },
    {
      "epoch": 0.4290104159738204,
      "grad_norm": 0.6202965378761292,
      "learning_rate": 0.00033967167919799504,
      "loss": 3.1251,
      "step": 64500
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.45281144976615906,
      "learning_rate": 0.0003384185463659148,
      "loss": 3.1203,
      "step": 65000
    },
    {
      "epoch": 0.4356617402524843,
      "grad_norm": 0.5787404179573059,
      "learning_rate": 0.0003371654135338346,
      "loss": 3.1201,
      "step": 65500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.4733366370201111,
      "learning_rate": 0.0003359122807017544,
      "loss": 3.1216,
      "step": 66000
    },
    {
      "epoch": 0.44231306453114816,
      "grad_norm": 0.5468994379043579,
      "learning_rate": 0.00033466165413533833,
      "loss": 3.1141,
      "step": 66500
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.9080352187156677,
      "learning_rate": 0.00033340852130325815,
      "loss": 3.1132,
      "step": 67000
    },
    {
      "epoch": 0.44896438880981204,
      "grad_norm": 0.4924597144126892,
      "learning_rate": 0.0003321553884711779,
      "loss": 3.1138,
      "step": 67500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.45970389246940613,
      "learning_rate": 0.0003309047619047619,
      "loss": 3.1127,
      "step": 68000
    },
    {
      "epoch": 0.452290050949144,
      "eval_loss": 3.1114375591278076,
      "eval_runtime": 135.4821,
      "eval_samples_per_second": 369.053,
      "eval_steps_per_second": 5.772,
      "step": 68000
    },
    {
      "epoch": 0.4556157130884759,
      "grad_norm": 0.5571473836898804,
      "learning_rate": 0.00032965162907268173,
      "loss": 3.1117,
      "step": 68500
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 1.043243169784546,
      "learning_rate": 0.00032839849624060154,
      "loss": 3.1129,
      "step": 69000
    },
    {
      "epoch": 0.4622670373671398,
      "grad_norm": 0.6595741510391235,
      "learning_rate": 0.0003271453634085213,
      "loss": 3.1072,
      "step": 69500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.5236812829971313,
      "learning_rate": 0.0003258922305764411,
      "loss": 3.1068,
      "step": 70000
    },
    {
      "epoch": 0.4689183616458037,
      "grad_norm": 0.6684610843658447,
      "learning_rate": 0.0003246390977443609,
      "loss": 3.1004,
      "step": 70500
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.4387127161026001,
      "learning_rate": 0.00032338596491228075,
      "loss": 3.1046,
      "step": 71000
    },
    {
      "epoch": 0.4755696859244676,
      "grad_norm": 0.6650027632713318,
      "learning_rate": 0.0003221328320802005,
      "loss": 3.1003,
      "step": 71500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.6236310005187988,
      "learning_rate": 0.00032087969924812033,
      "loss": 3.0975,
      "step": 72000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 3.097111225128174,
      "eval_runtime": 135.4188,
      "eval_samples_per_second": 369.225,
      "eval_steps_per_second": 5.775,
      "step": 72000
    },
    {
      "epoch": 0.48222101020313146,
      "grad_norm": 0.9194464683532715,
      "learning_rate": 0.0003196290726817043,
      "loss": 3.0987,
      "step": 72500
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.7914559245109558,
      "learning_rate": 0.00031837593984962404,
      "loss": 3.0942,
      "step": 73000
    },
    {
      "epoch": 0.48887233448179535,
      "grad_norm": 0.4503248631954193,
      "learning_rate": 0.00031712280701754386,
      "loss": 3.0948,
      "step": 73500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.4720672369003296,
      "learning_rate": 0.0003158696741854636,
      "loss": 3.0907,
      "step": 74000
    },
    {
      "epoch": 0.49552365876045923,
      "grad_norm": 0.8830485343933105,
      "learning_rate": 0.0003146165413533835,
      "loss": 3.0913,
      "step": 74500
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.6662659645080566,
      "learning_rate": 0.0003133659147869674,
      "loss": 3.0861,
      "step": 75000
    },
    {
      "epoch": 0.5021749830391231,
      "grad_norm": 0.44886431097984314,
      "learning_rate": 0.0003121152882205514,
      "loss": 3.0919,
      "step": 75500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.47580429911613464,
      "learning_rate": 0.00031086215538847115,
      "loss": 3.0875,
      "step": 76000
    },
    {
      "epoch": 0.505500645178455,
      "eval_loss": 3.0835723876953125,
      "eval_runtime": 135.3097,
      "eval_samples_per_second": 369.523,
      "eval_steps_per_second": 5.779,
      "step": 76000
    },
    {
      "epoch": 0.508826307317787,
      "grad_norm": 0.4857209622859955,
      "learning_rate": 0.000309609022556391,
      "loss": 3.0905,
      "step": 76500
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.5311977863311768,
      "learning_rate": 0.0003083558897243108,
      "loss": 3.0849,
      "step": 77000
    },
    {
      "epoch": 0.5154776315964509,
      "grad_norm": 0.45013338327407837,
      "learning_rate": 0.0003071027568922306,
      "loss": 3.0839,
      "step": 77500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.4452841579914093,
      "learning_rate": 0.00030584962406015036,
      "loss": 3.0762,
      "step": 78000
    },
    {
      "epoch": 0.5221289558751148,
      "grad_norm": 0.6254717707633972,
      "learning_rate": 0.0003045964912280702,
      "loss": 3.0812,
      "step": 78500
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.6399668455123901,
      "learning_rate": 0.00030334335839599,
      "loss": 3.0774,
      "step": 79000
    },
    {
      "epoch": 0.5287802801537786,
      "grad_norm": 0.5091209411621094,
      "learning_rate": 0.0003020902255639098,
      "loss": 3.0799,
      "step": 79500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.751666784286499,
      "learning_rate": 0.0003008370927318296,
      "loss": 3.0765,
      "step": 80000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 3.073323965072632,
      "eval_runtime": 135.4624,
      "eval_samples_per_second": 369.106,
      "eval_steps_per_second": 5.773,
      "step": 80000
    },
    {
      "epoch": 0.5354316044324425,
      "grad_norm": 0.49585551023483276,
      "learning_rate": 0.0002995839598997494,
      "loss": 3.0763,
      "step": 80500
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.47466427087783813,
      "learning_rate": 0.00029833082706766915,
      "loss": 3.0741,
      "step": 81000
    },
    {
      "epoch": 0.5420829287111064,
      "grad_norm": 0.5173195004463196,
      "learning_rate": 0.000297077694235589,
      "loss": 3.0725,
      "step": 81500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.4767504334449768,
      "learning_rate": 0.0002958245614035088,
      "loss": 3.0711,
      "step": 82000
    },
    {
      "epoch": 0.5487342529897703,
      "grad_norm": 0.8277539014816284,
      "learning_rate": 0.00029457644110275687,
      "loss": 3.0703,
      "step": 82500
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.7588657736778259,
      "learning_rate": 0.00029332330827067674,
      "loss": 3.0697,
      "step": 83000
    },
    {
      "epoch": 0.5553855772684342,
      "grad_norm": 0.7522991299629211,
      "learning_rate": 0.0002920701754385965,
      "loss": 3.063,
      "step": 83500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.48226210474967957,
      "learning_rate": 0.0002908170426065163,
      "loss": 3.0633,
      "step": 84000
    },
    {
      "epoch": 0.5587112394077661,
      "eval_loss": 3.06231427192688,
      "eval_runtime": 136.1018,
      "eval_samples_per_second": 367.372,
      "eval_steps_per_second": 5.746,
      "step": 84000
    },
    {
      "epoch": 0.5620369015470981,
      "grad_norm": 0.5565562844276428,
      "learning_rate": 0.0002895639097744361,
      "loss": 3.0618,
      "step": 84500
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.6962445378303528,
      "learning_rate": 0.0002883107769423559,
      "loss": 3.0657,
      "step": 85000
    },
    {
      "epoch": 0.568688225825762,
      "grad_norm": 0.5282956957817078,
      "learning_rate": 0.0002870576441102757,
      "loss": 3.0605,
      "step": 85500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.4532981216907501,
      "learning_rate": 0.00028580701754385966,
      "loss": 3.0631,
      "step": 86000
    },
    {
      "epoch": 0.5753395501044258,
      "grad_norm": 0.6023990511894226,
      "learning_rate": 0.0002845538847117795,
      "loss": 3.056,
      "step": 86500
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.4677445888519287,
      "learning_rate": 0.00028330325814536337,
      "loss": 3.0612,
      "step": 87000
    },
    {
      "epoch": 0.5819908743830897,
      "grad_norm": 0.46869152784347534,
      "learning_rate": 0.00028205012531328324,
      "loss": 3.0544,
      "step": 87500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.8077301383018494,
      "learning_rate": 0.000280796992481203,
      "loss": 3.05,
      "step": 88000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 3.052716016769409,
      "eval_runtime": 136.1275,
      "eval_samples_per_second": 367.303,
      "eval_steps_per_second": 5.745,
      "step": 88000
    },
    {
      "epoch": 0.5886421986617536,
      "grad_norm": 0.5334800481796265,
      "learning_rate": 0.0002795438596491228,
      "loss": 3.0558,
      "step": 88500
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.5582268238067627,
      "learning_rate": 0.0002782907268170426,
      "loss": 3.0522,
      "step": 89000
    },
    {
      "epoch": 0.5952935229404175,
      "grad_norm": 0.5099611282348633,
      "learning_rate": 0.0002770401002506266,
      "loss": 3.0484,
      "step": 89500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.5629527568817139,
      "learning_rate": 0.00027578696741854635,
      "loss": 3.0496,
      "step": 90000
    },
    {
      "epoch": 0.6019448472190814,
      "grad_norm": 0.751309335231781,
      "learning_rate": 0.0002745338345864662,
      "loss": 3.0452,
      "step": 90500
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.7245206236839294,
      "learning_rate": 0.000273280701754386,
      "loss": 3.0422,
      "step": 91000
    },
    {
      "epoch": 0.6085961714977453,
      "grad_norm": 0.5656214952468872,
      "learning_rate": 0.0002720275689223058,
      "loss": 3.0414,
      "step": 91500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.4964187741279602,
      "learning_rate": 0.00027077443609022556,
      "loss": 3.0451,
      "step": 92000
    },
    {
      "epoch": 0.6119218336370772,
      "eval_loss": 3.0412049293518066,
      "eval_runtime": 136.8476,
      "eval_samples_per_second": 365.37,
      "eval_steps_per_second": 5.714,
      "step": 92000
    },
    {
      "epoch": 0.6152474957764091,
      "grad_norm": 0.6322645545005798,
      "learning_rate": 0.00026952130325814537,
      "loss": 3.0424,
      "step": 92500
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.9989678859710693,
      "learning_rate": 0.0002682681704260652,
      "loss": 3.0394,
      "step": 93000
    },
    {
      "epoch": 0.6218988200550729,
      "grad_norm": 0.6514461636543274,
      "learning_rate": 0.000267015037593985,
      "loss": 3.0352,
      "step": 93500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.47543877363204956,
      "learning_rate": 0.00026576190476190477,
      "loss": 3.0352,
      "step": 94000
    },
    {
      "epoch": 0.6285501443337368,
      "grad_norm": 0.7306289672851562,
      "learning_rate": 0.0002645087719298246,
      "loss": 3.0375,
      "step": 94500
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.5951496958732605,
      "learning_rate": 0.00026325563909774434,
      "loss": 3.0349,
      "step": 95000
    },
    {
      "epoch": 0.6352014686124007,
      "grad_norm": 0.4633142948150635,
      "learning_rate": 0.0002620025062656642,
      "loss": 3.0339,
      "step": 95500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.6677867770195007,
      "learning_rate": 0.0002607518796992481,
      "loss": 3.0298,
      "step": 96000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 3.031404972076416,
      "eval_runtime": 135.9345,
      "eval_samples_per_second": 367.824,
      "eval_steps_per_second": 5.753,
      "step": 96000
    },
    {
      "epoch": 0.6418527928910646,
      "grad_norm": 0.5240382552146912,
      "learning_rate": 0.0002594987468671679,
      "loss": 3.0323,
      "step": 96500
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.5435243248939514,
      "learning_rate": 0.00025824561403508774,
      "loss": 3.0302,
      "step": 97000
    },
    {
      "epoch": 0.6485041171697284,
      "grad_norm": 0.5343034267425537,
      "learning_rate": 0.0002569924812030075,
      "loss": 3.0287,
      "step": 97500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.5084654688835144,
      "learning_rate": 0.0002557393483709273,
      "loss": 3.0286,
      "step": 98000
    },
    {
      "epoch": 0.6551554414483923,
      "grad_norm": 0.8164981603622437,
      "learning_rate": 0.0002544862155388471,
      "loss": 3.0293,
      "step": 98500
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.9557898044586182,
      "learning_rate": 0.00025323308270676695,
      "loss": 3.0244,
      "step": 99000
    },
    {
      "epoch": 0.6618067657270562,
      "grad_norm": 0.4890197217464447,
      "learning_rate": 0.00025198245614035085,
      "loss": 3.0267,
      "step": 99500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.4588499367237091,
      "learning_rate": 0.0002507293233082707,
      "loss": 3.0205,
      "step": 100000
    },
    {
      "epoch": 0.6651324278663882,
      "eval_loss": 3.021310567855835,
      "eval_runtime": 136.0547,
      "eval_samples_per_second": 367.499,
      "eval_steps_per_second": 5.748,
      "step": 100000
    },
    {
      "epoch": 0.6684580900057201,
      "grad_norm": 0.7693765163421631,
      "learning_rate": 0.0002494761904761905,
      "loss": 3.0245,
      "step": 100500
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.7496554851531982,
      "learning_rate": 0.00024822305764411024,
      "loss": 3.0186,
      "step": 101000
    },
    {
      "epoch": 0.675109414284384,
      "grad_norm": 0.5523166656494141,
      "learning_rate": 0.00024696992481203006,
      "loss": 3.0161,
      "step": 101500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.6522007584571838,
      "learning_rate": 0.00024571929824561406,
      "loss": 3.0174,
      "step": 102000
    },
    {
      "epoch": 0.6817607385630479,
      "grad_norm": 0.5102993845939636,
      "learning_rate": 0.0002444661654135338,
      "loss": 3.0229,
      "step": 102500
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.6378564834594727,
      "learning_rate": 0.00024321303258145364,
      "loss": 3.0186,
      "step": 103000
    },
    {
      "epoch": 0.6884120628417117,
      "grad_norm": 0.450772762298584,
      "learning_rate": 0.00024195989974937343,
      "loss": 3.0133,
      "step": 103500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.813488245010376,
      "learning_rate": 0.00024070676691729324,
      "loss": 3.0173,
      "step": 104000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 3.012176513671875,
      "eval_runtime": 135.973,
      "eval_samples_per_second": 367.72,
      "eval_steps_per_second": 5.751,
      "step": 104000
    },
    {
      "epoch": 0.6950633871203756,
      "grad_norm": 0.4268103837966919,
      "learning_rate": 0.00023945363408521303,
      "loss": 3.0134,
      "step": 104500
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.7199586033821106,
      "learning_rate": 0.00023820050125313282,
      "loss": 3.0096,
      "step": 105000
    },
    {
      "epoch": 0.7017147113990395,
      "grad_norm": 0.5603011250495911,
      "learning_rate": 0.00023694736842105264,
      "loss": 3.0093,
      "step": 105500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.4491276741027832,
      "learning_rate": 0.00023569423558897243,
      "loss": 3.0097,
      "step": 106000
    },
    {
      "epoch": 0.7083660356777034,
      "grad_norm": 0.641704797744751,
      "learning_rate": 0.00023444110275689224,
      "loss": 3.0083,
      "step": 106500
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.5258944630622864,
      "learning_rate": 0.00023318796992481203,
      "loss": 3.0054,
      "step": 107000
    },
    {
      "epoch": 0.7150173599563673,
      "grad_norm": 0.5682821869850159,
      "learning_rate": 0.000231937343358396,
      "loss": 3.0092,
      "step": 107500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.4879535734653473,
      "learning_rate": 0.0002306842105263158,
      "loss": 3.0059,
      "step": 108000
    },
    {
      "epoch": 0.7183430220956992,
      "eval_loss": 3.0037014484405518,
      "eval_runtime": 135.9642,
      "eval_samples_per_second": 367.744,
      "eval_steps_per_second": 5.752,
      "step": 108000
    },
    {
      "epoch": 0.7216686842350312,
      "grad_norm": 0.5772018432617188,
      "learning_rate": 0.0002294310776942356,
      "loss": 3.0081,
      "step": 108500
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.5619521737098694,
      "learning_rate": 0.0002281779448621554,
      "loss": 3.0037,
      "step": 109000
    },
    {
      "epoch": 0.728320008513695,
      "grad_norm": 0.7862581610679626,
      "learning_rate": 0.0002269248120300752,
      "loss": 3.0041,
      "step": 109500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.43742236495018005,
      "learning_rate": 0.00022567418546365914,
      "loss": 2.9992,
      "step": 110000
    },
    {
      "epoch": 0.7349713327923589,
      "grad_norm": 0.4792882204055786,
      "learning_rate": 0.00022442355889724312,
      "loss": 3.0008,
      "step": 110500
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.4929294288158417,
      "learning_rate": 0.0002231704260651629,
      "loss": 2.9951,
      "step": 111000
    },
    {
      "epoch": 0.7416226570710228,
      "grad_norm": 0.5304716229438782,
      "learning_rate": 0.00022191729323308272,
      "loss": 3.001,
      "step": 111500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.5073244571685791,
      "learning_rate": 0.0002206641604010025,
      "loss": 2.9969,
      "step": 112000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 2.9960687160491943,
      "eval_runtime": 135.9325,
      "eval_samples_per_second": 367.83,
      "eval_steps_per_second": 5.753,
      "step": 112000
    },
    {
      "epoch": 0.7482739813496867,
      "grad_norm": 0.4303211271762848,
      "learning_rate": 0.0002194110275689223,
      "loss": 2.9961,
      "step": 112500
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.5374110341072083,
      "learning_rate": 0.00021815789473684212,
      "loss": 2.9936,
      "step": 113000
    },
    {
      "epoch": 0.7549253056283506,
      "grad_norm": 0.4963967502117157,
      "learning_rate": 0.0002169047619047619,
      "loss": 2.9944,
      "step": 113500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.497687965631485,
      "learning_rate": 0.00021565162907268172,
      "loss": 2.9962,
      "step": 114000
    },
    {
      "epoch": 0.7615766299070145,
      "grad_norm": 0.5096191763877869,
      "learning_rate": 0.00021440100250626567,
      "loss": 2.9919,
      "step": 114500
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.4327288269996643,
      "learning_rate": 0.0002131478696741855,
      "loss": 2.9881,
      "step": 115000
    },
    {
      "epoch": 0.7682279541856784,
      "grad_norm": 0.6687582731246948,
      "learning_rate": 0.00021189473684210528,
      "loss": 2.9906,
      "step": 115500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.5406275987625122,
      "learning_rate": 0.00021064160401002507,
      "loss": 2.9863,
      "step": 116000
    },
    {
      "epoch": 0.7715536163250103,
      "eval_loss": 2.9876739978790283,
      "eval_runtime": 136.0061,
      "eval_samples_per_second": 367.631,
      "eval_steps_per_second": 5.75,
      "step": 116000
    },
    {
      "epoch": 0.7748792784643422,
      "grad_norm": 0.4352491497993469,
      "learning_rate": 0.00020938847117794488,
      "loss": 2.9879,
      "step": 116500
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.4660913348197937,
      "learning_rate": 0.00020813533834586467,
      "loss": 2.9901,
      "step": 117000
    },
    {
      "epoch": 0.7815306027430061,
      "grad_norm": 0.7767422795295715,
      "learning_rate": 0.0002068822055137845,
      "loss": 2.9885,
      "step": 117500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.46213099360466003,
      "learning_rate": 0.00020562907268170428,
      "loss": 2.9846,
      "step": 118000
    },
    {
      "epoch": 0.78818192702167,
      "grad_norm": 0.4848230481147766,
      "learning_rate": 0.00020437844611528823,
      "loss": 2.9854,
      "step": 118500
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.6155118942260742,
      "learning_rate": 0.0002031278195488722,
      "loss": 2.9823,
      "step": 119000
    },
    {
      "epoch": 0.7948332513003339,
      "grad_norm": 0.5076112151145935,
      "learning_rate": 0.000201874686716792,
      "loss": 2.9829,
      "step": 119500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.5664203763008118,
      "learning_rate": 0.00020062406015037594,
      "loss": 2.9854,
      "step": 120000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 2.979128122329712,
      "eval_runtime": 136.5433,
      "eval_samples_per_second": 366.184,
      "eval_steps_per_second": 5.727,
      "step": 120000
    },
    {
      "epoch": 0.8014845755789978,
      "grad_norm": 0.517902672290802,
      "learning_rate": 0.00019937092731829573,
      "loss": 2.9853,
      "step": 120500
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.8764330148696899,
      "learning_rate": 0.00019812280701754387,
      "loss": 2.9791,
      "step": 121000
    },
    {
      "epoch": 0.8081358998576617,
      "grad_norm": 0.5463972091674805,
      "learning_rate": 0.00019686967418546368,
      "loss": 2.9806,
      "step": 121500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.7654921412467957,
      "learning_rate": 0.00019561654135338347,
      "loss": 2.9773,
      "step": 122000
    },
    {
      "epoch": 0.8147872241363255,
      "grad_norm": 0.54847651720047,
      "learning_rate": 0.00019436340852130326,
      "loss": 2.9767,
      "step": 122500
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.5324961543083191,
      "learning_rate": 0.00019311027568922308,
      "loss": 2.9774,
      "step": 123000
    },
    {
      "epoch": 0.8214385484149894,
      "grad_norm": 0.5792108178138733,
      "learning_rate": 0.00019185714285714287,
      "loss": 2.9781,
      "step": 123500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.4725891053676605,
      "learning_rate": 0.00019060401002506266,
      "loss": 2.9718,
      "step": 124000
    },
    {
      "epoch": 0.8247642105543214,
      "eval_loss": 2.972066879272461,
      "eval_runtime": 135.9494,
      "eval_samples_per_second": 367.784,
      "eval_steps_per_second": 5.752,
      "step": 124000
    },
    {
      "epoch": 0.8280898726936533,
      "grad_norm": 0.48345157504081726,
      "learning_rate": 0.00018935087719298247,
      "loss": 2.9733,
      "step": 124500
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.5502886176109314,
      "learning_rate": 0.00018810025062656642,
      "loss": 2.9721,
      "step": 125000
    },
    {
      "epoch": 0.8347411969723172,
      "grad_norm": 0.45921704173088074,
      "learning_rate": 0.0001868471177944862,
      "loss": 2.972,
      "step": 125500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.45635467767715454,
      "learning_rate": 0.000185593984962406,
      "loss": 2.9706,
      "step": 126000
    },
    {
      "epoch": 0.8413925212509811,
      "grad_norm": 0.685971200466156,
      "learning_rate": 0.00018434085213032581,
      "loss": 2.9693,
      "step": 126500
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.556171178817749,
      "learning_rate": 0.0001830877192982456,
      "loss": 2.9724,
      "step": 127000
    },
    {
      "epoch": 0.848043845529645,
      "grad_norm": 0.49977102875709534,
      "learning_rate": 0.00018183458646616542,
      "loss": 2.9684,
      "step": 127500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.5263618230819702,
      "learning_rate": 0.0001805814536340852,
      "loss": 2.9684,
      "step": 128000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.9653427600860596,
      "eval_runtime": 136.3561,
      "eval_samples_per_second": 366.687,
      "eval_steps_per_second": 5.735,
      "step": 128000
    },
    {
      "epoch": 0.8546951698083088,
      "grad_norm": 0.5064967274665833,
      "learning_rate": 0.000179328320802005,
      "loss": 2.967,
      "step": 128500
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.46643251180648804,
      "learning_rate": 0.00017807518796992481,
      "loss": 2.9669,
      "step": 129000
    },
    {
      "epoch": 0.8613464940869727,
      "grad_norm": 0.5659502148628235,
      "learning_rate": 0.0001768220551378446,
      "loss": 2.964,
      "step": 129500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.6020098328590393,
      "learning_rate": 0.00017556892230576442,
      "loss": 2.9622,
      "step": 130000
    },
    {
      "epoch": 0.8679978183656366,
      "grad_norm": 0.677882194519043,
      "learning_rate": 0.0001743157894736842,
      "loss": 2.9622,
      "step": 130500
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.5314634442329407,
      "learning_rate": 0.000173062656641604,
      "loss": 2.9602,
      "step": 131000
    },
    {
      "epoch": 0.8746491426443005,
      "grad_norm": 0.6217937469482422,
      "learning_rate": 0.00017181203007518797,
      "loss": 2.9583,
      "step": 131500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.5144186615943909,
      "learning_rate": 0.00017055889724310776,
      "loss": 2.9587,
      "step": 132000
    },
    {
      "epoch": 0.8779748047836324,
      "eval_loss": 2.957390069961548,
      "eval_runtime": 135.9859,
      "eval_samples_per_second": 367.685,
      "eval_steps_per_second": 5.751,
      "step": 132000
    },
    {
      "epoch": 0.8813004669229644,
      "grad_norm": 0.5341763496398926,
      "learning_rate": 0.00016930576441102758,
      "loss": 2.9576,
      "step": 132500
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.6084029674530029,
      "learning_rate": 0.00016805263157894737,
      "loss": 2.9581,
      "step": 133000
    },
    {
      "epoch": 0.8879517912016283,
      "grad_norm": 0.4970773756504059,
      "learning_rate": 0.00016679949874686718,
      "loss": 2.9526,
      "step": 133500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.5179343819618225,
      "learning_rate": 0.00016554636591478697,
      "loss": 2.9553,
      "step": 134000
    },
    {
      "epoch": 0.8946031154802921,
      "grad_norm": 0.5164040923118591,
      "learning_rate": 0.00016429573934837095,
      "loss": 2.973,
      "step": 134500
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.5087942481040955,
      "learning_rate": 0.00016304260651629074,
      "loss": 2.9538,
      "step": 135000
    },
    {
      "epoch": 0.901254439758956,
      "grad_norm": 0.4687992036342621,
      "learning_rate": 0.00016178947368421055,
      "loss": 2.951,
      "step": 135500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.5240435004234314,
      "learning_rate": 0.00016053634085213034,
      "loss": 2.9521,
      "step": 136000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.950634479522705,
      "eval_runtime": 135.9934,
      "eval_samples_per_second": 367.665,
      "eval_steps_per_second": 5.75,
      "step": 136000
    },
    {
      "epoch": 0.9079057640376199,
      "grad_norm": 0.4375830292701721,
      "learning_rate": 0.00015928320802005013,
      "loss": 2.9498,
      "step": 136500
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.4611441195011139,
      "learning_rate": 0.00015803007518796995,
      "loss": 2.9523,
      "step": 137000
    },
    {
      "epoch": 0.9145570883162838,
      "grad_norm": 0.47533607482910156,
      "learning_rate": 0.00015677694235588974,
      "loss": 2.9506,
      "step": 137500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.5851709842681885,
      "learning_rate": 0.00015552380952380953,
      "loss": 2.9526,
      "step": 138000
    },
    {
      "epoch": 0.9212084125949477,
      "grad_norm": 0.49975964426994324,
      "learning_rate": 0.00015427318295739348,
      "loss": 2.9532,
      "step": 138500
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.5637458562850952,
      "learning_rate": 0.0001530200501253133,
      "loss": 2.9464,
      "step": 139000
    },
    {
      "epoch": 0.9278597368736116,
      "grad_norm": 0.48054906725883484,
      "learning_rate": 0.00015176691729323308,
      "loss": 2.9499,
      "step": 139500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.49620482325553894,
      "learning_rate": 0.00015051378446115287,
      "loss": 2.9466,
      "step": 140000
    },
    {
      "epoch": 0.9311853990129435,
      "eval_loss": 2.94350528717041,
      "eval_runtime": 136.0906,
      "eval_samples_per_second": 367.402,
      "eval_steps_per_second": 5.746,
      "step": 140000
    },
    {
      "epoch": 0.9345110611522754,
      "grad_norm": 0.5095962285995483,
      "learning_rate": 0.00014926065162907269,
      "loss": 2.9418,
      "step": 140500
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.5286227464675903,
      "learning_rate": 0.00014800751879699247,
      "loss": 2.9435,
      "step": 141000
    },
    {
      "epoch": 0.9411623854309393,
      "grad_norm": 0.7785512208938599,
      "learning_rate": 0.0001467543859649123,
      "loss": 2.9462,
      "step": 141500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.42256030440330505,
      "learning_rate": 0.00014550125313283208,
      "loss": 2.9431,
      "step": 142000
    },
    {
      "epoch": 0.9478137097096032,
      "grad_norm": 0.49724721908569336,
      "learning_rate": 0.00014424812030075187,
      "loss": 2.9457,
      "step": 142500
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.6465845108032227,
      "learning_rate": 0.00014299749373433585,
      "loss": 2.9438,
      "step": 143000
    },
    {
      "epoch": 0.9544650339882671,
      "grad_norm": 0.4595671594142914,
      "learning_rate": 0.00014174436090225563,
      "loss": 2.9384,
      "step": 143500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.4734817445278168,
      "learning_rate": 0.00014049122807017545,
      "loss": 2.9365,
      "step": 144000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.936551332473755,
      "eval_runtime": 136.2034,
      "eval_samples_per_second": 367.098,
      "eval_steps_per_second": 5.741,
      "step": 144000
    },
    {
      "epoch": 0.961116358266931,
      "grad_norm": 0.5216798782348633,
      "learning_rate": 0.00013923809523809524,
      "loss": 2.9395,
      "step": 144500
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.4386753439903259,
      "learning_rate": 0.0001379874686716792,
      "loss": 2.9383,
      "step": 145000
    },
    {
      "epoch": 0.9677676825455949,
      "grad_norm": 0.5750828981399536,
      "learning_rate": 0.00013673684210526317,
      "loss": 2.9371,
      "step": 145500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.5107158422470093,
      "learning_rate": 0.00013548370927318296,
      "loss": 2.9338,
      "step": 146000
    },
    {
      "epoch": 0.9744190068242587,
      "grad_norm": 0.44133996963500977,
      "learning_rate": 0.00013423057644110277,
      "loss": 2.9318,
      "step": 146500
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.4392240047454834,
      "learning_rate": 0.00013297744360902256,
      "loss": 2.9299,
      "step": 147000
    },
    {
      "epoch": 0.9810703311029226,
      "grad_norm": 0.5326952934265137,
      "learning_rate": 0.00013172431077694235,
      "loss": 2.9354,
      "step": 147500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.4618728756904602,
      "learning_rate": 0.00013047117794486217,
      "loss": 2.9325,
      "step": 148000
    },
    {
      "epoch": 0.9843959932422546,
      "eval_loss": 2.929994583129883,
      "eval_runtime": 135.9575,
      "eval_samples_per_second": 367.762,
      "eval_steps_per_second": 5.752,
      "step": 148000
    },
    {
      "epoch": 0.9877216553815865,
      "grad_norm": 0.6012449264526367,
      "learning_rate": 0.00012921804511278195,
      "loss": 2.9268,
      "step": 148500
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.4667312204837799,
      "learning_rate": 0.00012796741854636593,
      "loss": 2.9315,
      "step": 149000
    },
    {
      "epoch": 0.9943729796602504,
      "grad_norm": 0.5524675250053406,
      "learning_rate": 0.00012671428571428572,
      "loss": 2.9302,
      "step": 149500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.4560014307498932,
      "learning_rate": 0.00012546115288220554,
      "loss": 2.9288,
      "step": 150000
    },
    {
      "epoch": 1.0010243039389142,
      "grad_norm": 0.5663714408874512,
      "learning_rate": 0.00012420802005012532,
      "loss": 2.9221,
      "step": 150500
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.5040130615234375,
      "learning_rate": 0.00012295488721804511,
      "loss": 2.9176,
      "step": 151000
    },
    {
      "epoch": 1.007675628217578,
      "grad_norm": 0.4396806061267853,
      "learning_rate": 0.00012170175438596492,
      "loss": 2.9145,
      "step": 151500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.5001554489135742,
      "learning_rate": 0.0001204486215538847,
      "loss": 2.9138,
      "step": 152000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.9242472648620605,
      "eval_runtime": 135.807,
      "eval_samples_per_second": 368.17,
      "eval_steps_per_second": 5.758,
      "step": 152000
    },
    {
      "epoch": 1.014326952496242,
      "grad_norm": 0.5184929370880127,
      "learning_rate": 0.00011919548872180451,
      "loss": 2.9122,
      "step": 152500
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.557620644569397,
      "learning_rate": 0.00011794235588972431,
      "loss": 2.9139,
      "step": 153000
    },
    {
      "epoch": 1.0209782767749058,
      "grad_norm": 0.5238193869590759,
      "learning_rate": 0.00011669172932330827,
      "loss": 2.9119,
      "step": 153500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.4708521068096161,
      "learning_rate": 0.00011543859649122808,
      "loss": 2.9127,
      "step": 154000
    },
    {
      "epoch": 1.0276296010535697,
      "grad_norm": 0.5082117915153503,
      "learning_rate": 0.00011418546365914788,
      "loss": 2.9101,
      "step": 154500
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.4460030794143677,
      "learning_rate": 0.00011293233082706768,
      "loss": 2.9095,
      "step": 155000
    },
    {
      "epoch": 1.0342809253322336,
      "grad_norm": 0.44778940081596375,
      "learning_rate": 0.00011167919799498748,
      "loss": 2.9097,
      "step": 155500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.5583342909812927,
      "learning_rate": 0.00011042857142857143,
      "loss": 2.907,
      "step": 156000
    },
    {
      "epoch": 1.0376065874715656,
      "eval_loss": 2.9188756942749023,
      "eval_runtime": 136.1376,
      "eval_samples_per_second": 367.276,
      "eval_steps_per_second": 5.744,
      "step": 156000
    },
    {
      "epoch": 1.0409322496108975,
      "grad_norm": 0.5394067764282227,
      "learning_rate": 0.00010917543859649124,
      "loss": 2.9061,
      "step": 156500
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.5220584273338318,
      "learning_rate": 0.00010792230576441104,
      "loss": 2.9033,
      "step": 157000
    },
    {
      "epoch": 1.0475835738895614,
      "grad_norm": 0.4619869589805603,
      "learning_rate": 0.00010666917293233083,
      "loss": 2.9066,
      "step": 157500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.45090511441230774,
      "learning_rate": 0.00010541604010025063,
      "loss": 2.9081,
      "step": 158000
    },
    {
      "epoch": 1.0542348981682252,
      "grad_norm": 0.5054323077201843,
      "learning_rate": 0.00010416541353383459,
      "loss": 2.907,
      "step": 158500
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.5706467032432556,
      "learning_rate": 0.00010291228070175438,
      "loss": 2.903,
      "step": 159000
    },
    {
      "epoch": 1.0608862224468891,
      "grad_norm": 0.4887012243270874,
      "learning_rate": 0.00010165914786967418,
      "loss": 2.9051,
      "step": 159500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.6828362345695496,
      "learning_rate": 0.00010040601503759399,
      "loss": 2.9078,
      "step": 160000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.91200852394104,
      "eval_runtime": 135.862,
      "eval_samples_per_second": 368.02,
      "eval_steps_per_second": 5.756,
      "step": 160000
    },
    {
      "epoch": 1.067537546725553,
      "grad_norm": 0.6106777191162109,
      "learning_rate": 9.915288220551379e-05,
      "loss": 2.9014,
      "step": 160500
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.45103058218955994,
      "learning_rate": 9.790225563909774e-05,
      "loss": 2.9029,
      "step": 161000
    },
    {
      "epoch": 1.074188871004217,
      "grad_norm": 0.5863677859306335,
      "learning_rate": 9.664912280701754e-05,
      "loss": 2.9036,
      "step": 161500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.5100061893463135,
      "learning_rate": 9.539598997493734e-05,
      "loss": 2.902,
      "step": 162000
    },
    {
      "epoch": 1.0808401952828808,
      "grad_norm": 0.5237678289413452,
      "learning_rate": 9.414285714285715e-05,
      "loss": 2.9014,
      "step": 162500
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.4900262653827667,
      "learning_rate": 9.289223057644111e-05,
      "loss": 2.8943,
      "step": 163000
    },
    {
      "epoch": 1.0874915195615447,
      "grad_norm": 0.47104522585868835,
      "learning_rate": 9.163909774436091e-05,
      "loss": 2.9023,
      "step": 163500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.4741963744163513,
      "learning_rate": 9.038596491228071e-05,
      "loss": 2.8982,
      "step": 164000
    },
    {
      "epoch": 1.0908171817008767,
      "eval_loss": 2.906620979309082,
      "eval_runtime": 135.9266,
      "eval_samples_per_second": 367.846,
      "eval_steps_per_second": 5.753,
      "step": 164000
    },
    {
      "epoch": 1.0941428438402085,
      "grad_norm": 0.48910319805145264,
      "learning_rate": 8.91328320802005e-05,
      "loss": 2.8964,
      "step": 164500
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.5144573450088501,
      "learning_rate": 8.78796992481203e-05,
      "loss": 2.8941,
      "step": 165000
    },
    {
      "epoch": 1.1007941681188724,
      "grad_norm": 0.45192039012908936,
      "learning_rate": 8.662907268170427e-05,
      "loss": 2.899,
      "step": 165500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.502281665802002,
      "learning_rate": 8.537593984962406e-05,
      "loss": 2.8967,
      "step": 166000
    },
    {
      "epoch": 1.1074454923975363,
      "grad_norm": 0.4692590832710266,
      "learning_rate": 8.412280701754386e-05,
      "loss": 2.8948,
      "step": 166500
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.4791056215763092,
      "learning_rate": 8.286967418546366e-05,
      "loss": 2.8927,
      "step": 167000
    },
    {
      "epoch": 1.1140968166762002,
      "grad_norm": 0.48694440722465515,
      "learning_rate": 8.161904761904763e-05,
      "loss": 2.8956,
      "step": 167500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.6977211236953735,
      "learning_rate": 8.036591478696742e-05,
      "loss": 2.8951,
      "step": 168000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.9005703926086426,
      "eval_runtime": 136.1345,
      "eval_samples_per_second": 367.284,
      "eval_steps_per_second": 5.744,
      "step": 168000
    },
    {
      "epoch": 1.120748140954864,
      "grad_norm": 0.4571962356567383,
      "learning_rate": 7.911278195488722e-05,
      "loss": 2.8947,
      "step": 168500
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.6007220149040222,
      "learning_rate": 7.785964912280702e-05,
      "loss": 2.8963,
      "step": 169000
    },
    {
      "epoch": 1.127399465233528,
      "grad_norm": 0.4440295696258545,
      "learning_rate": 7.660902255639097e-05,
      "loss": 2.8914,
      "step": 169500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.4573350250720978,
      "learning_rate": 7.535588972431077e-05,
      "loss": 2.8905,
      "step": 170000
    },
    {
      "epoch": 1.1340507895121918,
      "grad_norm": 0.4361580014228821,
      "learning_rate": 7.410275689223058e-05,
      "loss": 2.8903,
      "step": 170500
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.4695655405521393,
      "learning_rate": 7.284962406015038e-05,
      "loss": 2.8919,
      "step": 171000
    },
    {
      "epoch": 1.1407021137908557,
      "grad_norm": 0.46493253111839294,
      "learning_rate": 7.159649122807017e-05,
      "loss": 2.8915,
      "step": 171500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.4759201109409332,
      "learning_rate": 7.034586466165414e-05,
      "loss": 2.888,
      "step": 172000
    },
    {
      "epoch": 1.1440277759301878,
      "eval_loss": 2.895179033279419,
      "eval_runtime": 136.0846,
      "eval_samples_per_second": 367.418,
      "eval_steps_per_second": 5.746,
      "step": 172000
    },
    {
      "epoch": 1.1473534380695196,
      "grad_norm": 0.4464028775691986,
      "learning_rate": 6.909273182957395e-05,
      "loss": 2.8865,
      "step": 172500
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.5284067392349243,
      "learning_rate": 6.783959899749374e-05,
      "loss": 2.884,
      "step": 173000
    },
    {
      "epoch": 1.1540047623481835,
      "grad_norm": 0.49800625443458557,
      "learning_rate": 6.658646616541352e-05,
      "loss": 2.8859,
      "step": 173500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.45887452363967896,
      "learning_rate": 6.533333333333333e-05,
      "loss": 2.8882,
      "step": 174000
    },
    {
      "epoch": 1.1606560866268474,
      "grad_norm": 0.43781954050064087,
      "learning_rate": 6.408020050125313e-05,
      "loss": 2.8854,
      "step": 174500
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.5367883443832397,
      "learning_rate": 6.282706766917293e-05,
      "loss": 2.8779,
      "step": 175000
    },
    {
      "epoch": 1.1673074109055113,
      "grad_norm": 0.6525694131851196,
      "learning_rate": 6.15764411027569e-05,
      "loss": 2.8875,
      "step": 175500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.4831027090549469,
      "learning_rate": 6.032330827067669e-05,
      "loss": 2.8838,
      "step": 176000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.8893184661865234,
      "eval_runtime": 135.9701,
      "eval_samples_per_second": 367.728,
      "eval_steps_per_second": 5.751,
      "step": 176000
    },
    {
      "epoch": 1.1739587351841752,
      "grad_norm": 0.4454297423362732,
      "learning_rate": 5.9070175438596486e-05,
      "loss": 2.8826,
      "step": 176500
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.535982072353363,
      "learning_rate": 5.781704260651629e-05,
      "loss": 2.881,
      "step": 177000
    },
    {
      "epoch": 1.180610059462839,
      "grad_norm": 0.5391727089881897,
      "learning_rate": 5.656641604010025e-05,
      "loss": 2.8796,
      "step": 177500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.4233517348766327,
      "learning_rate": 5.5313283208020055e-05,
      "loss": 2.8797,
      "step": 178000
    },
    {
      "epoch": 1.187261383741503,
      "grad_norm": 0.5042930245399475,
      "learning_rate": 5.406015037593985e-05,
      "loss": 2.8806,
      "step": 178500
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.6011501550674438,
      "learning_rate": 5.280701754385965e-05,
      "loss": 2.8803,
      "step": 179000
    },
    {
      "epoch": 1.1939127080201668,
      "grad_norm": 0.46398472785949707,
      "learning_rate": 5.155388471177945e-05,
      "loss": 2.8784,
      "step": 179500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.45910269021987915,
      "learning_rate": 5.030075187969925e-05,
      "loss": 2.8754,
      "step": 180000
    },
    {
      "epoch": 1.1972383701594986,
      "eval_loss": 2.883765697479248,
      "eval_runtime": 135.9127,
      "eval_samples_per_second": 367.883,
      "eval_steps_per_second": 5.754,
      "step": 180000
    },
    {
      "epoch": 1.2005640322988307,
      "grad_norm": 0.4323672950267792,
      "learning_rate": 4.904761904761905e-05,
      "loss": 2.8734,
      "step": 180500
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.47700178623199463,
      "learning_rate": 4.779448621553885e-05,
      "loss": 2.8802,
      "step": 181000
    },
    {
      "epoch": 1.2072153565774946,
      "grad_norm": 0.451030969619751,
      "learning_rate": 4.6543859649122806e-05,
      "loss": 2.8787,
      "step": 181500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.47890859842300415,
      "learning_rate": 4.529323308270677e-05,
      "loss": 2.873,
      "step": 182000
    },
    {
      "epoch": 1.2138666808561585,
      "grad_norm": 0.43807291984558105,
      "learning_rate": 4.4040100250626565e-05,
      "loss": 2.8728,
      "step": 182500
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.4877769649028778,
      "learning_rate": 4.278696741854637e-05,
      "loss": 2.8706,
      "step": 183000
    },
    {
      "epoch": 1.2205180051348223,
      "grad_norm": 0.5472012758255005,
      "learning_rate": 4.153383458646617e-05,
      "loss": 2.8712,
      "step": 183500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.48860737681388855,
      "learning_rate": 4.0280701754385966e-05,
      "loss": 2.8746,
      "step": 184000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.878875970840454,
      "eval_runtime": 135.9869,
      "eval_samples_per_second": 367.683,
      "eval_steps_per_second": 5.751,
      "step": 184000
    },
    {
      "epoch": 1.2271693294134862,
      "grad_norm": 0.5412521958351135,
      "learning_rate": 3.902756892230577e-05,
      "loss": 2.8727,
      "step": 184500
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.4786868989467621,
      "learning_rate": 3.7774436090225564e-05,
      "loss": 2.8728,
      "step": 185000
    },
    {
      "epoch": 1.23382065369215,
      "grad_norm": 0.4534826874732971,
      "learning_rate": 3.6521303258145366e-05,
      "loss": 2.8712,
      "step": 185500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.4864068329334259,
      "learning_rate": 3.526817042606516e-05,
      "loss": 2.8674,
      "step": 186000
    },
    {
      "epoch": 1.240471977970814,
      "grad_norm": 0.4790690839290619,
      "learning_rate": 3.4015037593984965e-05,
      "loss": 2.8681,
      "step": 186500
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.4941564202308655,
      "learning_rate": 3.276190476190476e-05,
      "loss": 2.8656,
      "step": 187000
    },
    {
      "epoch": 1.2471233022494779,
      "grad_norm": 0.45413896441459656,
      "learning_rate": 3.150877192982456e-05,
      "loss": 2.8691,
      "step": 187500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.596093475818634,
      "learning_rate": 3.0258145363408523e-05,
      "loss": 2.8753,
      "step": 188000
    },
    {
      "epoch": 1.2504489643888097,
      "eval_loss": 2.8742001056671143,
      "eval_runtime": 135.8971,
      "eval_samples_per_second": 367.925,
      "eval_steps_per_second": 5.754,
      "step": 188000
    },
    {
      "epoch": 1.2537746265281418,
      "grad_norm": 0.49756717681884766,
      "learning_rate": 2.9005012531328322e-05,
      "loss": 2.871,
      "step": 188500
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.4587422013282776,
      "learning_rate": 2.775187969924812e-05,
      "loss": 2.8628,
      "step": 189000
    },
    {
      "epoch": 1.2604259508068056,
      "grad_norm": 0.49636146426200867,
      "learning_rate": 2.649874686716792e-05,
      "loss": 2.8658,
      "step": 189500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.4927813708782196,
      "learning_rate": 2.5245614035087722e-05,
      "loss": 2.8649,
      "step": 190000
    },
    {
      "epoch": 1.2670772750854695,
      "grad_norm": 0.4956972301006317,
      "learning_rate": 2.399248120300752e-05,
      "loss": 2.8687,
      "step": 190500
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.4282548725605011,
      "learning_rate": 2.273934837092732e-05,
      "loss": 2.865,
      "step": 191000
    },
    {
      "epoch": 1.2737285993641334,
      "grad_norm": 0.4688011109828949,
      "learning_rate": 2.148621553884712e-05,
      "loss": 2.8618,
      "step": 191500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.4629952311515808,
      "learning_rate": 2.023558897243108e-05,
      "loss": 2.8638,
      "step": 192000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.869723320007324,
      "eval_runtime": 135.9629,
      "eval_samples_per_second": 367.747,
      "eval_steps_per_second": 5.752,
      "step": 192000
    },
    {
      "epoch": 1.2803799236427973,
      "grad_norm": 0.43347328901290894,
      "learning_rate": 1.898245614035088e-05,
      "loss": 2.8589,
      "step": 192500
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.4636514484882355,
      "learning_rate": 1.7729323308270678e-05,
      "loss": 2.862,
      "step": 193000
    },
    {
      "epoch": 1.2870312479214612,
      "grad_norm": 0.4798765778541565,
      "learning_rate": 1.6476190476190477e-05,
      "loss": 2.8633,
      "step": 193500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.47252458333969116,
      "learning_rate": 1.5225563909774435e-05,
      "loss": 2.8653,
      "step": 194000
    },
    {
      "epoch": 1.293682572200125,
      "grad_norm": 0.4901948869228363,
      "learning_rate": 1.3972431077694236e-05,
      "loss": 2.8597,
      "step": 194500
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.48928192257881165,
      "learning_rate": 1.2719298245614035e-05,
      "loss": 2.8581,
      "step": 195000
    },
    {
      "epoch": 1.300333896478789,
      "grad_norm": 0.5308343768119812,
      "learning_rate": 1.1466165413533834e-05,
      "loss": 2.8609,
      "step": 195500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.4767557680606842,
      "learning_rate": 1.0215538847117794e-05,
      "loss": 2.8624,
      "step": 196000
    },
    {
      "epoch": 1.3036595586181208,
      "eval_loss": 2.865924119949341,
      "eval_runtime": 136.0188,
      "eval_samples_per_second": 367.596,
      "eval_steps_per_second": 5.749,
      "step": 196000
    },
    {
      "epoch": 1.3069852207574528,
      "grad_norm": 0.43748337030410767,
      "learning_rate": 8.962406015037593e-06,
      "loss": 2.8587,
      "step": 196500
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.453535258769989,
      "learning_rate": 7.709273182957394e-06,
      "loss": 2.857,
      "step": 197000
    },
    {
      "epoch": 1.3136365450361167,
      "grad_norm": 0.4486870765686035,
      "learning_rate": 6.456140350877193e-06,
      "loss": 2.86,
      "step": 197500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.45859479904174805,
      "learning_rate": 5.205513784461153e-06,
      "loss": 2.8575,
      "step": 198000
    },
    {
      "epoch": 1.3202878693147806,
      "grad_norm": 0.4734078645706177,
      "learning_rate": 3.952380952380952e-06,
      "loss": 2.8582,
      "step": 198500
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.5787110328674316,
      "learning_rate": 2.699248120300752e-06,
      "loss": 2.8552,
      "step": 199000
    },
    {
      "epoch": 1.3269391935934445,
      "grad_norm": 0.48917391896247864,
      "learning_rate": 1.4486215538847119e-06,
      "loss": 2.8544,
      "step": 199500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.4873969852924347,
      "learning_rate": 1.9548872180451126e-07,
      "loss": 2.8568,
      "step": 200000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.863478660583496,
      "eval_runtime": 136.2263,
      "eval_samples_per_second": 367.036,
      "eval_steps_per_second": 5.74,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
