{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 18.250625610351562,
      "learning_rate": 0.000495,
      "loss": 17.5634,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 3.268401861190796,
      "learning_rate": 0.0004987593984962407,
      "loss": 6.5276,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 1.9227445125579834,
      "learning_rate": 0.0004975062656641604,
      "loss": 5.3387,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 1.9178602695465088,
      "learning_rate": 0.0004962531328320802,
      "loss": 4.9223,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 1.2450388669967651,
      "learning_rate": 0.000495,
      "loss": 4.6025,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.8540223836898804,
      "learning_rate": 0.0004937468671679198,
      "loss": 4.3435,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.7744991779327393,
      "learning_rate": 0.0004924937343358396,
      "loss": 4.1159,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.6561726331710815,
      "learning_rate": 0.0004912406015037594,
      "loss": 3.9634,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.9011378288269043,
      "eval_runtime": 65.6687,
      "eval_samples_per_second": 761.398,
      "eval_steps_per_second": 5.954,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.6620280742645264,
      "learning_rate": 0.0004899874686716792,
      "loss": 3.8525,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.5444425344467163,
      "learning_rate": 0.0004887343358395991,
      "loss": 3.7738,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.5423491597175598,
      "learning_rate": 0.0004874812030075188,
      "loss": 3.7081,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.5261217951774597,
      "learning_rate": 0.00048622807017543866,
      "loss": 3.6539,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.5215651392936707,
      "learning_rate": 0.0004849749373433584,
      "loss": 3.6094,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.545432448387146,
      "learning_rate": 0.00048372180451127823,
      "loss": 3.5724,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.47818607091903687,
      "learning_rate": 0.000482468671679198,
      "loss": 3.5313,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.5544637441635132,
      "learning_rate": 0.0004812155388471178,
      "loss": 3.5026,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.487244129180908,
      "eval_runtime": 65.6504,
      "eval_samples_per_second": 761.61,
      "eval_steps_per_second": 5.956,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.5251772403717041,
      "learning_rate": 0.00047996240601503763,
      "loss": 3.4754,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.4961968660354614,
      "learning_rate": 0.0004787142857142857,
      "loss": 3.4652,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.5478475093841553,
      "learning_rate": 0.0004774611528822055,
      "loss": 3.4229,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.49764689803123474,
      "learning_rate": 0.0004762080200501253,
      "loss": 3.4043,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.5617331266403198,
      "learning_rate": 0.00047495488721804516,
      "loss": 3.3854,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.48725736141204834,
      "learning_rate": 0.0004737017543859649,
      "loss": 3.3676,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.5816741585731506,
      "learning_rate": 0.00047244862155388474,
      "loss": 3.3447,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.5513253211975098,
      "learning_rate": 0.0004711954887218045,
      "loss": 3.3304,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.319284677505493,
      "eval_runtime": 65.5286,
      "eval_samples_per_second": 763.026,
      "eval_steps_per_second": 5.967,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.7912794351577759,
      "learning_rate": 0.0004699423558897243,
      "loss": 3.3171,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.5019416809082031,
      "learning_rate": 0.00046868922305764413,
      "loss": 3.305,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.48743292689323425,
      "learning_rate": 0.00046743609022556395,
      "loss": 3.2844,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.5131340622901917,
      "learning_rate": 0.0004661829573934837,
      "loss": 3.2768,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.44189906120300293,
      "learning_rate": 0.0004649298245614035,
      "loss": 3.2645,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.4945898950099945,
      "learning_rate": 0.0004636766917293233,
      "loss": 3.2543,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.48564741015434265,
      "learning_rate": 0.00046242606516290724,
      "loss": 3.2418,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.46329498291015625,
      "learning_rate": 0.00046117293233082705,
      "loss": 3.2349,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.2282721996307373,
      "eval_runtime": 65.7869,
      "eval_samples_per_second": 760.03,
      "eval_steps_per_second": 5.943,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.47268199920654297,
      "learning_rate": 0.00045991979949874687,
      "loss": 3.2242,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.45703017711639404,
      "learning_rate": 0.0004586666666666667,
      "loss": 3.2133,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.43160563707351685,
      "learning_rate": 0.00045741604010025063,
      "loss": 3.2067,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.6309652328491211,
      "learning_rate": 0.00045616290726817045,
      "loss": 3.1921,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.7010542750358582,
      "learning_rate": 0.0004549097744360902,
      "loss": 3.1876,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.4989576041698456,
      "learning_rate": 0.00045365664160401003,
      "loss": 3.1822,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.5747266411781311,
      "learning_rate": 0.00045240350877192984,
      "loss": 3.1688,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.9659748673439026,
      "learning_rate": 0.00045115037593984966,
      "loss": 3.1639,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.160597085952759,
      "eval_runtime": 65.7307,
      "eval_samples_per_second": 760.679,
      "eval_steps_per_second": 5.949,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.576724112033844,
      "learning_rate": 0.0004498972431077694,
      "loss": 3.1584,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.40289753675460815,
      "learning_rate": 0.0004486466165413534,
      "loss": 3.1524,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.6877216100692749,
      "learning_rate": 0.0004473934837092732,
      "loss": 3.1465,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.4369161128997803,
      "learning_rate": 0.000446140350877193,
      "loss": 3.1376,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.43458855152130127,
      "learning_rate": 0.00044488721804511277,
      "loss": 3.1334,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.622962474822998,
      "learning_rate": 0.0004436365914786967,
      "loss": 3.1259,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.5855018496513367,
      "learning_rate": 0.00044238345864661653,
      "loss": 3.1199,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.40682312846183777,
      "learning_rate": 0.00044113032581453635,
      "loss": 3.1136,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.1098875999450684,
      "eval_runtime": 65.7194,
      "eval_samples_per_second": 760.811,
      "eval_steps_per_second": 5.95,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.4365825355052948,
      "learning_rate": 0.0004398796992481203,
      "loss": 3.1099,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.5483603477478027,
      "learning_rate": 0.00043863157894736843,
      "loss": 3.1034,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.6276261210441589,
      "learning_rate": 0.0004373784461152882,
      "loss": 3.098,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.44340524077415466,
      "learning_rate": 0.000436125313283208,
      "loss": 3.0929,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.4119369685649872,
      "learning_rate": 0.00043487218045112783,
      "loss": 3.0867,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.5276899337768555,
      "learning_rate": 0.00043361904761904764,
      "loss": 3.0817,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.4673627018928528,
      "learning_rate": 0.0004323659147869674,
      "loss": 3.0793,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.646015465259552,
      "learning_rate": 0.0004311127819548872,
      "loss": 3.0725,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.0691144466400146,
      "eval_runtime": 65.7333,
      "eval_samples_per_second": 760.65,
      "eval_steps_per_second": 5.948,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.4773637056350708,
      "learning_rate": 0.000429859649122807,
      "loss": 3.0716,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.49277395009994507,
      "learning_rate": 0.00042860651629072685,
      "loss": 3.0677,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.41319745779037476,
      "learning_rate": 0.0004273533834586466,
      "loss": 3.0629,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.5168889760971069,
      "learning_rate": 0.00042610025062656643,
      "loss": 3.0561,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.4610770046710968,
      "learning_rate": 0.0004248471177944862,
      "loss": 3.0509,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.48921847343444824,
      "learning_rate": 0.000423593984962406,
      "loss": 3.0461,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.5426788330078125,
      "learning_rate": 0.0004223408521303258,
      "loss": 3.0435,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.39762604236602783,
      "learning_rate": 0.00042108771929824564,
      "loss": 3.0424,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.035984992980957,
      "eval_runtime": 65.7542,
      "eval_samples_per_second": 760.407,
      "eval_steps_per_second": 5.946,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.6020992994308472,
      "learning_rate": 0.0004198345864661654,
      "loss": 3.0352,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.4367969334125519,
      "learning_rate": 0.0004185814536340852,
      "loss": 3.0335,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.395092636346817,
      "learning_rate": 0.000417328320802005,
      "loss": 3.0256,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.4288499653339386,
      "learning_rate": 0.00041607518796992485,
      "loss": 3.0248,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.4688335359096527,
      "learning_rate": 0.0004148220551378446,
      "loss": 3.0242,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.3924867510795593,
      "learning_rate": 0.00041356892230576443,
      "loss": 3.0185,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.4721183180809021,
      "learning_rate": 0.0004123157894736842,
      "loss": 3.0144,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.42112499475479126,
      "learning_rate": 0.000411062656641604,
      "loss": 3.0114,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 3.008147716522217,
      "eval_runtime": 65.818,
      "eval_samples_per_second": 759.671,
      "eval_steps_per_second": 5.941,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.40001416206359863,
      "learning_rate": 0.0004098095238095238,
      "loss": 3.0077,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.5007827877998352,
      "learning_rate": 0.0004085588972431078,
      "loss": 3.0053,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.49378350377082825,
      "learning_rate": 0.0004073057644110276,
      "loss": 2.9999,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.4001918137073517,
      "learning_rate": 0.0004060576441102757,
      "loss": 3.0016,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.3816278874874115,
      "learning_rate": 0.0004048045112781955,
      "loss": 2.9981,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.42928552627563477,
      "learning_rate": 0.0004035513784461153,
      "loss": 2.9915,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.47364819049835205,
      "learning_rate": 0.0004022982456140351,
      "loss": 2.9921,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.4102801978588104,
      "learning_rate": 0.0004010451127819549,
      "loss": 2.9893,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 2.983691930770874,
      "eval_runtime": 65.6937,
      "eval_samples_per_second": 761.108,
      "eval_steps_per_second": 5.952,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.4036586582660675,
      "learning_rate": 0.0003997944862155389,
      "loss": 2.9852,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.45382386445999146,
      "learning_rate": 0.00039854135338345865,
      "loss": 2.9824,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.5423381328582764,
      "learning_rate": 0.00039728822055137847,
      "loss": 2.9811,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.42313891649246216,
      "learning_rate": 0.00039603508771929823,
      "loss": 2.9746,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.451820969581604,
      "learning_rate": 0.0003947819548872181,
      "loss": 2.9762,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.4094482958316803,
      "learning_rate": 0.000393531328320802,
      "loss": 2.9708,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.4099214971065521,
      "learning_rate": 0.0003922781954887218,
      "loss": 2.9689,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.37056055665016174,
      "learning_rate": 0.0003910250626566416,
      "loss": 2.9628,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 2.9630966186523438,
      "eval_runtime": 65.6263,
      "eval_samples_per_second": 761.89,
      "eval_steps_per_second": 5.958,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.504743218421936,
      "learning_rate": 0.0003897719298245614,
      "loss": 2.9666,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.42722731828689575,
      "learning_rate": 0.0003885187969924812,
      "loss": 2.9613,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.5323713421821594,
      "learning_rate": 0.00038726566416040096,
      "loss": 2.9552,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.38650432229042053,
      "learning_rate": 0.00038601503759398497,
      "loss": 2.9557,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.3953193724155426,
      "learning_rate": 0.00038476190476190473,
      "loss": 2.9524,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.3947380483150482,
      "learning_rate": 0.0003835087719298246,
      "loss": 2.9454,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.38948652148246765,
      "learning_rate": 0.00038225563909774436,
      "loss": 2.9493,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.5000821352005005,
      "learning_rate": 0.00038100751879699245,
      "loss": 2.9458,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 2.943378210067749,
      "eval_runtime": 65.6098,
      "eval_samples_per_second": 762.081,
      "eval_steps_per_second": 5.959,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.41533246636390686,
      "learning_rate": 0.0003797543859649123,
      "loss": 2.9448,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.38025030493736267,
      "learning_rate": 0.0003785012531328321,
      "loss": 2.9402,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.3948041796684265,
      "learning_rate": 0.0003772481203007519,
      "loss": 2.9399,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.40078333020210266,
      "learning_rate": 0.00037599498746867166,
      "loss": 2.9365,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.405072420835495,
      "learning_rate": 0.00037474436090225566,
      "loss": 2.9341,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.36211296916007996,
      "learning_rate": 0.0003734912280701754,
      "loss": 2.9303,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.3995010256767273,
      "learning_rate": 0.00037223809523809524,
      "loss": 2.9337,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.6082280874252319,
      "learning_rate": 0.00037098496240601505,
      "loss": 2.9282,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 2.924513339996338,
      "eval_runtime": 65.6802,
      "eval_samples_per_second": 761.264,
      "eval_steps_per_second": 5.953,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.3949277400970459,
      "learning_rate": 0.00036973182957393487,
      "loss": 2.9247,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.5321208238601685,
      "learning_rate": 0.00036847869674185463,
      "loss": 2.9224,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.39927735924720764,
      "learning_rate": 0.00036722556390977445,
      "loss": 2.9201,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.47340649366378784,
      "learning_rate": 0.0003659724310776942,
      "loss": 2.9208,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.40287142992019653,
      "learning_rate": 0.0003647192982456141,
      "loss": 2.919,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.35924431681632996,
      "learning_rate": 0.00036346616541353384,
      "loss": 2.9147,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.40575647354125977,
      "learning_rate": 0.00036221303258145366,
      "loss": 2.913,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.3995710611343384,
      "learning_rate": 0.0003609598997493734,
      "loss": 2.9126,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 2.9105095863342285,
      "eval_runtime": 65.5425,
      "eval_samples_per_second": 762.864,
      "eval_steps_per_second": 5.966,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.4570884704589844,
      "learning_rate": 0.00035970676691729324,
      "loss": 2.9089,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.48321402072906494,
      "learning_rate": 0.00035845363408521305,
      "loss": 2.9088,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.42807087302207947,
      "learning_rate": 0.00035720050125313287,
      "loss": 2.904,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.38394883275032043,
      "learning_rate": 0.0003559498746867168,
      "loss": 2.9031,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.5326892137527466,
      "learning_rate": 0.0003546967418546366,
      "loss": 2.9039,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.4181937277317047,
      "learning_rate": 0.0003534436090225564,
      "loss": 2.9012,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.396058589220047,
      "learning_rate": 0.00035219047619047616,
      "loss": 2.8979,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.47285088896751404,
      "learning_rate": 0.00035093984962406016,
      "loss": 2.8974,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 2.895164728164673,
      "eval_runtime": 65.6902,
      "eval_samples_per_second": 761.149,
      "eval_steps_per_second": 5.952,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.5633140802383423,
      "learning_rate": 0.0003496867167919799,
      "loss": 2.8974,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.3751356303691864,
      "learning_rate": 0.0003484335839598998,
      "loss": 2.8936,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.39082083106040955,
      "learning_rate": 0.00034718045112781956,
      "loss": 2.8914,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.4279535710811615,
      "learning_rate": 0.00034592731829573937,
      "loss": 2.8904,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.4618538022041321,
      "learning_rate": 0.00034467418546365913,
      "loss": 2.889,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.39539164304733276,
      "learning_rate": 0.00034342105263157895,
      "loss": 2.8865,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.39848223328590393,
      "learning_rate": 0.0003421704260651629,
      "loss": 2.8861,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.38437363505363464,
      "learning_rate": 0.0003409172932330827,
      "loss": 2.8863,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.8806588649749756,
      "eval_runtime": 65.5346,
      "eval_samples_per_second": 762.955,
      "eval_steps_per_second": 5.966,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.5103407502174377,
      "learning_rate": 0.00033966416040100253,
      "loss": 2.8826,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.4269680380821228,
      "learning_rate": 0.00033841102756892235,
      "loss": 2.88,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.47720274329185486,
      "learning_rate": 0.0003371578947368421,
      "loss": 2.8787,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.3742133378982544,
      "learning_rate": 0.0003359047619047619,
      "loss": 2.8773,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.4052673280239105,
      "learning_rate": 0.0003346516290726817,
      "loss": 2.8748,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.48173898458480835,
      "learning_rate": 0.00033339849624060156,
      "loss": 2.8712,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.566385805606842,
      "learning_rate": 0.0003321578947368421,
      "loss": 2.8773,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.3973683714866638,
      "learning_rate": 0.0003309047619047619,
      "loss": 2.8692,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.8678011894226074,
      "eval_runtime": 65.5682,
      "eval_samples_per_second": 762.565,
      "eval_steps_per_second": 5.963,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.4082339406013489,
      "learning_rate": 0.00032965162907268173,
      "loss": 2.8706,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.3849464952945709,
      "learning_rate": 0.00032839849624060154,
      "loss": 2.8714,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.3857268989086151,
      "learning_rate": 0.0003271453634085213,
      "loss": 2.8682,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.4295286536216736,
      "learning_rate": 0.0003258922305764411,
      "loss": 2.8673,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.374897837638855,
      "learning_rate": 0.0003246390977443609,
      "loss": 2.8639,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.346322625875473,
      "learning_rate": 0.00032338596491228075,
      "loss": 2.865,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.3802954852581024,
      "learning_rate": 0.0003221328320802005,
      "loss": 2.8637,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.37867775559425354,
      "learning_rate": 0.00032087969924812033,
      "loss": 2.8573,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.8582231998443604,
      "eval_runtime": 66.7558,
      "eval_samples_per_second": 748.998,
      "eval_steps_per_second": 5.857,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.36845579743385315,
      "learning_rate": 0.0003196265664160401,
      "loss": 2.8586,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.41646742820739746,
      "learning_rate": 0.0003183734335839599,
      "loss": 2.8569,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.3919699192047119,
      "learning_rate": 0.00031712030075187967,
      "loss": 2.8526,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.36855414509773254,
      "learning_rate": 0.00031586716791979954,
      "loss": 2.8555,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.515760600566864,
      "learning_rate": 0.0003146165413533835,
      "loss": 2.8532,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.4096037745475769,
      "learning_rate": 0.00031336340852130325,
      "loss": 2.851,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.36555567383766174,
      "learning_rate": 0.00031211027568922307,
      "loss": 2.8372,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.4501456022262573,
      "learning_rate": 0.00031085714285714283,
      "loss": 2.8301,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.8445639610290527,
      "eval_runtime": 65.6427,
      "eval_samples_per_second": 761.699,
      "eval_steps_per_second": 5.956,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.5643941760063171,
      "learning_rate": 0.00030960401002506265,
      "loss": 2.8295,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.44403737783432007,
      "learning_rate": 0.00030835087719298246,
      "loss": 2.8291,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.35345658659935,
      "learning_rate": 0.0003070977443609023,
      "loss": 2.8268,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.45314452052116394,
      "learning_rate": 0.00030584461152882204,
      "loss": 2.8256,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.535014271736145,
      "learning_rate": 0.00030459147869674186,
      "loss": 2.8235,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.48920390009880066,
      "learning_rate": 0.0003033383458646616,
      "loss": 2.8272,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.3995424807071686,
      "learning_rate": 0.0003020852130325815,
      "loss": 2.8234,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.5161363482475281,
      "learning_rate": 0.00030083208020050125,
      "loss": 2.826,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.8353464603424072,
      "eval_runtime": 65.5748,
      "eval_samples_per_second": 762.488,
      "eval_steps_per_second": 5.963,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.3404408395290375,
      "learning_rate": 0.00029957894736842107,
      "loss": 2.822,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.5345426797866821,
      "learning_rate": 0.00029832581453634083,
      "loss": 2.8231,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.3914720416069031,
      "learning_rate": 0.00029707268170426065,
      "loss": 2.8191,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.4873937666416168,
      "learning_rate": 0.0002958195488721804,
      "loss": 2.821,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.5928813219070435,
      "learning_rate": 0.0002945664160401003,
      "loss": 2.8176,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.4999792277812958,
      "learning_rate": 0.00029331578947368423,
      "loss": 2.819,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.45385318994522095,
      "learning_rate": 0.00029206265664160404,
      "loss": 2.8175,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.5041707158088684,
      "learning_rate": 0.0002908095238095238,
      "loss": 2.8172,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.8254172801971436,
      "eval_runtime": 65.5367,
      "eval_samples_per_second": 762.931,
      "eval_steps_per_second": 5.966,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.3896503150463104,
      "learning_rate": 0.0002895563909774436,
      "loss": 2.8176,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.3718748986721039,
      "learning_rate": 0.00028830576441102757,
      "loss": 2.8143,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.3872346580028534,
      "learning_rate": 0.0002870526315789474,
      "loss": 2.8156,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.34848225116729736,
      "learning_rate": 0.00028579949874686715,
      "loss": 2.8139,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.3954845070838928,
      "learning_rate": 0.000284546365914787,
      "loss": 2.8096,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.40796422958374023,
      "learning_rate": 0.0002832957393483709,
      "loss": 2.8118,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.35123342275619507,
      "learning_rate": 0.00028204260651629073,
      "loss": 2.8065,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.36216846108436584,
      "learning_rate": 0.00028078947368421055,
      "loss": 2.81,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.816941022872925,
      "eval_runtime": 65.683,
      "eval_samples_per_second": 761.232,
      "eval_steps_per_second": 5.953,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.5663700699806213,
      "learning_rate": 0.0002795363408521303,
      "loss": 2.8075,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.4571511745452881,
      "learning_rate": 0.0002782832080200501,
      "loss": 2.8057,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.3683861196041107,
      "learning_rate": 0.0002770375939849624,
      "loss": 2.8069,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.3886650502681732,
      "learning_rate": 0.0002757844611528822,
      "loss": 2.8039,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.38357749581336975,
      "learning_rate": 0.00027453132832080203,
      "loss": 2.8027,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.3844543993473053,
      "learning_rate": 0.0002732781954887218,
      "loss": 2.8012,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.5088574886322021,
      "learning_rate": 0.0002720250626566416,
      "loss": 2.8,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.3534376621246338,
      "learning_rate": 0.00027077192982456137,
      "loss": 2.8,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.807445526123047,
      "eval_runtime": 65.6572,
      "eval_samples_per_second": 761.531,
      "eval_steps_per_second": 5.955,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.3618190586566925,
      "learning_rate": 0.00026951879699248124,
      "loss": 2.802,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.427160382270813,
      "learning_rate": 0.000268265664160401,
      "loss": 2.7983,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.39699265360832214,
      "learning_rate": 0.0002670125313283208,
      "loss": 2.7957,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.35391902923583984,
      "learning_rate": 0.0002657593984962406,
      "loss": 2.7995,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.439194917678833,
      "learning_rate": 0.0002645087719298246,
      "loss": 2.7958,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.3788851499557495,
      "learning_rate": 0.00026325563909774434,
      "loss": 2.7947,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.46686607599258423,
      "learning_rate": 0.0002620025062656642,
      "loss": 2.7953,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.3590962588787079,
      "learning_rate": 0.000260749373433584,
      "loss": 2.7917,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.7994725704193115,
      "eval_runtime": 65.5607,
      "eval_samples_per_second": 762.652,
      "eval_steps_per_second": 5.964,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.4646049737930298,
      "learning_rate": 0.0002594962406015038,
      "loss": 2.7893,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.39900627732276917,
      "learning_rate": 0.00025824310776942355,
      "loss": 2.7936,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.3625752925872803,
      "learning_rate": 0.00025698997493734337,
      "loss": 2.7883,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.33795368671417236,
      "learning_rate": 0.00025573684210526313,
      "loss": 2.7898,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.3959719240665436,
      "learning_rate": 0.000254483709273183,
      "loss": 2.7864,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.36410942673683167,
      "learning_rate": 0.00025323308270676695,
      "loss": 2.7869,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.35501670837402344,
      "learning_rate": 0.0002519799498746867,
      "loss": 2.7855,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.35380175709724426,
      "learning_rate": 0.00025072681704260653,
      "loss": 2.7848,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.791719436645508,
      "eval_runtime": 66.1083,
      "eval_samples_per_second": 756.335,
      "eval_steps_per_second": 5.915,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.3343964219093323,
      "learning_rate": 0.00024947368421052635,
      "loss": 2.7807,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.48588502407073975,
      "learning_rate": 0.00024822305764411024,
      "loss": 2.7825,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.3525071144104004,
      "learning_rate": 0.00024696992481203006,
      "loss": 2.7822,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.39062395691871643,
      "learning_rate": 0.0002457167919799499,
      "loss": 2.7795,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.40128999948501587,
      "learning_rate": 0.0002444636591478697,
      "loss": 2.78,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.5577768087387085,
      "learning_rate": 0.00024321303258145364,
      "loss": 2.7779,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.4451453685760498,
      "learning_rate": 0.00024195989974937343,
      "loss": 2.7781,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.3535541594028473,
      "learning_rate": 0.00024070676691729324,
      "loss": 2.7755,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 2.7832963466644287,
      "eval_runtime": 65.541,
      "eval_samples_per_second": 762.881,
      "eval_steps_per_second": 5.966,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.46866145730018616,
      "learning_rate": 0.00023945363408521303,
      "loss": 2.7779,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.39303091168403625,
      "learning_rate": 0.00023820050125313282,
      "loss": 2.7726,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.4137360751628876,
      "learning_rate": 0.0002369498746867168,
      "loss": 2.7709,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.40775981545448303,
      "learning_rate": 0.00023569674185463661,
      "loss": 2.7726,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.3998144268989563,
      "learning_rate": 0.0002344436090225564,
      "loss": 2.773,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.5329558849334717,
      "learning_rate": 0.0002331904761904762,
      "loss": 2.7707,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.34523898363113403,
      "learning_rate": 0.000231937343358396,
      "loss": 2.7716,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.5763334035873413,
      "learning_rate": 0.00023068671679197996,
      "loss": 2.7685,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 2.775177240371704,
      "eval_runtime": 65.7269,
      "eval_samples_per_second": 760.723,
      "eval_steps_per_second": 5.949,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.3764604330062866,
      "learning_rate": 0.0002294360902255639,
      "loss": 2.7684,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.3558729588985443,
      "learning_rate": 0.00022818295739348372,
      "loss": 2.767,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.48814675211906433,
      "learning_rate": 0.0002269298245614035,
      "loss": 2.7641,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.36789101362228394,
      "learning_rate": 0.0002256766917293233,
      "loss": 2.7689,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.37030595541000366,
      "learning_rate": 0.00022442355889724312,
      "loss": 2.7637,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.3678591251373291,
      "learning_rate": 0.0002231729323308271,
      "loss": 2.7659,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.3918779194355011,
      "learning_rate": 0.00022191979949874688,
      "loss": 2.7638,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.3606208562850952,
      "learning_rate": 0.00022066666666666667,
      "loss": 2.7622,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 2.7680296897888184,
      "eval_runtime": 65.7739,
      "eval_samples_per_second": 760.18,
      "eval_steps_per_second": 5.945,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.36212244629859924,
      "learning_rate": 0.0002194135338345865,
      "loss": 2.7617,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.3780193030834198,
      "learning_rate": 0.00021816040100250628,
      "loss": 2.7606,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.36505237221717834,
      "learning_rate": 0.0002169072681704261,
      "loss": 2.7608,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.33775243163108826,
      "learning_rate": 0.00021565413533834588,
      "loss": 2.7593,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.37851977348327637,
      "learning_rate": 0.00021440100250626567,
      "loss": 2.7594,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.4872801601886749,
      "learning_rate": 0.0002131478696741855,
      "loss": 2.7547,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.38332313299179077,
      "learning_rate": 0.0002118972431077694,
      "loss": 2.7574,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.37168025970458984,
      "learning_rate": 0.00021064411027568923,
      "loss": 2.756,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 2.7605996131896973,
      "eval_runtime": 65.645,
      "eval_samples_per_second": 761.673,
      "eval_steps_per_second": 5.956,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.40183037519454956,
      "learning_rate": 0.00020939097744360902,
      "loss": 2.7578,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.36332079768180847,
      "learning_rate": 0.00020813784461152883,
      "loss": 2.7541,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.34446391463279724,
      "learning_rate": 0.00020688721804511278,
      "loss": 2.7528,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.35097646713256836,
      "learning_rate": 0.0002056340852130326,
      "loss": 2.7527,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.4029129147529602,
      "learning_rate": 0.00020438095238095239,
      "loss": 2.7535,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.36238640546798706,
      "learning_rate": 0.0002031278195488722,
      "loss": 2.7506,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.3726668953895569,
      "learning_rate": 0.000201874686716792,
      "loss": 2.7504,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.35264575481414795,
      "learning_rate": 0.00020062155388471178,
      "loss": 2.7503,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 2.75342059135437,
      "eval_runtime": 65.6253,
      "eval_samples_per_second": 761.901,
      "eval_steps_per_second": 5.958,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.39579808712005615,
      "learning_rate": 0.00019937092731829573,
      "loss": 2.7474,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.3311944603919983,
      "learning_rate": 0.00019811779448621552,
      "loss": 2.7497,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.35839998722076416,
      "learning_rate": 0.00019686466165413533,
      "loss": 2.7454,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.4034605622291565,
      "learning_rate": 0.0001956140350877193,
      "loss": 2.7468,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.3636569380760193,
      "learning_rate": 0.0001943609022556391,
      "loss": 2.747,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.34315356612205505,
      "learning_rate": 0.0001931077694235589,
      "loss": 2.7418,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.3813273310661316,
      "learning_rate": 0.0001918546365914787,
      "loss": 2.7462,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.39435431361198425,
      "learning_rate": 0.0001906015037593985,
      "loss": 2.7433,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 2.7472052574157715,
      "eval_runtime": 65.7352,
      "eval_samples_per_second": 760.628,
      "eval_steps_per_second": 5.948,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.3555227518081665,
      "learning_rate": 0.0001893483709273183,
      "loss": 2.7409,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.39995819330215454,
      "learning_rate": 0.0001880952380952381,
      "loss": 2.74,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.39164862036705017,
      "learning_rate": 0.0001868421052631579,
      "loss": 2.7385,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.36791566014289856,
      "learning_rate": 0.0001855889724310777,
      "loss": 2.7405,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.42369145154953003,
      "learning_rate": 0.0001843358395989975,
      "loss": 2.7371,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.36638107895851135,
      "learning_rate": 0.00018308521303258147,
      "loss": 2.7394,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.3689916431903839,
      "learning_rate": 0.00018183208020050126,
      "loss": 2.7362,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.3498673737049103,
      "learning_rate": 0.00018057894736842108,
      "loss": 2.7355,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 2.740556001663208,
      "eval_runtime": 65.6094,
      "eval_samples_per_second": 762.086,
      "eval_steps_per_second": 5.96,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.3887746334075928,
      "learning_rate": 0.00017932581453634086,
      "loss": 2.7361,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.3544365167617798,
      "learning_rate": 0.00017807518796992481,
      "loss": 2.7353,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.3660636842250824,
      "learning_rate": 0.0001768220551378446,
      "loss": 2.7362,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.40071383118629456,
      "learning_rate": 0.00017556892230576442,
      "loss": 2.7321,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.5196642875671387,
      "learning_rate": 0.00017431829573934837,
      "loss": 2.7284,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.34810519218444824,
      "learning_rate": 0.00017306516290726818,
      "loss": 2.7305,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.36464351415634155,
      "learning_rate": 0.00017181203007518797,
      "loss": 2.7297,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.3557049036026001,
      "learning_rate": 0.00017055889724310776,
      "loss": 2.7289,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 2.734233856201172,
      "eval_runtime": 66.7027,
      "eval_samples_per_second": 749.595,
      "eval_steps_per_second": 5.862,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.36353686451911926,
      "learning_rate": 0.00016930576441102758,
      "loss": 2.7266,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.33701956272125244,
      "learning_rate": 0.00016805263157894737,
      "loss": 2.7272,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.3626628816127777,
      "learning_rate": 0.00016679949874686718,
      "loss": 2.7277,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.38372159004211426,
      "learning_rate": 0.00016554636591478697,
      "loss": 2.7262,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.3416692912578583,
      "learning_rate": 0.00016429323308270676,
      "loss": 2.7269,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.3602693974971771,
      "learning_rate": 0.00016304260651629074,
      "loss": 2.7275,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.41130462288856506,
      "learning_rate": 0.00016178947368421055,
      "loss": 2.7251,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.3991070091724396,
      "learning_rate": 0.00016053634085213034,
      "loss": 2.7218,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 2.7285304069519043,
      "eval_runtime": 65.6315,
      "eval_samples_per_second": 761.83,
      "eval_steps_per_second": 5.958,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.3723570704460144,
      "learning_rate": 0.00015928320802005013,
      "loss": 2.7222,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.36241838335990906,
      "learning_rate": 0.00015803258145363408,
      "loss": 2.7224,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.42686042189598083,
      "learning_rate": 0.00015677944862155387,
      "loss": 2.7205,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.35864773392677307,
      "learning_rate": 0.0001555263157894737,
      "loss": 2.7199,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.33289164304733276,
      "learning_rate": 0.00015427318295739348,
      "loss": 2.719,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.4642522633075714,
      "learning_rate": 0.0001530200501253133,
      "loss": 2.7226,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.37152621150016785,
      "learning_rate": 0.00015176691729323308,
      "loss": 2.7164,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.34285086393356323,
      "learning_rate": 0.00015051378446115287,
      "loss": 2.7179,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 2.721445083618164,
      "eval_runtime": 65.5477,
      "eval_samples_per_second": 762.804,
      "eval_steps_per_second": 5.965,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.4132268726825714,
      "learning_rate": 0.00014926065162907269,
      "loss": 2.7184,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.369078665971756,
      "learning_rate": 0.00014801002506265666,
      "loss": 2.7161,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.3725782334804535,
      "learning_rate": 0.00014675689223057645,
      "loss": 2.7158,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.35908979177474976,
      "learning_rate": 0.00014550375939849624,
      "loss": 2.7126,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.3718813359737396,
      "learning_rate": 0.00014425062656641606,
      "loss": 2.7145,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.3694252669811249,
      "learning_rate": 0.00014299999999999998,
      "loss": 2.711,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.3537362813949585,
      "learning_rate": 0.0001417468671679198,
      "loss": 2.7132,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.3693881630897522,
      "learning_rate": 0.00014049373433583958,
      "loss": 2.7118,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 2.715388059616089,
      "eval_runtime": 65.5444,
      "eval_samples_per_second": 762.842,
      "eval_steps_per_second": 5.965,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.34157678484916687,
      "learning_rate": 0.0001392406015037594,
      "loss": 2.7107,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.39708974957466125,
      "learning_rate": 0.00013798997493734335,
      "loss": 2.7115,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.3467925786972046,
      "learning_rate": 0.00013673684210526317,
      "loss": 2.713,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.41966700553894043,
      "learning_rate": 0.00013548370927318296,
      "loss": 2.7091,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.35121968388557434,
      "learning_rate": 0.00013423057644110277,
      "loss": 2.7072,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.3588290810585022,
      "learning_rate": 0.00013297744360902256,
      "loss": 2.7078,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.38201704621315,
      "learning_rate": 0.00013172681704260654,
      "loss": 2.7074,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.3707919120788574,
      "learning_rate": 0.00013047368421052633,
      "loss": 2.705,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 2.709589958190918,
      "eval_runtime": 65.6531,
      "eval_samples_per_second": 761.579,
      "eval_steps_per_second": 5.956,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.3985368013381958,
      "learning_rate": 0.00012922055137844611,
      "loss": 2.7052,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.36795637011528015,
      "learning_rate": 0.00012796741854636593,
      "loss": 2.7042,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.3665353059768677,
      "learning_rate": 0.00012671428571428572,
      "loss": 2.7018,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.3657040297985077,
      "learning_rate": 0.00012546115288220554,
      "loss": 2.7036,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.36361658573150635,
      "learning_rate": 0.00012421052631578949,
      "loss": 2.6973,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.3851342797279358,
      "learning_rate": 0.00012295739348370927,
      "loss": 2.6798,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.3751385807991028,
      "learning_rate": 0.00012170426065162908,
      "loss": 2.6805,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.4026876389980316,
      "learning_rate": 0.00012045112781954888,
      "loss": 2.6759,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 2.7052366733551025,
      "eval_runtime": 65.6446,
      "eval_samples_per_second": 761.677,
      "eval_steps_per_second": 5.956,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.3614616096019745,
      "learning_rate": 0.00011919799498746868,
      "loss": 2.6792,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.37380850315093994,
      "learning_rate": 0.00011794486215538848,
      "loss": 2.6772,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.3810529112815857,
      "learning_rate": 0.00011669172932330827,
      "loss": 2.6797,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.4103080928325653,
      "learning_rate": 0.00011543859649122808,
      "loss": 2.6779,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.36416661739349365,
      "learning_rate": 0.00011418796992481204,
      "loss": 2.6799,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.36413687467575073,
      "learning_rate": 0.00011293483709273183,
      "loss": 2.6766,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.3829492926597595,
      "learning_rate": 0.00011168170426065163,
      "loss": 2.6771,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.3790566623210907,
      "learning_rate": 0.00011042857142857143,
      "loss": 2.6762,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 2.700080633163452,
      "eval_runtime": 65.6054,
      "eval_samples_per_second": 762.132,
      "eval_steps_per_second": 5.96,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.34533944725990295,
      "learning_rate": 0.00010917543859649124,
      "loss": 2.6765,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.3835839331150055,
      "learning_rate": 0.00010792230576441104,
      "loss": 2.6749,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.35224205255508423,
      "learning_rate": 0.00010666917293233083,
      "loss": 2.6763,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.3676272928714752,
      "learning_rate": 0.00010541854636591479,
      "loss": 2.6751,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.3771659731864929,
      "learning_rate": 0.00010416541353383459,
      "loss": 2.6731,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.35771238803863525,
      "learning_rate": 0.00010291228070175438,
      "loss": 2.6727,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.37295258045196533,
      "learning_rate": 0.00010165914786967418,
      "loss": 2.6741,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.3791646957397461,
      "learning_rate": 0.00010040601503759399,
      "loss": 2.6729,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 2.6953516006469727,
      "eval_runtime": 65.681,
      "eval_samples_per_second": 761.255,
      "eval_steps_per_second": 5.953,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.42332056164741516,
      "learning_rate": 9.915288220551379e-05,
      "loss": 2.6732,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.46269211173057556,
      "learning_rate": 9.789974937343359e-05,
      "loss": 2.6729,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.350329726934433,
      "learning_rate": 9.664661654135338e-05,
      "loss": 2.6717,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.3814627230167389,
      "learning_rate": 9.539598997493734e-05,
      "loss": 2.6699,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.3532300591468811,
      "learning_rate": 9.414285714285715e-05,
      "loss": 2.6715,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.38899344205856323,
      "learning_rate": 9.288972431077694e-05,
      "loss": 2.6676,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.4015907347202301,
      "learning_rate": 9.163659147869674e-05,
      "loss": 2.6661,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.3575168550014496,
      "learning_rate": 9.038596491228071e-05,
      "loss": 2.6697,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 2.6907737255096436,
      "eval_runtime": 65.5616,
      "eval_samples_per_second": 762.641,
      "eval_steps_per_second": 5.964,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.3756255805492401,
      "learning_rate": 8.913533834586466e-05,
      "loss": 2.6685,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.3825206160545349,
      "learning_rate": 8.788220551378447e-05,
      "loss": 2.6668,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.3557768166065216,
      "learning_rate": 8.662907268170427e-05,
      "loss": 2.6671,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.345070481300354,
      "learning_rate": 8.537593984962406e-05,
      "loss": 2.664,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.4139256477355957,
      "learning_rate": 8.412280701754386e-05,
      "loss": 2.6689,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.37782588601112366,
      "learning_rate": 8.286967418546366e-05,
      "loss": 2.6649,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.38592860102653503,
      "learning_rate": 8.161654135338347e-05,
      "loss": 2.6672,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.3528195917606354,
      "learning_rate": 8.036340852130327e-05,
      "loss": 2.6628,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 2.6849868297576904,
      "eval_runtime": 65.6711,
      "eval_samples_per_second": 761.37,
      "eval_steps_per_second": 5.954,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.36283355951309204,
      "learning_rate": 7.911278195488722e-05,
      "loss": 2.6633,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.3832107484340668,
      "learning_rate": 7.785964912280702e-05,
      "loss": 2.665,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.35072124004364014,
      "learning_rate": 7.660651629072682e-05,
      "loss": 2.6634,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.3586668074131012,
      "learning_rate": 7.535588972431077e-05,
      "loss": 2.6638,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.3796570301055908,
      "learning_rate": 7.410275689223058e-05,
      "loss": 2.6618,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.35588279366493225,
      "learning_rate": 7.284962406015038e-05,
      "loss": 2.6593,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.36228451132774353,
      "learning_rate": 7.159649122807017e-05,
      "loss": 2.6592,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.3635830581188202,
      "learning_rate": 7.034335839598997e-05,
      "loss": 2.66,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 2.680266857147217,
      "eval_runtime": 65.696,
      "eval_samples_per_second": 761.081,
      "eval_steps_per_second": 5.952,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.4020514190196991,
      "learning_rate": 6.909022556390977e-05,
      "loss": 2.6591,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.36333537101745605,
      "learning_rate": 6.783709273182957e-05,
      "loss": 2.66,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.37943515181541443,
      "learning_rate": 6.658395989974938e-05,
      "loss": 2.6618,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.3645075261592865,
      "learning_rate": 6.533333333333333e-05,
      "loss": 2.6574,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.36123234033584595,
      "learning_rate": 6.408020050125313e-05,
      "loss": 2.6602,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.36192306876182556,
      "learning_rate": 6.282706766917293e-05,
      "loss": 2.6553,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.3526756465435028,
      "learning_rate": 6.157393483709273e-05,
      "loss": 2.6572,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.3432188630104065,
      "learning_rate": 6.032330827067669e-05,
      "loss": 2.6586,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.6757490634918213,
      "eval_runtime": 65.7054,
      "eval_samples_per_second": 760.973,
      "eval_steps_per_second": 5.951,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.3996213376522064,
      "learning_rate": 5.9070175438596486e-05,
      "loss": 2.6563,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.3843194842338562,
      "learning_rate": 5.781704260651629e-05,
      "loss": 2.6538,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.39428675174713135,
      "learning_rate": 5.656390977443609e-05,
      "loss": 2.6528,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.35372433066368103,
      "learning_rate": 5.5313283208020055e-05,
      "loss": 2.6547,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.359332799911499,
      "learning_rate": 5.406015037593985e-05,
      "loss": 2.6539,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.3612329065799713,
      "learning_rate": 5.280701754385965e-05,
      "loss": 2.6529,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.35806527733802795,
      "learning_rate": 5.155388471177945e-05,
      "loss": 2.6553,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.34669971466064453,
      "learning_rate": 5.0303258145363405e-05,
      "loss": 2.651,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.671065092086792,
      "eval_runtime": 65.5839,
      "eval_samples_per_second": 762.383,
      "eval_steps_per_second": 5.962,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.3851897716522217,
      "learning_rate": 4.905012531328321e-05,
      "loss": 2.6477,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.3584868907928467,
      "learning_rate": 4.7796992481203003e-05,
      "loss": 2.6492,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.3532809913158417,
      "learning_rate": 4.6543859649122806e-05,
      "loss": 2.649,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.38128992915153503,
      "learning_rate": 4.529323308270677e-05,
      "loss": 2.6484,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.37678053975105286,
      "learning_rate": 4.4040100250626565e-05,
      "loss": 2.6462,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.3916684091091156,
      "learning_rate": 4.278696741854637e-05,
      "loss": 2.6478,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.34224843978881836,
      "learning_rate": 4.153383458646617e-05,
      "loss": 2.649,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.34972262382507324,
      "learning_rate": 4.028320802005012e-05,
      "loss": 2.6508,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.6664540767669678,
      "eval_runtime": 65.5869,
      "eval_samples_per_second": 762.347,
      "eval_steps_per_second": 5.962,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.36855950951576233,
      "learning_rate": 3.903007518796992e-05,
      "loss": 2.6467,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.35113444924354553,
      "learning_rate": 3.7776942355889725e-05,
      "loss": 2.6471,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.3564552962779999,
      "learning_rate": 3.652380952380952e-05,
      "loss": 2.6458,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.3624327480792999,
      "learning_rate": 3.5273182957393484e-05,
      "loss": 2.6441,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.37404006719589233,
      "learning_rate": 3.4020050125313286e-05,
      "loss": 2.6448,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.39796289801597595,
      "learning_rate": 3.276691729323308e-05,
      "loss": 2.6419,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.3689802885055542,
      "learning_rate": 3.1513784461152884e-05,
      "loss": 2.6436,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.3935149312019348,
      "learning_rate": 3.0263157894736844e-05,
      "loss": 2.6454,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.6622378826141357,
      "eval_runtime": 65.5575,
      "eval_samples_per_second": 762.689,
      "eval_steps_per_second": 5.964,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.36624589562416077,
      "learning_rate": 2.9010025062656643e-05,
      "loss": 2.6396,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.34926265478134155,
      "learning_rate": 2.7756892230576442e-05,
      "loss": 2.6433,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.36464422941207886,
      "learning_rate": 2.650375939849624e-05,
      "loss": 2.6413,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.35847729444503784,
      "learning_rate": 2.52531328320802e-05,
      "loss": 2.642,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.3685363531112671,
      "learning_rate": 2.4e-05,
      "loss": 2.6413,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.3625328540802002,
      "learning_rate": 2.27468671679198e-05,
      "loss": 2.6391,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.37850257754325867,
      "learning_rate": 2.14937343358396e-05,
      "loss": 2.6376,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.35061517357826233,
      "learning_rate": 2.024310776942356e-05,
      "loss": 2.6382,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.65842604637146,
      "eval_runtime": 66.6692,
      "eval_samples_per_second": 749.971,
      "eval_steps_per_second": 5.865,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.3541260063648224,
      "learning_rate": 1.8989974937343358e-05,
      "loss": 2.6394,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.36190709471702576,
      "learning_rate": 1.773684210526316e-05,
      "loss": 2.6401,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.3630730211734772,
      "learning_rate": 1.648370927318296e-05,
      "loss": 2.6351,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.348744660615921,
      "learning_rate": 1.5230576441102759e-05,
      "loss": 2.6391,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.3735438585281372,
      "learning_rate": 1.3979949874686718e-05,
      "loss": 2.6397,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.35963258147239685,
      "learning_rate": 1.2726817042606518e-05,
      "loss": 2.6371,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.35441264510154724,
      "learning_rate": 1.1473684210526317e-05,
      "loss": 2.6338,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.3502815067768097,
      "learning_rate": 1.0220551378446116e-05,
      "loss": 2.6372,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.6551196575164795,
      "eval_runtime": 65.628,
      "eval_samples_per_second": 761.87,
      "eval_steps_per_second": 5.958,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.35631510615348816,
      "learning_rate": 8.969924812030076e-06,
      "loss": 2.6329,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.3359445333480835,
      "learning_rate": 7.716791979949875e-06,
      "loss": 2.6351,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.35541629791259766,
      "learning_rate": 6.463659147869674e-06,
      "loss": 2.6312,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.35936230421066284,
      "learning_rate": 5.210526315789474e-06,
      "loss": 2.635,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.34688594937324524,
      "learning_rate": 3.959899749373434e-06,
      "loss": 2.6321,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.3451939821243286,
      "learning_rate": 2.706766917293233e-06,
      "loss": 2.6368,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.348779559135437,
      "learning_rate": 1.4536340852130326e-06,
      "loss": 2.6316,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.35569822788238525,
      "learning_rate": 2.005012531328321e-07,
      "loss": 2.6327,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.6529319286346436,
      "eval_runtime": 65.4832,
      "eval_samples_per_second": 763.554,
      "eval_steps_per_second": 5.971,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
