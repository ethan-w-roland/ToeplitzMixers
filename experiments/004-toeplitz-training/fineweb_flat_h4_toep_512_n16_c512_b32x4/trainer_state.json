{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 11.062904357910156,
      "learning_rate": 0.000495,
      "loss": 14.4341,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 3.8306548595428467,
      "learning_rate": 0.0004987593984962407,
      "loss": 6.2879,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 1.569245457649231,
      "learning_rate": 0.0004975062656641604,
      "loss": 5.4679,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 1.8220229148864746,
      "learning_rate": 0.0004962531328320802,
      "loss": 5.1386,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 1.0743353366851807,
      "learning_rate": 0.000495,
      "loss": 4.8721,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.9821901917457581,
      "learning_rate": 0.0004937468671679198,
      "loss": 4.6086,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 1.1329278945922852,
      "learning_rate": 0.0004924937343358396,
      "loss": 4.3839,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.9868093132972717,
      "learning_rate": 0.0004912406015037594,
      "loss": 4.2199,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 4.150118827819824,
      "eval_runtime": 30.6063,
      "eval_samples_per_second": 1633.649,
      "eval_steps_per_second": 12.775,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.8018276691436768,
      "learning_rate": 0.0004899874686716792,
      "loss": 4.1005,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.6310262084007263,
      "learning_rate": 0.0004887343358395991,
      "loss": 4.015,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.628688633441925,
      "learning_rate": 0.0004874812030075188,
      "loss": 3.9455,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.7086575627326965,
      "learning_rate": 0.00048622807017543866,
      "loss": 3.8896,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.5939396023750305,
      "learning_rate": 0.0004849749373433584,
      "loss": 3.8428,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.6150661706924438,
      "learning_rate": 0.00048372180451127823,
      "loss": 3.8041,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.6228803396224976,
      "learning_rate": 0.000482468671679198,
      "loss": 3.7638,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.5583569407463074,
      "learning_rate": 0.0004812155388471178,
      "loss": 3.7356,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.7188303470611572,
      "eval_runtime": 30.6612,
      "eval_samples_per_second": 1630.724,
      "eval_steps_per_second": 12.752,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.6975231170654297,
      "learning_rate": 0.00047996240601503763,
      "loss": 3.7075,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.6069868803024292,
      "learning_rate": 0.00047870927318295744,
      "loss": 3.681,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.549079418182373,
      "learning_rate": 0.0004774561403508772,
      "loss": 3.6552,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.6626317501068115,
      "learning_rate": 0.000476203007518797,
      "loss": 3.6372,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.5654289126396179,
      "learning_rate": 0.0004749498746867168,
      "loss": 3.6163,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.540459394454956,
      "learning_rate": 0.0004736967418546366,
      "loss": 3.5999,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.561683714389801,
      "learning_rate": 0.0004724436090225564,
      "loss": 3.5804,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.5132479071617126,
      "learning_rate": 0.00047119047619047623,
      "loss": 3.5654,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.556063413619995,
      "eval_runtime": 30.6767,
      "eval_samples_per_second": 1629.902,
      "eval_steps_per_second": 12.746,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.5010752081871033,
      "learning_rate": 0.000469937343358396,
      "loss": 3.5523,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.5605061054229736,
      "learning_rate": 0.0004686842105263158,
      "loss": 3.5411,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.49760571122169495,
      "learning_rate": 0.00046743609022556395,
      "loss": 3.5216,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.5671586990356445,
      "learning_rate": 0.0004661829573934837,
      "loss": 3.5129,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.5338588356971741,
      "learning_rate": 0.0004649298245614035,
      "loss": 3.5009,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.5154351592063904,
      "learning_rate": 0.0004636766917293233,
      "loss": 3.4914,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.5565956234931946,
      "learning_rate": 0.00046242355889724316,
      "loss": 3.4799,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.48719316720962524,
      "learning_rate": 0.00046117293233082705,
      "loss": 3.4737,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.464576482772827,
      "eval_runtime": 30.5519,
      "eval_samples_per_second": 1636.561,
      "eval_steps_per_second": 12.798,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.45867541432380676,
      "learning_rate": 0.000459922305764411,
      "loss": 3.4628,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.5585813522338867,
      "learning_rate": 0.00045866917293233087,
      "loss": 3.4528,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.455459326505661,
      "learning_rate": 0.00045741604010025063,
      "loss": 3.446,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.5636876821517944,
      "learning_rate": 0.00045616290726817045,
      "loss": 3.4333,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.5181415677070618,
      "learning_rate": 0.0004549097744360902,
      "loss": 3.4283,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.4852342903614044,
      "learning_rate": 0.00045365664160401003,
      "loss": 3.4245,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.46782755851745605,
      "learning_rate": 0.00045240350877192984,
      "loss": 3.4121,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.4974786043167114,
      "learning_rate": 0.00045115037593984966,
      "loss": 3.4065,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.4020025730133057,
      "eval_runtime": 30.6044,
      "eval_samples_per_second": 1633.753,
      "eval_steps_per_second": 12.776,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.4683123230934143,
      "learning_rate": 0.0004498972431077694,
      "loss": 3.4002,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.4515521824359894,
      "learning_rate": 0.0004486541353383459,
      "loss": 3.4,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.43096718192100525,
      "learning_rate": 0.0004474010025062657,
      "loss": 3.3903,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.4851820766925812,
      "learning_rate": 0.00044614786967418546,
      "loss": 3.3824,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.46139952540397644,
      "learning_rate": 0.0004448947368421053,
      "loss": 3.3781,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.44623687863349915,
      "learning_rate": 0.0004436416040100251,
      "loss": 3.3711,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.5478469133377075,
      "learning_rate": 0.0004423884711779449,
      "loss": 3.3658,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.4387587308883667,
      "learning_rate": 0.00044113533834586467,
      "loss": 3.3603,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.3555309772491455,
      "eval_runtime": 30.5639,
      "eval_samples_per_second": 1635.915,
      "eval_steps_per_second": 12.793,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.4098879098892212,
      "learning_rate": 0.0004398822055137845,
      "loss": 3.3567,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.4454744756221771,
      "learning_rate": 0.00043862907268170425,
      "loss": 3.3503,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.4465881288051605,
      "learning_rate": 0.0004373759398496241,
      "loss": 3.3461,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.45675045251846313,
      "learning_rate": 0.0004361228070175439,
      "loss": 3.3409,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.44058412313461304,
      "learning_rate": 0.0004348696741854637,
      "loss": 3.3367,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.518500566482544,
      "learning_rate": 0.00043361654135338346,
      "loss": 3.3319,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.4450201690196991,
      "learning_rate": 0.0004323634085213033,
      "loss": 3.3297,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.4455573856830597,
      "learning_rate": 0.0004311102756892231,
      "loss": 3.3237,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.322315216064453,
      "eval_runtime": 30.8683,
      "eval_samples_per_second": 1619.787,
      "eval_steps_per_second": 12.667,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.4258936047554016,
      "learning_rate": 0.0004298571428571429,
      "loss": 3.3232,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.45674511790275574,
      "learning_rate": 0.00042860651629072685,
      "loss": 3.3173,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.44736742973327637,
      "learning_rate": 0.0004273533834586466,
      "loss": 3.3144,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.4218812584877014,
      "learning_rate": 0.00042610025062656643,
      "loss": 3.3088,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.415708065032959,
      "learning_rate": 0.0004248471177944862,
      "loss": 3.3041,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.42991212010383606,
      "learning_rate": 0.000423593984962406,
      "loss": 3.3001,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.41389256715774536,
      "learning_rate": 0.0004223408521303258,
      "loss": 3.298,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.44141897559165955,
      "learning_rate": 0.00042108771929824564,
      "loss": 3.2969,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.2904796600341797,
      "eval_runtime": 30.5641,
      "eval_samples_per_second": 1635.906,
      "eval_steps_per_second": 12.793,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.4321063458919525,
      "learning_rate": 0.0004198345864661654,
      "loss": 3.291,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.419603168964386,
      "learning_rate": 0.0004185814536340852,
      "loss": 3.2889,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.42568060755729675,
      "learning_rate": 0.000417328320802005,
      "loss": 3.2823,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.41105592250823975,
      "learning_rate": 0.00041607518796992485,
      "loss": 3.2819,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.3979828357696533,
      "learning_rate": 0.00041482456140350875,
      "loss": 3.2809,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.4408877491950989,
      "learning_rate": 0.0004135714285714286,
      "loss": 3.2766,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.4292106628417969,
      "learning_rate": 0.0004123182957393484,
      "loss": 3.2729,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.4271835684776306,
      "learning_rate": 0.00041106766917293233,
      "loss": 3.2706,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 3.265547513961792,
      "eval_runtime": 30.6252,
      "eval_samples_per_second": 1632.644,
      "eval_steps_per_second": 12.767,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.4119184911251068,
      "learning_rate": 0.00040981704260651633,
      "loss": 3.2696,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.4403517246246338,
      "learning_rate": 0.0004085639097744361,
      "loss": 3.2649,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.40469253063201904,
      "learning_rate": 0.0004073107769423559,
      "loss": 3.2602,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.4254316985607147,
      "learning_rate": 0.0004060576441102757,
      "loss": 3.2617,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.37111181020736694,
      "learning_rate": 0.0004048045112781955,
      "loss": 3.2582,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.4313582181930542,
      "learning_rate": 0.0004035513784461153,
      "loss": 3.2534,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.4147012233734131,
      "learning_rate": 0.0004022982456140351,
      "loss": 3.254,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.41720178723335266,
      "learning_rate": 0.0004010451127819549,
      "loss": 3.2519,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 3.2460291385650635,
      "eval_runtime": 30.6454,
      "eval_samples_per_second": 1631.565,
      "eval_steps_per_second": 12.759,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.3685327470302582,
      "learning_rate": 0.0003997919799498747,
      "loss": 3.2481,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.40042445063591003,
      "learning_rate": 0.00039853884711779446,
      "loss": 3.2453,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.3841919004917145,
      "learning_rate": 0.00039728571428571433,
      "loss": 3.2448,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.4177643358707428,
      "learning_rate": 0.0003960325814536341,
      "loss": 3.2388,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.38101643323898315,
      "learning_rate": 0.0003947794486215539,
      "loss": 3.2408,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.3997165560722351,
      "learning_rate": 0.00039352882205513786,
      "loss": 3.2355,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.3931017220020294,
      "learning_rate": 0.0003922756892230577,
      "loss": 3.2345,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.3519805371761322,
      "learning_rate": 0.0003910250626566416,
      "loss": 3.2292,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 3.227330207824707,
      "eval_runtime": 30.6211,
      "eval_samples_per_second": 1632.863,
      "eval_steps_per_second": 12.769,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.37389469146728516,
      "learning_rate": 0.0003897719298245614,
      "loss": 3.2327,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.3757936358451843,
      "learning_rate": 0.0003885187969924812,
      "loss": 3.2281,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.37752658128738403,
      "learning_rate": 0.00038726566416040096,
      "loss": 3.222,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.3786940276622772,
      "learning_rate": 0.00038601253132832084,
      "loss": 3.2227,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.39350175857543945,
      "learning_rate": 0.0003847593984962406,
      "loss": 3.2206,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.3548401892185211,
      "learning_rate": 0.0003835087719298246,
      "loss": 3.2145,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.40663114190101624,
      "learning_rate": 0.00038225563909774436,
      "loss": 3.2178,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.3555915057659149,
      "learning_rate": 0.0003810025062656642,
      "loss": 3.2136,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 3.211315393447876,
      "eval_runtime": 30.4843,
      "eval_samples_per_second": 1640.191,
      "eval_steps_per_second": 12.826,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.36379876732826233,
      "learning_rate": 0.00037974937343358394,
      "loss": 3.213,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.36551177501678467,
      "learning_rate": 0.00037849624060150376,
      "loss": 3.2099,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.4249362051486969,
      "learning_rate": 0.00037724310776942357,
      "loss": 3.21,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.38009798526763916,
      "learning_rate": 0.0003759899749373434,
      "loss": 3.2068,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.3471199870109558,
      "learning_rate": 0.00037474185463659147,
      "loss": 3.2062,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.3594423532485962,
      "learning_rate": 0.0003734887218045113,
      "loss": 3.2011,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.3674548268318176,
      "learning_rate": 0.0003722355889724311,
      "loss": 3.2045,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.3457079231739044,
      "learning_rate": 0.00037098245614035087,
      "loss": 3.2001,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 3.1961355209350586,
      "eval_runtime": 30.4874,
      "eval_samples_per_second": 1640.019,
      "eval_steps_per_second": 12.825,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.35321804881095886,
      "learning_rate": 0.0003697293233082707,
      "loss": 3.1954,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.37979772686958313,
      "learning_rate": 0.00036847619047619044,
      "loss": 3.1949,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.33966049551963806,
      "learning_rate": 0.0003672230576441103,
      "loss": 3.1926,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.34924814105033875,
      "learning_rate": 0.0003659699248120301,
      "loss": 3.1947,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.3995196521282196,
      "learning_rate": 0.0003647167919799499,
      "loss": 3.193,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.34825435280799866,
      "learning_rate": 0.00036346365914786965,
      "loss": 3.1884,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.34998032450675964,
      "learning_rate": 0.00036221052631578947,
      "loss": 3.1869,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.3452050983905792,
      "learning_rate": 0.0003609573934837093,
      "loss": 3.1876,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 3.1832504272460938,
      "eval_runtime": 30.534,
      "eval_samples_per_second": 1637.518,
      "eval_steps_per_second": 12.805,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.3991404175758362,
      "learning_rate": 0.0003597042606516291,
      "loss": 3.1843,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.35506507754325867,
      "learning_rate": 0.00035845112781954886,
      "loss": 3.184,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.3474563956260681,
      "learning_rate": 0.0003571979949874687,
      "loss": 3.1798,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.37463298439979553,
      "learning_rate": 0.00035594736842105263,
      "loss": 3.1796,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.3392904996871948,
      "learning_rate": 0.00035469423558897245,
      "loss": 3.1797,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.3495337665081024,
      "learning_rate": 0.0003534411027568922,
      "loss": 3.1781,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.36822599172592163,
      "learning_rate": 0.0003521879699248121,
      "loss": 3.1748,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.33831751346588135,
      "learning_rate": 0.00035093483709273184,
      "loss": 3.1746,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 3.170797824859619,
      "eval_runtime": 30.6405,
      "eval_samples_per_second": 1631.828,
      "eval_steps_per_second": 12.761,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.3713547885417938,
      "learning_rate": 0.00034968170426065166,
      "loss": 3.1752,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.3641899824142456,
      "learning_rate": 0.0003484285714285714,
      "loss": 3.1715,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.3438906669616699,
      "learning_rate": 0.00034717794486215537,
      "loss": 3.17,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.33996179699897766,
      "learning_rate": 0.0003459248120300752,
      "loss": 3.1689,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.41909754276275635,
      "learning_rate": 0.00034467167919799495,
      "loss": 3.168,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.3442580997943878,
      "learning_rate": 0.0003434185463659148,
      "loss": 3.1656,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.33965134620666504,
      "learning_rate": 0.0003421654135338346,
      "loss": 3.1656,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.3589034080505371,
      "learning_rate": 0.0003409122807017544,
      "loss": 3.1663,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 3.1596295833587646,
      "eval_runtime": 30.6108,
      "eval_samples_per_second": 1633.41,
      "eval_steps_per_second": 12.773,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.3676135838031769,
      "learning_rate": 0.00033965914786967416,
      "loss": 3.1629,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.38126882910728455,
      "learning_rate": 0.00033840601503759397,
      "loss": 3.161,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.4240553081035614,
      "learning_rate": 0.0003371528822055138,
      "loss": 3.1594,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.38000258803367615,
      "learning_rate": 0.0003358997493734336,
      "loss": 3.1586,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.32924461364746094,
      "learning_rate": 0.0003346516290726817,
      "loss": 3.1564,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.3766532242298126,
      "learning_rate": 0.00033339849624060156,
      "loss": 3.1528,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.34258899092674255,
      "learning_rate": 0.0003321453634085213,
      "loss": 3.1549,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.32522550225257874,
      "learning_rate": 0.00033089223057644114,
      "loss": 3.1508,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 3.1492631435394287,
      "eval_runtime": 30.5529,
      "eval_samples_per_second": 1636.508,
      "eval_steps_per_second": 12.797,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.33905667066574097,
      "learning_rate": 0.0003296390977443609,
      "loss": 3.1536,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.3482935428619385,
      "learning_rate": 0.0003283859649122807,
      "loss": 3.1538,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.3392352759838104,
      "learning_rate": 0.00032713283208020053,
      "loss": 3.1517,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.3374268710613251,
      "learning_rate": 0.00032587969924812035,
      "loss": 3.1514,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.3423709273338318,
      "learning_rate": 0.0003246265664160401,
      "loss": 3.1473,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.3614925742149353,
      "learning_rate": 0.0003233734335839599,
      "loss": 3.1492,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.34474313259124756,
      "learning_rate": 0.0003221203007518797,
      "loss": 3.1474,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.34574761986732483,
      "learning_rate": 0.00032086716791979956,
      "loss": 3.1417,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 3.1405837535858154,
      "eval_runtime": 30.6194,
      "eval_samples_per_second": 1632.949,
      "eval_steps_per_second": 12.77,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.3634089529514313,
      "learning_rate": 0.0003196140350877193,
      "loss": 3.1438,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.34350600838661194,
      "learning_rate": 0.00031836090225563913,
      "loss": 3.1411,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.3402990996837616,
      "learning_rate": 0.0003171077694235589,
      "loss": 3.1376,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.34356889128685,
      "learning_rate": 0.0003158546365914787,
      "loss": 3.1412,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.33878129720687866,
      "learning_rate": 0.00031460401002506266,
      "loss": 3.1357,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.38406428694725037,
      "learning_rate": 0.0003133533834586466,
      "loss": 3.1369,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.3421376645565033,
      "learning_rate": 0.0003121027568922306,
      "loss": 3.1301,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.33940252661705017,
      "learning_rate": 0.0003108496240601504,
      "loss": 3.1265,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 3.1307272911071777,
      "eval_runtime": 30.6683,
      "eval_samples_per_second": 1630.348,
      "eval_steps_per_second": 12.749,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.3309890925884247,
      "learning_rate": 0.0003095964912280702,
      "loss": 3.1258,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.34206512570381165,
      "learning_rate": 0.00030834335839599,
      "loss": 3.1252,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.34182849526405334,
      "learning_rate": 0.0003070902255639098,
      "loss": 3.1241,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.35566797852516174,
      "learning_rate": 0.0003058370927318296,
      "loss": 3.1222,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.35128387808799744,
      "learning_rate": 0.00030458646616541354,
      "loss": 3.1197,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.34972840547561646,
      "learning_rate": 0.00030333333333333335,
      "loss": 3.124,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.38923385739326477,
      "learning_rate": 0.0003020802005012531,
      "loss": 3.1209,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.34895244240760803,
      "learning_rate": 0.00030082706766917293,
      "loss": 3.1224,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 3.123368501663208,
      "eval_runtime": 30.6265,
      "eval_samples_per_second": 1632.571,
      "eval_steps_per_second": 12.767,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.3703494369983673,
      "learning_rate": 0.00029957393483709275,
      "loss": 3.1187,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.3527235686779022,
      "learning_rate": 0.00029832080200501256,
      "loss": 3.1197,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.34385403990745544,
      "learning_rate": 0.0002970676691729323,
      "loss": 3.1158,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.3307126462459564,
      "learning_rate": 0.00029581453634085214,
      "loss": 3.1175,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.3378129303455353,
      "learning_rate": 0.0002945614035087719,
      "loss": 3.1143,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.3344132900238037,
      "learning_rate": 0.00029330827067669177,
      "loss": 3.1162,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.454896479845047,
      "learning_rate": 0.00029205513784461153,
      "loss": 3.114,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.3706006109714508,
      "learning_rate": 0.00029080451127819554,
      "loss": 3.1148,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 3.1164183616638184,
      "eval_runtime": 30.5233,
      "eval_samples_per_second": 1638.095,
      "eval_steps_per_second": 12.81,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.35590675473213196,
      "learning_rate": 0.0002895513784461153,
      "loss": 3.1147,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.3315085768699646,
      "learning_rate": 0.0002882982456140351,
      "loss": 3.1121,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.3551880717277527,
      "learning_rate": 0.00028704761904761907,
      "loss": 3.113,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.34578755497932434,
      "learning_rate": 0.00028579448621553883,
      "loss": 3.1114,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.34199628233909607,
      "learning_rate": 0.00028454135338345864,
      "loss": 3.1077,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.3218826353549957,
      "learning_rate": 0.0002832882205513784,
      "loss": 3.1108,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.3266555070877075,
      "learning_rate": 0.0002820350877192983,
      "loss": 3.1047,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.34577953815460205,
      "learning_rate": 0.00028078195488721804,
      "loss": 3.1087,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 3.1077468395233154,
      "eval_runtime": 30.5806,
      "eval_samples_per_second": 1635.024,
      "eval_steps_per_second": 12.786,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.4086623191833496,
      "learning_rate": 0.00027952882205513785,
      "loss": 3.1067,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.3267974555492401,
      "learning_rate": 0.0002782756892230576,
      "loss": 3.1044,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.34453845024108887,
      "learning_rate": 0.00027702255639097743,
      "loss": 3.1052,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.34615564346313477,
      "learning_rate": 0.00027576942355889725,
      "loss": 3.1026,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.37158119678497314,
      "learning_rate": 0.00027451629072681706,
      "loss": 3.1025,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.3596280813217163,
      "learning_rate": 0.0002732631578947368,
      "loss": 3.1006,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.3352728486061096,
      "learning_rate": 0.00027201253132832083,
      "loss": 3.0997,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.34912487864494324,
      "learning_rate": 0.0002707593984962406,
      "loss": 3.0993,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 3.1004037857055664,
      "eval_runtime": 30.6391,
      "eval_samples_per_second": 1631.903,
      "eval_steps_per_second": 12.761,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.35650643706321716,
      "learning_rate": 0.0002695062656641604,
      "loss": 3.1016,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.3425370454788208,
      "learning_rate": 0.00026825563909774436,
      "loss": 3.0986,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.3625929653644562,
      "learning_rate": 0.0002670050125313283,
      "loss": 3.0955,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.34339767694473267,
      "learning_rate": 0.0002657518796992481,
      "loss": 3.0992,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.3368509113788605,
      "learning_rate": 0.0002644987468671679,
      "loss": 3.0962,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.34388041496276855,
      "learning_rate": 0.00026324561403508775,
      "loss": 3.0951,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.34203094244003296,
      "learning_rate": 0.0002619924812030075,
      "loss": 3.0957,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.34346723556518555,
      "learning_rate": 0.00026073934837092733,
      "loss": 3.0923,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 3.094144105911255,
      "eval_runtime": 30.4859,
      "eval_samples_per_second": 1640.1,
      "eval_steps_per_second": 12.826,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.3285444974899292,
      "learning_rate": 0.0002594862155388471,
      "loss": 3.0908,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.36860597133636475,
      "learning_rate": 0.0002582330827067669,
      "loss": 3.0948,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.3390297591686249,
      "learning_rate": 0.00025698245614035086,
      "loss": 3.0901,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.34396371245384216,
      "learning_rate": 0.0002557293233082707,
      "loss": 3.0912,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.3436431586742401,
      "learning_rate": 0.0002544761904761905,
      "loss": 3.0887,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.35532355308532715,
      "learning_rate": 0.0002532230576441103,
      "loss": 3.0894,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.32970520853996277,
      "learning_rate": 0.00025197243107769426,
      "loss": 3.0877,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.3395639955997467,
      "learning_rate": 0.000250719298245614,
      "loss": 3.0869,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 3.0878541469573975,
      "eval_runtime": 30.4861,
      "eval_samples_per_second": 1640.09,
      "eval_steps_per_second": 12.826,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.31901514530181885,
      "learning_rate": 0.00024946616541353384,
      "loss": 3.0832,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.3289446532726288,
      "learning_rate": 0.0002482155388471178,
      "loss": 3.0851,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.35152262449264526,
      "learning_rate": 0.0002469624060150376,
      "loss": 3.0855,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.3534244894981384,
      "learning_rate": 0.0002457092731829574,
      "loss": 3.0827,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.3306119441986084,
      "learning_rate": 0.00024445614035087723,
      "loss": 3.0834,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.36062875390052795,
      "learning_rate": 0.00024320300751879702,
      "loss": 3.0814,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.3519364297389984,
      "learning_rate": 0.0002419498746867168,
      "loss": 3.0821,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.331572562456131,
      "learning_rate": 0.0002406967418546366,
      "loss": 3.0792,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 3.0821006298065186,
      "eval_runtime": 30.4777,
      "eval_samples_per_second": 1640.545,
      "eval_steps_per_second": 12.829,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.3560656011104584,
      "learning_rate": 0.00023944360902255642,
      "loss": 3.0816,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.32790398597717285,
      "learning_rate": 0.0002381904761904762,
      "loss": 3.0771,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.3240337073802948,
      "learning_rate": 0.000236937343358396,
      "loss": 3.0752,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.32727736234664917,
      "learning_rate": 0.0002356842105263158,
      "loss": 3.0773,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.34193775057792664,
      "learning_rate": 0.0002344310776942356,
      "loss": 3.0771,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.3127436339855194,
      "learning_rate": 0.00023317794486215542,
      "loss": 3.0757,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.3271180987358093,
      "learning_rate": 0.0002319248120300752,
      "loss": 3.0763,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.332582026720047,
      "learning_rate": 0.000230671679197995,
      "loss": 3.0734,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 3.07495379447937,
      "eval_runtime": 30.4974,
      "eval_samples_per_second": 1639.484,
      "eval_steps_per_second": 12.821,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.34160512685775757,
      "learning_rate": 0.0002294185463659148,
      "loss": 3.0745,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.32972845435142517,
      "learning_rate": 0.00022816791979949876,
      "loss": 3.0729,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.3295431137084961,
      "learning_rate": 0.00022691478696741855,
      "loss": 3.0696,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.3365635275840759,
      "learning_rate": 0.00022566165413533834,
      "loss": 3.0735,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.3337620198726654,
      "learning_rate": 0.00022440852130325815,
      "loss": 3.0697,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.3255786895751953,
      "learning_rate": 0.0002231578947368421,
      "loss": 3.0723,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.3331986367702484,
      "learning_rate": 0.00022190476190476192,
      "loss": 3.0705,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.3320137858390808,
      "learning_rate": 0.00022065413533834587,
      "loss": 3.0694,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 3.069824457168579,
      "eval_runtime": 30.5492,
      "eval_samples_per_second": 1636.702,
      "eval_steps_per_second": 12.799,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.3567129671573639,
      "learning_rate": 0.00021940100250626566,
      "loss": 3.068,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.3468823730945587,
      "learning_rate": 0.00021814786967418545,
      "loss": 3.0675,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.3424499034881592,
      "learning_rate": 0.00021689473684210526,
      "loss": 3.068,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.33232155442237854,
      "learning_rate": 0.00021564160401002505,
      "loss": 3.0668,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.3547650873661041,
      "learning_rate": 0.00021438847117794487,
      "loss": 3.0664,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.35547852516174316,
      "learning_rate": 0.00021313784461152882,
      "loss": 3.0622,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.3444303870201111,
      "learning_rate": 0.00021188471177944863,
      "loss": 3.0656,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.3690791726112366,
      "learning_rate": 0.00021063157894736842,
      "loss": 3.0647,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 3.0639615058898926,
      "eval_runtime": 30.6258,
      "eval_samples_per_second": 1632.609,
      "eval_steps_per_second": 12.767,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.3468642830848694,
      "learning_rate": 0.0002093784461152882,
      "loss": 3.0664,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.3487868309020996,
      "learning_rate": 0.00020812531328320803,
      "loss": 3.0625,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.3212760388851166,
      "learning_rate": 0.00020687218045112782,
      "loss": 3.061,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.3489161729812622,
      "learning_rate": 0.00020561904761904763,
      "loss": 3.0617,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.3439090847969055,
      "learning_rate": 0.00020436591478696742,
      "loss": 3.0622,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.3724427819252014,
      "learning_rate": 0.0002031152882205514,
      "loss": 3.0593,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.3511965572834015,
      "learning_rate": 0.00020186466165413532,
      "loss": 3.0593,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.32883942127227783,
      "learning_rate": 0.0002006140350877193,
      "loss": 3.0595,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 3.0590949058532715,
      "eval_runtime": 30.5202,
      "eval_samples_per_second": 1638.257,
      "eval_steps_per_second": 12.811,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.34756046533584595,
      "learning_rate": 0.00019936090225563911,
      "loss": 3.0572,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.32497915625572205,
      "learning_rate": 0.0001981077694235589,
      "loss": 3.0588,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.33424270153045654,
      "learning_rate": 0.0001968546365914787,
      "loss": 3.0558,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.3375464975833893,
      "learning_rate": 0.0001956015037593985,
      "loss": 3.057,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.362063467502594,
      "learning_rate": 0.00019435087719298248,
      "loss": 3.0578,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.36170950531959534,
      "learning_rate": 0.00019309774436090227,
      "loss": 3.0522,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.3525761067867279,
      "learning_rate": 0.00019184461152882206,
      "loss": 3.0573,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.3327922821044922,
      "learning_rate": 0.00019059147869674188,
      "loss": 3.054,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 3.053201913833618,
      "eval_runtime": 30.6549,
      "eval_samples_per_second": 1631.062,
      "eval_steps_per_second": 12.755,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.344123512506485,
      "learning_rate": 0.00018933834586466167,
      "loss": 3.052,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.3677169680595398,
      "learning_rate": 0.00018808521303258148,
      "loss": 3.051,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.32226309180259705,
      "learning_rate": 0.00018683208020050127,
      "loss": 3.05,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.3339182138442993,
      "learning_rate": 0.00018558145363408522,
      "loss": 3.0519,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.33458203077316284,
      "learning_rate": 0.000184328320802005,
      "loss": 3.0488,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.34075191617012024,
      "learning_rate": 0.0001830751879699248,
      "loss": 3.0507,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.315410852432251,
      "learning_rate": 0.00018182205513784462,
      "loss": 3.0482,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.33061549067497253,
      "learning_rate": 0.0001805689223057644,
      "loss": 3.048,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 3.04888653755188,
      "eval_runtime": 30.4753,
      "eval_samples_per_second": 1640.673,
      "eval_steps_per_second": 12.83,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.3449750244617462,
      "learning_rate": 0.00017931578947368422,
      "loss": 3.0483,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.3418000638484955,
      "learning_rate": 0.00017806516290726817,
      "loss": 3.0476,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.3430327773094177,
      "learning_rate": 0.000176812030075188,
      "loss": 3.0491,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.3436329662799835,
      "learning_rate": 0.00017555889724310778,
      "loss": 3.0449,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.34543314576148987,
      "learning_rate": 0.0001743057644110276,
      "loss": 3.0414,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.3453441560268402,
      "learning_rate": 0.00017305263157894738,
      "loss": 3.0442,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.3256646394729614,
      "learning_rate": 0.00017179949874686717,
      "loss": 3.0432,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.32963985204696655,
      "learning_rate": 0.00017054636591478699,
      "loss": 3.0423,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 3.0428781509399414,
      "eval_runtime": 30.5072,
      "eval_samples_per_second": 1638.959,
      "eval_steps_per_second": 12.817,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.32870471477508545,
      "learning_rate": 0.00016929323308270677,
      "loss": 3.0404,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.33225929737091064,
      "learning_rate": 0.00016804010025062656,
      "loss": 3.0413,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.36325111985206604,
      "learning_rate": 0.0001667894736842105,
      "loss": 3.0421,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.340878963470459,
      "learning_rate": 0.00016553634085213033,
      "loss": 3.0404,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.3396754562854767,
      "learning_rate": 0.00016428320802005012,
      "loss": 3.0416,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.3671005368232727,
      "learning_rate": 0.0001630300751879699,
      "loss": 3.0416,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.332255482673645,
      "learning_rate": 0.00016177694235588972,
      "loss": 3.0394,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.3372390866279602,
      "learning_rate": 0.0001605238095238095,
      "loss": 3.0371,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 3.0384037494659424,
      "eval_runtime": 30.6155,
      "eval_samples_per_second": 1633.162,
      "eval_steps_per_second": 12.771,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.33632922172546387,
      "learning_rate": 0.00015927067669172933,
      "loss": 3.0373,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.34721794724464417,
      "learning_rate": 0.00015801754385964912,
      "loss": 3.0377,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.3700343668460846,
      "learning_rate": 0.00015676942355889725,
      "loss": 3.0362,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.3246232271194458,
      "learning_rate": 0.00015551629072681704,
      "loss": 3.0364,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.35426682233810425,
      "learning_rate": 0.00015426315789473686,
      "loss": 3.0345,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.3572610914707184,
      "learning_rate": 0.00015301002506265665,
      "loss": 3.0381,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.3268469274044037,
      "learning_rate": 0.00015175689223057646,
      "loss": 3.0323,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.3353798985481262,
      "learning_rate": 0.00015050375939849625,
      "loss": 3.0343,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 3.0336990356445312,
      "eval_runtime": 30.4397,
      "eval_samples_per_second": 1642.592,
      "eval_steps_per_second": 12.845,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.37766751646995544,
      "learning_rate": 0.00014925062656641604,
      "loss": 3.034,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.3499487042427063,
      "learning_rate": 0.000148,
      "loss": 3.0326,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.3339119851589203,
      "learning_rate": 0.0001467468671679198,
      "loss": 3.0325,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.34490033984184265,
      "learning_rate": 0.0001454937343358396,
      "loss": 3.0291,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.351091206073761,
      "learning_rate": 0.00014424310776942357,
      "loss": 3.032,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.33287546038627625,
      "learning_rate": 0.00014298997493734336,
      "loss": 3.0286,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.33159059286117554,
      "learning_rate": 0.00014173684210526315,
      "loss": 3.0294,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.32740065455436707,
      "learning_rate": 0.00014048621553884713,
      "loss": 3.0289,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 3.029103994369507,
      "eval_runtime": 30.5571,
      "eval_samples_per_second": 1636.282,
      "eval_steps_per_second": 12.796,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.33494389057159424,
      "learning_rate": 0.00013923308270676695,
      "loss": 3.0283,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.32266736030578613,
      "learning_rate": 0.00013797994987468673,
      "loss": 3.0288,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.338114857673645,
      "learning_rate": 0.00013672681704260652,
      "loss": 3.0313,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.3394032418727875,
      "learning_rate": 0.00013547368421052634,
      "loss": 3.0272,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.32369205355644226,
      "learning_rate": 0.00013422055137844613,
      "loss": 3.0256,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.34842658042907715,
      "learning_rate": 0.00013296741854636594,
      "loss": 3.0262,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.3448280394077301,
      "learning_rate": 0.0001317142857142857,
      "loss": 3.0265,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.3418121933937073,
      "learning_rate": 0.0001304611528822055,
      "loss": 3.0241,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 3.0244011878967285,
      "eval_runtime": 30.5859,
      "eval_samples_per_second": 1634.738,
      "eval_steps_per_second": 12.784,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.3299791216850281,
      "learning_rate": 0.0001292080200501253,
      "loss": 3.0242,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.33638182282447815,
      "learning_rate": 0.0001279548872180451,
      "loss": 3.023,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.34489625692367554,
      "learning_rate": 0.0001267017543859649,
      "loss": 3.0209,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.35322272777557373,
      "learning_rate": 0.0001254486215538847,
      "loss": 3.0227,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.3364919126033783,
      "learning_rate": 0.00012419799498746868,
      "loss": 3.0205,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.338817298412323,
      "learning_rate": 0.00012294486215538847,
      "loss": 3.0127,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.3328445851802826,
      "learning_rate": 0.00012169172932330827,
      "loss": 3.0134,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.3406074345111847,
      "learning_rate": 0.00012043859649122808,
      "loss": 3.009,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 3.0204200744628906,
      "eval_runtime": 30.5828,
      "eval_samples_per_second": 1634.904,
      "eval_steps_per_second": 12.785,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.33985966444015503,
      "learning_rate": 0.00011918796992481203,
      "loss": 3.0122,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.3512479364871979,
      "learning_rate": 0.00011793483709273183,
      "loss": 3.0103,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.3258785605430603,
      "learning_rate": 0.00011668170426065163,
      "loss": 3.0124,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.3417997360229492,
      "learning_rate": 0.00011542857142857142,
      "loss": 3.0103,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.3373924791812897,
      "learning_rate": 0.0001141779448621554,
      "loss": 3.0123,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.36019012331962585,
      "learning_rate": 0.0001129248120300752,
      "loss": 3.0088,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.33251774311065674,
      "learning_rate": 0.00011167167919799499,
      "loss": 3.0091,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.37498074769973755,
      "learning_rate": 0.00011041854636591479,
      "loss": 3.009,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 3.0165693759918213,
      "eval_runtime": 30.5204,
      "eval_samples_per_second": 1638.248,
      "eval_steps_per_second": 12.811,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.340859979391098,
      "learning_rate": 0.00010916541353383459,
      "loss": 3.0093,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.3571089804172516,
      "learning_rate": 0.0001079122807017544,
      "loss": 3.0076,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.3599487841129303,
      "learning_rate": 0.0001066591478696742,
      "loss": 3.0082,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.3468054533004761,
      "learning_rate": 0.00010540601503759399,
      "loss": 3.0081,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.3376311659812927,
      "learning_rate": 0.00010415288220551379,
      "loss": 3.0058,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.3730427324771881,
      "learning_rate": 0.00010289974937343359,
      "loss": 3.0058,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.3383892774581909,
      "learning_rate": 0.0001016466165413534,
      "loss": 3.0064,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.33253318071365356,
      "learning_rate": 0.00010039348370927318,
      "loss": 3.0061,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 3.012399435043335,
      "eval_runtime": 30.4178,
      "eval_samples_per_second": 1643.773,
      "eval_steps_per_second": 12.854,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.35400500893592834,
      "learning_rate": 9.914035087719299e-05,
      "loss": 3.0059,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.36816564202308655,
      "learning_rate": 9.788721804511279e-05,
      "loss": 3.0056,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.3436061143875122,
      "learning_rate": 9.663408521303259e-05,
      "loss": 3.0051,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.3326449394226074,
      "learning_rate": 9.538095238095239e-05,
      "loss": 3.0029,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.34585806727409363,
      "learning_rate": 9.413032581453634e-05,
      "loss": 3.0045,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.34524792432785034,
      "learning_rate": 9.28796992481203e-05,
      "loss": 3.0006,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.33335259556770325,
      "learning_rate": 9.162907268170426e-05,
      "loss": 2.9999,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.32730939984321594,
      "learning_rate": 9.037844611528823e-05,
      "loss": 3.0023,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 3.009094715118408,
      "eval_runtime": 30.5958,
      "eval_samples_per_second": 1634.21,
      "eval_steps_per_second": 12.78,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.33704131841659546,
      "learning_rate": 8.913032581453634e-05,
      "loss": 3.0022,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.35020264983177185,
      "learning_rate": 8.787719298245615e-05,
      "loss": 3.0002,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.3393847644329071,
      "learning_rate": 8.662406015037593e-05,
      "loss": 3.0009,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.33595210313796997,
      "learning_rate": 8.537092731829574e-05,
      "loss": 2.9976,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.3386451005935669,
      "learning_rate": 8.411779448621554e-05,
      "loss": 3.002,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.35025259852409363,
      "learning_rate": 8.286466165413534e-05,
      "loss": 2.9993,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.3543010950088501,
      "learning_rate": 8.161152882205513e-05,
      "loss": 3.001,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.33229735493659973,
      "learning_rate": 8.035839598997493e-05,
      "loss": 2.9975,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 3.0049257278442383,
      "eval_runtime": 30.5264,
      "eval_samples_per_second": 1637.925,
      "eval_steps_per_second": 12.809,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.3380805552005768,
      "learning_rate": 7.910526315789474e-05,
      "loss": 2.9967,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.354256808757782,
      "learning_rate": 7.785213032581454e-05,
      "loss": 2.9994,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.3332548439502716,
      "learning_rate": 7.659899749373434e-05,
      "loss": 2.9983,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.3672926425933838,
      "learning_rate": 7.534586466165413e-05,
      "loss": 2.9978,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.36271315813064575,
      "learning_rate": 7.409273182957393e-05,
      "loss": 2.9961,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.33875247836112976,
      "learning_rate": 7.283959899749373e-05,
      "loss": 2.9942,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.3351382315158844,
      "learning_rate": 7.158897243107768e-05,
      "loss": 2.9942,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.3478543162345886,
      "learning_rate": 7.033583959899749e-05,
      "loss": 2.9946,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 3.000925064086914,
      "eval_runtime": 30.5118,
      "eval_samples_per_second": 1638.711,
      "eval_steps_per_second": 12.815,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.34683147072792053,
      "learning_rate": 6.908270676691729e-05,
      "loss": 2.9943,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.3379780948162079,
      "learning_rate": 6.782957393483709e-05,
      "loss": 2.9953,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.336566686630249,
      "learning_rate": 6.65764411027569e-05,
      "loss": 2.9967,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.3626662492752075,
      "learning_rate": 6.532330827067668e-05,
      "loss": 2.9934,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.3417770266532898,
      "learning_rate": 6.407017543859649e-05,
      "loss": 2.9957,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.34103924036026,
      "learning_rate": 6.281704260651629e-05,
      "loss": 2.9899,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.34699299931526184,
      "learning_rate": 6.156390977443609e-05,
      "loss": 2.9928,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.3367495536804199,
      "learning_rate": 6.0310776942355893e-05,
      "loss": 2.9941,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.997191905975342,
      "eval_runtime": 30.6095,
      "eval_samples_per_second": 1633.482,
      "eval_steps_per_second": 12.774,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.35737818479537964,
      "learning_rate": 5.905764411027569e-05,
      "loss": 2.9926,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.33237090706825256,
      "learning_rate": 5.780451127819549e-05,
      "loss": 2.9899,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.3463173806667328,
      "learning_rate": 5.6551378446115294e-05,
      "loss": 2.9888,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.33239665627479553,
      "learning_rate": 5.529824561403509e-05,
      "loss": 2.9901,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.3414013981819153,
      "learning_rate": 5.404511278195489e-05,
      "loss": 2.9902,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.3478035628795624,
      "learning_rate": 5.279197994987469e-05,
      "loss": 2.9894,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.33559244871139526,
      "learning_rate": 5.1541353383458645e-05,
      "loss": 2.9908,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.3528498709201813,
      "learning_rate": 5.028822055137845e-05,
      "loss": 2.9872,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.993462562561035,
      "eval_runtime": 30.6353,
      "eval_samples_per_second": 1632.103,
      "eval_steps_per_second": 12.763,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.3527124524116516,
      "learning_rate": 4.903508771929824e-05,
      "loss": 2.9845,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.3345884382724762,
      "learning_rate": 4.7781954887218045e-05,
      "loss": 2.9858,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.3598685562610626,
      "learning_rate": 4.653132832080201e-05,
      "loss": 2.9858,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.36545807123184204,
      "learning_rate": 4.5278195488721804e-05,
      "loss": 2.985,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.3507697880268097,
      "learning_rate": 4.402506265664161e-05,
      "loss": 2.9832,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.36388370394706726,
      "learning_rate": 4.277192982456141e-05,
      "loss": 2.9852,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.32698696851730347,
      "learning_rate": 4.1521303258145366e-05,
      "loss": 2.9865,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.33655625581741333,
      "learning_rate": 4.026817042606516e-05,
      "loss": 2.9873,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.989908456802368,
      "eval_runtime": 30.5969,
      "eval_samples_per_second": 1634.153,
      "eval_steps_per_second": 12.779,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.34691402316093445,
      "learning_rate": 3.9015037593984964e-05,
      "loss": 2.985,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.3454461991786957,
      "learning_rate": 3.776190476190476e-05,
      "loss": 2.9852,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.33999061584472656,
      "learning_rate": 3.651127819548872e-05,
      "loss": 2.9831,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.33483609557151794,
      "learning_rate": 3.5258145363408526e-05,
      "loss": 2.982,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.35133805871009827,
      "learning_rate": 3.400501253132832e-05,
      "loss": 2.9828,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.35037505626678467,
      "learning_rate": 3.2751879699248124e-05,
      "loss": 2.9801,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.3394879102706909,
      "learning_rate": 3.150375939849624e-05,
      "loss": 2.9814,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.3664805293083191,
      "learning_rate": 3.0250626566416044e-05,
      "loss": 2.9832,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.9865756034851074,
      "eval_runtime": 30.6132,
      "eval_samples_per_second": 1633.285,
      "eval_steps_per_second": 12.772,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.3392302989959717,
      "learning_rate": 2.8997493734335843e-05,
      "loss": 2.9779,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.33225908875465393,
      "learning_rate": 2.7746867167919803e-05,
      "loss": 2.9815,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.3335796892642975,
      "learning_rate": 2.6493734335839602e-05,
      "loss": 2.9803,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.34051066637039185,
      "learning_rate": 2.52406015037594e-05,
      "loss": 2.9804,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.33565568923950195,
      "learning_rate": 2.3987468671679197e-05,
      "loss": 2.9798,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.33689504861831665,
      "learning_rate": 2.2734335839598996e-05,
      "loss": 2.978,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.33771196007728577,
      "learning_rate": 2.1481203007518795e-05,
      "loss": 2.9767,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.3370472192764282,
      "learning_rate": 2.0228070175438594e-05,
      "loss": 2.977,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.9836316108703613,
      "eval_runtime": 30.5989,
      "eval_samples_per_second": 1634.044,
      "eval_steps_per_second": 12.778,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.34264177083969116,
      "learning_rate": 1.8974937343358396e-05,
      "loss": 2.9779,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.3445304334163666,
      "learning_rate": 1.7721804511278196e-05,
      "loss": 2.979,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.3493712544441223,
      "learning_rate": 1.6468671679197995e-05,
      "loss": 2.9745,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.3395511209964752,
      "learning_rate": 1.5215538847117795e-05,
      "loss": 2.9776,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.344730406999588,
      "learning_rate": 1.3962406015037595e-05,
      "loss": 2.9787,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.3313277065753937,
      "learning_rate": 1.2711779448621554e-05,
      "loss": 2.9765,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.33582720160484314,
      "learning_rate": 1.1458646616541354e-05,
      "loss": 2.9737,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.3292255699634552,
      "learning_rate": 1.0208020050125313e-05,
      "loss": 2.9768,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.980987548828125,
      "eval_runtime": 30.6065,
      "eval_samples_per_second": 1633.638,
      "eval_steps_per_second": 12.775,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.332777202129364,
      "learning_rate": 8.957393483709273e-06,
      "loss": 2.9732,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.33570727705955505,
      "learning_rate": 7.704260651629072e-06,
      "loss": 2.9748,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.3405674993991852,
      "learning_rate": 6.4511278195488724e-06,
      "loss": 2.9705,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.3338797688484192,
      "learning_rate": 5.197994987468672e-06,
      "loss": 2.9747,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.33160924911499023,
      "learning_rate": 3.9448621553884715e-06,
      "loss": 2.9723,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.32764193415641785,
      "learning_rate": 2.6917293233082706e-06,
      "loss": 2.977,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.3235991895198822,
      "learning_rate": 1.4385964912280704e-06,
      "loss": 2.971,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.33738094568252563,
      "learning_rate": 1.8546365914786967e-07,
      "loss": 2.9722,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.979240894317627,
      "eval_runtime": 30.4849,
      "eval_samples_per_second": 1640.158,
      "eval_steps_per_second": 12.826,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
