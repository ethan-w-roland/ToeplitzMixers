{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.320988639689254,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013302471599223136,
      "grad_norm": 11.708501815795898,
      "learning_rate": 0.000497,
      "loss": 15.2775,
      "step": 500
    },
    {
      "epoch": 0.026604943198446272,
      "grad_norm": 2.643282651901245,
      "learning_rate": 0.0004987543859649123,
      "loss": 6.294,
      "step": 1000
    },
    {
      "epoch": 0.039907414797669405,
      "grad_norm": 1.661927580833435,
      "learning_rate": 0.0004975012531328321,
      "loss": 5.462,
      "step": 1500
    },
    {
      "epoch": 0.053209886396892545,
      "grad_norm": 1.8973413705825806,
      "learning_rate": 0.0004962481203007519,
      "loss": 5.1124,
      "step": 2000
    },
    {
      "epoch": 0.06651235799611568,
      "grad_norm": 1.5970110893249512,
      "learning_rate": 0.0004949949874686716,
      "loss": 4.8686,
      "step": 2500
    },
    {
      "epoch": 0.07981482959533881,
      "grad_norm": 0.9135380983352661,
      "learning_rate": 0.0004937418546365915,
      "loss": 4.6532,
      "step": 3000
    },
    {
      "epoch": 0.09311730119456195,
      "grad_norm": 0.5752859711647034,
      "learning_rate": 0.0004924887218045113,
      "loss": 4.4288,
      "step": 3500
    },
    {
      "epoch": 0.10641977279378509,
      "grad_norm": 0.5063055157661438,
      "learning_rate": 0.0004912355889724311,
      "loss": 4.2438,
      "step": 4000
    },
    {
      "epoch": 0.10641977279378509,
      "eval_loss": 4.097398281097412,
      "eval_runtime": 24.2819,
      "eval_samples_per_second": 2059.149,
      "eval_steps_per_second": 8.072,
      "step": 4000
    },
    {
      "epoch": 0.11972224439300821,
      "grad_norm": 0.41844961047172546,
      "learning_rate": 0.0004899824561403509,
      "loss": 4.1183,
      "step": 4500
    },
    {
      "epoch": 0.13302471599223137,
      "grad_norm": 0.5096714496612549,
      "learning_rate": 0.0004887293233082707,
      "loss": 4.0244,
      "step": 5000
    },
    {
      "epoch": 0.1463271875914545,
      "grad_norm": 0.534998893737793,
      "learning_rate": 0.00048747619047619046,
      "loss": 3.956,
      "step": 5500
    },
    {
      "epoch": 0.15962965919067762,
      "grad_norm": 0.43801477551460266,
      "learning_rate": 0.0004862230576441103,
      "loss": 3.8986,
      "step": 6000
    },
    {
      "epoch": 0.17293213078990077,
      "grad_norm": 0.47384101152420044,
      "learning_rate": 0.00048496992481203004,
      "loss": 3.8569,
      "step": 6500
    },
    {
      "epoch": 0.1862346023891239,
      "grad_norm": 0.40904128551483154,
      "learning_rate": 0.0004837167919799499,
      "loss": 3.815,
      "step": 7000
    },
    {
      "epoch": 0.19953707398834702,
      "grad_norm": 0.3863528370857239,
      "learning_rate": 0.0004824636591478697,
      "loss": 3.7835,
      "step": 7500
    },
    {
      "epoch": 0.21283954558757018,
      "grad_norm": 0.4095156490802765,
      "learning_rate": 0.0004812105263157895,
      "loss": 3.7555,
      "step": 8000
    },
    {
      "epoch": 0.21283954558757018,
      "eval_loss": 3.6618306636810303,
      "eval_runtime": 24.2434,
      "eval_samples_per_second": 2062.415,
      "eval_steps_per_second": 8.085,
      "step": 8000
    },
    {
      "epoch": 0.2261420171867933,
      "grad_norm": 0.34067997336387634,
      "learning_rate": 0.00047995739348370925,
      "loss": 3.7303,
      "step": 8500
    },
    {
      "epoch": 0.23944448878601643,
      "grad_norm": 0.42846187949180603,
      "learning_rate": 0.00047870676691729326,
      "loss": 3.7055,
      "step": 9000
    },
    {
      "epoch": 0.2527469603852396,
      "grad_norm": 0.42299628257751465,
      "learning_rate": 0.000477453634085213,
      "loss": 3.6877,
      "step": 9500
    },
    {
      "epoch": 0.26604943198446274,
      "grad_norm": 0.44047853350639343,
      "learning_rate": 0.00047620050125313283,
      "loss": 3.6663,
      "step": 10000
    },
    {
      "epoch": 0.27935190358368583,
      "grad_norm": 0.3265865743160248,
      "learning_rate": 0.00047494736842105265,
      "loss": 3.6518,
      "step": 10500
    },
    {
      "epoch": 0.292654375182909,
      "grad_norm": 0.7670242190361023,
      "learning_rate": 0.00047369423558897247,
      "loss": 3.637,
      "step": 11000
    },
    {
      "epoch": 0.30595684678213214,
      "grad_norm": 0.44048264622688293,
      "learning_rate": 0.00047244110275689223,
      "loss": 3.6229,
      "step": 11500
    },
    {
      "epoch": 0.31925931838135524,
      "grad_norm": 0.3390102982521057,
      "learning_rate": 0.0004711954887218045,
      "loss": 3.6095,
      "step": 12000
    },
    {
      "epoch": 0.31925931838135524,
      "eval_loss": 3.5249931812286377,
      "eval_runtime": 24.252,
      "eval_samples_per_second": 2061.682,
      "eval_steps_per_second": 8.082,
      "step": 12000
    },
    {
      "epoch": 0.3325617899805784,
      "grad_norm": 0.3391568958759308,
      "learning_rate": 0.0004699423558897243,
      "loss": 3.5976,
      "step": 12500
    },
    {
      "epoch": 0.34586426157980155,
      "grad_norm": 0.3608202338218689,
      "learning_rate": 0.00046868922305764413,
      "loss": 3.5849,
      "step": 13000
    },
    {
      "epoch": 0.35916673317902464,
      "grad_norm": 0.3589939773082733,
      "learning_rate": 0.00046743609022556395,
      "loss": 3.5742,
      "step": 13500
    },
    {
      "epoch": 0.3724692047782478,
      "grad_norm": 0.3515351414680481,
      "learning_rate": 0.0004661829573934837,
      "loss": 3.5647,
      "step": 14000
    },
    {
      "epoch": 0.38577167637747095,
      "grad_norm": 0.5184058547019958,
      "learning_rate": 0.00046493483709273185,
      "loss": 3.5776,
      "step": 14500
    },
    {
      "epoch": 0.39907414797669405,
      "grad_norm": 0.3409671187400818,
      "learning_rate": 0.00046368170426065166,
      "loss": 3.5478,
      "step": 15000
    },
    {
      "epoch": 0.4123766195759172,
      "grad_norm": 0.43336138129234314,
      "learning_rate": 0.0004624285714285714,
      "loss": 3.5373,
      "step": 15500
    },
    {
      "epoch": 0.42567909117514036,
      "grad_norm": 0.3923925757408142,
      "learning_rate": 0.00046117543859649124,
      "loss": 3.5317,
      "step": 16000
    },
    {
      "epoch": 0.42567909117514036,
      "eval_loss": 3.44754695892334,
      "eval_runtime": 24.337,
      "eval_samples_per_second": 2054.483,
      "eval_steps_per_second": 8.054,
      "step": 16000
    },
    {
      "epoch": 0.43898156277436345,
      "grad_norm": 0.4803563952445984,
      "learning_rate": 0.000459922305764411,
      "loss": 3.5232,
      "step": 16500
    },
    {
      "epoch": 0.4522840343735866,
      "grad_norm": 0.47166553139686584,
      "learning_rate": 0.00045866917293233087,
      "loss": 3.5152,
      "step": 17000
    },
    {
      "epoch": 0.46558650597280976,
      "grad_norm": 0.5672960877418518,
      "learning_rate": 0.00045741604010025063,
      "loss": 3.5101,
      "step": 17500
    },
    {
      "epoch": 0.47888897757203286,
      "grad_norm": 0.4579872488975525,
      "learning_rate": 0.00045616290726817045,
      "loss": 3.5026,
      "step": 18000
    },
    {
      "epoch": 0.492191449171256,
      "grad_norm": 0.34892982244491577,
      "learning_rate": 0.0004549097744360902,
      "loss": 3.4962,
      "step": 18500
    },
    {
      "epoch": 0.5054939207704792,
      "grad_norm": 0.31974655389785767,
      "learning_rate": 0.00045365664160401003,
      "loss": 3.4904,
      "step": 19000
    },
    {
      "epoch": 0.5187963923697023,
      "grad_norm": 0.6274232268333435,
      "learning_rate": 0.00045240350877192984,
      "loss": 3.4852,
      "step": 19500
    },
    {
      "epoch": 0.5320988639689255,
      "grad_norm": 0.32352250814437866,
      "learning_rate": 0.00045115037593984966,
      "loss": 3.4819,
      "step": 20000
    },
    {
      "epoch": 0.5320988639689255,
      "eval_loss": 3.3975322246551514,
      "eval_runtime": 24.2812,
      "eval_samples_per_second": 2059.204,
      "eval_steps_per_second": 8.072,
      "step": 20000
    },
    {
      "epoch": 0.5454013355681485,
      "grad_norm": 0.3319440484046936,
      "learning_rate": 0.0004498972431077694,
      "loss": 3.4753,
      "step": 20500
    },
    {
      "epoch": 0.5587038071673717,
      "grad_norm": 0.356292188167572,
      "learning_rate": 0.00044864411027568924,
      "loss": 3.47,
      "step": 21000
    },
    {
      "epoch": 0.5720062787665948,
      "grad_norm": 0.4001571834087372,
      "learning_rate": 0.000447390977443609,
      "loss": 3.4664,
      "step": 21500
    },
    {
      "epoch": 0.585308750365818,
      "grad_norm": 0.4385356605052948,
      "learning_rate": 0.0004461378446115288,
      "loss": 3.4602,
      "step": 22000
    },
    {
      "epoch": 0.5986112219650411,
      "grad_norm": 0.33693578839302063,
      "learning_rate": 0.00044488471177944863,
      "loss": 3.4579,
      "step": 22500
    },
    {
      "epoch": 0.6119136935642643,
      "grad_norm": 0.3575786054134369,
      "learning_rate": 0.00044363157894736845,
      "loss": 3.4498,
      "step": 23000
    },
    {
      "epoch": 0.6252161651634873,
      "grad_norm": 0.7054786086082458,
      "learning_rate": 0.0004423784461152882,
      "loss": 3.4455,
      "step": 23500
    },
    {
      "epoch": 0.6385186367627105,
      "grad_norm": 0.6076480150222778,
      "learning_rate": 0.0004411278195488722,
      "loss": 3.4429,
      "step": 24000
    },
    {
      "epoch": 0.6385186367627105,
      "eval_loss": 3.3604087829589844,
      "eval_runtime": 24.2999,
      "eval_samples_per_second": 2057.621,
      "eval_steps_per_second": 8.066,
      "step": 24000
    },
    {
      "epoch": 0.6518211083619336,
      "grad_norm": 0.45082372426986694,
      "learning_rate": 0.00043987719298245616,
      "loss": 3.44,
      "step": 24500
    },
    {
      "epoch": 0.6651235799611568,
      "grad_norm": 0.31278154253959656,
      "learning_rate": 0.0004386240601503759,
      "loss": 3.4354,
      "step": 25000
    },
    {
      "epoch": 0.6784260515603799,
      "grad_norm": 0.325135201215744,
      "learning_rate": 0.00043737092731829574,
      "loss": 3.4297,
      "step": 25500
    },
    {
      "epoch": 0.6917285231596031,
      "grad_norm": 0.3270033001899719,
      "learning_rate": 0.0004361177944862155,
      "loss": 3.4294,
      "step": 26000
    },
    {
      "epoch": 0.7050309947588261,
      "grad_norm": 0.3672407865524292,
      "learning_rate": 0.0004348646616541354,
      "loss": 3.4216,
      "step": 26500
    },
    {
      "epoch": 0.7183334663580493,
      "grad_norm": 0.3371821939945221,
      "learning_rate": 0.00043361152882205514,
      "loss": 3.4205,
      "step": 27000
    },
    {
      "epoch": 0.7316359379572724,
      "grad_norm": 0.3261682093143463,
      "learning_rate": 0.00043235839598997495,
      "loss": 3.4171,
      "step": 27500
    },
    {
      "epoch": 0.7449384095564956,
      "grad_norm": 0.47737210988998413,
      "learning_rate": 0.0004311052631578947,
      "loss": 3.4136,
      "step": 28000
    },
    {
      "epoch": 0.7449384095564956,
      "eval_loss": 3.331617593765259,
      "eval_runtime": 24.2584,
      "eval_samples_per_second": 2061.139,
      "eval_steps_per_second": 8.08,
      "step": 28000
    },
    {
      "epoch": 0.7582408811557187,
      "grad_norm": 0.368500679731369,
      "learning_rate": 0.00042985213032581453,
      "loss": 3.4112,
      "step": 28500
    },
    {
      "epoch": 0.7715433527549419,
      "grad_norm": 0.4530341625213623,
      "learning_rate": 0.00042860401002506267,
      "loss": 3.4086,
      "step": 29000
    },
    {
      "epoch": 0.7848458243541651,
      "grad_norm": 0.35291025042533875,
      "learning_rate": 0.0004273508771929825,
      "loss": 3.4055,
      "step": 29500
    },
    {
      "epoch": 0.7981482959533881,
      "grad_norm": 0.32673636078834534,
      "learning_rate": 0.00042609774436090224,
      "loss": 3.4013,
      "step": 30000
    },
    {
      "epoch": 0.8114507675526113,
      "grad_norm": 0.3969733715057373,
      "learning_rate": 0.0004248446115288221,
      "loss": 3.4,
      "step": 30500
    },
    {
      "epoch": 0.8247532391518344,
      "grad_norm": 0.3999054431915283,
      "learning_rate": 0.0004235914786967419,
      "loss": 3.3959,
      "step": 31000
    },
    {
      "epoch": 0.8380557107510576,
      "grad_norm": 0.35064542293548584,
      "learning_rate": 0.00042234335839598996,
      "loss": 3.395,
      "step": 31500
    },
    {
      "epoch": 0.8513581823502807,
      "grad_norm": 0.5046707391738892,
      "learning_rate": 0.0004210902255639098,
      "loss": 3.3936,
      "step": 32000
    },
    {
      "epoch": 0.8513581823502807,
      "eval_loss": 3.3094258308410645,
      "eval_runtime": 24.3,
      "eval_samples_per_second": 2057.612,
      "eval_steps_per_second": 8.066,
      "step": 32000
    },
    {
      "epoch": 0.8646606539495039,
      "grad_norm": 0.4120793640613556,
      "learning_rate": 0.0004198370927318296,
      "loss": 3.3892,
      "step": 32500
    },
    {
      "epoch": 0.8779631255487269,
      "grad_norm": 0.3903389573097229,
      "learning_rate": 0.0004185839598997494,
      "loss": 3.3865,
      "step": 33000
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.34149789810180664,
      "learning_rate": 0.00041733082706766917,
      "loss": 3.382,
      "step": 33500
    },
    {
      "epoch": 0.9045680687471732,
      "grad_norm": 0.42285820841789246,
      "learning_rate": 0.000416077694235589,
      "loss": 3.38,
      "step": 34000
    },
    {
      "epoch": 0.9178705403463964,
      "grad_norm": 0.34022077918052673,
      "learning_rate": 0.00041482456140350875,
      "loss": 3.3805,
      "step": 34500
    },
    {
      "epoch": 0.9311730119456195,
      "grad_norm": 0.39704611897468567,
      "learning_rate": 0.0004135714285714286,
      "loss": 3.3789,
      "step": 35000
    },
    {
      "epoch": 0.9444754835448427,
      "grad_norm": 0.4527583718299866,
      "learning_rate": 0.0004123182957393484,
      "loss": 3.3755,
      "step": 35500
    },
    {
      "epoch": 0.9577779551440657,
      "grad_norm": 0.5926409959793091,
      "learning_rate": 0.0004110651629072682,
      "loss": 3.3719,
      "step": 36000
    },
    {
      "epoch": 0.9577779551440657,
      "eval_loss": 3.2896058559417725,
      "eval_runtime": 24.2883,
      "eval_samples_per_second": 2058.605,
      "eval_steps_per_second": 8.07,
      "step": 36000
    },
    {
      "epoch": 0.9710804267432889,
      "grad_norm": 0.46225377917289734,
      "learning_rate": 0.00040981203007518796,
      "loss": 3.3702,
      "step": 36500
    },
    {
      "epoch": 0.984382898342512,
      "grad_norm": 0.3055514097213745,
      "learning_rate": 0.0004085588972431078,
      "loss": 3.3671,
      "step": 37000
    },
    {
      "epoch": 0.9976853699417352,
      "grad_norm": 0.4503965973854065,
      "learning_rate": 0.0004073057644110276,
      "loss": 3.3641,
      "step": 37500
    },
    {
      "epoch": 1.0109878415409583,
      "grad_norm": 0.30128663778305054,
      "learning_rate": 0.0004060526315789474,
      "loss": 3.3596,
      "step": 38000
    },
    {
      "epoch": 1.0242903131401815,
      "grad_norm": 0.35037240386009216,
      "learning_rate": 0.00040479949874686717,
      "loss": 3.3571,
      "step": 38500
    },
    {
      "epoch": 1.0375927847394046,
      "grad_norm": 0.405442476272583,
      "learning_rate": 0.000403546365914787,
      "loss": 3.3548,
      "step": 39000
    },
    {
      "epoch": 1.0508952563386278,
      "grad_norm": 0.43216267228126526,
      "learning_rate": 0.00040229323308270675,
      "loss": 3.3535,
      "step": 39500
    },
    {
      "epoch": 1.064197727937851,
      "grad_norm": 0.3598766326904297,
      "learning_rate": 0.0004010401002506266,
      "loss": 3.3537,
      "step": 40000
    },
    {
      "epoch": 1.064197727937851,
      "eval_loss": 3.2726991176605225,
      "eval_runtime": 24.2233,
      "eval_samples_per_second": 2064.125,
      "eval_steps_per_second": 8.091,
      "step": 40000
    },
    {
      "epoch": 1.077500199537074,
      "grad_norm": 0.38022366166114807,
      "learning_rate": 0.0003997869674185464,
      "loss": 3.3508,
      "step": 40500
    },
    {
      "epoch": 1.090802671136297,
      "grad_norm": 0.33575356006622314,
      "learning_rate": 0.0003985338345864662,
      "loss": 3.348,
      "step": 41000
    },
    {
      "epoch": 1.1041051427355202,
      "grad_norm": 0.5182079076766968,
      "learning_rate": 0.00039728070175438596,
      "loss": 3.3468,
      "step": 41500
    },
    {
      "epoch": 1.1174076143347433,
      "grad_norm": 0.3691936731338501,
      "learning_rate": 0.00039602756892230577,
      "loss": 3.3459,
      "step": 42000
    },
    {
      "epoch": 1.1307100859339665,
      "grad_norm": 0.3681364059448242,
      "learning_rate": 0.0003947744360902256,
      "loss": 3.3447,
      "step": 42500
    },
    {
      "epoch": 1.1440125575331896,
      "grad_norm": 0.34480515122413635,
      "learning_rate": 0.0003935213032581454,
      "loss": 3.3439,
      "step": 43000
    },
    {
      "epoch": 1.1573150291324128,
      "grad_norm": 0.3006117641925812,
      "learning_rate": 0.00039226817042606517,
      "loss": 3.341,
      "step": 43500
    },
    {
      "epoch": 1.170617500731636,
      "grad_norm": 0.42098644375801086,
      "learning_rate": 0.000391015037593985,
      "loss": 3.3384,
      "step": 44000
    },
    {
      "epoch": 1.170617500731636,
      "eval_loss": 3.2588725090026855,
      "eval_runtime": 24.3564,
      "eval_samples_per_second": 2052.847,
      "eval_steps_per_second": 8.047,
      "step": 44000
    },
    {
      "epoch": 1.183919972330859,
      "grad_norm": 0.3167800009250641,
      "learning_rate": 0.00038976190476190474,
      "loss": 3.3374,
      "step": 44500
    },
    {
      "epoch": 1.1972224439300823,
      "grad_norm": 0.40917837619781494,
      "learning_rate": 0.0003885087719298246,
      "loss": 3.3363,
      "step": 45000
    },
    {
      "epoch": 1.2105249155293054,
      "grad_norm": 0.503820538520813,
      "learning_rate": 0.0003872581453634085,
      "loss": 3.3336,
      "step": 45500
    },
    {
      "epoch": 1.2238273871285286,
      "grad_norm": 0.3353216350078583,
      "learning_rate": 0.0003860050125313283,
      "loss": 3.332,
      "step": 46000
    },
    {
      "epoch": 1.2371298587277515,
      "grad_norm": 0.3509925603866577,
      "learning_rate": 0.00038475187969924814,
      "loss": 3.3319,
      "step": 46500
    },
    {
      "epoch": 1.2504323303269747,
      "grad_norm": 0.3945606052875519,
      "learning_rate": 0.0003834987468671679,
      "loss": 3.3297,
      "step": 47000
    },
    {
      "epoch": 1.2637348019261978,
      "grad_norm": 0.4009542167186737,
      "learning_rate": 0.0003822456140350877,
      "loss": 3.328,
      "step": 47500
    },
    {
      "epoch": 1.277037273525421,
      "grad_norm": 0.32312914729118347,
      "learning_rate": 0.00038099498746867167,
      "loss": 3.3269,
      "step": 48000
    },
    {
      "epoch": 1.277037273525421,
      "eval_loss": 3.246556282043457,
      "eval_runtime": 24.2817,
      "eval_samples_per_second": 2059.165,
      "eval_steps_per_second": 8.072,
      "step": 48000
    },
    {
      "epoch": 1.290339745124644,
      "grad_norm": 0.3247356414794922,
      "learning_rate": 0.0003797418546365915,
      "loss": 3.3256,
      "step": 48500
    },
    {
      "epoch": 1.3036422167238673,
      "grad_norm": 0.33100199699401855,
      "learning_rate": 0.00037848872180451125,
      "loss": 3.3236,
      "step": 49000
    },
    {
      "epoch": 1.3169446883230904,
      "grad_norm": 0.44898200035095215,
      "learning_rate": 0.0003772355889724311,
      "loss": 3.3226,
      "step": 49500
    },
    {
      "epoch": 1.3302471599223136,
      "grad_norm": 0.33166518807411194,
      "learning_rate": 0.00037598496240601507,
      "loss": 3.3204,
      "step": 50000
    },
    {
      "epoch": 1.3435496315215367,
      "grad_norm": 0.31784433126449585,
      "learning_rate": 0.0003747318295739349,
      "loss": 3.3173,
      "step": 50500
    },
    {
      "epoch": 1.3568521031207599,
      "grad_norm": 0.29918909072875977,
      "learning_rate": 0.00037348120300751883,
      "loss": 3.3176,
      "step": 51000
    },
    {
      "epoch": 1.370154574719983,
      "grad_norm": 0.3201218247413635,
      "learning_rate": 0.0003722280701754386,
      "loss": 3.3157,
      "step": 51500
    },
    {
      "epoch": 1.3834570463192062,
      "grad_norm": 0.4111556112766266,
      "learning_rate": 0.0003709749373433584,
      "loss": 3.3146,
      "step": 52000
    },
    {
      "epoch": 1.3834570463192062,
      "eval_loss": 3.233426809310913,
      "eval_runtime": 24.3136,
      "eval_samples_per_second": 2056.465,
      "eval_steps_per_second": 8.061,
      "step": 52000
    },
    {
      "epoch": 1.3967595179184293,
      "grad_norm": 0.3248349726200104,
      "learning_rate": 0.00036972180451127817,
      "loss": 3.3129,
      "step": 52500
    },
    {
      "epoch": 1.4100619895176525,
      "grad_norm": 0.33411532640457153,
      "learning_rate": 0.000368468671679198,
      "loss": 3.3101,
      "step": 53000
    },
    {
      "epoch": 1.4233644611168756,
      "grad_norm": 0.3109601140022278,
      "learning_rate": 0.0003672155388471178,
      "loss": 3.3104,
      "step": 53500
    },
    {
      "epoch": 1.4366669327160986,
      "grad_norm": 0.39764857292175293,
      "learning_rate": 0.0003659624060150376,
      "loss": 3.3087,
      "step": 54000
    },
    {
      "epoch": 1.4499694043153217,
      "grad_norm": 0.30247700214385986,
      "learning_rate": 0.0003647092731829574,
      "loss": 3.3084,
      "step": 54500
    },
    {
      "epoch": 1.4632718759145449,
      "grad_norm": 0.41603997349739075,
      "learning_rate": 0.0003634561403508772,
      "loss": 3.306,
      "step": 55000
    },
    {
      "epoch": 1.476574347513768,
      "grad_norm": 0.38981184363365173,
      "learning_rate": 0.00036220551378446115,
      "loss": 3.3059,
      "step": 55500
    },
    {
      "epoch": 1.4898768191129912,
      "grad_norm": 0.3159763514995575,
      "learning_rate": 0.00036095238095238096,
      "loss": 3.3049,
      "step": 56000
    },
    {
      "epoch": 1.4898768191129912,
      "eval_loss": 3.222005605697632,
      "eval_runtime": 24.3499,
      "eval_samples_per_second": 2053.397,
      "eval_steps_per_second": 8.049,
      "step": 56000
    },
    {
      "epoch": 1.5031792907122143,
      "grad_norm": 0.36469611525535583,
      "learning_rate": 0.0003596992481203007,
      "loss": 3.3027,
      "step": 56500
    },
    {
      "epoch": 1.5164817623114375,
      "grad_norm": 0.2968452572822571,
      "learning_rate": 0.0003584461152882206,
      "loss": 3.3025,
      "step": 57000
    },
    {
      "epoch": 1.5297842339106607,
      "grad_norm": 0.30674439668655396,
      "learning_rate": 0.0003571954887218045,
      "loss": 3.3,
      "step": 57500
    },
    {
      "epoch": 1.5430867055098836,
      "grad_norm": 0.32871684432029724,
      "learning_rate": 0.00035594235588972436,
      "loss": 3.3007,
      "step": 58000
    },
    {
      "epoch": 1.5563891771091067,
      "grad_norm": 0.3283652663230896,
      "learning_rate": 0.0003546892230576441,
      "loss": 3.3,
      "step": 58500
    },
    {
      "epoch": 1.56969164870833,
      "grad_norm": 0.32946908473968506,
      "learning_rate": 0.0003534385964912281,
      "loss": 3.2973,
      "step": 59000
    },
    {
      "epoch": 1.582994120307553,
      "grad_norm": 0.40528205037117004,
      "learning_rate": 0.0003521854636591479,
      "loss": 3.2971,
      "step": 59500
    },
    {
      "epoch": 1.5962965919067762,
      "grad_norm": 0.3473675549030304,
      "learning_rate": 0.00035093233082706765,
      "loss": 3.2962,
      "step": 60000
    },
    {
      "epoch": 1.5962965919067762,
      "eval_loss": 3.2132620811462402,
      "eval_runtime": 24.2862,
      "eval_samples_per_second": 2058.783,
      "eval_steps_per_second": 8.07,
      "step": 60000
    },
    {
      "epoch": 1.6095990635059994,
      "grad_norm": 0.3448873460292816,
      "learning_rate": 0.00034967919799498747,
      "loss": 3.2947,
      "step": 60500
    },
    {
      "epoch": 1.6229015351052225,
      "grad_norm": 0.3738086223602295,
      "learning_rate": 0.0003484260651629073,
      "loss": 3.2938,
      "step": 61000
    },
    {
      "epoch": 1.6362040067044457,
      "grad_norm": 0.43880534172058105,
      "learning_rate": 0.0003471729323308271,
      "loss": 3.2921,
      "step": 61500
    },
    {
      "epoch": 1.6495064783036688,
      "grad_norm": 0.3456054925918579,
      "learning_rate": 0.00034591979949874686,
      "loss": 3.2923,
      "step": 62000
    },
    {
      "epoch": 1.662808949902892,
      "grad_norm": 0.2854778468608856,
      "learning_rate": 0.0003446666666666667,
      "loss": 3.2892,
      "step": 62500
    },
    {
      "epoch": 1.6761114215021151,
      "grad_norm": 0.40610578656196594,
      "learning_rate": 0.00034341353383458644,
      "loss": 3.2888,
      "step": 63000
    },
    {
      "epoch": 1.6894138931013383,
      "grad_norm": 0.31456702947616577,
      "learning_rate": 0.00034216290726817044,
      "loss": 3.2873,
      "step": 63500
    },
    {
      "epoch": 1.7027163647005614,
      "grad_norm": 0.3248228430747986,
      "learning_rate": 0.0003409097744360902,
      "loss": 3.2863,
      "step": 64000
    },
    {
      "epoch": 1.7027163647005614,
      "eval_loss": 3.2048568725585938,
      "eval_runtime": 24.2968,
      "eval_samples_per_second": 2057.887,
      "eval_steps_per_second": 8.067,
      "step": 64000
    },
    {
      "epoch": 1.7160188362997846,
      "grad_norm": 0.42077332735061646,
      "learning_rate": 0.0003396566416040101,
      "loss": 3.2858,
      "step": 64500
    },
    {
      "epoch": 1.7293213078990077,
      "grad_norm": 0.35154375433921814,
      "learning_rate": 0.00033840350877192984,
      "loss": 3.2856,
      "step": 65000
    },
    {
      "epoch": 1.7426237794982309,
      "grad_norm": 0.32585737109184265,
      "learning_rate": 0.0003371553884711779,
      "loss": 3.2815,
      "step": 65500
    },
    {
      "epoch": 1.755926251097454,
      "grad_norm": 0.378326952457428,
      "learning_rate": 0.0003359022556390978,
      "loss": 3.282,
      "step": 66000
    },
    {
      "epoch": 1.7692287226966772,
      "grad_norm": 0.301222026348114,
      "learning_rate": 0.00033464912280701755,
      "loss": 3.2799,
      "step": 66500
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 0.2866257429122925,
      "learning_rate": 0.00033339598997493737,
      "loss": 3.2808,
      "step": 67000
    },
    {
      "epoch": 1.7958336658951233,
      "grad_norm": 0.36454275250434875,
      "learning_rate": 0.0003321453634085213,
      "loss": 3.281,
      "step": 67500
    },
    {
      "epoch": 1.8091361374943464,
      "grad_norm": 0.3223206102848053,
      "learning_rate": 0.00033089223057644114,
      "loss": 3.2782,
      "step": 68000
    },
    {
      "epoch": 1.8091361374943464,
      "eval_loss": 3.1968142986297607,
      "eval_runtime": 24.2811,
      "eval_samples_per_second": 2059.217,
      "eval_steps_per_second": 8.072,
      "step": 68000
    },
    {
      "epoch": 1.8224386090935696,
      "grad_norm": 0.36175820231437683,
      "learning_rate": 0.0003296390977443609,
      "loss": 3.2775,
      "step": 68500
    },
    {
      "epoch": 1.8357410806927927,
      "grad_norm": 0.34414634108543396,
      "learning_rate": 0.0003283859649122807,
      "loss": 3.2768,
      "step": 69000
    },
    {
      "epoch": 1.849043552292016,
      "grad_norm": 0.3239957094192505,
      "learning_rate": 0.00032713283208020053,
      "loss": 3.2766,
      "step": 69500
    },
    {
      "epoch": 1.862346023891239,
      "grad_norm": 0.2994060814380646,
      "learning_rate": 0.00032587969924812035,
      "loss": 3.2742,
      "step": 70000
    },
    {
      "epoch": 1.875648495490462,
      "grad_norm": 0.3117155432701111,
      "learning_rate": 0.0003246265664160401,
      "loss": 3.2737,
      "step": 70500
    },
    {
      "epoch": 1.8889509670896851,
      "grad_norm": 0.3188328742980957,
      "learning_rate": 0.0003233734335839599,
      "loss": 3.272,
      "step": 71000
    },
    {
      "epoch": 1.9022534386889083,
      "grad_norm": 0.36510100960731506,
      "learning_rate": 0.0003221203007518797,
      "loss": 3.2719,
      "step": 71500
    },
    {
      "epoch": 1.9155559102881314,
      "grad_norm": 0.48163923621177673,
      "learning_rate": 0.00032086716791979956,
      "loss": 3.2704,
      "step": 72000
    },
    {
      "epoch": 1.9155559102881314,
      "eval_loss": 3.189951181411743,
      "eval_runtime": 24.2587,
      "eval_samples_per_second": 2061.116,
      "eval_steps_per_second": 8.08,
      "step": 72000
    },
    {
      "epoch": 1.9288583818873546,
      "grad_norm": 0.28836971521377563,
      "learning_rate": 0.0003196140350877193,
      "loss": 3.2702,
      "step": 72500
    },
    {
      "epoch": 1.9421608534865777,
      "grad_norm": 0.30696797370910645,
      "learning_rate": 0.00031836090225563913,
      "loss": 3.2717,
      "step": 73000
    },
    {
      "epoch": 1.955463325085801,
      "grad_norm": 0.2962409257888794,
      "learning_rate": 0.0003171077694235589,
      "loss": 3.2681,
      "step": 73500
    },
    {
      "epoch": 1.968765796685024,
      "grad_norm": 0.38496133685112,
      "learning_rate": 0.00031585714285714284,
      "loss": 3.2676,
      "step": 74000
    },
    {
      "epoch": 1.9820682682842472,
      "grad_norm": 0.29067671298980713,
      "learning_rate": 0.00031460401002506266,
      "loss": 3.266,
      "step": 74500
    },
    {
      "epoch": 1.9953707398834704,
      "grad_norm": 0.46996885538101196,
      "learning_rate": 0.0003133508771929824,
      "loss": 3.2649,
      "step": 75000
    },
    {
      "epoch": 2.0086732114826935,
      "grad_norm": 0.45013612508773804,
      "learning_rate": 0.0003120977443609023,
      "loss": 3.2631,
      "step": 75500
    },
    {
      "epoch": 2.0219756830819167,
      "grad_norm": 0.3189330995082855,
      "learning_rate": 0.00031084461152882205,
      "loss": 3.2603,
      "step": 76000
    },
    {
      "epoch": 2.0219756830819167,
      "eval_loss": 3.1835367679595947,
      "eval_runtime": 24.2585,
      "eval_samples_per_second": 2061.136,
      "eval_steps_per_second": 8.08,
      "step": 76000
    },
    {
      "epoch": 2.03527815468114,
      "grad_norm": 0.3362482786178589,
      "learning_rate": 0.00030959398496240606,
      "loss": 3.2598,
      "step": 76500
    },
    {
      "epoch": 2.048580626280363,
      "grad_norm": 0.4547310173511505,
      "learning_rate": 0.0003083408521303258,
      "loss": 3.2601,
      "step": 77000
    },
    {
      "epoch": 2.061883097879586,
      "grad_norm": 0.30234700441360474,
      "learning_rate": 0.00030708771929824564,
      "loss": 3.2597,
      "step": 77500
    },
    {
      "epoch": 2.0751855694788093,
      "grad_norm": 0.38318657875061035,
      "learning_rate": 0.0003058345864661654,
      "loss": 3.2587,
      "step": 78000
    },
    {
      "epoch": 2.0884880410780324,
      "grad_norm": 0.3099946677684784,
      "learning_rate": 0.00030458395989974935,
      "loss": 3.2579,
      "step": 78500
    },
    {
      "epoch": 2.1017905126772556,
      "grad_norm": 0.3158225119113922,
      "learning_rate": 0.00030333082706766916,
      "loss": 3.2577,
      "step": 79000
    },
    {
      "epoch": 2.1150929842764787,
      "grad_norm": 0.29689356684684753,
      "learning_rate": 0.0003020776942355889,
      "loss": 3.2555,
      "step": 79500
    },
    {
      "epoch": 2.128395455875702,
      "grad_norm": 0.287536084651947,
      "learning_rate": 0.0003008245614035088,
      "loss": 3.2561,
      "step": 80000
    },
    {
      "epoch": 2.128395455875702,
      "eval_loss": 3.174669027328491,
      "eval_runtime": 24.2532,
      "eval_samples_per_second": 2061.582,
      "eval_steps_per_second": 8.081,
      "step": 80000
    },
    {
      "epoch": 2.141697927474925,
      "grad_norm": 0.3544728457927704,
      "learning_rate": 0.00029957142857142856,
      "loss": 3.2553,
      "step": 80500
    },
    {
      "epoch": 2.155000399074148,
      "grad_norm": 0.29459652304649353,
      "learning_rate": 0.00029832080200501256,
      "loss": 3.2543,
      "step": 81000
    },
    {
      "epoch": 2.168302870673371,
      "grad_norm": 0.4215697646141052,
      "learning_rate": 0.00029707268170426065,
      "loss": 3.2534,
      "step": 81500
    },
    {
      "epoch": 2.181605342272594,
      "grad_norm": 0.298277884721756,
      "learning_rate": 0.0002958195488721804,
      "loss": 3.2518,
      "step": 82000
    },
    {
      "epoch": 2.194907813871817,
      "grad_norm": 0.32912835478782654,
      "learning_rate": 0.0002945664160401003,
      "loss": 3.2514,
      "step": 82500
    },
    {
      "epoch": 2.2082102854710404,
      "grad_norm": 0.3689306080341339,
      "learning_rate": 0.00029331328320802004,
      "loss": 3.2502,
      "step": 83000
    },
    {
      "epoch": 2.2215127570702635,
      "grad_norm": 0.3104954659938812,
      "learning_rate": 0.00029206015037593986,
      "loss": 3.2516,
      "step": 83500
    },
    {
      "epoch": 2.2348152286694867,
      "grad_norm": 0.30196505784988403,
      "learning_rate": 0.0002908070175438596,
      "loss": 3.2507,
      "step": 84000
    },
    {
      "epoch": 2.2348152286694867,
      "eval_loss": 3.1687169075012207,
      "eval_runtime": 24.2676,
      "eval_samples_per_second": 2060.36,
      "eval_steps_per_second": 8.077,
      "step": 84000
    },
    {
      "epoch": 2.24811770026871,
      "grad_norm": 0.29449784755706787,
      "learning_rate": 0.00028955388471177943,
      "loss": 3.2497,
      "step": 84500
    },
    {
      "epoch": 2.261420171867933,
      "grad_norm": 0.30292949080467224,
      "learning_rate": 0.00028830075187969925,
      "loss": 3.2498,
      "step": 85000
    },
    {
      "epoch": 2.274722643467156,
      "grad_norm": 0.28702813386917114,
      "learning_rate": 0.00028704761904761907,
      "loss": 3.2474,
      "step": 85500
    },
    {
      "epoch": 2.2880251150663793,
      "grad_norm": 0.28267744183540344,
      "learning_rate": 0.00028579448621553883,
      "loss": 3.2469,
      "step": 86000
    },
    {
      "epoch": 2.3013275866656024,
      "grad_norm": 0.2871388792991638,
      "learning_rate": 0.00028454135338345864,
      "loss": 3.2473,
      "step": 86500
    },
    {
      "epoch": 2.3146300582648256,
      "grad_norm": 0.3521350622177124,
      "learning_rate": 0.0002832882205513784,
      "loss": 3.2474,
      "step": 87000
    },
    {
      "epoch": 2.3279325298640487,
      "grad_norm": 0.30266931653022766,
      "learning_rate": 0.0002820375939849624,
      "loss": 3.2453,
      "step": 87500
    },
    {
      "epoch": 2.341235001463272,
      "grad_norm": 0.3038886785507202,
      "learning_rate": 0.00028078696741854636,
      "loss": 3.2463,
      "step": 88000
    },
    {
      "epoch": 2.341235001463272,
      "eval_loss": 3.1648099422454834,
      "eval_runtime": 24.322,
      "eval_samples_per_second": 2055.748,
      "eval_steps_per_second": 8.059,
      "step": 88000
    },
    {
      "epoch": 2.354537473062495,
      "grad_norm": 0.30594152212142944,
      "learning_rate": 0.0002795338345864662,
      "loss": 3.2445,
      "step": 88500
    },
    {
      "epoch": 2.367839944661718,
      "grad_norm": 0.29921337962150574,
      "learning_rate": 0.000278280701754386,
      "loss": 3.2432,
      "step": 89000
    },
    {
      "epoch": 2.3811424162609414,
      "grad_norm": 0.30120256543159485,
      "learning_rate": 0.0002770275689223058,
      "loss": 3.2438,
      "step": 89500
    },
    {
      "epoch": 2.3944448878601645,
      "grad_norm": 0.29124021530151367,
      "learning_rate": 0.00027577443609022557,
      "loss": 3.2426,
      "step": 90000
    },
    {
      "epoch": 2.4077473594593877,
      "grad_norm": 0.2947174906730652,
      "learning_rate": 0.0002745213032581454,
      "loss": 3.2392,
      "step": 90500
    },
    {
      "epoch": 2.421049831058611,
      "grad_norm": 0.3960943818092346,
      "learning_rate": 0.00027326817042606515,
      "loss": 3.2397,
      "step": 91000
    },
    {
      "epoch": 2.434352302657834,
      "grad_norm": 0.30368468165397644,
      "learning_rate": 0.000272015037593985,
      "loss": 3.239,
      "step": 91500
    },
    {
      "epoch": 2.447654774257057,
      "grad_norm": 0.4117695689201355,
      "learning_rate": 0.0002707644110275689,
      "loss": 3.2415,
      "step": 92000
    },
    {
      "epoch": 2.447654774257057,
      "eval_loss": 3.157994031906128,
      "eval_runtime": 24.2896,
      "eval_samples_per_second": 2058.492,
      "eval_steps_per_second": 8.069,
      "step": 92000
    },
    {
      "epoch": 2.4609572458562803,
      "grad_norm": 0.337422639131546,
      "learning_rate": 0.00026951127819548873,
      "loss": 3.2398,
      "step": 92500
    },
    {
      "epoch": 2.474259717455503,
      "grad_norm": 0.3542685806751251,
      "learning_rate": 0.00026825814536340854,
      "loss": 3.2372,
      "step": 93000
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.2986062169075012,
      "learning_rate": 0.0002670050125313283,
      "loss": 3.2368,
      "step": 93500
    },
    {
      "epoch": 2.5008646606539493,
      "grad_norm": 0.3605614900588989,
      "learning_rate": 0.0002657518796992481,
      "loss": 3.2377,
      "step": 94000
    },
    {
      "epoch": 2.5141671322531725,
      "grad_norm": 0.4099574387073517,
      "learning_rate": 0.00026450125313283207,
      "loss": 3.2354,
      "step": 94500
    },
    {
      "epoch": 2.5274696038523956,
      "grad_norm": 0.4187985956668854,
      "learning_rate": 0.0002632481203007519,
      "loss": 3.2359,
      "step": 95000
    },
    {
      "epoch": 2.5407720754516188,
      "grad_norm": 0.31584569811820984,
      "learning_rate": 0.00026199498746867165,
      "loss": 3.2349,
      "step": 95500
    },
    {
      "epoch": 2.554074547050842,
      "grad_norm": 0.3016689121723175,
      "learning_rate": 0.0002607418546365915,
      "loss": 3.2322,
      "step": 96000
    },
    {
      "epoch": 2.554074547050842,
      "eval_loss": 3.1531097888946533,
      "eval_runtime": 24.3004,
      "eval_samples_per_second": 2057.577,
      "eval_steps_per_second": 8.066,
      "step": 96000
    },
    {
      "epoch": 2.567377018650065,
      "grad_norm": 0.2990950047969818,
      "learning_rate": 0.00025949122807017547,
      "loss": 3.2344,
      "step": 96500
    },
    {
      "epoch": 2.580679490249288,
      "grad_norm": 0.34966057538986206,
      "learning_rate": 0.00025823809523809523,
      "loss": 3.232,
      "step": 97000
    },
    {
      "epoch": 2.5939819618485114,
      "grad_norm": 0.4278000593185425,
      "learning_rate": 0.00025698496240601505,
      "loss": 3.2338,
      "step": 97500
    },
    {
      "epoch": 2.6072844334477345,
      "grad_norm": 0.3391219973564148,
      "learning_rate": 0.0002557318295739348,
      "loss": 3.2316,
      "step": 98000
    },
    {
      "epoch": 2.6205869050469577,
      "grad_norm": 0.29166102409362793,
      "learning_rate": 0.0002544812030075188,
      "loss": 3.2304,
      "step": 98500
    },
    {
      "epoch": 2.633889376646181,
      "grad_norm": 0.35172125697135925,
      "learning_rate": 0.0002532280701754386,
      "loss": 3.2287,
      "step": 99000
    },
    {
      "epoch": 2.647191848245404,
      "grad_norm": 0.2931186258792877,
      "learning_rate": 0.0002519749373433584,
      "loss": 3.2307,
      "step": 99500
    },
    {
      "epoch": 2.660494319844627,
      "grad_norm": 0.2969956696033478,
      "learning_rate": 0.0002507218045112782,
      "loss": 3.2274,
      "step": 100000
    },
    {
      "epoch": 2.660494319844627,
      "eval_loss": 3.1480531692504883,
      "eval_runtime": 24.3053,
      "eval_samples_per_second": 2057.164,
      "eval_steps_per_second": 8.064,
      "step": 100000
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 0.42931944131851196,
      "learning_rate": 0.000249468671679198,
      "loss": 3.2276,
      "step": 100500
    },
    {
      "epoch": 2.6870992630430734,
      "grad_norm": 0.3466760516166687,
      "learning_rate": 0.0002482155388471178,
      "loss": 3.2281,
      "step": 101000
    },
    {
      "epoch": 2.7004017346422966,
      "grad_norm": 0.34068453311920166,
      "learning_rate": 0.0002469624060150376,
      "loss": 3.2273,
      "step": 101500
    },
    {
      "epoch": 2.7137042062415198,
      "grad_norm": 0.3652836084365845,
      "learning_rate": 0.0002457092731829574,
      "loss": 3.2264,
      "step": 102000
    },
    {
      "epoch": 2.727006677840743,
      "grad_norm": 0.4563342034816742,
      "learning_rate": 0.00024445614035087723,
      "loss": 3.2265,
      "step": 102500
    },
    {
      "epoch": 2.740309149439966,
      "grad_norm": 0.28997325897216797,
      "learning_rate": 0.00024320551378446116,
      "loss": 3.2249,
      "step": 103000
    },
    {
      "epoch": 2.753611621039189,
      "grad_norm": 0.3262353837490082,
      "learning_rate": 0.00024195238095238095,
      "loss": 3.2251,
      "step": 103500
    },
    {
      "epoch": 2.7669140926384124,
      "grad_norm": 0.3031652271747589,
      "learning_rate": 0.00024069924812030076,
      "loss": 3.2246,
      "step": 104000
    },
    {
      "epoch": 2.7669140926384124,
      "eval_loss": 3.1439638137817383,
      "eval_runtime": 24.2701,
      "eval_samples_per_second": 2060.146,
      "eval_steps_per_second": 8.076,
      "step": 104000
    },
    {
      "epoch": 2.7802165642376355,
      "grad_norm": 0.32371455430984497,
      "learning_rate": 0.00023944611528822055,
      "loss": 3.2238,
      "step": 104500
    },
    {
      "epoch": 2.7935190358368587,
      "grad_norm": 0.3394489288330078,
      "learning_rate": 0.00023819548872180453,
      "loss": 3.2222,
      "step": 105000
    },
    {
      "epoch": 2.806821507436082,
      "grad_norm": 0.3052513301372528,
      "learning_rate": 0.00023694486215538845,
      "loss": 3.223,
      "step": 105500
    },
    {
      "epoch": 2.820123979035305,
      "grad_norm": 0.2985069453716278,
      "learning_rate": 0.00023569172932330827,
      "loss": 3.2218,
      "step": 106000
    },
    {
      "epoch": 2.833426450634528,
      "grad_norm": 0.30205237865448,
      "learning_rate": 0.00023443859649122805,
      "loss": 3.2226,
      "step": 106500
    },
    {
      "epoch": 2.8467289222337513,
      "grad_norm": 0.3074747622013092,
      "learning_rate": 0.00023318546365914787,
      "loss": 3.2227,
      "step": 107000
    },
    {
      "epoch": 2.860031393832974,
      "grad_norm": 0.37289077043533325,
      "learning_rate": 0.00023193233082706766,
      "loss": 3.2206,
      "step": 107500
    },
    {
      "epoch": 2.873333865432197,
      "grad_norm": 0.31376123428344727,
      "learning_rate": 0.00023067919799498745,
      "loss": 3.2222,
      "step": 108000
    },
    {
      "epoch": 2.873333865432197,
      "eval_loss": 3.139058828353882,
      "eval_runtime": 24.2916,
      "eval_samples_per_second": 2058.327,
      "eval_steps_per_second": 8.069,
      "step": 108000
    },
    {
      "epoch": 2.8866363370314203,
      "grad_norm": 0.37276023626327515,
      "learning_rate": 0.00022942606516290726,
      "loss": 3.2192,
      "step": 108500
    },
    {
      "epoch": 2.8999388086306435,
      "grad_norm": 0.3171160817146301,
      "learning_rate": 0.00022817293233082705,
      "loss": 3.2188,
      "step": 109000
    },
    {
      "epoch": 2.9132412802298666,
      "grad_norm": 0.4469095468521118,
      "learning_rate": 0.00022691979949874687,
      "loss": 3.2199,
      "step": 109500
    },
    {
      "epoch": 2.9265437518290898,
      "grad_norm": 0.32652321457862854,
      "learning_rate": 0.00022566917293233082,
      "loss": 3.218,
      "step": 110000
    },
    {
      "epoch": 2.939846223428313,
      "grad_norm": 0.3065187633037567,
      "learning_rate": 0.00022441604010025064,
      "loss": 3.2178,
      "step": 110500
    },
    {
      "epoch": 2.953148695027536,
      "grad_norm": 0.30305370688438416,
      "learning_rate": 0.00022316290726817042,
      "loss": 3.2171,
      "step": 111000
    },
    {
      "epoch": 2.9664511666267592,
      "grad_norm": 0.28157755732536316,
      "learning_rate": 0.00022190977443609024,
      "loss": 3.2163,
      "step": 111500
    },
    {
      "epoch": 2.9797536382259824,
      "grad_norm": 0.320007860660553,
      "learning_rate": 0.0002206591478696742,
      "loss": 3.2159,
      "step": 112000
    },
    {
      "epoch": 2.9797536382259824,
      "eval_loss": 3.134408712387085,
      "eval_runtime": 24.3031,
      "eval_samples_per_second": 2057.349,
      "eval_steps_per_second": 8.065,
      "step": 112000
    },
    {
      "epoch": 2.9930561098252055,
      "grad_norm": 0.31929999589920044,
      "learning_rate": 0.000219406015037594,
      "loss": 3.2148,
      "step": 112500
    },
    {
      "epoch": 3.0063585814244287,
      "grad_norm": 0.356179803609848,
      "learning_rate": 0.0002181528822055138,
      "loss": 3.2133,
      "step": 113000
    },
    {
      "epoch": 3.019661053023652,
      "grad_norm": 0.2837272882461548,
      "learning_rate": 0.00021689974937343358,
      "loss": 3.2106,
      "step": 113500
    },
    {
      "epoch": 3.032963524622875,
      "grad_norm": 0.28846269845962524,
      "learning_rate": 0.00021564912280701753,
      "loss": 3.2105,
      "step": 114000
    },
    {
      "epoch": 3.046265996222098,
      "grad_norm": 0.32729730010032654,
      "learning_rate": 0.00021439598997493735,
      "loss": 3.21,
      "step": 114500
    },
    {
      "epoch": 3.0595684678213213,
      "grad_norm": 0.3002837002277374,
      "learning_rate": 0.00021314285714285714,
      "loss": 3.2106,
      "step": 115000
    },
    {
      "epoch": 3.0728709394205445,
      "grad_norm": 0.33629053831100464,
      "learning_rate": 0.00021188972431077693,
      "loss": 3.2092,
      "step": 115500
    },
    {
      "epoch": 3.0861734110197676,
      "grad_norm": 0.34630143642425537,
      "learning_rate": 0.00021063659147869674,
      "loss": 3.2113,
      "step": 116000
    },
    {
      "epoch": 3.0861734110197676,
      "eval_loss": 3.1307051181793213,
      "eval_runtime": 24.2733,
      "eval_samples_per_second": 2059.88,
      "eval_steps_per_second": 8.075,
      "step": 116000
    },
    {
      "epoch": 3.0994758826189908,
      "grad_norm": 0.2924683392047882,
      "learning_rate": 0.00020938596491228072,
      "loss": 3.2116,
      "step": 116500
    },
    {
      "epoch": 3.112778354218214,
      "grad_norm": 0.2942814230918884,
      "learning_rate": 0.0002081328320802005,
      "loss": 3.2095,
      "step": 117000
    },
    {
      "epoch": 3.126080825817437,
      "grad_norm": 0.29981866478919983,
      "learning_rate": 0.0002068796992481203,
      "loss": 3.2085,
      "step": 117500
    },
    {
      "epoch": 3.1393832974166602,
      "grad_norm": 0.35430294275283813,
      "learning_rate": 0.00020562907268170428,
      "loss": 3.2075,
      "step": 118000
    },
    {
      "epoch": 3.152685769015883,
      "grad_norm": 0.3017905056476593,
      "learning_rate": 0.00020437593984962406,
      "loss": 3.206,
      "step": 118500
    },
    {
      "epoch": 3.165988240615106,
      "grad_norm": 0.3141261637210846,
      "learning_rate": 0.00020312280701754388,
      "loss": 3.2069,
      "step": 119000
    },
    {
      "epoch": 3.1792907122143292,
      "grad_norm": 0.2991432845592499,
      "learning_rate": 0.00020186967418546367,
      "loss": 3.2063,
      "step": 119500
    },
    {
      "epoch": 3.1925931838135524,
      "grad_norm": 0.3045481741428375,
      "learning_rate": 0.00020061654135338349,
      "loss": 3.2052,
      "step": 120000
    },
    {
      "epoch": 3.1925931838135524,
      "eval_loss": 3.126707077026367,
      "eval_runtime": 24.255,
      "eval_samples_per_second": 2061.427,
      "eval_steps_per_second": 8.081,
      "step": 120000
    },
    {
      "epoch": 3.2058956554127755,
      "grad_norm": 0.2911725640296936,
      "learning_rate": 0.00019936340852130327,
      "loss": 3.2046,
      "step": 120500
    },
    {
      "epoch": 3.2191981270119987,
      "grad_norm": 0.29767900705337524,
      "learning_rate": 0.00019811027568922306,
      "loss": 3.2043,
      "step": 121000
    },
    {
      "epoch": 3.232500598611222,
      "grad_norm": 0.30845603346824646,
      "learning_rate": 0.00019685714285714288,
      "loss": 3.2047,
      "step": 121500
    },
    {
      "epoch": 3.245803070210445,
      "grad_norm": 0.28650420904159546,
      "learning_rate": 0.00019560401002506267,
      "loss": 3.2062,
      "step": 122000
    },
    {
      "epoch": 3.259105541809668,
      "grad_norm": 0.3092186450958252,
      "learning_rate": 0.00019435338345864662,
      "loss": 3.2053,
      "step": 122500
    },
    {
      "epoch": 3.2724080134088913,
      "grad_norm": 0.29617035388946533,
      "learning_rate": 0.0001931002506265664,
      "loss": 3.2031,
      "step": 123000
    },
    {
      "epoch": 3.2857104850081145,
      "grad_norm": 0.3178594410419464,
      "learning_rate": 0.00019184711779448622,
      "loss": 3.2035,
      "step": 123500
    },
    {
      "epoch": 3.2990129566073376,
      "grad_norm": 0.2856387794017792,
      "learning_rate": 0.000190593984962406,
      "loss": 3.2029,
      "step": 124000
    },
    {
      "epoch": 3.2990129566073376,
      "eval_loss": 3.122591257095337,
      "eval_runtime": 24.3092,
      "eval_samples_per_second": 2056.834,
      "eval_steps_per_second": 8.063,
      "step": 124000
    },
    {
      "epoch": 3.3123154282065608,
      "grad_norm": 0.3025442063808441,
      "learning_rate": 0.0001893408521303258,
      "loss": 3.2036,
      "step": 124500
    },
    {
      "epoch": 3.325617899805784,
      "grad_norm": 0.3661075830459595,
      "learning_rate": 0.00018808771929824562,
      "loss": 3.2009,
      "step": 125000
    },
    {
      "epoch": 3.338920371405007,
      "grad_norm": 0.3010828495025635,
      "learning_rate": 0.0001868345864661654,
      "loss": 3.2021,
      "step": 125500
    },
    {
      "epoch": 3.3522228430042302,
      "grad_norm": 0.3077359199523926,
      "learning_rate": 0.00018558395989974938,
      "loss": 3.2015,
      "step": 126000
    },
    {
      "epoch": 3.3655253146034534,
      "grad_norm": 0.337761789560318,
      "learning_rate": 0.00018433082706766917,
      "loss": 3.1988,
      "step": 126500
    },
    {
      "epoch": 3.3788277862026765,
      "grad_norm": 0.3098054826259613,
      "learning_rate": 0.000183077694235589,
      "loss": 3.1984,
      "step": 127000
    },
    {
      "epoch": 3.3921302578018997,
      "grad_norm": 0.29893553256988525,
      "learning_rate": 0.00018182456140350878,
      "loss": 3.2005,
      "step": 127500
    },
    {
      "epoch": 3.405432729401123,
      "grad_norm": 0.2850848436355591,
      "learning_rate": 0.0001805714285714286,
      "loss": 3.2026,
      "step": 128000
    },
    {
      "epoch": 3.405432729401123,
      "eval_loss": 3.119077444076538,
      "eval_runtime": 24.3217,
      "eval_samples_per_second": 2055.774,
      "eval_steps_per_second": 8.059,
      "step": 128000
    },
    {
      "epoch": 3.418735201000346,
      "grad_norm": 0.28518199920654297,
      "learning_rate": 0.00017932080200501252,
      "loss": 3.1988,
      "step": 128500
    },
    {
      "epoch": 3.432037672599569,
      "grad_norm": 0.3038414716720581,
      "learning_rate": 0.00017806766917293233,
      "loss": 3.1986,
      "step": 129000
    },
    {
      "epoch": 3.4453401441987923,
      "grad_norm": 0.2953645884990692,
      "learning_rate": 0.00017681453634085212,
      "loss": 3.1978,
      "step": 129500
    },
    {
      "epoch": 3.4586426157980155,
      "grad_norm": 0.2965751588344574,
      "learning_rate": 0.0001755614035087719,
      "loss": 3.198,
      "step": 130000
    },
    {
      "epoch": 3.4719450873972386,
      "grad_norm": 0.2902427613735199,
      "learning_rate": 0.00017431077694235589,
      "loss": 3.1981,
      "step": 130500
    },
    {
      "epoch": 3.4852475589964618,
      "grad_norm": 0.3446428179740906,
      "learning_rate": 0.0001730576441102757,
      "loss": 3.1966,
      "step": 131000
    },
    {
      "epoch": 3.498550030595685,
      "grad_norm": 0.3127058446407318,
      "learning_rate": 0.0001718045112781955,
      "loss": 3.1976,
      "step": 131500
    },
    {
      "epoch": 3.511852502194908,
      "grad_norm": 0.30590614676475525,
      "learning_rate": 0.00017055137844611528,
      "loss": 3.1968,
      "step": 132000
    },
    {
      "epoch": 3.511852502194908,
      "eval_loss": 3.1158809661865234,
      "eval_runtime": 24.2783,
      "eval_samples_per_second": 2059.452,
      "eval_steps_per_second": 8.073,
      "step": 132000
    },
    {
      "epoch": 3.525154973794131,
      "grad_norm": 0.34733331203460693,
      "learning_rate": 0.0001692982456140351,
      "loss": 3.1933,
      "step": 132500
    },
    {
      "epoch": 3.538457445393354,
      "grad_norm": 0.3710230588912964,
      "learning_rate": 0.00016804761904761907,
      "loss": 3.1955,
      "step": 133000
    },
    {
      "epoch": 3.551759916992577,
      "grad_norm": 0.3025432229042053,
      "learning_rate": 0.00016679448621553886,
      "loss": 3.1946,
      "step": 133500
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.3688335716724396,
      "learning_rate": 0.00016554135338345865,
      "loss": 3.1965,
      "step": 134000
    },
    {
      "epoch": 3.5783648601910234,
      "grad_norm": 0.32382670044898987,
      "learning_rate": 0.00016428822055137847,
      "loss": 3.1961,
      "step": 134500
    },
    {
      "epoch": 3.5916673317902466,
      "grad_norm": 0.2985891103744507,
      "learning_rate": 0.0001630375939849624,
      "loss": 3.1923,
      "step": 135000
    },
    {
      "epoch": 3.6049698033894697,
      "grad_norm": 0.2979185879230499,
      "learning_rate": 0.0001617844611528822,
      "loss": 3.1944,
      "step": 135500
    },
    {
      "epoch": 3.618272274988693,
      "grad_norm": 0.31024783849716187,
      "learning_rate": 0.000160531328320802,
      "loss": 3.1936,
      "step": 136000
    },
    {
      "epoch": 3.618272274988693,
      "eval_loss": 3.1117584705352783,
      "eval_runtime": 24.2729,
      "eval_samples_per_second": 2059.915,
      "eval_steps_per_second": 8.075,
      "step": 136000
    },
    {
      "epoch": 3.631574746587916,
      "grad_norm": 0.2902712821960449,
      "learning_rate": 0.0001592781954887218,
      "loss": 3.1926,
      "step": 136500
    },
    {
      "epoch": 3.644877218187139,
      "grad_norm": 0.29149046540260315,
      "learning_rate": 0.0001580250626566416,
      "loss": 3.1906,
      "step": 137000
    },
    {
      "epoch": 3.6581796897863623,
      "grad_norm": 0.4368008077144623,
      "learning_rate": 0.00015677443609022558,
      "loss": 3.1922,
      "step": 137500
    },
    {
      "epoch": 3.6714821613855855,
      "grad_norm": 0.2833610475063324,
      "learning_rate": 0.00015552130325814537,
      "loss": 3.1914,
      "step": 138000
    },
    {
      "epoch": 3.6847846329848086,
      "grad_norm": 0.29680633544921875,
      "learning_rate": 0.00015426817042606518,
      "loss": 3.1909,
      "step": 138500
    },
    {
      "epoch": 3.698087104584032,
      "grad_norm": 0.30673137307167053,
      "learning_rate": 0.00015301503759398497,
      "loss": 3.1897,
      "step": 139000
    },
    {
      "epoch": 3.711389576183255,
      "grad_norm": 0.30505648255348206,
      "learning_rate": 0.00015176190476190476,
      "loss": 3.1898,
      "step": 139500
    },
    {
      "epoch": 3.724692047782478,
      "grad_norm": 0.32809415459632874,
      "learning_rate": 0.00015051127819548874,
      "loss": 3.1886,
      "step": 140000
    },
    {
      "epoch": 3.724692047782478,
      "eval_loss": 3.1086339950561523,
      "eval_runtime": 24.2932,
      "eval_samples_per_second": 2058.189,
      "eval_steps_per_second": 8.068,
      "step": 140000
    },
    {
      "epoch": 3.7379945193817012,
      "grad_norm": 0.2867564558982849,
      "learning_rate": 0.00014925814536340853,
      "loss": 3.19,
      "step": 140500
    },
    {
      "epoch": 3.7512969909809244,
      "grad_norm": 0.2891601026058197,
      "learning_rate": 0.00014800501253132834,
      "loss": 3.1899,
      "step": 141000
    },
    {
      "epoch": 3.7645994625801475,
      "grad_norm": 0.2861756384372711,
      "learning_rate": 0.00014675187969924813,
      "loss": 3.1881,
      "step": 141500
    },
    {
      "epoch": 3.7779019341793703,
      "grad_norm": 0.2874830365180969,
      "learning_rate": 0.00014550125313283208,
      "loss": 3.1886,
      "step": 142000
    },
    {
      "epoch": 3.7912044057785934,
      "grad_norm": 0.3329005837440491,
      "learning_rate": 0.00014424812030075187,
      "loss": 3.1872,
      "step": 142500
    },
    {
      "epoch": 3.8045068773778166,
      "grad_norm": 0.34000134468078613,
      "learning_rate": 0.00014299498746867168,
      "loss": 3.1867,
      "step": 143000
    },
    {
      "epoch": 3.8178093489770397,
      "grad_norm": 0.2903097867965698,
      "learning_rate": 0.00014174185463659147,
      "loss": 3.1873,
      "step": 143500
    },
    {
      "epoch": 3.831111820576263,
      "grad_norm": 0.28473785519599915,
      "learning_rate": 0.00014049122807017545,
      "loss": 3.1879,
      "step": 144000
    },
    {
      "epoch": 3.831111820576263,
      "eval_loss": 3.1057703495025635,
      "eval_runtime": 24.2944,
      "eval_samples_per_second": 2058.087,
      "eval_steps_per_second": 8.068,
      "step": 144000
    },
    {
      "epoch": 3.844414292175486,
      "grad_norm": 0.2959291338920593,
      "learning_rate": 0.00013923809523809524,
      "loss": 3.1882,
      "step": 144500
    },
    {
      "epoch": 3.857716763774709,
      "grad_norm": 0.296318918466568,
      "learning_rate": 0.00013798496240601506,
      "loss": 3.1837,
      "step": 145000
    },
    {
      "epoch": 3.8710192353739323,
      "grad_norm": 0.2852119207382202,
      "learning_rate": 0.00013673433583959898,
      "loss": 3.1862,
      "step": 145500
    },
    {
      "epoch": 3.8843217069731555,
      "grad_norm": 0.3294094502925873,
      "learning_rate": 0.0001354812030075188,
      "loss": 3.1851,
      "step": 146000
    },
    {
      "epoch": 3.8976241785723786,
      "grad_norm": 0.2802225649356842,
      "learning_rate": 0.00013422807017543858,
      "loss": 3.1845,
      "step": 146500
    },
    {
      "epoch": 3.910926650171602,
      "grad_norm": 0.2803482413291931,
      "learning_rate": 0.0001329749373433584,
      "loss": 3.1851,
      "step": 147000
    },
    {
      "epoch": 3.924229121770825,
      "grad_norm": 0.3031865060329437,
      "learning_rate": 0.0001317218045112782,
      "loss": 3.1834,
      "step": 147500
    },
    {
      "epoch": 3.937531593370048,
      "grad_norm": 0.29815182089805603,
      "learning_rate": 0.00013046867167919798,
      "loss": 3.1825,
      "step": 148000
    },
    {
      "epoch": 3.937531593370048,
      "eval_loss": 3.102733850479126,
      "eval_runtime": 24.2756,
      "eval_samples_per_second": 2059.682,
      "eval_steps_per_second": 8.074,
      "step": 148000
    },
    {
      "epoch": 3.9508340649692713,
      "grad_norm": 0.28909823298454285,
      "learning_rate": 0.0001292155388471178,
      "loss": 3.1818,
      "step": 148500
    },
    {
      "epoch": 3.9641365365684944,
      "grad_norm": 0.2881418466567993,
      "learning_rate": 0.00012796240601503758,
      "loss": 3.1852,
      "step": 149000
    },
    {
      "epoch": 3.9774390081677176,
      "grad_norm": 0.31401577591896057,
      "learning_rate": 0.00012671177944862156,
      "loss": 3.1822,
      "step": 149500
    },
    {
      "epoch": 3.9907414797669407,
      "grad_norm": 0.29192158579826355,
      "learning_rate": 0.00012545864661654135,
      "loss": 3.1818,
      "step": 150000
    },
    {
      "epoch": 4.004043951366164,
      "grad_norm": 0.3353523313999176,
      "learning_rate": 0.00012420551378446116,
      "loss": 3.1795,
      "step": 150500
    },
    {
      "epoch": 4.017346422965387,
      "grad_norm": 0.2815832793712616,
      "learning_rate": 0.00012295238095238095,
      "loss": 3.1777,
      "step": 151000
    },
    {
      "epoch": 4.03064889456461,
      "grad_norm": 0.3815671503543854,
      "learning_rate": 0.00012169924812030076,
      "loss": 3.1769,
      "step": 151500
    },
    {
      "epoch": 4.043951366163833,
      "grad_norm": 0.30579107999801636,
      "learning_rate": 0.0001204486215538847,
      "loss": 3.1775,
      "step": 152000
    },
    {
      "epoch": 4.043951366163833,
      "eval_loss": 3.0996127128601074,
      "eval_runtime": 24.2221,
      "eval_samples_per_second": 2064.227,
      "eval_steps_per_second": 8.092,
      "step": 152000
    },
    {
      "epoch": 4.0572538377630565,
      "grad_norm": 0.3222203552722931,
      "learning_rate": 0.00011919548872180451,
      "loss": 3.177,
      "step": 152500
    },
    {
      "epoch": 4.07055630936228,
      "grad_norm": 0.3086029589176178,
      "learning_rate": 0.00011794235588972431,
      "loss": 3.1775,
      "step": 153000
    },
    {
      "epoch": 4.083858780961503,
      "grad_norm": 0.3005966246128082,
      "learning_rate": 0.00011668922305764411,
      "loss": 3.1774,
      "step": 153500
    },
    {
      "epoch": 4.097161252560726,
      "grad_norm": 0.3873879313468933,
      "learning_rate": 0.00011543859649122808,
      "loss": 3.1762,
      "step": 154000
    },
    {
      "epoch": 4.110463724159949,
      "grad_norm": 0.3432535231113434,
      "learning_rate": 0.00011418546365914788,
      "loss": 3.1775,
      "step": 154500
    },
    {
      "epoch": 4.123766195759172,
      "grad_norm": 0.29011598229408264,
      "learning_rate": 0.00011293233082706768,
      "loss": 3.1756,
      "step": 155000
    },
    {
      "epoch": 4.137068667358395,
      "grad_norm": 0.2908502221107483,
      "learning_rate": 0.00011167919799498748,
      "loss": 3.1764,
      "step": 155500
    },
    {
      "epoch": 4.1503711389576186,
      "grad_norm": 0.3062160611152649,
      "learning_rate": 0.00011042606516290727,
      "loss": 3.1754,
      "step": 156000
    },
    {
      "epoch": 4.1503711389576186,
      "eval_loss": 3.097616195678711,
      "eval_runtime": 24.2384,
      "eval_samples_per_second": 2062.839,
      "eval_steps_per_second": 8.086,
      "step": 156000
    },
    {
      "epoch": 4.163673610556842,
      "grad_norm": 0.2918618321418762,
      "learning_rate": 0.00010917543859649124,
      "loss": 3.1758,
      "step": 156500
    },
    {
      "epoch": 4.176976082156065,
      "grad_norm": 0.3058534860610962,
      "learning_rate": 0.00010792230576441104,
      "loss": 3.1746,
      "step": 157000
    },
    {
      "epoch": 4.190278553755288,
      "grad_norm": 0.28340351581573486,
      "learning_rate": 0.00010666917293233083,
      "loss": 3.1736,
      "step": 157500
    },
    {
      "epoch": 4.203581025354511,
      "grad_norm": 0.2905232608318329,
      "learning_rate": 0.00010541604010025063,
      "loss": 3.1749,
      "step": 158000
    },
    {
      "epoch": 4.216883496953734,
      "grad_norm": 0.281068354845047,
      "learning_rate": 0.00010416541353383459,
      "loss": 3.1743,
      "step": 158500
    },
    {
      "epoch": 4.2301859685529575,
      "grad_norm": 0.28447526693344116,
      "learning_rate": 0.00010291478696741854,
      "loss": 3.174,
      "step": 159000
    },
    {
      "epoch": 4.243488440152181,
      "grad_norm": 0.30350378155708313,
      "learning_rate": 0.00010166165413533835,
      "loss": 3.1717,
      "step": 159500
    },
    {
      "epoch": 4.256790911751404,
      "grad_norm": 0.35575422644615173,
      "learning_rate": 0.00010040852130325815,
      "loss": 3.1736,
      "step": 160000
    },
    {
      "epoch": 4.256790911751404,
      "eval_loss": 3.0942599773406982,
      "eval_runtime": 24.2427,
      "eval_samples_per_second": 2062.474,
      "eval_steps_per_second": 8.085,
      "step": 160000
    },
    {
      "epoch": 4.270093383350627,
      "grad_norm": 0.3270854651927948,
      "learning_rate": 9.915538847117794e-05,
      "loss": 3.1717,
      "step": 160500
    },
    {
      "epoch": 4.28339585494985,
      "grad_norm": 0.296501487493515,
      "learning_rate": 9.790225563909774e-05,
      "loss": 3.173,
      "step": 161000
    },
    {
      "epoch": 4.296698326549073,
      "grad_norm": 0.30132919549942017,
      "learning_rate": 9.664912280701754e-05,
      "loss": 3.1721,
      "step": 161500
    },
    {
      "epoch": 4.310000798148296,
      "grad_norm": 0.31358128786087036,
      "learning_rate": 9.539598997493734e-05,
      "loss": 3.1725,
      "step": 162000
    },
    {
      "epoch": 4.3233032697475196,
      "grad_norm": 0.30308017134666443,
      "learning_rate": 9.414285714285715e-05,
      "loss": 3.1728,
      "step": 162500
    },
    {
      "epoch": 4.336605741346742,
      "grad_norm": 0.3250839114189148,
      "learning_rate": 9.289223057644111e-05,
      "loss": 3.1691,
      "step": 163000
    },
    {
      "epoch": 4.349908212945965,
      "grad_norm": 0.30133944749832153,
      "learning_rate": 9.163909774436091e-05,
      "loss": 3.1697,
      "step": 163500
    },
    {
      "epoch": 4.363210684545188,
      "grad_norm": 0.3188856840133667,
      "learning_rate": 9.038596491228071e-05,
      "loss": 3.1712,
      "step": 164000
    },
    {
      "epoch": 4.363210684545188,
      "eval_loss": 3.091209888458252,
      "eval_runtime": 24.2483,
      "eval_samples_per_second": 2062.001,
      "eval_steps_per_second": 8.083,
      "step": 164000
    },
    {
      "epoch": 4.376513156144411,
      "grad_norm": 0.3035358786582947,
      "learning_rate": 8.91328320802005e-05,
      "loss": 3.1707,
      "step": 164500
    },
    {
      "epoch": 4.389815627743634,
      "grad_norm": 0.29258623719215393,
      "learning_rate": 8.78796992481203e-05,
      "loss": 3.1723,
      "step": 165000
    },
    {
      "epoch": 4.403118099342858,
      "grad_norm": 0.28007984161376953,
      "learning_rate": 8.662907268170427e-05,
      "loss": 3.1684,
      "step": 165500
    },
    {
      "epoch": 4.416420570942081,
      "grad_norm": 0.33045363426208496,
      "learning_rate": 8.537593984962406e-05,
      "loss": 3.1687,
      "step": 166000
    },
    {
      "epoch": 4.429723042541304,
      "grad_norm": 0.3879069983959198,
      "learning_rate": 8.412280701754386e-05,
      "loss": 3.1702,
      "step": 166500
    },
    {
      "epoch": 4.443025514140527,
      "grad_norm": 0.3016442358493805,
      "learning_rate": 8.286967418546366e-05,
      "loss": 3.168,
      "step": 167000
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.3020322322845459,
      "learning_rate": 8.161904761904763e-05,
      "loss": 3.1686,
      "step": 167500
    },
    {
      "epoch": 4.469630457338973,
      "grad_norm": 0.30714327096939087,
      "learning_rate": 8.036591478696742e-05,
      "loss": 3.1681,
      "step": 168000
    },
    {
      "epoch": 4.469630457338973,
      "eval_loss": 3.0885818004608154,
      "eval_runtime": 24.2294,
      "eval_samples_per_second": 2063.607,
      "eval_steps_per_second": 8.089,
      "step": 168000
    },
    {
      "epoch": 4.4829329289381965,
      "grad_norm": 0.3205668330192566,
      "learning_rate": 7.911278195488722e-05,
      "loss": 3.168,
      "step": 168500
    },
    {
      "epoch": 4.49623540053742,
      "grad_norm": 0.3012321889400482,
      "learning_rate": 7.785964912280702e-05,
      "loss": 3.1677,
      "step": 169000
    },
    {
      "epoch": 4.509537872136643,
      "grad_norm": 0.28914567828178406,
      "learning_rate": 7.660651629072682e-05,
      "loss": 3.1684,
      "step": 169500
    },
    {
      "epoch": 4.522840343735866,
      "grad_norm": 0.2859634757041931,
      "learning_rate": 7.535338345864661e-05,
      "loss": 3.1678,
      "step": 170000
    },
    {
      "epoch": 4.536142815335089,
      "grad_norm": 0.297030508518219,
      "learning_rate": 7.410275689223058e-05,
      "loss": 3.1688,
      "step": 170500
    },
    {
      "epoch": 4.549445286934312,
      "grad_norm": 0.2819767892360687,
      "learning_rate": 7.284962406015038e-05,
      "loss": 3.1683,
      "step": 171000
    },
    {
      "epoch": 4.562747758533535,
      "grad_norm": 0.29196229577064514,
      "learning_rate": 7.159649122807017e-05,
      "loss": 3.1664,
      "step": 171500
    },
    {
      "epoch": 4.576050230132759,
      "grad_norm": 0.30091938376426697,
      "learning_rate": 7.034335839598997e-05,
      "loss": 3.1675,
      "step": 172000
    },
    {
      "epoch": 4.576050230132759,
      "eval_loss": 3.0860965251922607,
      "eval_runtime": 24.2504,
      "eval_samples_per_second": 2061.822,
      "eval_steps_per_second": 8.082,
      "step": 172000
    },
    {
      "epoch": 4.589352701731982,
      "grad_norm": 0.3159467279911041,
      "learning_rate": 6.909273182957395e-05,
      "loss": 3.1676,
      "step": 172500
    },
    {
      "epoch": 4.602655173331205,
      "grad_norm": 0.3085513710975647,
      "learning_rate": 6.783959899749374e-05,
      "loss": 3.1657,
      "step": 173000
    },
    {
      "epoch": 4.615957644930428,
      "grad_norm": 0.3170807957649231,
      "learning_rate": 6.658646616541352e-05,
      "loss": 3.1654,
      "step": 173500
    },
    {
      "epoch": 4.629260116529651,
      "grad_norm": 0.28566327691078186,
      "learning_rate": 6.533333333333333e-05,
      "loss": 3.164,
      "step": 174000
    },
    {
      "epoch": 4.642562588128874,
      "grad_norm": 0.28979355096817017,
      "learning_rate": 6.408020050125313e-05,
      "loss": 3.1643,
      "step": 174500
    },
    {
      "epoch": 4.6558650597280975,
      "grad_norm": 0.28862622380256653,
      "learning_rate": 6.282957393483709e-05,
      "loss": 3.1645,
      "step": 175000
    },
    {
      "epoch": 4.669167531327321,
      "grad_norm": 0.28897011280059814,
      "learning_rate": 6.15764411027569e-05,
      "loss": 3.1648,
      "step": 175500
    },
    {
      "epoch": 4.682470002926544,
      "grad_norm": 0.2833220660686493,
      "learning_rate": 6.032330827067669e-05,
      "loss": 3.1634,
      "step": 176000
    },
    {
      "epoch": 4.682470002926544,
      "eval_loss": 3.0836567878723145,
      "eval_runtime": 24.2439,
      "eval_samples_per_second": 2062.379,
      "eval_steps_per_second": 8.085,
      "step": 176000
    },
    {
      "epoch": 4.695772474525767,
      "grad_norm": 0.2934861481189728,
      "learning_rate": 5.9070175438596486e-05,
      "loss": 3.1634,
      "step": 176500
    },
    {
      "epoch": 4.70907494612499,
      "grad_norm": 0.29941755533218384,
      "learning_rate": 5.781704260651629e-05,
      "loss": 3.1616,
      "step": 177000
    },
    {
      "epoch": 4.722377417724213,
      "grad_norm": 0.31638845801353455,
      "learning_rate": 5.656641604010025e-05,
      "loss": 3.164,
      "step": 177500
    },
    {
      "epoch": 4.735679889323436,
      "grad_norm": 0.28935039043426514,
      "learning_rate": 5.5313283208020055e-05,
      "loss": 3.1618,
      "step": 178000
    },
    {
      "epoch": 4.74898236092266,
      "grad_norm": 0.3077198266983032,
      "learning_rate": 5.406015037593985e-05,
      "loss": 3.1625,
      "step": 178500
    },
    {
      "epoch": 4.762284832521883,
      "grad_norm": 0.2943679094314575,
      "learning_rate": 5.280701754385965e-05,
      "loss": 3.1625,
      "step": 179000
    },
    {
      "epoch": 4.775587304121106,
      "grad_norm": 0.28696903586387634,
      "learning_rate": 5.155639097744361e-05,
      "loss": 3.1602,
      "step": 179500
    },
    {
      "epoch": 4.788889775720329,
      "grad_norm": 0.29074540734291077,
      "learning_rate": 5.0303258145363405e-05,
      "loss": 3.1624,
      "step": 180000
    },
    {
      "epoch": 4.788889775720329,
      "eval_loss": 3.081617593765259,
      "eval_runtime": 24.2373,
      "eval_samples_per_second": 2062.939,
      "eval_steps_per_second": 8.087,
      "step": 180000
    },
    {
      "epoch": 4.802192247319552,
      "grad_norm": 0.30733388662338257,
      "learning_rate": 4.905012531328321e-05,
      "loss": 3.1618,
      "step": 180500
    },
    {
      "epoch": 4.815494718918775,
      "grad_norm": 0.2967178523540497,
      "learning_rate": 4.7796992481203003e-05,
      "loss": 3.1609,
      "step": 181000
    },
    {
      "epoch": 4.8287971905179985,
      "grad_norm": 0.28327304124832153,
      "learning_rate": 4.654636591478697e-05,
      "loss": 3.1612,
      "step": 181500
    },
    {
      "epoch": 4.842099662117222,
      "grad_norm": 0.28168681263923645,
      "learning_rate": 4.529323308270677e-05,
      "loss": 3.1612,
      "step": 182000
    },
    {
      "epoch": 4.855402133716445,
      "grad_norm": 0.28490912914276123,
      "learning_rate": 4.4042606516290726e-05,
      "loss": 3.1627,
      "step": 182500
    },
    {
      "epoch": 4.868704605315668,
      "grad_norm": 0.2832616865634918,
      "learning_rate": 4.278947368421052e-05,
      "loss": 3.1597,
      "step": 183000
    },
    {
      "epoch": 4.882007076914891,
      "grad_norm": 0.2756200134754181,
      "learning_rate": 4.1536340852130324e-05,
      "loss": 3.16,
      "step": 183500
    },
    {
      "epoch": 4.895309548514114,
      "grad_norm": 0.30823320150375366,
      "learning_rate": 4.028320802005012e-05,
      "loss": 3.1589,
      "step": 184000
    },
    {
      "epoch": 4.895309548514114,
      "eval_loss": 3.0791726112365723,
      "eval_runtime": 24.2589,
      "eval_samples_per_second": 2061.098,
      "eval_steps_per_second": 8.08,
      "step": 184000
    },
    {
      "epoch": 4.908612020113337,
      "grad_norm": 0.2834506332874298,
      "learning_rate": 3.903007518796992e-05,
      "loss": 3.1583,
      "step": 184500
    },
    {
      "epoch": 4.921914491712561,
      "grad_norm": 0.2909003794193268,
      "learning_rate": 3.7776942355889725e-05,
      "loss": 3.1628,
      "step": 185000
    },
    {
      "epoch": 4.935216963311783,
      "grad_norm": 0.324039101600647,
      "learning_rate": 3.652380952380952e-05,
      "loss": 3.1601,
      "step": 185500
    },
    {
      "epoch": 4.948519434911006,
      "grad_norm": 0.28548958897590637,
      "learning_rate": 3.527067669172932e-05,
      "loss": 3.1621,
      "step": 186000
    },
    {
      "epoch": 4.961821906510229,
      "grad_norm": 0.28133100271224976,
      "learning_rate": 3.401754385964912e-05,
      "loss": 3.1587,
      "step": 186500
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.28338080644607544,
      "learning_rate": 3.276441102756892e-05,
      "loss": 3.158,
      "step": 187000
    },
    {
      "epoch": 4.9884268497086754,
      "grad_norm": 0.2850435674190521,
      "learning_rate": 3.151127819548872e-05,
      "loss": 3.1577,
      "step": 187500
    },
    {
      "epoch": 5.001729321307899,
      "grad_norm": 0.2868407070636749,
      "learning_rate": 3.0260651629072683e-05,
      "loss": 3.1569,
      "step": 188000
    },
    {
      "epoch": 5.001729321307899,
      "eval_loss": 3.0770983695983887,
      "eval_runtime": 24.2399,
      "eval_samples_per_second": 2062.715,
      "eval_steps_per_second": 8.086,
      "step": 188000
    },
    {
      "epoch": 5.015031792907122,
      "grad_norm": 0.29360973834991455,
      "learning_rate": 2.9007518796992483e-05,
      "loss": 3.1545,
      "step": 188500
    },
    {
      "epoch": 5.028334264506345,
      "grad_norm": 0.30341172218322754,
      "learning_rate": 2.775438596491228e-05,
      "loss": 3.154,
      "step": 189000
    },
    {
      "epoch": 5.041636736105568,
      "grad_norm": 0.28817591071128845,
      "learning_rate": 2.650125313283208e-05,
      "loss": 3.1541,
      "step": 189500
    },
    {
      "epoch": 5.054939207704791,
      "grad_norm": 0.2950757145881653,
      "learning_rate": 2.524812030075188e-05,
      "loss": 3.1542,
      "step": 190000
    },
    {
      "epoch": 5.068241679304014,
      "grad_norm": 0.288467139005661,
      "learning_rate": 2.399749373433584e-05,
      "loss": 3.1538,
      "step": 190500
    },
    {
      "epoch": 5.0815441509032375,
      "grad_norm": 0.29197296500205994,
      "learning_rate": 2.274436090225564e-05,
      "loss": 3.1537,
      "step": 191000
    },
    {
      "epoch": 5.094846622502461,
      "grad_norm": 0.2867943048477173,
      "learning_rate": 2.149122807017544e-05,
      "loss": 3.1526,
      "step": 191500
    },
    {
      "epoch": 5.108149094101684,
      "grad_norm": 0.2882676422595978,
      "learning_rate": 2.023809523809524e-05,
      "loss": 3.1526,
      "step": 192000
    },
    {
      "epoch": 5.108149094101684,
      "eval_loss": 3.0754594802856445,
      "eval_runtime": 24.2309,
      "eval_samples_per_second": 2063.478,
      "eval_steps_per_second": 8.089,
      "step": 192000
    },
    {
      "epoch": 5.121451565700907,
      "grad_norm": 0.3027030825614929,
      "learning_rate": 1.89874686716792e-05,
      "loss": 3.1534,
      "step": 192500
    },
    {
      "epoch": 5.13475403730013,
      "grad_norm": 0.2879238426685333,
      "learning_rate": 1.7734335839599e-05,
      "loss": 3.1556,
      "step": 193000
    },
    {
      "epoch": 5.148056508899353,
      "grad_norm": 0.2840542495250702,
      "learning_rate": 1.64812030075188e-05,
      "loss": 3.152,
      "step": 193500
    },
    {
      "epoch": 5.161358980498576,
      "grad_norm": 0.279735267162323,
      "learning_rate": 1.5228070175438596e-05,
      "loss": 3.1532,
      "step": 194000
    },
    {
      "epoch": 5.1746614520978,
      "grad_norm": 0.297212153673172,
      "learning_rate": 1.3974937343358395e-05,
      "loss": 3.1535,
      "step": 194500
    },
    {
      "epoch": 5.187963923697023,
      "grad_norm": 0.28057554364204407,
      "learning_rate": 1.2724310776942355e-05,
      "loss": 3.1506,
      "step": 195000
    },
    {
      "epoch": 5.201266395296246,
      "grad_norm": 0.28096380829811096,
      "learning_rate": 1.1471177944862154e-05,
      "loss": 3.1533,
      "step": 195500
    },
    {
      "epoch": 5.214568866895469,
      "grad_norm": 0.28391018509864807,
      "learning_rate": 1.0218045112781955e-05,
      "loss": 3.151,
      "step": 196000
    },
    {
      "epoch": 5.214568866895469,
      "eval_loss": 3.0737926959991455,
      "eval_runtime": 24.2433,
      "eval_samples_per_second": 2062.426,
      "eval_steps_per_second": 8.085,
      "step": 196000
    },
    {
      "epoch": 5.227871338494692,
      "grad_norm": 0.28975382447242737,
      "learning_rate": 8.964912280701754e-06,
      "loss": 3.1515,
      "step": 196500
    },
    {
      "epoch": 5.241173810093915,
      "grad_norm": 0.3068234920501709,
      "learning_rate": 7.711779448621555e-06,
      "loss": 3.153,
      "step": 197000
    },
    {
      "epoch": 5.2544762816931385,
      "grad_norm": 0.2801830768585205,
      "learning_rate": 6.461152882205514e-06,
      "loss": 3.1514,
      "step": 197500
    },
    {
      "epoch": 5.267778753292362,
      "grad_norm": 0.2992650270462036,
      "learning_rate": 5.208020050125314e-06,
      "loss": 3.1514,
      "step": 198000
    },
    {
      "epoch": 5.281081224891585,
      "grad_norm": 0.2872859835624695,
      "learning_rate": 3.954887218045113e-06,
      "loss": 3.1526,
      "step": 198500
    },
    {
      "epoch": 5.294383696490808,
      "grad_norm": 0.2943345606327057,
      "learning_rate": 2.701754385964912e-06,
      "loss": 3.1516,
      "step": 199000
    },
    {
      "epoch": 5.307686168090031,
      "grad_norm": 0.2926018238067627,
      "learning_rate": 1.4486215538847119e-06,
      "loss": 3.1505,
      "step": 199500
    },
    {
      "epoch": 5.320988639689254,
      "grad_norm": 0.280894935131073,
      "learning_rate": 1.9799498746867167e-07,
      "loss": 3.1512,
      "step": 200000
    },
    {
      "epoch": 5.320988639689254,
      "eval_loss": 3.0728118419647217,
      "eval_runtime": 24.2391,
      "eval_samples_per_second": 2062.787,
      "eval_steps_per_second": 8.086,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
