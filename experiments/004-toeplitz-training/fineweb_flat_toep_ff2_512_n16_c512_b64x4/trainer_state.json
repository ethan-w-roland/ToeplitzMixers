{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.320988639689254,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013302471599223136,
      "grad_norm": 7.053361415863037,
      "learning_rate": 0.0005,
      "loss": 9.9053,
      "step": 500
    },
    {
      "epoch": 0.026604943198446272,
      "grad_norm": 4.102897644042969,
      "learning_rate": 0.0004987468671679198,
      "loss": 5.6629,
      "step": 1000
    },
    {
      "epoch": 0.039907414797669405,
      "grad_norm": 4.913902759552002,
      "learning_rate": 0.0004974937343358396,
      "loss": 5.4417,
      "step": 1500
    },
    {
      "epoch": 0.053209886396892545,
      "grad_norm": 1.9145245552062988,
      "learning_rate": 0.0004962406015037594,
      "loss": 5.2747,
      "step": 2000
    },
    {
      "epoch": 0.06651235799611568,
      "grad_norm": 3.295389175415039,
      "learning_rate": 0.0004949874686716792,
      "loss": 5.0308,
      "step": 2500
    },
    {
      "epoch": 0.07981482959533881,
      "grad_norm": 1.3266898393630981,
      "learning_rate": 0.000493734335839599,
      "loss": 4.8019,
      "step": 3000
    },
    {
      "epoch": 0.09311730119456195,
      "grad_norm": 0.5689725875854492,
      "learning_rate": 0.0004924812030075188,
      "loss": 4.5193,
      "step": 3500
    },
    {
      "epoch": 0.10641977279378509,
      "grad_norm": 0.5238780379295349,
      "learning_rate": 0.0004912280701754386,
      "loss": 4.3297,
      "step": 4000
    },
    {
      "epoch": 0.10641977279378509,
      "eval_loss": 4.174042701721191,
      "eval_runtime": 22.2576,
      "eval_samples_per_second": 2246.425,
      "eval_steps_per_second": 8.806,
      "step": 4000
    },
    {
      "epoch": 0.11972224439300821,
      "grad_norm": 0.24970419704914093,
      "learning_rate": 0.0004899749373433584,
      "loss": 4.2075,
      "step": 4500
    },
    {
      "epoch": 0.13302471599223137,
      "grad_norm": 0.6031115055084229,
      "learning_rate": 0.0004887218045112781,
      "loss": 4.1181,
      "step": 5000
    },
    {
      "epoch": 0.1463271875914545,
      "grad_norm": 0.6496514678001404,
      "learning_rate": 0.000487468671679198,
      "loss": 4.0506,
      "step": 5500
    },
    {
      "epoch": 0.15962965919067762,
      "grad_norm": 1.3367559909820557,
      "learning_rate": 0.00048621553884711777,
      "loss": 3.9933,
      "step": 6000
    },
    {
      "epoch": 0.17293213078990077,
      "grad_norm": 0.27906909584999084,
      "learning_rate": 0.0004849649122807018,
      "loss": 3.9498,
      "step": 6500
    },
    {
      "epoch": 0.1862346023891239,
      "grad_norm": 0.7731922268867493,
      "learning_rate": 0.00048371177944862154,
      "loss": 3.9068,
      "step": 7000
    },
    {
      "epoch": 0.19953707398834702,
      "grad_norm": 0.24300159513950348,
      "learning_rate": 0.00048245864661654135,
      "loss": 3.8729,
      "step": 7500
    },
    {
      "epoch": 0.21283954558757018,
      "grad_norm": 0.4609782099723816,
      "learning_rate": 0.00048120551378446117,
      "loss": 3.8429,
      "step": 8000
    },
    {
      "epoch": 0.21283954558757018,
      "eval_loss": 3.7379651069641113,
      "eval_runtime": 22.0848,
      "eval_samples_per_second": 2264.003,
      "eval_steps_per_second": 8.875,
      "step": 8000
    },
    {
      "epoch": 0.2261420171867933,
      "grad_norm": 0.30074065923690796,
      "learning_rate": 0.000479952380952381,
      "loss": 3.8152,
      "step": 8500
    },
    {
      "epoch": 0.23944448878601643,
      "grad_norm": 0.3045711815357208,
      "learning_rate": 0.00047869924812030075,
      "loss": 3.7885,
      "step": 9000
    },
    {
      "epoch": 0.2527469603852396,
      "grad_norm": 0.27436843514442444,
      "learning_rate": 0.00047744611528822056,
      "loss": 3.7684,
      "step": 9500
    },
    {
      "epoch": 0.26604943198446274,
      "grad_norm": 0.23825807869434357,
      "learning_rate": 0.0004761929824561403,
      "loss": 3.7447,
      "step": 10000
    },
    {
      "epoch": 0.27935190358368583,
      "grad_norm": 0.3546406328678131,
      "learning_rate": 0.00047494235588972433,
      "loss": 3.7278,
      "step": 10500
    },
    {
      "epoch": 0.292654375182909,
      "grad_norm": 0.35234537720680237,
      "learning_rate": 0.0004736967418546366,
      "loss": 3.7122,
      "step": 11000
    },
    {
      "epoch": 0.30595684678213214,
      "grad_norm": 0.39178743958473206,
      "learning_rate": 0.0004724436090225564,
      "loss": 3.6952,
      "step": 11500
    },
    {
      "epoch": 0.31925931838135524,
      "grad_norm": 0.28701528906822205,
      "learning_rate": 0.00047119047619047623,
      "loss": 3.679,
      "step": 12000
    },
    {
      "epoch": 0.31925931838135524,
      "eval_loss": 3.5812575817108154,
      "eval_runtime": 22.089,
      "eval_samples_per_second": 2263.574,
      "eval_steps_per_second": 8.873,
      "step": 12000
    },
    {
      "epoch": 0.3325617899805784,
      "grad_norm": 0.23577027022838593,
      "learning_rate": 0.000469937343358396,
      "loss": 3.6657,
      "step": 12500
    },
    {
      "epoch": 0.34586426157980155,
      "grad_norm": 0.26465675234794617,
      "learning_rate": 0.0004686842105263158,
      "loss": 3.6518,
      "step": 13000
    },
    {
      "epoch": 0.35916673317902464,
      "grad_norm": 0.5178013443946838,
      "learning_rate": 0.00046743107769423557,
      "loss": 3.6393,
      "step": 13500
    },
    {
      "epoch": 0.3724692047782478,
      "grad_norm": 0.5077665448188782,
      "learning_rate": 0.00046617794486215544,
      "loss": 3.6281,
      "step": 14000
    },
    {
      "epoch": 0.38577167637747095,
      "grad_norm": 0.24588634073734283,
      "learning_rate": 0.0004649248120300752,
      "loss": 3.6189,
      "step": 14500
    },
    {
      "epoch": 0.39907414797669405,
      "grad_norm": 0.30779504776000977,
      "learning_rate": 0.000463671679197995,
      "loss": 3.6078,
      "step": 15000
    },
    {
      "epoch": 0.4123766195759172,
      "grad_norm": 0.257217675447464,
      "learning_rate": 0.0004624185463659148,
      "loss": 3.5959,
      "step": 15500
    },
    {
      "epoch": 0.42567909117514036,
      "grad_norm": 0.22792139649391174,
      "learning_rate": 0.0004611654135338346,
      "loss": 3.5892,
      "step": 16000
    },
    {
      "epoch": 0.42567909117514036,
      "eval_loss": 3.4904563426971436,
      "eval_runtime": 22.1192,
      "eval_samples_per_second": 2260.482,
      "eval_steps_per_second": 8.861,
      "step": 16000
    },
    {
      "epoch": 0.43898156277436345,
      "grad_norm": 0.295029878616333,
      "learning_rate": 0.0004599122807017544,
      "loss": 3.5798,
      "step": 16500
    },
    {
      "epoch": 0.4522840343735866,
      "grad_norm": 0.34194788336753845,
      "learning_rate": 0.00045865914786967423,
      "loss": 3.5706,
      "step": 17000
    },
    {
      "epoch": 0.46558650597280976,
      "grad_norm": 0.22858312726020813,
      "learning_rate": 0.000457406015037594,
      "loss": 3.5643,
      "step": 17500
    },
    {
      "epoch": 0.47888897757203286,
      "grad_norm": 0.22985653579235077,
      "learning_rate": 0.0004561528822055138,
      "loss": 3.5559,
      "step": 18000
    },
    {
      "epoch": 0.492191449171256,
      "grad_norm": 0.26510611176490784,
      "learning_rate": 0.00045489974937343357,
      "loss": 3.5487,
      "step": 18500
    },
    {
      "epoch": 0.5054939207704792,
      "grad_norm": 0.2391340732574463,
      "learning_rate": 0.00045364661654135344,
      "loss": 3.5421,
      "step": 19000
    },
    {
      "epoch": 0.5187963923697023,
      "grad_norm": 0.2834140360355377,
      "learning_rate": 0.00045239598997493733,
      "loss": 3.536,
      "step": 19500
    },
    {
      "epoch": 0.5320988639689255,
      "grad_norm": 0.29017147421836853,
      "learning_rate": 0.0004511453634085213,
      "loss": 3.5323,
      "step": 20000
    },
    {
      "epoch": 0.5320988639689255,
      "eval_loss": 3.4329793453216553,
      "eval_runtime": 22.381,
      "eval_samples_per_second": 2234.041,
      "eval_steps_per_second": 8.757,
      "step": 20000
    },
    {
      "epoch": 0.5454013355681485,
      "grad_norm": 0.2581113874912262,
      "learning_rate": 0.00044989223057644115,
      "loss": 3.5245,
      "step": 20500
    },
    {
      "epoch": 0.5587038071673717,
      "grad_norm": 0.2206934541463852,
      "learning_rate": 0.0004486390977443609,
      "loss": 3.5188,
      "step": 21000
    },
    {
      "epoch": 0.5720062787665948,
      "grad_norm": 0.30228716135025024,
      "learning_rate": 0.00044738596491228073,
      "loss": 3.5143,
      "step": 21500
    },
    {
      "epoch": 0.585308750365818,
      "grad_norm": 0.23264801502227783,
      "learning_rate": 0.0004461353383458647,
      "loss": 3.5078,
      "step": 22000
    },
    {
      "epoch": 0.5986112219650411,
      "grad_norm": 0.23161815106868744,
      "learning_rate": 0.00044488220551378444,
      "loss": 3.5049,
      "step": 22500
    },
    {
      "epoch": 0.6119136935642643,
      "grad_norm": 0.26345497369766235,
      "learning_rate": 0.00044363157894736845,
      "loss": 3.4965,
      "step": 23000
    },
    {
      "epoch": 0.6252161651634873,
      "grad_norm": 0.3110395669937134,
      "learning_rate": 0.0004423784461152882,
      "loss": 3.4911,
      "step": 23500
    },
    {
      "epoch": 0.6385186367627105,
      "grad_norm": 0.26880577206611633,
      "learning_rate": 0.000441125313283208,
      "loss": 3.4881,
      "step": 24000
    },
    {
      "epoch": 0.6385186367627105,
      "eval_loss": 3.3911571502685547,
      "eval_runtime": 22.1032,
      "eval_samples_per_second": 2262.111,
      "eval_steps_per_second": 8.867,
      "step": 24000
    },
    {
      "epoch": 0.6518211083619336,
      "grad_norm": 0.2406725287437439,
      "learning_rate": 0.0004398721804511278,
      "loss": 3.4837,
      "step": 24500
    },
    {
      "epoch": 0.6651235799611568,
      "grad_norm": 0.24775391817092896,
      "learning_rate": 0.0004386215538847118,
      "loss": 3.4798,
      "step": 25000
    },
    {
      "epoch": 0.6784260515603799,
      "grad_norm": 0.4553605914115906,
      "learning_rate": 0.0004373684210526316,
      "loss": 3.474,
      "step": 25500
    },
    {
      "epoch": 0.6917285231596031,
      "grad_norm": 0.34033891558647156,
      "learning_rate": 0.0004361152882205514,
      "loss": 3.4731,
      "step": 26000
    },
    {
      "epoch": 0.7050309947588261,
      "grad_norm": 0.21971917152404785,
      "learning_rate": 0.0004348646616541354,
      "loss": 3.4649,
      "step": 26500
    },
    {
      "epoch": 0.7183334663580493,
      "grad_norm": 0.21006013453006744,
      "learning_rate": 0.00043361152882205514,
      "loss": 3.4635,
      "step": 27000
    },
    {
      "epoch": 0.7316359379572724,
      "grad_norm": 0.20757098495960236,
      "learning_rate": 0.00043235839598997495,
      "loss": 3.4597,
      "step": 27500
    },
    {
      "epoch": 0.7449384095564956,
      "grad_norm": 0.2099795788526535,
      "learning_rate": 0.0004311052631578947,
      "loss": 3.4562,
      "step": 28000
    },
    {
      "epoch": 0.7449384095564956,
      "eval_loss": 3.3603920936584473,
      "eval_runtime": 22.0905,
      "eval_samples_per_second": 2263.412,
      "eval_steps_per_second": 8.873,
      "step": 28000
    },
    {
      "epoch": 0.7582408811557187,
      "grad_norm": 0.20908160507678986,
      "learning_rate": 0.00042985213032581453,
      "loss": 3.4534,
      "step": 28500
    },
    {
      "epoch": 0.7715433527549419,
      "grad_norm": 0.2166576087474823,
      "learning_rate": 0.00042859899749373435,
      "loss": 3.4475,
      "step": 29000
    },
    {
      "epoch": 0.7848458243541651,
      "grad_norm": 0.2034868746995926,
      "learning_rate": 0.00042734586466165416,
      "loss": 3.4472,
      "step": 29500
    },
    {
      "epoch": 0.7981482959533881,
      "grad_norm": 0.25779566168785095,
      "learning_rate": 0.0004260927318295739,
      "loss": 3.4428,
      "step": 30000
    },
    {
      "epoch": 0.8114507675526113,
      "grad_norm": 0.3706924319267273,
      "learning_rate": 0.00042483959899749374,
      "loss": 3.4414,
      "step": 30500
    },
    {
      "epoch": 0.8247532391518344,
      "grad_norm": 0.23909127712249756,
      "learning_rate": 0.0004235864661654135,
      "loss": 3.437,
      "step": 31000
    },
    {
      "epoch": 0.8380557107510576,
      "grad_norm": 0.24832502007484436,
      "learning_rate": 0.00042233333333333337,
      "loss": 3.4345,
      "step": 31500
    },
    {
      "epoch": 0.8513581823502807,
      "grad_norm": 0.2697898745536804,
      "learning_rate": 0.00042108020050125313,
      "loss": 3.4334,
      "step": 32000
    },
    {
      "epoch": 0.8513581823502807,
      "eval_loss": 3.3347952365875244,
      "eval_runtime": 22.084,
      "eval_samples_per_second": 2264.084,
      "eval_steps_per_second": 8.875,
      "step": 32000
    },
    {
      "epoch": 0.8646606539495039,
      "grad_norm": 0.23372265696525574,
      "learning_rate": 0.00041982706766917295,
      "loss": 3.4291,
      "step": 32500
    },
    {
      "epoch": 0.8779631255487269,
      "grad_norm": 0.28547781705856323,
      "learning_rate": 0.0004185739348370927,
      "loss": 3.4268,
      "step": 33000
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.29617416858673096,
      "learning_rate": 0.0004173208020050125,
      "loss": 3.422,
      "step": 33500
    },
    {
      "epoch": 0.9045680687471732,
      "grad_norm": 0.23843739926815033,
      "learning_rate": 0.00041606766917293234,
      "loss": 3.4201,
      "step": 34000
    },
    {
      "epoch": 0.9178705403463964,
      "grad_norm": 0.3281664550304413,
      "learning_rate": 0.00041481453634085216,
      "loss": 3.4206,
      "step": 34500
    },
    {
      "epoch": 0.9311730119456195,
      "grad_norm": 0.3245660662651062,
      "learning_rate": 0.0004135614035087719,
      "loss": 3.419,
      "step": 35000
    },
    {
      "epoch": 0.9444754835448427,
      "grad_norm": 0.22070616483688354,
      "learning_rate": 0.00041230827067669174,
      "loss": 3.4154,
      "step": 35500
    },
    {
      "epoch": 0.9577779551440657,
      "grad_norm": 0.2301182597875595,
      "learning_rate": 0.0004110551378446115,
      "loss": 3.4119,
      "step": 36000
    },
    {
      "epoch": 0.9577779551440657,
      "eval_loss": 3.313814401626587,
      "eval_runtime": 22.101,
      "eval_samples_per_second": 2262.339,
      "eval_steps_per_second": 8.868,
      "step": 36000
    },
    {
      "epoch": 0.9710804267432889,
      "grad_norm": 0.20850123465061188,
      "learning_rate": 0.0004098045112781955,
      "loss": 3.4104,
      "step": 36500
    },
    {
      "epoch": 0.984382898342512,
      "grad_norm": 0.20530137419700623,
      "learning_rate": 0.00040855137844611526,
      "loss": 3.4069,
      "step": 37000
    },
    {
      "epoch": 0.9976853699417352,
      "grad_norm": 0.23407617211341858,
      "learning_rate": 0.00040729824561403513,
      "loss": 3.4036,
      "step": 37500
    },
    {
      "epoch": 1.0109878415409583,
      "grad_norm": 0.2946275770664215,
      "learning_rate": 0.0004060451127819549,
      "loss": 3.3998,
      "step": 38000
    },
    {
      "epoch": 1.0242903131401815,
      "grad_norm": 0.255139023065567,
      "learning_rate": 0.0004047944862155389,
      "loss": 3.3972,
      "step": 38500
    },
    {
      "epoch": 1.0375927847394046,
      "grad_norm": 0.21280749142169952,
      "learning_rate": 0.00040354135338345866,
      "loss": 3.3948,
      "step": 39000
    },
    {
      "epoch": 1.0508952563386278,
      "grad_norm": 0.20986278355121613,
      "learning_rate": 0.0004022882205513785,
      "loss": 3.393,
      "step": 39500
    },
    {
      "epoch": 1.064197727937851,
      "grad_norm": 0.2164836823940277,
      "learning_rate": 0.00040103508771929824,
      "loss": 3.3935,
      "step": 40000
    },
    {
      "epoch": 1.064197727937851,
      "eval_loss": 3.2977561950683594,
      "eval_runtime": 22.1047,
      "eval_samples_per_second": 2261.96,
      "eval_steps_per_second": 8.867,
      "step": 40000
    },
    {
      "epoch": 1.077500199537074,
      "grad_norm": 0.25500190258026123,
      "learning_rate": 0.00039978195488721806,
      "loss": 3.3905,
      "step": 40500
    },
    {
      "epoch": 1.090802671136297,
      "grad_norm": 0.22200508415699005,
      "learning_rate": 0.00039852882205513787,
      "loss": 3.3877,
      "step": 41000
    },
    {
      "epoch": 1.1041051427355202,
      "grad_norm": 0.41946738958358765,
      "learning_rate": 0.00039727819548872177,
      "loss": 3.3867,
      "step": 41500
    },
    {
      "epoch": 1.1174076143347433,
      "grad_norm": 0.30224499106407166,
      "learning_rate": 0.00039602506265664164,
      "loss": 3.3859,
      "step": 42000
    },
    {
      "epoch": 1.1307100859339665,
      "grad_norm": 0.21669478714466095,
      "learning_rate": 0.0003947719298245614,
      "loss": 3.3844,
      "step": 42500
    },
    {
      "epoch": 1.1440125575331896,
      "grad_norm": 0.21646848320960999,
      "learning_rate": 0.0003935187969924812,
      "loss": 3.3837,
      "step": 43000
    },
    {
      "epoch": 1.1573150291324128,
      "grad_norm": 0.3236684799194336,
      "learning_rate": 0.00039226817042606517,
      "loss": 3.3807,
      "step": 43500
    },
    {
      "epoch": 1.170617500731636,
      "grad_norm": 0.19164542853832245,
      "learning_rate": 0.000391015037593985,
      "loss": 3.3785,
      "step": 44000
    },
    {
      "epoch": 1.170617500731636,
      "eval_loss": 3.282921552658081,
      "eval_runtime": 22.0831,
      "eval_samples_per_second": 2264.17,
      "eval_steps_per_second": 8.876,
      "step": 44000
    },
    {
      "epoch": 1.183919972330859,
      "grad_norm": 0.23016691207885742,
      "learning_rate": 0.00038976190476190474,
      "loss": 3.3773,
      "step": 44500
    },
    {
      "epoch": 1.1972224439300823,
      "grad_norm": 0.22914279997348785,
      "learning_rate": 0.0003885087719298246,
      "loss": 3.376,
      "step": 45000
    },
    {
      "epoch": 1.2105249155293054,
      "grad_norm": 0.23256942629814148,
      "learning_rate": 0.0003872556390977444,
      "loss": 3.3735,
      "step": 45500
    },
    {
      "epoch": 1.2238273871285286,
      "grad_norm": 0.21868689358234406,
      "learning_rate": 0.0003860025062656642,
      "loss": 3.3717,
      "step": 46000
    },
    {
      "epoch": 1.2371298587277515,
      "grad_norm": 0.33138975501060486,
      "learning_rate": 0.00038474937343358395,
      "loss": 3.3719,
      "step": 46500
    },
    {
      "epoch": 1.2504323303269747,
      "grad_norm": 0.42020106315612793,
      "learning_rate": 0.0003834987468671679,
      "loss": 3.3699,
      "step": 47000
    },
    {
      "epoch": 1.2637348019261978,
      "grad_norm": 0.1913258582353592,
      "learning_rate": 0.0003822456140350877,
      "loss": 3.3682,
      "step": 47500
    },
    {
      "epoch": 1.277037273525421,
      "grad_norm": 0.26740962266921997,
      "learning_rate": 0.0003809924812030075,
      "loss": 3.367,
      "step": 48000
    },
    {
      "epoch": 1.277037273525421,
      "eval_loss": 3.270127773284912,
      "eval_runtime": 22.103,
      "eval_samples_per_second": 2262.133,
      "eval_steps_per_second": 8.868,
      "step": 48000
    },
    {
      "epoch": 1.290339745124644,
      "grad_norm": 0.33415526151657104,
      "learning_rate": 0.00037973934837092735,
      "loss": 3.3657,
      "step": 48500
    },
    {
      "epoch": 1.3036422167238673,
      "grad_norm": 0.18704986572265625,
      "learning_rate": 0.0003784862155388471,
      "loss": 3.3639,
      "step": 49000
    },
    {
      "epoch": 1.3169446883230904,
      "grad_norm": 0.27155956625938416,
      "learning_rate": 0.00037723308270676693,
      "loss": 3.363,
      "step": 49500
    },
    {
      "epoch": 1.3302471599223136,
      "grad_norm": 0.26096829771995544,
      "learning_rate": 0.0003759824561403509,
      "loss": 3.3612,
      "step": 50000
    },
    {
      "epoch": 1.3435496315215367,
      "grad_norm": 0.2234015017747879,
      "learning_rate": 0.0003747293233082707,
      "loss": 3.358,
      "step": 50500
    },
    {
      "epoch": 1.3568521031207599,
      "grad_norm": 0.26827049255371094,
      "learning_rate": 0.00037347619047619046,
      "loss": 3.358,
      "step": 51000
    },
    {
      "epoch": 1.370154574719983,
      "grad_norm": 0.21828141808509827,
      "learning_rate": 0.0003722230576441103,
      "loss": 3.3565,
      "step": 51500
    },
    {
      "epoch": 1.3834570463192062,
      "grad_norm": 0.22245822846889496,
      "learning_rate": 0.0003709699248120301,
      "loss": 3.3554,
      "step": 52000
    },
    {
      "epoch": 1.3834570463192062,
      "eval_loss": 3.258556604385376,
      "eval_runtime": 22.091,
      "eval_samples_per_second": 2263.368,
      "eval_steps_per_second": 8.872,
      "step": 52000
    },
    {
      "epoch": 1.3967595179184293,
      "grad_norm": 0.26239684224128723,
      "learning_rate": 0.0003697167919799499,
      "loss": 3.3535,
      "step": 52500
    },
    {
      "epoch": 1.4100619895176525,
      "grad_norm": 0.18818004429340363,
      "learning_rate": 0.00036846365914786967,
      "loss": 3.3509,
      "step": 53000
    },
    {
      "epoch": 1.4233644611168756,
      "grad_norm": 0.19289672374725342,
      "learning_rate": 0.0003672105263157895,
      "loss": 3.3513,
      "step": 53500
    },
    {
      "epoch": 1.4366669327160986,
      "grad_norm": 0.21637770533561707,
      "learning_rate": 0.00036595989974937343,
      "loss": 3.3499,
      "step": 54000
    },
    {
      "epoch": 1.4499694043153217,
      "grad_norm": 0.20685166120529175,
      "learning_rate": 0.00036470676691729325,
      "loss": 3.3493,
      "step": 54500
    },
    {
      "epoch": 1.4632718759145449,
      "grad_norm": 0.26926887035369873,
      "learning_rate": 0.000363453634085213,
      "loss": 3.3473,
      "step": 55000
    },
    {
      "epoch": 1.476574347513768,
      "grad_norm": 0.24804982542991638,
      "learning_rate": 0.0003622005012531329,
      "loss": 3.3469,
      "step": 55500
    },
    {
      "epoch": 1.4898768191129912,
      "grad_norm": 0.2053537368774414,
      "learning_rate": 0.00036094987468671683,
      "loss": 3.3462,
      "step": 56000
    },
    {
      "epoch": 1.4898768191129912,
      "eval_loss": 3.248842716217041,
      "eval_runtime": 22.1227,
      "eval_samples_per_second": 2260.123,
      "eval_steps_per_second": 8.86,
      "step": 56000
    },
    {
      "epoch": 1.5031792907122143,
      "grad_norm": 0.20908452570438385,
      "learning_rate": 0.0003596992481203007,
      "loss": 3.3443,
      "step": 56500
    },
    {
      "epoch": 1.5164817623114375,
      "grad_norm": 0.23992538452148438,
      "learning_rate": 0.0003584461152882206,
      "loss": 3.3441,
      "step": 57000
    },
    {
      "epoch": 1.5297842339106607,
      "grad_norm": 0.20105382800102234,
      "learning_rate": 0.00035719298245614036,
      "loss": 3.3411,
      "step": 57500
    },
    {
      "epoch": 1.5430867055098836,
      "grad_norm": 0.27005288004875183,
      "learning_rate": 0.0003559398496240602,
      "loss": 3.3424,
      "step": 58000
    },
    {
      "epoch": 1.5563891771091067,
      "grad_norm": 0.23349907994270325,
      "learning_rate": 0.00035468671679197994,
      "loss": 3.3418,
      "step": 58500
    },
    {
      "epoch": 1.56969164870833,
      "grad_norm": 0.21178483963012695,
      "learning_rate": 0.00035343358395989975,
      "loss": 3.3392,
      "step": 59000
    },
    {
      "epoch": 1.582994120307553,
      "grad_norm": 0.22521750628948212,
      "learning_rate": 0.00035218045112781957,
      "loss": 3.3392,
      "step": 59500
    },
    {
      "epoch": 1.5962965919067762,
      "grad_norm": 0.2545359134674072,
      "learning_rate": 0.0003509273182957394,
      "loss": 3.3384,
      "step": 60000
    },
    {
      "epoch": 1.5962965919067762,
      "eval_loss": 3.23956036567688,
      "eval_runtime": 22.0491,
      "eval_samples_per_second": 2267.668,
      "eval_steps_per_second": 8.889,
      "step": 60000
    },
    {
      "epoch": 1.6095990635059994,
      "grad_norm": 0.2015499770641327,
      "learning_rate": 0.00034967919799498747,
      "loss": 3.3367,
      "step": 60500
    },
    {
      "epoch": 1.6229015351052225,
      "grad_norm": 0.3108934760093689,
      "learning_rate": 0.0003484260651629073,
      "loss": 3.3361,
      "step": 61000
    },
    {
      "epoch": 1.6362040067044457,
      "grad_norm": 0.20155876874923706,
      "learning_rate": 0.0003471729323308271,
      "loss": 3.3346,
      "step": 61500
    },
    {
      "epoch": 1.6495064783036688,
      "grad_norm": 0.23235832154750824,
      "learning_rate": 0.00034591979949874686,
      "loss": 3.3347,
      "step": 62000
    },
    {
      "epoch": 1.662808949902892,
      "grad_norm": 0.26533499360084534,
      "learning_rate": 0.0003446666666666667,
      "loss": 3.3317,
      "step": 62500
    },
    {
      "epoch": 1.6761114215021151,
      "grad_norm": 0.22852420806884766,
      "learning_rate": 0.00034341353383458644,
      "loss": 3.3315,
      "step": 63000
    },
    {
      "epoch": 1.6894138931013383,
      "grad_norm": 0.4290655553340912,
      "learning_rate": 0.00034216040100250626,
      "loss": 3.33,
      "step": 63500
    },
    {
      "epoch": 1.7027163647005614,
      "grad_norm": 0.2693019509315491,
      "learning_rate": 0.00034090726817042607,
      "loss": 3.3293,
      "step": 64000
    },
    {
      "epoch": 1.7027163647005614,
      "eval_loss": 3.2318296432495117,
      "eval_runtime": 22.0877,
      "eval_samples_per_second": 2263.707,
      "eval_steps_per_second": 8.874,
      "step": 64000
    },
    {
      "epoch": 1.7160188362997846,
      "grad_norm": 0.3961065411567688,
      "learning_rate": 0.00033965914786967416,
      "loss": 3.329,
      "step": 64500
    },
    {
      "epoch": 1.7293213078990077,
      "grad_norm": 0.18452592194080353,
      "learning_rate": 0.00033840601503759397,
      "loss": 3.3289,
      "step": 65000
    },
    {
      "epoch": 1.7426237794982309,
      "grad_norm": 0.18443663418293,
      "learning_rate": 0.0003371528822055138,
      "loss": 3.3248,
      "step": 65500
    },
    {
      "epoch": 1.755926251097454,
      "grad_norm": 0.20520110428333282,
      "learning_rate": 0.0003358997493734336,
      "loss": 3.3255,
      "step": 66000
    },
    {
      "epoch": 1.7692287226966772,
      "grad_norm": 0.20938660204410553,
      "learning_rate": 0.00033464661654135337,
      "loss": 3.3234,
      "step": 66500
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 0.2341250330209732,
      "learning_rate": 0.0003333934837092732,
      "loss": 3.3248,
      "step": 67000
    },
    {
      "epoch": 1.7958336658951233,
      "grad_norm": 0.18823620676994324,
      "learning_rate": 0.00033214035087719294,
      "loss": 3.3245,
      "step": 67500
    },
    {
      "epoch": 1.8091361374943464,
      "grad_norm": 0.3950521647930145,
      "learning_rate": 0.0003308872180451128,
      "loss": 3.3219,
      "step": 68000
    },
    {
      "epoch": 1.8091361374943464,
      "eval_loss": 3.2246291637420654,
      "eval_runtime": 22.0601,
      "eval_samples_per_second": 2266.534,
      "eval_steps_per_second": 8.885,
      "step": 68000
    },
    {
      "epoch": 1.8224386090935696,
      "grad_norm": 0.20423738658428192,
      "learning_rate": 0.0003296365914786967,
      "loss": 3.3213,
      "step": 68500
    },
    {
      "epoch": 1.8357410806927927,
      "grad_norm": 0.20356008410453796,
      "learning_rate": 0.0003283834586466166,
      "loss": 3.3211,
      "step": 69000
    },
    {
      "epoch": 1.849043552292016,
      "grad_norm": 0.2093319594860077,
      "learning_rate": 0.00032713032581453634,
      "loss": 3.3209,
      "step": 69500
    },
    {
      "epoch": 1.862346023891239,
      "grad_norm": 0.19520489871501923,
      "learning_rate": 0.00032587719298245616,
      "loss": 3.3185,
      "step": 70000
    },
    {
      "epoch": 1.875648495490462,
      "grad_norm": 0.21022121608257294,
      "learning_rate": 0.0003246240601503759,
      "loss": 3.3182,
      "step": 70500
    },
    {
      "epoch": 1.8889509670896851,
      "grad_norm": 0.3124026358127594,
      "learning_rate": 0.00032337092731829574,
      "loss": 3.3165,
      "step": 71000
    },
    {
      "epoch": 1.9022534386889083,
      "grad_norm": 0.18477287888526917,
      "learning_rate": 0.00032211779448621555,
      "loss": 3.3167,
      "step": 71500
    },
    {
      "epoch": 1.9155559102881314,
      "grad_norm": 0.23945152759552002,
      "learning_rate": 0.00032086466165413537,
      "loss": 3.315,
      "step": 72000
    },
    {
      "epoch": 1.9155559102881314,
      "eval_loss": 3.217479705810547,
      "eval_runtime": 22.1085,
      "eval_samples_per_second": 2261.576,
      "eval_steps_per_second": 8.865,
      "step": 72000
    },
    {
      "epoch": 1.9288583818873546,
      "grad_norm": 0.2330087423324585,
      "learning_rate": 0.0003196140350877193,
      "loss": 3.3149,
      "step": 72500
    },
    {
      "epoch": 1.9421608534865777,
      "grad_norm": 0.28507834672927856,
      "learning_rate": 0.00031836090225563913,
      "loss": 3.3167,
      "step": 73000
    },
    {
      "epoch": 1.955463325085801,
      "grad_norm": 0.2766783535480499,
      "learning_rate": 0.0003171077694235589,
      "loss": 3.3133,
      "step": 73500
    },
    {
      "epoch": 1.968765796685024,
      "grad_norm": 0.19033896923065186,
      "learning_rate": 0.0003158546365914787,
      "loss": 3.3129,
      "step": 74000
    },
    {
      "epoch": 1.9820682682842472,
      "grad_norm": 0.18295764923095703,
      "learning_rate": 0.00031460401002506266,
      "loss": 3.3114,
      "step": 74500
    },
    {
      "epoch": 1.9953707398834704,
      "grad_norm": 0.21147623658180237,
      "learning_rate": 0.0003133508771929824,
      "loss": 3.3104,
      "step": 75000
    },
    {
      "epoch": 2.0086732114826935,
      "grad_norm": 0.29428449273109436,
      "learning_rate": 0.0003120977443609023,
      "loss": 3.3091,
      "step": 75500
    },
    {
      "epoch": 2.0219756830819167,
      "grad_norm": 0.4308910369873047,
      "learning_rate": 0.00031084461152882205,
      "loss": 3.3066,
      "step": 76000
    },
    {
      "epoch": 2.0219756830819167,
      "eval_loss": 3.211134672164917,
      "eval_runtime": 22.0932,
      "eval_samples_per_second": 2263.142,
      "eval_steps_per_second": 8.872,
      "step": 76000
    },
    {
      "epoch": 2.03527815468114,
      "grad_norm": 0.26356080174446106,
      "learning_rate": 0.00030959398496240606,
      "loss": 3.3064,
      "step": 76500
    },
    {
      "epoch": 2.048580626280363,
      "grad_norm": 0.2934107482433319,
      "learning_rate": 0.0003083408521303258,
      "loss": 3.3067,
      "step": 77000
    },
    {
      "epoch": 2.061883097879586,
      "grad_norm": 0.4811367094516754,
      "learning_rate": 0.00030708771929824564,
      "loss": 3.3063,
      "step": 77500
    },
    {
      "epoch": 2.0751855694788093,
      "grad_norm": 0.2500606179237366,
      "learning_rate": 0.0003058345864661654,
      "loss": 3.3055,
      "step": 78000
    },
    {
      "epoch": 2.0884880410780324,
      "grad_norm": 0.19804203510284424,
      "learning_rate": 0.00030458395989974935,
      "loss": 3.3045,
      "step": 78500
    },
    {
      "epoch": 2.1017905126772556,
      "grad_norm": 0.2702544331550598,
      "learning_rate": 0.00030333082706766916,
      "loss": 3.3045,
      "step": 79000
    },
    {
      "epoch": 2.1150929842764787,
      "grad_norm": 0.20269042253494263,
      "learning_rate": 0.0003020776942355889,
      "loss": 3.3025,
      "step": 79500
    },
    {
      "epoch": 2.128395455875702,
      "grad_norm": 0.18850409984588623,
      "learning_rate": 0.0003008245614035088,
      "loss": 3.3033,
      "step": 80000
    },
    {
      "epoch": 2.128395455875702,
      "eval_loss": 3.2055509090423584,
      "eval_runtime": 22.0874,
      "eval_samples_per_second": 2263.736,
      "eval_steps_per_second": 8.874,
      "step": 80000
    },
    {
      "epoch": 2.141697927474925,
      "grad_norm": 0.24291302263736725,
      "learning_rate": 0.00029957393483709275,
      "loss": 3.3027,
      "step": 80500
    },
    {
      "epoch": 2.155000399074148,
      "grad_norm": 0.2208072692155838,
      "learning_rate": 0.00029832080200501256,
      "loss": 3.3018,
      "step": 81000
    },
    {
      "epoch": 2.168302870673371,
      "grad_norm": 0.32271528244018555,
      "learning_rate": 0.0002970676691729323,
      "loss": 3.3003,
      "step": 81500
    },
    {
      "epoch": 2.181605342272594,
      "grad_norm": 0.3463640809059143,
      "learning_rate": 0.00029581453634085214,
      "loss": 3.2994,
      "step": 82000
    },
    {
      "epoch": 2.194907813871817,
      "grad_norm": 0.2902471721172333,
      "learning_rate": 0.0002945639097744361,
      "loss": 3.2991,
      "step": 82500
    },
    {
      "epoch": 2.2082102854710404,
      "grad_norm": 0.18060819804668427,
      "learning_rate": 0.0002933107769423559,
      "loss": 3.2984,
      "step": 83000
    },
    {
      "epoch": 2.2215127570702635,
      "grad_norm": 0.2590099275112152,
      "learning_rate": 0.00029205764411027567,
      "loss": 3.2998,
      "step": 83500
    },
    {
      "epoch": 2.2348152286694867,
      "grad_norm": 0.22599975764751434,
      "learning_rate": 0.00029080451127819554,
      "loss": 3.2989,
      "step": 84000
    },
    {
      "epoch": 2.2348152286694867,
      "eval_loss": 3.2004363536834717,
      "eval_runtime": 22.0878,
      "eval_samples_per_second": 2263.696,
      "eval_steps_per_second": 8.874,
      "step": 84000
    },
    {
      "epoch": 2.24811770026871,
      "grad_norm": 0.20809701085090637,
      "learning_rate": 0.00028955388471177943,
      "loss": 3.2977,
      "step": 84500
    },
    {
      "epoch": 2.261420171867933,
      "grad_norm": 0.2326059341430664,
      "learning_rate": 0.00028830075187969925,
      "loss": 3.2978,
      "step": 85000
    },
    {
      "epoch": 2.274722643467156,
      "grad_norm": 0.20260514318943024,
      "learning_rate": 0.00028704761904761907,
      "loss": 3.2959,
      "step": 85500
    },
    {
      "epoch": 2.2880251150663793,
      "grad_norm": 0.2513546049594879,
      "learning_rate": 0.00028579448621553883,
      "loss": 3.2952,
      "step": 86000
    },
    {
      "epoch": 2.3013275866656024,
      "grad_norm": 0.18171148002147675,
      "learning_rate": 0.00028454385964912283,
      "loss": 3.2962,
      "step": 86500
    },
    {
      "epoch": 2.3146300582648256,
      "grad_norm": 0.20359571278095245,
      "learning_rate": 0.0002832907268170426,
      "loss": 3.2964,
      "step": 87000
    },
    {
      "epoch": 2.3279325298640487,
      "grad_norm": 0.3692037761211395,
      "learning_rate": 0.0002820375939849624,
      "loss": 3.2941,
      "step": 87500
    },
    {
      "epoch": 2.341235001463272,
      "grad_norm": 0.23144406080245972,
      "learning_rate": 0.00028078446115288217,
      "loss": 3.2954,
      "step": 88000
    },
    {
      "epoch": 2.341235001463272,
      "eval_loss": 3.195965528488159,
      "eval_runtime": 22.085,
      "eval_samples_per_second": 2263.982,
      "eval_steps_per_second": 8.875,
      "step": 88000
    },
    {
      "epoch": 2.354537473062495,
      "grad_norm": 0.18175484240055084,
      "learning_rate": 0.0002795338345864662,
      "loss": 3.2936,
      "step": 88500
    },
    {
      "epoch": 2.367839944661718,
      "grad_norm": 0.21674591302871704,
      "learning_rate": 0.000278280701754386,
      "loss": 3.2925,
      "step": 89000
    },
    {
      "epoch": 2.3811424162609414,
      "grad_norm": 0.32385706901550293,
      "learning_rate": 0.0002770275689223058,
      "loss": 3.2932,
      "step": 89500
    },
    {
      "epoch": 2.3944448878601645,
      "grad_norm": 0.24056199193000793,
      "learning_rate": 0.00027577443609022557,
      "loss": 3.2923,
      "step": 90000
    },
    {
      "epoch": 2.4077473594593877,
      "grad_norm": 0.33632001280784607,
      "learning_rate": 0.0002745238095238095,
      "loss": 3.2889,
      "step": 90500
    },
    {
      "epoch": 2.421049831058611,
      "grad_norm": 0.20562171936035156,
      "learning_rate": 0.00027327067669172933,
      "loss": 3.2893,
      "step": 91000
    },
    {
      "epoch": 2.434352302657834,
      "grad_norm": 0.2665664851665497,
      "learning_rate": 0.0002720175438596491,
      "loss": 3.289,
      "step": 91500
    },
    {
      "epoch": 2.447654774257057,
      "grad_norm": 0.17609959840774536,
      "learning_rate": 0.0002707644110275689,
      "loss": 3.2913,
      "step": 92000
    },
    {
      "epoch": 2.447654774257057,
      "eval_loss": 3.191814661026001,
      "eval_runtime": 22.1012,
      "eval_samples_per_second": 2262.324,
      "eval_steps_per_second": 8.868,
      "step": 92000
    },
    {
      "epoch": 2.4609572458562803,
      "grad_norm": 0.2473093867301941,
      "learning_rate": 0.00026951378446115286,
      "loss": 3.2898,
      "step": 92500
    },
    {
      "epoch": 2.474259717455503,
      "grad_norm": 0.3788157105445862,
      "learning_rate": 0.0002682606516290727,
      "loss": 3.2876,
      "step": 93000
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.17716540396213531,
      "learning_rate": 0.0002670075187969925,
      "loss": 3.2872,
      "step": 93500
    },
    {
      "epoch": 2.5008646606539493,
      "grad_norm": 0.20569400489330292,
      "learning_rate": 0.0002657543859649123,
      "loss": 3.2882,
      "step": 94000
    },
    {
      "epoch": 2.5141671322531725,
      "grad_norm": 0.29587310552597046,
      "learning_rate": 0.00026450375939849626,
      "loss": 3.2862,
      "step": 94500
    },
    {
      "epoch": 2.5274696038523956,
      "grad_norm": 0.20186223089694977,
      "learning_rate": 0.000263250626566416,
      "loss": 3.2865,
      "step": 95000
    },
    {
      "epoch": 2.5407720754516188,
      "grad_norm": 0.17427371442317963,
      "learning_rate": 0.00026199749373433584,
      "loss": 3.2858,
      "step": 95500
    },
    {
      "epoch": 2.554074547050842,
      "grad_norm": 0.18455049395561218,
      "learning_rate": 0.0002607443609022556,
      "loss": 3.2831,
      "step": 96000
    },
    {
      "epoch": 2.554074547050842,
      "eval_loss": 3.186833143234253,
      "eval_runtime": 22.4082,
      "eval_samples_per_second": 2231.323,
      "eval_steps_per_second": 8.747,
      "step": 96000
    },
    {
      "epoch": 2.567377018650065,
      "grad_norm": 0.22807112336158752,
      "learning_rate": 0.0002594937343358396,
      "loss": 3.2855,
      "step": 96500
    },
    {
      "epoch": 2.580679490249288,
      "grad_norm": 0.1827966421842575,
      "learning_rate": 0.00025824060150375937,
      "loss": 3.283,
      "step": 97000
    },
    {
      "epoch": 2.5939819618485114,
      "grad_norm": 0.18019884824752808,
      "learning_rate": 0.00025698746867167924,
      "loss": 3.2852,
      "step": 97500
    },
    {
      "epoch": 2.6072844334477345,
      "grad_norm": 0.17372865974903107,
      "learning_rate": 0.000255734335839599,
      "loss": 3.283,
      "step": 98000
    },
    {
      "epoch": 2.6205869050469577,
      "grad_norm": 0.21212555468082428,
      "learning_rate": 0.000254483709273183,
      "loss": 3.2818,
      "step": 98500
    },
    {
      "epoch": 2.633889376646181,
      "grad_norm": 0.1905345767736435,
      "learning_rate": 0.00025323057644110276,
      "loss": 3.2804,
      "step": 99000
    },
    {
      "epoch": 2.647191848245404,
      "grad_norm": 0.21752728521823883,
      "learning_rate": 0.0002519774436090226,
      "loss": 3.2826,
      "step": 99500
    },
    {
      "epoch": 2.660494319844627,
      "grad_norm": 0.22301867604255676,
      "learning_rate": 0.00025072431077694234,
      "loss": 3.2792,
      "step": 100000
    },
    {
      "epoch": 2.660494319844627,
      "eval_loss": 3.1838574409484863,
      "eval_runtime": 22.0883,
      "eval_samples_per_second": 2263.638,
      "eval_steps_per_second": 8.873,
      "step": 100000
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 0.18072260916233063,
      "learning_rate": 0.00024947368421052635,
      "loss": 3.2793,
      "step": 100500
    },
    {
      "epoch": 2.6870992630430734,
      "grad_norm": 0.17672061920166016,
      "learning_rate": 0.0002482205513784461,
      "loss": 3.2803,
      "step": 101000
    },
    {
      "epoch": 2.7004017346422966,
      "grad_norm": 0.2106786072254181,
      "learning_rate": 0.0002469674185463659,
      "loss": 3.2797,
      "step": 101500
    },
    {
      "epoch": 2.7137042062415198,
      "grad_norm": 0.21248279511928558,
      "learning_rate": 0.00024571428571428574,
      "loss": 3.2787,
      "step": 102000
    },
    {
      "epoch": 2.727006677840743,
      "grad_norm": 0.22984057664871216,
      "learning_rate": 0.0002444636591478697,
      "loss": 3.2793,
      "step": 102500
    },
    {
      "epoch": 2.740309149439966,
      "grad_norm": 0.2262801229953766,
      "learning_rate": 0.00024321052631578948,
      "loss": 3.2774,
      "step": 103000
    },
    {
      "epoch": 2.753611621039189,
      "grad_norm": 0.21357764303684235,
      "learning_rate": 0.00024195739348370927,
      "loss": 3.2777,
      "step": 103500
    },
    {
      "epoch": 2.7669140926384124,
      "grad_norm": 0.38720470666885376,
      "learning_rate": 0.00024070676691729324,
      "loss": 3.2775,
      "step": 104000
    },
    {
      "epoch": 2.7669140926384124,
      "eval_loss": 3.178469657897949,
      "eval_runtime": 22.5387,
      "eval_samples_per_second": 2218.402,
      "eval_steps_per_second": 8.696,
      "step": 104000
    },
    {
      "epoch": 2.7802165642376355,
      "grad_norm": 0.1883421540260315,
      "learning_rate": 0.00023945363408521303,
      "loss": 3.2768,
      "step": 104500
    },
    {
      "epoch": 2.7935190358368587,
      "grad_norm": 0.2512264847755432,
      "learning_rate": 0.00023820050125313282,
      "loss": 3.2753,
      "step": 105000
    },
    {
      "epoch": 2.806821507436082,
      "grad_norm": 0.3280524015426636,
      "learning_rate": 0.00023694736842105264,
      "loss": 3.2762,
      "step": 105500
    },
    {
      "epoch": 2.820123979035305,
      "grad_norm": 0.2301386445760727,
      "learning_rate": 0.00023569423558897243,
      "loss": 3.2751,
      "step": 106000
    },
    {
      "epoch": 2.833426450634528,
      "grad_norm": 0.19285452365875244,
      "learning_rate": 0.00023444110275689224,
      "loss": 3.2759,
      "step": 106500
    },
    {
      "epoch": 2.8467289222337513,
      "grad_norm": 0.16995371878147125,
      "learning_rate": 0.00023318796992481203,
      "loss": 3.2765,
      "step": 107000
    },
    {
      "epoch": 2.860031393832974,
      "grad_norm": 0.19181229174137115,
      "learning_rate": 0.000231937343358396,
      "loss": 3.2744,
      "step": 107500
    },
    {
      "epoch": 2.873333865432197,
      "grad_norm": 0.2975299060344696,
      "learning_rate": 0.00023068671679197996,
      "loss": 3.276,
      "step": 108000
    },
    {
      "epoch": 2.873333865432197,
      "eval_loss": 3.174905300140381,
      "eval_runtime": 22.0554,
      "eval_samples_per_second": 2267.013,
      "eval_steps_per_second": 8.887,
      "step": 108000
    },
    {
      "epoch": 2.8866363370314203,
      "grad_norm": 0.19541768729686737,
      "learning_rate": 0.00022943358395989975,
      "loss": 3.2731,
      "step": 108500
    },
    {
      "epoch": 2.8999388086306435,
      "grad_norm": 0.18461042642593384,
      "learning_rate": 0.00022818045112781954,
      "loss": 3.2733,
      "step": 109000
    },
    {
      "epoch": 2.9132412802298666,
      "grad_norm": 0.16871009767055511,
      "learning_rate": 0.00022692731829573935,
      "loss": 3.2738,
      "step": 109500
    },
    {
      "epoch": 2.9265437518290898,
      "grad_norm": 0.3424469232559204,
      "learning_rate": 0.00022567418546365914,
      "loss": 3.2723,
      "step": 110000
    },
    {
      "epoch": 2.939846223428313,
      "grad_norm": 0.2894395887851715,
      "learning_rate": 0.00022442105263157893,
      "loss": 3.272,
      "step": 110500
    },
    {
      "epoch": 2.953148695027536,
      "grad_norm": 0.1723097860813141,
      "learning_rate": 0.00022316791979949875,
      "loss": 3.2718,
      "step": 111000
    },
    {
      "epoch": 2.9664511666267592,
      "grad_norm": 0.19894389808177948,
      "learning_rate": 0.00022191478696741853,
      "loss": 3.2708,
      "step": 111500
    },
    {
      "epoch": 2.9797536382259824,
      "grad_norm": 0.3607000410556793,
      "learning_rate": 0.00022066165413533835,
      "loss": 3.2706,
      "step": 112000
    },
    {
      "epoch": 2.9797536382259824,
      "eval_loss": 3.17195725440979,
      "eval_runtime": 22.0686,
      "eval_samples_per_second": 2265.662,
      "eval_steps_per_second": 8.881,
      "step": 112000
    },
    {
      "epoch": 2.9930561098252055,
      "grad_norm": 0.3117738366127014,
      "learning_rate": 0.00021940852130325814,
      "loss": 3.2696,
      "step": 112500
    },
    {
      "epoch": 3.0063585814244287,
      "grad_norm": 0.21605437994003296,
      "learning_rate": 0.00021815538847117793,
      "loss": 3.2684,
      "step": 113000
    },
    {
      "epoch": 3.019661053023652,
      "grad_norm": 0.18229997158050537,
      "learning_rate": 0.00021690225563909774,
      "loss": 3.2666,
      "step": 113500
    },
    {
      "epoch": 3.032963524622875,
      "grad_norm": 0.3093135356903076,
      "learning_rate": 0.00021565162907268172,
      "loss": 3.2663,
      "step": 114000
    },
    {
      "epoch": 3.046265996222098,
      "grad_norm": 0.3540351986885071,
      "learning_rate": 0.0002143984962406015,
      "loss": 3.2656,
      "step": 114500
    },
    {
      "epoch": 3.0595684678213213,
      "grad_norm": 0.167195662856102,
      "learning_rate": 0.0002131453634085213,
      "loss": 3.2665,
      "step": 115000
    },
    {
      "epoch": 3.0728709394205445,
      "grad_norm": 0.20744264125823975,
      "learning_rate": 0.00021189223057644112,
      "loss": 3.2654,
      "step": 115500
    },
    {
      "epoch": 3.0861734110197676,
      "grad_norm": 0.1828465461730957,
      "learning_rate": 0.00021064160401002507,
      "loss": 3.2675,
      "step": 116000
    },
    {
      "epoch": 3.0861734110197676,
      "eval_loss": 3.168931484222412,
      "eval_runtime": 22.0649,
      "eval_samples_per_second": 2266.039,
      "eval_steps_per_second": 8.883,
      "step": 116000
    },
    {
      "epoch": 3.0994758826189908,
      "grad_norm": 0.20370270311832428,
      "learning_rate": 0.00020938847117794488,
      "loss": 3.2677,
      "step": 116500
    },
    {
      "epoch": 3.112778354218214,
      "grad_norm": 0.1891409009695053,
      "learning_rate": 0.00020813533834586467,
      "loss": 3.2657,
      "step": 117000
    },
    {
      "epoch": 3.126080825817437,
      "grad_norm": 0.3685793876647949,
      "learning_rate": 0.0002068822055137845,
      "loss": 3.2647,
      "step": 117500
    },
    {
      "epoch": 3.1393832974166602,
      "grad_norm": 0.1810102015733719,
      "learning_rate": 0.0002056315789473684,
      "loss": 3.264,
      "step": 118000
    },
    {
      "epoch": 3.152685769015883,
      "grad_norm": 0.19056768715381622,
      "learning_rate": 0.00020437844611528823,
      "loss": 3.2623,
      "step": 118500
    },
    {
      "epoch": 3.165988240615106,
      "grad_norm": 0.36522769927978516,
      "learning_rate": 0.0002031278195488722,
      "loss": 3.264,
      "step": 119000
    },
    {
      "epoch": 3.1792907122143292,
      "grad_norm": 0.1910599321126938,
      "learning_rate": 0.000201874686716792,
      "loss": 3.2629,
      "step": 119500
    },
    {
      "epoch": 3.1925931838135524,
      "grad_norm": 0.17657633125782013,
      "learning_rate": 0.00020062155388471178,
      "loss": 3.2621,
      "step": 120000
    },
    {
      "epoch": 3.1925931838135524,
      "eval_loss": 3.1653616428375244,
      "eval_runtime": 22.0875,
      "eval_samples_per_second": 2263.726,
      "eval_steps_per_second": 8.874,
      "step": 120000
    },
    {
      "epoch": 3.2058956554127755,
      "grad_norm": 0.1937638819217682,
      "learning_rate": 0.0001993684210526316,
      "loss": 3.2616,
      "step": 120500
    },
    {
      "epoch": 3.2191981270119987,
      "grad_norm": 0.1946459412574768,
      "learning_rate": 0.00019811528822055138,
      "loss": 3.2614,
      "step": 121000
    },
    {
      "epoch": 3.232500598611222,
      "grad_norm": 0.19570840895175934,
      "learning_rate": 0.00019686466165413533,
      "loss": 3.2621,
      "step": 121500
    },
    {
      "epoch": 3.245803070210445,
      "grad_norm": 0.2121397852897644,
      "learning_rate": 0.00019561152882205512,
      "loss": 3.2637,
      "step": 122000
    },
    {
      "epoch": 3.259105541809668,
      "grad_norm": 0.23116213083267212,
      "learning_rate": 0.00019435839598997494,
      "loss": 3.2627,
      "step": 122500
    },
    {
      "epoch": 3.2724080134088913,
      "grad_norm": 0.2550022304058075,
      "learning_rate": 0.00019310526315789473,
      "loss": 3.2609,
      "step": 123000
    },
    {
      "epoch": 3.2857104850081145,
      "grad_norm": 0.3405880928039551,
      "learning_rate": 0.00019185213032581452,
      "loss": 3.2613,
      "step": 123500
    },
    {
      "epoch": 3.2990129566073376,
      "grad_norm": 0.17449389398097992,
      "learning_rate": 0.00019059899749373433,
      "loss": 3.2608,
      "step": 124000
    },
    {
      "epoch": 3.2990129566073376,
      "eval_loss": 3.1625027656555176,
      "eval_runtime": 22.0802,
      "eval_samples_per_second": 2264.472,
      "eval_steps_per_second": 8.877,
      "step": 124000
    },
    {
      "epoch": 3.3123154282065608,
      "grad_norm": 0.19650591909885406,
      "learning_rate": 0.00018934586466165412,
      "loss": 3.2614,
      "step": 124500
    },
    {
      "epoch": 3.325617899805784,
      "grad_norm": 0.19023165106773376,
      "learning_rate": 0.00018809273182957394,
      "loss": 3.2592,
      "step": 125000
    },
    {
      "epoch": 3.338920371405007,
      "grad_norm": 0.26677894592285156,
      "learning_rate": 0.0001868421052631579,
      "loss": 3.2603,
      "step": 125500
    },
    {
      "epoch": 3.3522228430042302,
      "grad_norm": 0.21683959662914276,
      "learning_rate": 0.0001855889724310777,
      "loss": 3.2595,
      "step": 126000
    },
    {
      "epoch": 3.3655253146034534,
      "grad_norm": 0.18189947307109833,
      "learning_rate": 0.0001843358395989975,
      "loss": 3.2574,
      "step": 126500
    },
    {
      "epoch": 3.3788277862026765,
      "grad_norm": 0.1832115203142166,
      "learning_rate": 0.00018308270676691728,
      "loss": 3.2568,
      "step": 127000
    },
    {
      "epoch": 3.3921302578018997,
      "grad_norm": 0.2025858759880066,
      "learning_rate": 0.00018183208020050126,
      "loss": 3.2591,
      "step": 127500
    },
    {
      "epoch": 3.405432729401123,
      "grad_norm": 0.21227480471134186,
      "learning_rate": 0.00018057894736842108,
      "loss": 3.2614,
      "step": 128000
    },
    {
      "epoch": 3.405432729401123,
      "eval_loss": 3.1597187519073486,
      "eval_runtime": 22.0899,
      "eval_samples_per_second": 2263.475,
      "eval_steps_per_second": 8.873,
      "step": 128000
    },
    {
      "epoch": 3.418735201000346,
      "grad_norm": 0.2659952938556671,
      "learning_rate": 0.00017932581453634086,
      "loss": 3.2573,
      "step": 128500
    },
    {
      "epoch": 3.432037672599569,
      "grad_norm": 0.255425363779068,
      "learning_rate": 0.00017807268170426065,
      "loss": 3.2574,
      "step": 129000
    },
    {
      "epoch": 3.4453401441987923,
      "grad_norm": 0.19571080803871155,
      "learning_rate": 0.0001768220551378446,
      "loss": 3.2569,
      "step": 129500
    },
    {
      "epoch": 3.4586426157980155,
      "grad_norm": 0.18101203441619873,
      "learning_rate": 0.00017556892230576442,
      "loss": 3.2571,
      "step": 130000
    },
    {
      "epoch": 3.4719450873972386,
      "grad_norm": 0.20136237144470215,
      "learning_rate": 0.0001743157894736842,
      "loss": 3.2573,
      "step": 130500
    },
    {
      "epoch": 3.4852475589964618,
      "grad_norm": 0.17003825306892395,
      "learning_rate": 0.000173062656641604,
      "loss": 3.2559,
      "step": 131000
    },
    {
      "epoch": 3.498550030595685,
      "grad_norm": 0.17732028663158417,
      "learning_rate": 0.00017181203007518797,
      "loss": 3.257,
      "step": 131500
    },
    {
      "epoch": 3.511852502194908,
      "grad_norm": 0.28955286741256714,
      "learning_rate": 0.00017055889724310776,
      "loss": 3.2562,
      "step": 132000
    },
    {
      "epoch": 3.511852502194908,
      "eval_loss": 3.1578521728515625,
      "eval_runtime": 22.1141,
      "eval_samples_per_second": 2261.004,
      "eval_steps_per_second": 8.863,
      "step": 132000
    },
    {
      "epoch": 3.525154973794131,
      "grad_norm": 0.21034182608127594,
      "learning_rate": 0.00016930576441102758,
      "loss": 3.2526,
      "step": 132500
    },
    {
      "epoch": 3.538457445393354,
      "grad_norm": 0.19830310344696045,
      "learning_rate": 0.00016805263157894737,
      "loss": 3.2551,
      "step": 133000
    },
    {
      "epoch": 3.551759916992577,
      "grad_norm": 0.31276223063468933,
      "learning_rate": 0.00016680451127819548,
      "loss": 3.2544,
      "step": 133500
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.2741609811782837,
      "learning_rate": 0.0001655513784461153,
      "loss": 3.2566,
      "step": 134000
    },
    {
      "epoch": 3.5783648601910234,
      "grad_norm": 0.16568315029144287,
      "learning_rate": 0.00016429824561403508,
      "loss": 3.2562,
      "step": 134500
    },
    {
      "epoch": 3.5916673317902466,
      "grad_norm": 0.18884243071079254,
      "learning_rate": 0.00016304511278195487,
      "loss": 3.2525,
      "step": 135000
    },
    {
      "epoch": 3.6049698033894697,
      "grad_norm": 0.25863122940063477,
      "learning_rate": 0.0001617919799498747,
      "loss": 3.2543,
      "step": 135500
    },
    {
      "epoch": 3.618272274988693,
      "grad_norm": 0.1998624950647354,
      "learning_rate": 0.00016053884711779448,
      "loss": 3.2538,
      "step": 136000
    },
    {
      "epoch": 3.618272274988693,
      "eval_loss": 3.1541519165039062,
      "eval_runtime": 22.0875,
      "eval_samples_per_second": 2263.719,
      "eval_steps_per_second": 8.874,
      "step": 136000
    },
    {
      "epoch": 3.631574746587916,
      "grad_norm": 0.20339526236057281,
      "learning_rate": 0.0001592857142857143,
      "loss": 3.2533,
      "step": 136500
    },
    {
      "epoch": 3.644877218187139,
      "grad_norm": 0.23959311842918396,
      "learning_rate": 0.00015803258145363408,
      "loss": 3.2511,
      "step": 137000
    },
    {
      "epoch": 3.6581796897863623,
      "grad_norm": 0.18740661442279816,
      "learning_rate": 0.0001567844611528822,
      "loss": 3.2529,
      "step": 137500
    },
    {
      "epoch": 3.6714821613855855,
      "grad_norm": 0.314931720495224,
      "learning_rate": 0.000155531328320802,
      "loss": 3.2522,
      "step": 138000
    },
    {
      "epoch": 3.6847846329848086,
      "grad_norm": 0.18093590438365936,
      "learning_rate": 0.0001542781954887218,
      "loss": 3.2522,
      "step": 138500
    },
    {
      "epoch": 3.698087104584032,
      "grad_norm": 0.20800535380840302,
      "learning_rate": 0.0001530250626566416,
      "loss": 3.2508,
      "step": 139000
    },
    {
      "epoch": 3.711389576183255,
      "grad_norm": 0.21377485990524292,
      "learning_rate": 0.0001517719298245614,
      "loss": 3.2512,
      "step": 139500
    },
    {
      "epoch": 3.724692047782478,
      "grad_norm": 0.24159406125545502,
      "learning_rate": 0.0001505187969924812,
      "loss": 3.25,
      "step": 140000
    },
    {
      "epoch": 3.724692047782478,
      "eval_loss": 3.151909589767456,
      "eval_runtime": 22.101,
      "eval_samples_per_second": 2262.345,
      "eval_steps_per_second": 8.868,
      "step": 140000
    },
    {
      "epoch": 3.7379945193817012,
      "grad_norm": 0.19721141457557678,
      "learning_rate": 0.00014926566416040098,
      "loss": 3.2513,
      "step": 140500
    },
    {
      "epoch": 3.7512969909809244,
      "grad_norm": 0.17336562275886536,
      "learning_rate": 0.0001480125313283208,
      "loss": 3.2514,
      "step": 141000
    },
    {
      "epoch": 3.7645994625801475,
      "grad_norm": 0.17159917950630188,
      "learning_rate": 0.00014676190476190477,
      "loss": 3.2494,
      "step": 141500
    },
    {
      "epoch": 3.7779019341793703,
      "grad_norm": 0.24846838414669037,
      "learning_rate": 0.00014550877192982456,
      "loss": 3.2503,
      "step": 142000
    },
    {
      "epoch": 3.7912044057785934,
      "grad_norm": 0.19000670313835144,
      "learning_rate": 0.00014425563909774435,
      "loss": 3.249,
      "step": 142500
    },
    {
      "epoch": 3.8045068773778166,
      "grad_norm": 0.2055562436580658,
      "learning_rate": 0.00014300250626566417,
      "loss": 3.2489,
      "step": 143000
    },
    {
      "epoch": 3.8178093489770397,
      "grad_norm": 0.201969712972641,
      "learning_rate": 0.00014175187969924814,
      "loss": 3.2494,
      "step": 143500
    },
    {
      "epoch": 3.831111820576263,
      "grad_norm": 0.2234257012605667,
      "learning_rate": 0.00014049874686716793,
      "loss": 3.25,
      "step": 144000
    },
    {
      "epoch": 3.831111820576263,
      "eval_loss": 3.1494572162628174,
      "eval_runtime": 22.0886,
      "eval_samples_per_second": 2263.616,
      "eval_steps_per_second": 8.873,
      "step": 144000
    },
    {
      "epoch": 3.844414292175486,
      "grad_norm": 0.18487517535686493,
      "learning_rate": 0.00013924561403508772,
      "loss": 3.2505,
      "step": 144500
    },
    {
      "epoch": 3.857716763774709,
      "grad_norm": 0.26943498849868774,
      "learning_rate": 0.00013799248120300754,
      "loss": 3.2463,
      "step": 145000
    },
    {
      "epoch": 3.8710192353739323,
      "grad_norm": 0.18744409084320068,
      "learning_rate": 0.00013674185463659146,
      "loss": 3.2484,
      "step": 145500
    },
    {
      "epoch": 3.8843217069731555,
      "grad_norm": 0.17788629233837128,
      "learning_rate": 0.00013548872180451128,
      "loss": 3.2475,
      "step": 146000
    },
    {
      "epoch": 3.8976241785723786,
      "grad_norm": 0.2295607477426529,
      "learning_rate": 0.00013423558897243107,
      "loss": 3.2471,
      "step": 146500
    },
    {
      "epoch": 3.910926650171602,
      "grad_norm": 0.2104986310005188,
      "learning_rate": 0.00013298245614035088,
      "loss": 3.2478,
      "step": 147000
    },
    {
      "epoch": 3.924229121770825,
      "grad_norm": 0.21896010637283325,
      "learning_rate": 0.00013173182957393483,
      "loss": 3.2462,
      "step": 147500
    },
    {
      "epoch": 3.937531593370048,
      "grad_norm": 0.17639513313770294,
      "learning_rate": 0.00013047869674185465,
      "loss": 3.2451,
      "step": 148000
    },
    {
      "epoch": 3.937531593370048,
      "eval_loss": 3.1475203037261963,
      "eval_runtime": 22.1004,
      "eval_samples_per_second": 2262.398,
      "eval_steps_per_second": 8.869,
      "step": 148000
    },
    {
      "epoch": 3.9508340649692713,
      "grad_norm": 0.27296754717826843,
      "learning_rate": 0.00012922556390977444,
      "loss": 3.245,
      "step": 148500
    },
    {
      "epoch": 3.9641365365684944,
      "grad_norm": 0.20404034852981567,
      "learning_rate": 0.00012797243107769425,
      "loss": 3.2484,
      "step": 149000
    },
    {
      "epoch": 3.9774390081677176,
      "grad_norm": 0.19234056770801544,
      "learning_rate": 0.0001267218045112782,
      "loss": 3.2455,
      "step": 149500
    },
    {
      "epoch": 3.9907414797669407,
      "grad_norm": 0.22161851823329926,
      "learning_rate": 0.00012546867167919802,
      "loss": 3.2448,
      "step": 150000
    },
    {
      "epoch": 4.004043951366164,
      "grad_norm": 0.30801764130592346,
      "learning_rate": 0.0001242155388471178,
      "loss": 3.2432,
      "step": 150500
    },
    {
      "epoch": 4.017346422965387,
      "grad_norm": 0.19725559651851654,
      "learning_rate": 0.0001229624060150376,
      "loss": 3.2421,
      "step": 151000
    },
    {
      "epoch": 4.03064889456461,
      "grad_norm": 0.18508471548557281,
      "learning_rate": 0.00012171177944862155,
      "loss": 3.2414,
      "step": 151500
    },
    {
      "epoch": 4.043951366163833,
      "grad_norm": 0.19269821047782898,
      "learning_rate": 0.00012045864661654135,
      "loss": 3.2419,
      "step": 152000
    },
    {
      "epoch": 4.043951366163833,
      "eval_loss": 3.1455705165863037,
      "eval_runtime": 22.0942,
      "eval_samples_per_second": 2263.034,
      "eval_steps_per_second": 8.871,
      "step": 152000
    },
    {
      "epoch": 4.0572538377630565,
      "grad_norm": 0.38826173543930054,
      "learning_rate": 0.00011920551378446115,
      "loss": 3.2425,
      "step": 152500
    },
    {
      "epoch": 4.07055630936228,
      "grad_norm": 0.1974782645702362,
      "learning_rate": 0.00011795238095238095,
      "loss": 3.2414,
      "step": 153000
    },
    {
      "epoch": 4.083858780961503,
      "grad_norm": 0.23216865956783295,
      "learning_rate": 0.00011670175438596492,
      "loss": 3.2414,
      "step": 153500
    },
    {
      "epoch": 4.097161252560726,
      "grad_norm": 0.1869179904460907,
      "learning_rate": 0.00011544862155388472,
      "loss": 3.2435,
      "step": 154000
    },
    {
      "epoch": 4.110463724159949,
      "grad_norm": 0.18802353739738464,
      "learning_rate": 0.00011419548872180452,
      "loss": 3.2426,
      "step": 154500
    },
    {
      "epoch": 4.123766195759172,
      "grad_norm": 0.18656401336193085,
      "learning_rate": 0.00011294235588972432,
      "loss": 3.2425,
      "step": 155000
    },
    {
      "epoch": 4.137068667358395,
      "grad_norm": 0.20822089910507202,
      "learning_rate": 0.00011169172932330827,
      "loss": 3.2427,
      "step": 155500
    },
    {
      "epoch": 4.1503711389576186,
      "grad_norm": 0.1727118343114853,
      "learning_rate": 0.00011043859649122808,
      "loss": 3.2387,
      "step": 156000
    },
    {
      "epoch": 4.1503711389576186,
      "eval_loss": 3.1434872150421143,
      "eval_runtime": 22.1881,
      "eval_samples_per_second": 2253.461,
      "eval_steps_per_second": 8.834,
      "step": 156000
    },
    {
      "epoch": 4.163673610556842,
      "grad_norm": 0.19976840913295746,
      "learning_rate": 0.00010918546365914788,
      "loss": 3.2431,
      "step": 156500
    },
    {
      "epoch": 4.176976082156065,
      "grad_norm": 0.18597383797168732,
      "learning_rate": 0.00010793233082706767,
      "loss": 3.2399,
      "step": 157000
    },
    {
      "epoch": 4.190278553755288,
      "grad_norm": 0.2084772288799286,
      "learning_rate": 0.00010668170426065163,
      "loss": 3.2398,
      "step": 157500
    },
    {
      "epoch": 4.203581025354511,
      "grad_norm": 0.18216916918754578,
      "learning_rate": 0.00010542857142857143,
      "loss": 3.2412,
      "step": 158000
    },
    {
      "epoch": 4.216883496953734,
      "grad_norm": 0.17363348603248596,
      "learning_rate": 0.00010417543859649122,
      "loss": 3.2387,
      "step": 158500
    },
    {
      "epoch": 4.2301859685529575,
      "grad_norm": 0.18292184174060822,
      "learning_rate": 0.00010292230576441103,
      "loss": 3.2394,
      "step": 159000
    },
    {
      "epoch": 4.243488440152181,
      "grad_norm": 0.19087795913219452,
      "learning_rate": 0.00010166917293233083,
      "loss": 3.2392,
      "step": 159500
    },
    {
      "epoch": 4.256790911751404,
      "grad_norm": 0.18720228970050812,
      "learning_rate": 0.00010041854636591478,
      "loss": 3.2404,
      "step": 160000
    },
    {
      "epoch": 4.256790911751404,
      "eval_loss": 3.141202449798584,
      "eval_runtime": 22.0846,
      "eval_samples_per_second": 2264.016,
      "eval_steps_per_second": 8.875,
      "step": 160000
    },
    {
      "epoch": 4.270093383350627,
      "grad_norm": 0.17440234124660492,
      "learning_rate": 9.916541353383458e-05,
      "loss": 3.2391,
      "step": 160500
    },
    {
      "epoch": 4.28339585494985,
      "grad_norm": 0.17469628155231476,
      "learning_rate": 9.791228070175438e-05,
      "loss": 3.2388,
      "step": 161000
    },
    {
      "epoch": 4.296698326549073,
      "grad_norm": 0.1655171811580658,
      "learning_rate": 9.665914786967418e-05,
      "loss": 3.2389,
      "step": 161500
    },
    {
      "epoch": 4.310000798148296,
      "grad_norm": 0.20141328871250153,
      "learning_rate": 9.540852130325815e-05,
      "loss": 3.2388,
      "step": 162000
    },
    {
      "epoch": 4.3233032697475196,
      "grad_norm": 0.20853598415851593,
      "learning_rate": 9.415538847117795e-05,
      "loss": 3.2387,
      "step": 162500
    },
    {
      "epoch": 4.336605741346742,
      "grad_norm": 0.25287988781929016,
      "learning_rate": 9.290225563909775e-05,
      "loss": 3.2391,
      "step": 163000
    },
    {
      "epoch": 4.349908212945965,
      "grad_norm": 0.18629615008831024,
      "learning_rate": 9.164912280701756e-05,
      "loss": 3.2398,
      "step": 163500
    },
    {
      "epoch": 4.363210684545188,
      "grad_norm": 0.189655601978302,
      "learning_rate": 9.03984962406015e-05,
      "loss": 3.2372,
      "step": 164000
    },
    {
      "epoch": 4.363210684545188,
      "eval_loss": 3.139512538909912,
      "eval_runtime": 22.0827,
      "eval_samples_per_second": 2264.22,
      "eval_steps_per_second": 8.876,
      "step": 164000
    },
    {
      "epoch": 4.376513156144411,
      "grad_norm": 0.2068314105272293,
      "learning_rate": 8.914536340852131e-05,
      "loss": 3.2366,
      "step": 164500
    },
    {
      "epoch": 4.389815627743634,
      "grad_norm": 0.18468399345874786,
      "learning_rate": 8.789223057644111e-05,
      "loss": 3.2374,
      "step": 165000
    },
    {
      "epoch": 4.403118099342858,
      "grad_norm": 0.20894144475460052,
      "learning_rate": 8.663909774436091e-05,
      "loss": 3.2377,
      "step": 165500
    },
    {
      "epoch": 4.416420570942081,
      "grad_norm": 0.18016333878040314,
      "learning_rate": 8.538847117794486e-05,
      "loss": 3.2372,
      "step": 166000
    },
    {
      "epoch": 4.429723042541304,
      "grad_norm": 0.18210339546203613,
      "learning_rate": 8.413533834586467e-05,
      "loss": 3.237,
      "step": 166500
    },
    {
      "epoch": 4.443025514140527,
      "grad_norm": 0.22970369458198547,
      "learning_rate": 8.288220551378447e-05,
      "loss": 3.2374,
      "step": 167000
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.17482416331768036,
      "learning_rate": 8.162907268170426e-05,
      "loss": 3.2346,
      "step": 167500
    },
    {
      "epoch": 4.469630457338973,
      "grad_norm": 0.2427154779434204,
      "learning_rate": 8.037844611528822e-05,
      "loss": 3.2363,
      "step": 168000
    },
    {
      "epoch": 4.469630457338973,
      "eval_loss": 3.1374385356903076,
      "eval_runtime": 22.3694,
      "eval_samples_per_second": 2235.198,
      "eval_steps_per_second": 8.762,
      "step": 168000
    },
    {
      "epoch": 4.4829329289381965,
      "grad_norm": 0.17342384159564972,
      "learning_rate": 7.912531328320802e-05,
      "loss": 3.2347,
      "step": 168500
    },
    {
      "epoch": 4.49623540053742,
      "grad_norm": 0.1691494584083557,
      "learning_rate": 7.787218045112781e-05,
      "loss": 3.2364,
      "step": 169000
    },
    {
      "epoch": 4.509537872136643,
      "grad_norm": 0.18109120428562164,
      "learning_rate": 7.661904761904761e-05,
      "loss": 3.236,
      "step": 169500
    },
    {
      "epoch": 4.522840343735866,
      "grad_norm": 0.18004631996154785,
      "learning_rate": 7.536842105263159e-05,
      "loss": 3.2355,
      "step": 170000
    },
    {
      "epoch": 4.536142815335089,
      "grad_norm": 0.1748267412185669,
      "learning_rate": 7.411528822055138e-05,
      "loss": 3.2352,
      "step": 170500
    },
    {
      "epoch": 4.549445286934312,
      "grad_norm": 0.20084188878536224,
      "learning_rate": 7.286215538847118e-05,
      "loss": 3.2353,
      "step": 171000
    },
    {
      "epoch": 4.562747758533535,
      "grad_norm": 0.17561814188957214,
      "learning_rate": 7.160902255639098e-05,
      "loss": 3.2337,
      "step": 171500
    },
    {
      "epoch": 4.576050230132759,
      "grad_norm": 0.1698097586631775,
      "learning_rate": 7.035839598997493e-05,
      "loss": 3.2356,
      "step": 172000
    },
    {
      "epoch": 4.576050230132759,
      "eval_loss": 3.135622262954712,
      "eval_runtime": 22.1118,
      "eval_samples_per_second": 2261.236,
      "eval_steps_per_second": 8.864,
      "step": 172000
    },
    {
      "epoch": 4.589352701731982,
      "grad_norm": 0.20132514834403992,
      "learning_rate": 6.910526315789474e-05,
      "loss": 3.236,
      "step": 172500
    },
    {
      "epoch": 4.602655173331205,
      "grad_norm": 0.1658679097890854,
      "learning_rate": 6.785213032581454e-05,
      "loss": 3.2326,
      "step": 173000
    },
    {
      "epoch": 4.615957644930428,
      "grad_norm": 0.17251074314117432,
      "learning_rate": 6.659899749373434e-05,
      "loss": 3.2336,
      "step": 173500
    },
    {
      "epoch": 4.629260116529651,
      "grad_norm": 0.18215583264827728,
      "learning_rate": 6.534837092731829e-05,
      "loss": 3.2324,
      "step": 174000
    },
    {
      "epoch": 4.642562588128874,
      "grad_norm": 0.17668408155441284,
      "learning_rate": 6.40952380952381e-05,
      "loss": 3.2348,
      "step": 174500
    },
    {
      "epoch": 4.6558650597280975,
      "grad_norm": 0.170611172914505,
      "learning_rate": 6.28421052631579e-05,
      "loss": 3.2334,
      "step": 175000
    },
    {
      "epoch": 4.669167531327321,
      "grad_norm": 0.22791938483715057,
      "learning_rate": 6.15889724310777e-05,
      "loss": 3.2322,
      "step": 175500
    },
    {
      "epoch": 4.682470002926544,
      "grad_norm": 0.1737978160381317,
      "learning_rate": 6.0338345864661656e-05,
      "loss": 3.2341,
      "step": 176000
    },
    {
      "epoch": 4.682470002926544,
      "eval_loss": 3.1339852809906006,
      "eval_runtime": 22.0955,
      "eval_samples_per_second": 2262.906,
      "eval_steps_per_second": 8.871,
      "step": 176000
    },
    {
      "epoch": 4.695772474525767,
      "grad_norm": 0.17522571980953217,
      "learning_rate": 5.908521303258146e-05,
      "loss": 3.2339,
      "step": 176500
    },
    {
      "epoch": 4.70907494612499,
      "grad_norm": 0.17651772499084473,
      "learning_rate": 5.7832080200501254e-05,
      "loss": 3.2328,
      "step": 177000
    },
    {
      "epoch": 4.722377417724213,
      "grad_norm": 0.1766221821308136,
      "learning_rate": 5.6578947368421056e-05,
      "loss": 3.2317,
      "step": 177500
    },
    {
      "epoch": 4.735679889323436,
      "grad_norm": 0.17151203751564026,
      "learning_rate": 5.532832080200501e-05,
      "loss": 3.2309,
      "step": 178000
    },
    {
      "epoch": 4.74898236092266,
      "grad_norm": 0.17986877262592316,
      "learning_rate": 5.4075187969924815e-05,
      "loss": 3.2291,
      "step": 178500
    },
    {
      "epoch": 4.762284832521883,
      "grad_norm": 0.1722394973039627,
      "learning_rate": 5.282205513784461e-05,
      "loss": 3.2313,
      "step": 179000
    },
    {
      "epoch": 4.775587304121106,
      "grad_norm": 0.17864800989627838,
      "learning_rate": 5.1568922305764413e-05,
      "loss": 3.2313,
      "step": 179500
    },
    {
      "epoch": 4.788889775720329,
      "grad_norm": 0.1766739785671234,
      "learning_rate": 5.031829573934838e-05,
      "loss": 3.232,
      "step": 180000
    },
    {
      "epoch": 4.788889775720329,
      "eval_loss": 3.1324210166931152,
      "eval_runtime": 22.2581,
      "eval_samples_per_second": 2246.372,
      "eval_steps_per_second": 8.806,
      "step": 180000
    },
    {
      "epoch": 4.802192247319552,
      "grad_norm": 0.24475501477718353,
      "learning_rate": 4.906516290726817e-05,
      "loss": 3.231,
      "step": 180500
    },
    {
      "epoch": 4.815494718918775,
      "grad_norm": 0.1692131906747818,
      "learning_rate": 4.7812030075187975e-05,
      "loss": 3.2317,
      "step": 181000
    },
    {
      "epoch": 4.8287971905179985,
      "grad_norm": 0.16501586139202118,
      "learning_rate": 4.655889724310777e-05,
      "loss": 3.2316,
      "step": 181500
    },
    {
      "epoch": 4.842099662117222,
      "grad_norm": 0.17519162595272064,
      "learning_rate": 4.530827067669173e-05,
      "loss": 3.2313,
      "step": 182000
    },
    {
      "epoch": 4.855402133716445,
      "grad_norm": 0.18840035796165466,
      "learning_rate": 4.405513784461153e-05,
      "loss": 3.2313,
      "step": 182500
    },
    {
      "epoch": 4.868704605315668,
      "grad_norm": 0.1807580292224884,
      "learning_rate": 4.2802005012531325e-05,
      "loss": 3.2305,
      "step": 183000
    },
    {
      "epoch": 4.882007076914891,
      "grad_norm": 0.19750642776489258,
      "learning_rate": 4.154887218045113e-05,
      "loss": 3.2322,
      "step": 183500
    },
    {
      "epoch": 4.895309548514114,
      "grad_norm": 0.1914033442735672,
      "learning_rate": 4.029824561403509e-05,
      "loss": 3.2301,
      "step": 184000
    },
    {
      "epoch": 4.895309548514114,
      "eval_loss": 3.1310131549835205,
      "eval_runtime": 22.1099,
      "eval_samples_per_second": 2261.426,
      "eval_steps_per_second": 8.865,
      "step": 184000
    },
    {
      "epoch": 4.908612020113337,
      "grad_norm": 0.18783047795295715,
      "learning_rate": 3.9045112781954894e-05,
      "loss": 3.2299,
      "step": 184500
    },
    {
      "epoch": 4.921914491712561,
      "grad_norm": 0.20336049795150757,
      "learning_rate": 3.779197994987469e-05,
      "loss": 3.2303,
      "step": 185000
    },
    {
      "epoch": 4.935216963311783,
      "grad_norm": 0.17453603446483612,
      "learning_rate": 3.653884711779449e-05,
      "loss": 3.229,
      "step": 185500
    },
    {
      "epoch": 4.948519434911006,
      "grad_norm": 0.20196004211902618,
      "learning_rate": 3.528822055137845e-05,
      "loss": 3.2309,
      "step": 186000
    },
    {
      "epoch": 4.961821906510229,
      "grad_norm": 0.17922991514205933,
      "learning_rate": 3.4035087719298244e-05,
      "loss": 3.2299,
      "step": 186500
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.1823427677154541,
      "learning_rate": 3.278195488721805e-05,
      "loss": 3.2303,
      "step": 187000
    },
    {
      "epoch": 4.9884268497086754,
      "grad_norm": 0.17102621495723724,
      "learning_rate": 3.152882205513784e-05,
      "loss": 3.2285,
      "step": 187500
    },
    {
      "epoch": 5.001729321307899,
      "grad_norm": 0.1891639679670334,
      "learning_rate": 3.0278195488721806e-05,
      "loss": 3.2299,
      "step": 188000
    },
    {
      "epoch": 5.001729321307899,
      "eval_loss": 3.129685401916504,
      "eval_runtime": 22.0844,
      "eval_samples_per_second": 2264.038,
      "eval_steps_per_second": 8.875,
      "step": 188000
    },
    {
      "epoch": 5.015031792907122,
      "grad_norm": 0.17388908565044403,
      "learning_rate": 2.9025062656641605e-05,
      "loss": 3.2266,
      "step": 188500
    },
    {
      "epoch": 5.028334264506345,
      "grad_norm": 0.1691235601902008,
      "learning_rate": 2.7771929824561404e-05,
      "loss": 3.2262,
      "step": 189000
    },
    {
      "epoch": 5.041636736105568,
      "grad_norm": 0.16405145823955536,
      "learning_rate": 2.6518796992481203e-05,
      "loss": 3.2262,
      "step": 189500
    },
    {
      "epoch": 5.054939207704791,
      "grad_norm": 0.17067742347717285,
      "learning_rate": 2.5268170426065163e-05,
      "loss": 3.2264,
      "step": 190000
    },
    {
      "epoch": 5.068241679304014,
      "grad_norm": 0.17443490028381348,
      "learning_rate": 2.4015037593984962e-05,
      "loss": 3.2262,
      "step": 190500
    },
    {
      "epoch": 5.0815441509032375,
      "grad_norm": 0.17541196942329407,
      "learning_rate": 2.276190476190476e-05,
      "loss": 3.2262,
      "step": 191000
    },
    {
      "epoch": 5.094846622502461,
      "grad_norm": 0.17105184495449066,
      "learning_rate": 2.150877192982456e-05,
      "loss": 3.2249,
      "step": 191500
    },
    {
      "epoch": 5.108149094101684,
      "grad_norm": 0.17584098875522614,
      "learning_rate": 2.025814536340852e-05,
      "loss": 3.2254,
      "step": 192000
    },
    {
      "epoch": 5.108149094101684,
      "eval_loss": 3.1288840770721436,
      "eval_runtime": 22.094,
      "eval_samples_per_second": 2263.055,
      "eval_steps_per_second": 8.871,
      "step": 192000
    },
    {
      "epoch": 5.121451565700907,
      "grad_norm": 0.21826913952827454,
      "learning_rate": 1.900501253132832e-05,
      "loss": 3.226,
      "step": 192500
    },
    {
      "epoch": 5.13475403730013,
      "grad_norm": 0.18409700691699982,
      "learning_rate": 1.775187969924812e-05,
      "loss": 3.2285,
      "step": 193000
    },
    {
      "epoch": 5.148056508899353,
      "grad_norm": 0.18179069459438324,
      "learning_rate": 1.649874686716792e-05,
      "loss": 3.2244,
      "step": 193500
    },
    {
      "epoch": 5.161358980498576,
      "grad_norm": 0.18736238777637482,
      "learning_rate": 1.524812030075188e-05,
      "loss": 3.2263,
      "step": 194000
    },
    {
      "epoch": 5.1746614520978,
      "grad_norm": 0.1692899912595749,
      "learning_rate": 1.399498746867168e-05,
      "loss": 3.2262,
      "step": 194500
    },
    {
      "epoch": 5.187963923697023,
      "grad_norm": 0.1674872487783432,
      "learning_rate": 1.2741854636591479e-05,
      "loss": 3.2234,
      "step": 195000
    },
    {
      "epoch": 5.201266395296246,
      "grad_norm": 0.21306653320789337,
      "learning_rate": 1.1488721804511278e-05,
      "loss": 3.2267,
      "step": 195500
    },
    {
      "epoch": 5.214568866895469,
      "grad_norm": 0.1702425479888916,
      "learning_rate": 1.023809523809524e-05,
      "loss": 3.2242,
      "step": 196000
    },
    {
      "epoch": 5.214568866895469,
      "eval_loss": 3.127734899520874,
      "eval_runtime": 22.3651,
      "eval_samples_per_second": 2235.628,
      "eval_steps_per_second": 8.764,
      "step": 196000
    },
    {
      "epoch": 5.227871338494692,
      "grad_norm": 0.19393718242645264,
      "learning_rate": 8.984962406015039e-06,
      "loss": 3.2246,
      "step": 196500
    },
    {
      "epoch": 5.241173810093915,
      "grad_norm": 0.1808965802192688,
      "learning_rate": 7.731829573934838e-06,
      "loss": 3.2263,
      "step": 197000
    },
    {
      "epoch": 5.2544762816931385,
      "grad_norm": 0.16852127015590668,
      "learning_rate": 6.478696741854637e-06,
      "loss": 3.2246,
      "step": 197500
    },
    {
      "epoch": 5.267778753292362,
      "grad_norm": 0.1727801412343979,
      "learning_rate": 5.228070175438597e-06,
      "loss": 3.2247,
      "step": 198000
    },
    {
      "epoch": 5.281081224891585,
      "grad_norm": 0.17424406111240387,
      "learning_rate": 3.974937343358396e-06,
      "loss": 3.2259,
      "step": 198500
    },
    {
      "epoch": 5.294383696490808,
      "grad_norm": 0.17258337140083313,
      "learning_rate": 2.7218045112781956e-06,
      "loss": 3.2249,
      "step": 199000
    },
    {
      "epoch": 5.307686168090031,
      "grad_norm": 0.1678473949432373,
      "learning_rate": 1.4686716791979949e-06,
      "loss": 3.224,
      "step": 199500
    },
    {
      "epoch": 5.320988639689254,
      "grad_norm": 0.16425389051437378,
      "learning_rate": 2.1804511278195488e-07,
      "loss": 3.2249,
      "step": 200000
    },
    {
      "epoch": 5.320988639689254,
      "eval_loss": 3.1271321773529053,
      "eval_runtime": 22.1085,
      "eval_samples_per_second": 2261.572,
      "eval_steps_per_second": 8.865,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
