{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.320988639689254,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013302471599223136,
      "grad_norm": 0.8612095713615417,
      "learning_rate": 0.0005,
      "loss": 6.4275,
      "step": 500
    },
    {
      "epoch": 0.026604943198446272,
      "grad_norm": 0.6745781302452087,
      "learning_rate": 0.0004987468671679198,
      "loss": 4.9284,
      "step": 1000
    },
    {
      "epoch": 0.039907414797669405,
      "grad_norm": 0.6498855352401733,
      "learning_rate": 0.0004974937343358396,
      "loss": 4.4886,
      "step": 1500
    },
    {
      "epoch": 0.053209886396892545,
      "grad_norm": 0.6493515372276306,
      "learning_rate": 0.0004962406015037594,
      "loss": 4.2676,
      "step": 2000
    },
    {
      "epoch": 0.06651235799611568,
      "grad_norm": 0.6376157402992249,
      "learning_rate": 0.0004949874686716792,
      "loss": 4.1315,
      "step": 2500
    },
    {
      "epoch": 0.07981482959533881,
      "grad_norm": 0.6106085181236267,
      "learning_rate": 0.000493734335839599,
      "loss": 4.0322,
      "step": 3000
    },
    {
      "epoch": 0.09311730119456195,
      "grad_norm": 0.5778577923774719,
      "learning_rate": 0.0004924812030075188,
      "loss": 3.9567,
      "step": 3500
    },
    {
      "epoch": 0.10641977279378509,
      "grad_norm": 0.5673505663871765,
      "learning_rate": 0.0004912280701754386,
      "loss": 3.8932,
      "step": 4000
    },
    {
      "epoch": 0.10641977279378509,
      "eval_loss": 3.8635506629943848,
      "eval_runtime": 19.6819,
      "eval_samples_per_second": 2540.405,
      "eval_steps_per_second": 9.958,
      "step": 4000
    },
    {
      "epoch": 0.11972224439300821,
      "grad_norm": 0.544014036655426,
      "learning_rate": 0.0004899749373433584,
      "loss": 3.8436,
      "step": 4500
    },
    {
      "epoch": 0.13302471599223137,
      "grad_norm": 0.5238434076309204,
      "learning_rate": 0.0004887218045112781,
      "loss": 3.7996,
      "step": 5000
    },
    {
      "epoch": 0.1463271875914545,
      "grad_norm": 0.5208697319030762,
      "learning_rate": 0.000487468671679198,
      "loss": 3.7633,
      "step": 5500
    },
    {
      "epoch": 0.15962965919067762,
      "grad_norm": 0.527947187423706,
      "learning_rate": 0.00048621553884711777,
      "loss": 3.7279,
      "step": 6000
    },
    {
      "epoch": 0.17293213078990077,
      "grad_norm": 0.5171797871589661,
      "learning_rate": 0.0004849624060150376,
      "loss": 3.7016,
      "step": 6500
    },
    {
      "epoch": 0.1862346023891239,
      "grad_norm": 0.4679117798805237,
      "learning_rate": 0.0004837092731829574,
      "loss": 3.6709,
      "step": 7000
    },
    {
      "epoch": 0.19953707398834702,
      "grad_norm": 0.47985872626304626,
      "learning_rate": 0.0004824561403508772,
      "loss": 3.649,
      "step": 7500
    },
    {
      "epoch": 0.21283954558757018,
      "grad_norm": 0.46201202273368835,
      "learning_rate": 0.000481203007518797,
      "loss": 3.6272,
      "step": 8000
    },
    {
      "epoch": 0.21283954558757018,
      "eval_loss": 3.6140389442443848,
      "eval_runtime": 19.5816,
      "eval_samples_per_second": 2553.412,
      "eval_steps_per_second": 10.009,
      "step": 8000
    },
    {
      "epoch": 0.2261420171867933,
      "grad_norm": 0.44785159826278687,
      "learning_rate": 0.000479952380952381,
      "loss": 3.6069,
      "step": 8500
    },
    {
      "epoch": 0.23944448878601643,
      "grad_norm": 0.44681817293167114,
      "learning_rate": 0.00047869924812030075,
      "loss": 3.5868,
      "step": 9000
    },
    {
      "epoch": 0.2527469603852396,
      "grad_norm": 0.4491918385028839,
      "learning_rate": 0.00047744611528822056,
      "loss": 3.572,
      "step": 9500
    },
    {
      "epoch": 0.26604943198446274,
      "grad_norm": 0.4247804582118988,
      "learning_rate": 0.0004761929824561403,
      "loss": 3.5526,
      "step": 10000
    },
    {
      "epoch": 0.27935190358368583,
      "grad_norm": 0.423692911863327,
      "learning_rate": 0.00047494235588972433,
      "loss": 3.5399,
      "step": 10500
    },
    {
      "epoch": 0.292654375182909,
      "grad_norm": 0.4111795723438263,
      "learning_rate": 0.0004736892230576441,
      "loss": 3.5271,
      "step": 11000
    },
    {
      "epoch": 0.30595684678213214,
      "grad_norm": 0.4009139835834503,
      "learning_rate": 0.00047243859649122804,
      "loss": 3.5136,
      "step": 11500
    },
    {
      "epoch": 0.31925931838135524,
      "grad_norm": 0.4088633954524994,
      "learning_rate": 0.0004711854636591479,
      "loss": 3.501,
      "step": 12000
    },
    {
      "epoch": 0.31925931838135524,
      "eval_loss": 3.4933266639709473,
      "eval_runtime": 19.5844,
      "eval_samples_per_second": 2553.058,
      "eval_steps_per_second": 10.008,
      "step": 12000
    },
    {
      "epoch": 0.3325617899805784,
      "grad_norm": 0.38976553082466125,
      "learning_rate": 0.00046993233082706767,
      "loss": 3.4905,
      "step": 12500
    },
    {
      "epoch": 0.34586426157980155,
      "grad_norm": 0.39881864190101624,
      "learning_rate": 0.0004686791979949875,
      "loss": 3.4787,
      "step": 13000
    },
    {
      "epoch": 0.35916673317902464,
      "grad_norm": 0.3925181031227112,
      "learning_rate": 0.00046742606516290725,
      "loss": 3.469,
      "step": 13500
    },
    {
      "epoch": 0.3724692047782478,
      "grad_norm": 0.3811570107936859,
      "learning_rate": 0.00046617293233082707,
      "loss": 3.4596,
      "step": 14000
    },
    {
      "epoch": 0.38577167637747095,
      "grad_norm": 0.3863876461982727,
      "learning_rate": 0.00046491979949874683,
      "loss": 3.4528,
      "step": 14500
    },
    {
      "epoch": 0.39907414797669405,
      "grad_norm": 0.3812693655490875,
      "learning_rate": 0.0004636666666666667,
      "loss": 3.4436,
      "step": 15000
    },
    {
      "epoch": 0.4123766195759172,
      "grad_norm": 0.3660045266151428,
      "learning_rate": 0.00046241604010025065,
      "loss": 3.4333,
      "step": 15500
    },
    {
      "epoch": 0.42567909117514036,
      "grad_norm": 0.37081801891326904,
      "learning_rate": 0.00046116290726817046,
      "loss": 3.428,
      "step": 16000
    },
    {
      "epoch": 0.42567909117514036,
      "eval_loss": 3.4206387996673584,
      "eval_runtime": 19.5766,
      "eval_samples_per_second": 2554.069,
      "eval_steps_per_second": 10.012,
      "step": 16000
    },
    {
      "epoch": 0.43898156277436345,
      "grad_norm": 0.37134215235710144,
      "learning_rate": 0.0004599097744360902,
      "loss": 3.42,
      "step": 16500
    },
    {
      "epoch": 0.4522840343735866,
      "grad_norm": 0.3750905990600586,
      "learning_rate": 0.00045865664160401004,
      "loss": 3.4119,
      "step": 17000
    },
    {
      "epoch": 0.46558650597280976,
      "grad_norm": 0.35639697313308716,
      "learning_rate": 0.000457406015037594,
      "loss": 3.4072,
      "step": 17500
    },
    {
      "epoch": 0.47888897757203286,
      "grad_norm": 0.3540899157524109,
      "learning_rate": 0.0004561528822055138,
      "loss": 3.3999,
      "step": 18000
    },
    {
      "epoch": 0.492191449171256,
      "grad_norm": 0.38646894693374634,
      "learning_rate": 0.00045489974937343357,
      "loss": 3.3935,
      "step": 18500
    },
    {
      "epoch": 0.5054939207704792,
      "grad_norm": 0.35014235973358154,
      "learning_rate": 0.00045364661654135344,
      "loss": 3.388,
      "step": 19000
    },
    {
      "epoch": 0.5187963923697023,
      "grad_norm": 0.35319259762763977,
      "learning_rate": 0.00045239598997493733,
      "loss": 3.3829,
      "step": 19500
    },
    {
      "epoch": 0.5320988639689255,
      "grad_norm": 0.3526269793510437,
      "learning_rate": 0.00045114285714285715,
      "loss": 3.3801,
      "step": 20000
    },
    {
      "epoch": 0.5320988639689255,
      "eval_loss": 3.3719959259033203,
      "eval_runtime": 19.5586,
      "eval_samples_per_second": 2556.422,
      "eval_steps_per_second": 10.021,
      "step": 20000
    },
    {
      "epoch": 0.5454013355681485,
      "grad_norm": 0.36137333512306213,
      "learning_rate": 0.00044988972431077697,
      "loss": 3.3734,
      "step": 20500
    },
    {
      "epoch": 0.5587038071673717,
      "grad_norm": 0.34715041518211365,
      "learning_rate": 0.00044863659147869673,
      "loss": 3.3682,
      "step": 21000
    },
    {
      "epoch": 0.5720062787665948,
      "grad_norm": 0.34533998370170593,
      "learning_rate": 0.00044738596491228073,
      "loss": 3.3644,
      "step": 21500
    },
    {
      "epoch": 0.585308750365818,
      "grad_norm": 0.343231737613678,
      "learning_rate": 0.0004461328320802005,
      "loss": 3.3583,
      "step": 22000
    },
    {
      "epoch": 0.5986112219650411,
      "grad_norm": 0.34365954995155334,
      "learning_rate": 0.0004448796992481203,
      "loss": 3.3562,
      "step": 22500
    },
    {
      "epoch": 0.6119136935642643,
      "grad_norm": 0.3509041666984558,
      "learning_rate": 0.0004436265664160401,
      "loss": 3.3484,
      "step": 23000
    },
    {
      "epoch": 0.6252161651634873,
      "grad_norm": 0.35621973872184753,
      "learning_rate": 0.000442375939849624,
      "loss": 3.3437,
      "step": 23500
    },
    {
      "epoch": 0.6385186367627105,
      "grad_norm": 0.34111806750297546,
      "learning_rate": 0.0004411228070175439,
      "loss": 3.341,
      "step": 24000
    },
    {
      "epoch": 0.6385186367627105,
      "eval_loss": 3.337155818939209,
      "eval_runtime": 19.5674,
      "eval_samples_per_second": 2555.27,
      "eval_steps_per_second": 10.017,
      "step": 24000
    },
    {
      "epoch": 0.6518211083619336,
      "grad_norm": 0.32931041717529297,
      "learning_rate": 0.00043986967418546365,
      "loss": 3.3371,
      "step": 24500
    },
    {
      "epoch": 0.6651235799611568,
      "grad_norm": 0.34752368927001953,
      "learning_rate": 0.00043861654135338347,
      "loss": 3.3338,
      "step": 25000
    },
    {
      "epoch": 0.6784260515603799,
      "grad_norm": 0.3511612117290497,
      "learning_rate": 0.0004373659147869674,
      "loss": 3.3279,
      "step": 25500
    },
    {
      "epoch": 0.6917285231596031,
      "grad_norm": 0.33167335391044617,
      "learning_rate": 0.00043611278195488724,
      "loss": 3.3278,
      "step": 26000
    },
    {
      "epoch": 0.7050309947588261,
      "grad_norm": 0.33495527505874634,
      "learning_rate": 0.000434859649122807,
      "loss": 3.3202,
      "step": 26500
    },
    {
      "epoch": 0.7183334663580493,
      "grad_norm": 0.32751601934432983,
      "learning_rate": 0.0004336065162907268,
      "loss": 3.3187,
      "step": 27000
    },
    {
      "epoch": 0.7316359379572724,
      "grad_norm": 0.33304935693740845,
      "learning_rate": 0.00043235588972431076,
      "loss": 3.3156,
      "step": 27500
    },
    {
      "epoch": 0.7449384095564956,
      "grad_norm": 0.33447718620300293,
      "learning_rate": 0.00043110275689223063,
      "loss": 3.3122,
      "step": 28000
    },
    {
      "epoch": 0.7449384095564956,
      "eval_loss": 3.30954909324646,
      "eval_runtime": 19.5693,
      "eval_samples_per_second": 2555.018,
      "eval_steps_per_second": 10.016,
      "step": 28000
    },
    {
      "epoch": 0.7582408811557187,
      "grad_norm": 0.3336104452610016,
      "learning_rate": 0.0004298496240601504,
      "loss": 3.3096,
      "step": 28500
    },
    {
      "epoch": 0.7715433527549419,
      "grad_norm": 0.3334333002567291,
      "learning_rate": 0.0004285964912280702,
      "loss": 3.3043,
      "step": 29000
    },
    {
      "epoch": 0.7848458243541651,
      "grad_norm": 0.329298198223114,
      "learning_rate": 0.00042734586466165416,
      "loss": 3.3039,
      "step": 29500
    },
    {
      "epoch": 0.7981482959533881,
      "grad_norm": 0.3361956477165222,
      "learning_rate": 0.0004260927318295739,
      "loss": 3.3002,
      "step": 30000
    },
    {
      "epoch": 0.8114507675526113,
      "grad_norm": 0.3260180950164795,
      "learning_rate": 0.00042483959899749374,
      "loss": 3.299,
      "step": 30500
    },
    {
      "epoch": 0.8247532391518344,
      "grad_norm": 0.33025601506233215,
      "learning_rate": 0.0004235864661654135,
      "loss": 3.2947,
      "step": 31000
    },
    {
      "epoch": 0.8380557107510576,
      "grad_norm": 0.3335062861442566,
      "learning_rate": 0.0004223358395989975,
      "loss": 3.2927,
      "step": 31500
    },
    {
      "epoch": 0.8513581823502807,
      "grad_norm": 0.330624520778656,
      "learning_rate": 0.00042108270676691727,
      "loss": 3.2916,
      "step": 32000
    },
    {
      "epoch": 0.8513581823502807,
      "eval_loss": 3.2856125831604004,
      "eval_runtime": 19.5939,
      "eval_samples_per_second": 2551.818,
      "eval_steps_per_second": 10.003,
      "step": 32000
    },
    {
      "epoch": 0.8646606539495039,
      "grad_norm": 0.3358777165412903,
      "learning_rate": 0.00041982957393483714,
      "loss": 3.2877,
      "step": 32500
    },
    {
      "epoch": 0.8779631255487269,
      "grad_norm": 0.3217785060405731,
      "learning_rate": 0.0004185764411027569,
      "loss": 3.2851,
      "step": 33000
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.324814110994339,
      "learning_rate": 0.0004173258145363409,
      "loss": 3.281,
      "step": 33500
    },
    {
      "epoch": 0.9045680687471732,
      "grad_norm": 0.3321230709552765,
      "learning_rate": 0.00041607268170426066,
      "loss": 3.279,
      "step": 34000
    },
    {
      "epoch": 0.9178705403463964,
      "grad_norm": 0.34314900636672974,
      "learning_rate": 0.0004148195488721805,
      "loss": 3.2798,
      "step": 34500
    },
    {
      "epoch": 0.9311730119456195,
      "grad_norm": 0.3446454405784607,
      "learning_rate": 0.00041356641604010024,
      "loss": 3.2779,
      "step": 35000
    },
    {
      "epoch": 0.9444754835448427,
      "grad_norm": 0.31819918751716614,
      "learning_rate": 0.00041231328320802006,
      "loss": 3.2752,
      "step": 35500
    },
    {
      "epoch": 0.9577779551440657,
      "grad_norm": 0.31763336062431335,
      "learning_rate": 0.000411062656641604,
      "loss": 3.2712,
      "step": 36000
    },
    {
      "epoch": 0.9577779551440657,
      "eval_loss": 3.2662858963012695,
      "eval_runtime": 19.5704,
      "eval_samples_per_second": 2554.88,
      "eval_steps_per_second": 10.015,
      "step": 36000
    },
    {
      "epoch": 0.9710804267432889,
      "grad_norm": 0.3232869803905487,
      "learning_rate": 0.0004098095238095238,
      "loss": 3.2694,
      "step": 36500
    },
    {
      "epoch": 0.984382898342512,
      "grad_norm": 0.32495468854904175,
      "learning_rate": 0.00040855639097744364,
      "loss": 3.2667,
      "step": 37000
    },
    {
      "epoch": 0.9976853699417352,
      "grad_norm": 0.3482922613620758,
      "learning_rate": 0.0004073032581453634,
      "loss": 3.2634,
      "step": 37500
    },
    {
      "epoch": 1.0109878415409583,
      "grad_norm": 0.3367442488670349,
      "learning_rate": 0.0004060526315789474,
      "loss": 3.2575,
      "step": 38000
    },
    {
      "epoch": 1.0242903131401815,
      "grad_norm": 0.32803794741630554,
      "learning_rate": 0.00040479949874686717,
      "loss": 3.2552,
      "step": 38500
    },
    {
      "epoch": 1.0375927847394046,
      "grad_norm": 0.33583834767341614,
      "learning_rate": 0.000403546365914787,
      "loss": 3.2531,
      "step": 39000
    },
    {
      "epoch": 1.0508952563386278,
      "grad_norm": 0.32097840309143066,
      "learning_rate": 0.00040229323308270675,
      "loss": 3.2516,
      "step": 39500
    },
    {
      "epoch": 1.064197727937851,
      "grad_norm": 0.33330291509628296,
      "learning_rate": 0.0004010426065162907,
      "loss": 3.252,
      "step": 40000
    },
    {
      "epoch": 1.064197727937851,
      "eval_loss": 3.251896858215332,
      "eval_runtime": 19.8455,
      "eval_samples_per_second": 2519.46,
      "eval_steps_per_second": 9.876,
      "step": 40000
    },
    {
      "epoch": 1.077500199537074,
      "grad_norm": 0.31949126720428467,
      "learning_rate": 0.0003997894736842105,
      "loss": 3.2496,
      "step": 40500
    },
    {
      "epoch": 1.090802671136297,
      "grad_norm": 0.31288421154022217,
      "learning_rate": 0.00039853634085213033,
      "loss": 3.2469,
      "step": 41000
    },
    {
      "epoch": 1.1041051427355202,
      "grad_norm": 0.3186192214488983,
      "learning_rate": 0.00039728320802005014,
      "loss": 3.2456,
      "step": 41500
    },
    {
      "epoch": 1.1174076143347433,
      "grad_norm": 0.33090946078300476,
      "learning_rate": 0.0003960325814536341,
      "loss": 3.245,
      "step": 42000
    },
    {
      "epoch": 1.1307100859339665,
      "grad_norm": 0.3200485110282898,
      "learning_rate": 0.0003947794486215539,
      "loss": 3.2443,
      "step": 42500
    },
    {
      "epoch": 1.1440125575331896,
      "grad_norm": 0.31845971941947937,
      "learning_rate": 0.00039352631578947367,
      "loss": 3.2433,
      "step": 43000
    },
    {
      "epoch": 1.1573150291324128,
      "grad_norm": 0.3436291217803955,
      "learning_rate": 0.0003922731829573935,
      "loss": 3.2406,
      "step": 43500
    },
    {
      "epoch": 1.170617500731636,
      "grad_norm": 0.3174836337566376,
      "learning_rate": 0.00039102255639097744,
      "loss": 3.2381,
      "step": 44000
    },
    {
      "epoch": 1.170617500731636,
      "eval_loss": 3.2377843856811523,
      "eval_runtime": 19.5616,
      "eval_samples_per_second": 2556.024,
      "eval_steps_per_second": 10.02,
      "step": 44000
    },
    {
      "epoch": 1.183919972330859,
      "grad_norm": 0.3232472538948059,
      "learning_rate": 0.00038976942355889725,
      "loss": 3.2372,
      "step": 44500
    },
    {
      "epoch": 1.1972224439300823,
      "grad_norm": 0.3181820213794708,
      "learning_rate": 0.00038851629072681707,
      "loss": 3.236,
      "step": 45000
    },
    {
      "epoch": 1.2105249155293054,
      "grad_norm": 0.3215442895889282,
      "learning_rate": 0.0003872631578947369,
      "loss": 3.2333,
      "step": 45500
    },
    {
      "epoch": 1.2238273871285286,
      "grad_norm": 0.31309378147125244,
      "learning_rate": 0.00038601253132832084,
      "loss": 3.2315,
      "step": 46000
    },
    {
      "epoch": 1.2371298587277515,
      "grad_norm": 0.3147583305835724,
      "learning_rate": 0.0003847593984962406,
      "loss": 3.2321,
      "step": 46500
    },
    {
      "epoch": 1.2504323303269747,
      "grad_norm": 0.31503233313560486,
      "learning_rate": 0.0003835062656641604,
      "loss": 3.2297,
      "step": 47000
    },
    {
      "epoch": 1.2637348019261978,
      "grad_norm": 0.3166837692260742,
      "learning_rate": 0.0003822531328320802,
      "loss": 3.2283,
      "step": 47500
    },
    {
      "epoch": 1.277037273525421,
      "grad_norm": 0.32833290100097656,
      "learning_rate": 0.0003810025062656642,
      "loss": 3.2273,
      "step": 48000
    },
    {
      "epoch": 1.277037273525421,
      "eval_loss": 3.2253336906433105,
      "eval_runtime": 19.6568,
      "eval_samples_per_second": 2543.648,
      "eval_steps_per_second": 9.971,
      "step": 48000
    },
    {
      "epoch": 1.290339745124644,
      "grad_norm": 0.30922356247901917,
      "learning_rate": 0.00037974937343358394,
      "loss": 3.226,
      "step": 48500
    },
    {
      "epoch": 1.3036422167238673,
      "grad_norm": 0.3065843880176544,
      "learning_rate": 0.00037849624060150376,
      "loss": 3.2242,
      "step": 49000
    },
    {
      "epoch": 1.3169446883230904,
      "grad_norm": 0.3276602625846863,
      "learning_rate": 0.00037724310776942357,
      "loss": 3.223,
      "step": 49500
    },
    {
      "epoch": 1.3302471599223136,
      "grad_norm": 0.3216276168823242,
      "learning_rate": 0.0003759924812030076,
      "loss": 3.2212,
      "step": 50000
    },
    {
      "epoch": 1.3435496315215367,
      "grad_norm": 0.3255636990070343,
      "learning_rate": 0.00037473934837092734,
      "loss": 3.2182,
      "step": 50500
    },
    {
      "epoch": 1.3568521031207599,
      "grad_norm": 0.33202287554740906,
      "learning_rate": 0.00037348621553884715,
      "loss": 3.2185,
      "step": 51000
    },
    {
      "epoch": 1.370154574719983,
      "grad_norm": 0.33350247144699097,
      "learning_rate": 0.0003722330827067669,
      "loss": 3.2171,
      "step": 51500
    },
    {
      "epoch": 1.3834570463192062,
      "grad_norm": 0.33052727580070496,
      "learning_rate": 0.00037098245614035087,
      "loss": 3.2155,
      "step": 52000
    },
    {
      "epoch": 1.3834570463192062,
      "eval_loss": 3.2148866653442383,
      "eval_runtime": 19.5658,
      "eval_samples_per_second": 2555.479,
      "eval_steps_per_second": 10.017,
      "step": 52000
    },
    {
      "epoch": 1.3967595179184293,
      "grad_norm": 0.3184044361114502,
      "learning_rate": 0.0003697293233082707,
      "loss": 3.214,
      "step": 52500
    },
    {
      "epoch": 1.4100619895176525,
      "grad_norm": 0.3405366539955139,
      "learning_rate": 0.00036847619047619044,
      "loss": 3.2113,
      "step": 53000
    },
    {
      "epoch": 1.4233644611168756,
      "grad_norm": 0.31694701313972473,
      "learning_rate": 0.0003672230576441103,
      "loss": 3.2118,
      "step": 53500
    },
    {
      "epoch": 1.4366669327160986,
      "grad_norm": 0.3221794366836548,
      "learning_rate": 0.0003659724310776942,
      "loss": 3.2105,
      "step": 54000
    },
    {
      "epoch": 1.4499694043153217,
      "grad_norm": 0.31774666905403137,
      "learning_rate": 0.0003647192982456141,
      "loss": 3.21,
      "step": 54500
    },
    {
      "epoch": 1.4632718759145449,
      "grad_norm": 0.3267674148082733,
      "learning_rate": 0.00036346616541353384,
      "loss": 3.2079,
      "step": 55000
    },
    {
      "epoch": 1.476574347513768,
      "grad_norm": 0.3241252303123474,
      "learning_rate": 0.00036221303258145366,
      "loss": 3.2073,
      "step": 55500
    },
    {
      "epoch": 1.4898768191129912,
      "grad_norm": 0.314014732837677,
      "learning_rate": 0.0003609598997493734,
      "loss": 3.2067,
      "step": 56000
    },
    {
      "epoch": 1.4898768191129912,
      "eval_loss": 3.2048466205596924,
      "eval_runtime": 19.5876,
      "eval_samples_per_second": 2552.631,
      "eval_steps_per_second": 10.006,
      "step": 56000
    },
    {
      "epoch": 1.5031792907122143,
      "grad_norm": 0.30441856384277344,
      "learning_rate": 0.00035970927318295737,
      "loss": 3.2047,
      "step": 56500
    },
    {
      "epoch": 1.5164817623114375,
      "grad_norm": 0.30744820833206177,
      "learning_rate": 0.0003584561403508772,
      "loss": 3.2046,
      "step": 57000
    },
    {
      "epoch": 1.5297842339106607,
      "grad_norm": 0.33400383591651917,
      "learning_rate": 0.00035720300751879695,
      "loss": 3.202,
      "step": 57500
    },
    {
      "epoch": 1.5430867055098836,
      "grad_norm": 0.3225882649421692,
      "learning_rate": 0.0003559498746867168,
      "loss": 3.203,
      "step": 58000
    },
    {
      "epoch": 1.5563891771091067,
      "grad_norm": 0.34389352798461914,
      "learning_rate": 0.00035469924812030077,
      "loss": 3.2023,
      "step": 58500
    },
    {
      "epoch": 1.56969164870833,
      "grad_norm": 0.3104828894138336,
      "learning_rate": 0.0003534461152882206,
      "loss": 3.1996,
      "step": 59000
    },
    {
      "epoch": 1.582994120307553,
      "grad_norm": 0.31579655408859253,
      "learning_rate": 0.00035219298245614035,
      "loss": 3.1997,
      "step": 59500
    },
    {
      "epoch": 1.5962965919067762,
      "grad_norm": 0.3105311095714569,
      "learning_rate": 0.00035093984962406016,
      "loss": 3.1987,
      "step": 60000
    },
    {
      "epoch": 1.5962965919067762,
      "eval_loss": 3.1958794593811035,
      "eval_runtime": 19.7799,
      "eval_samples_per_second": 2527.815,
      "eval_steps_per_second": 9.909,
      "step": 60000
    },
    {
      "epoch": 1.6095990635059994,
      "grad_norm": 0.315207839012146,
      "learning_rate": 0.0003496892230576441,
      "loss": 3.1971,
      "step": 60500
    },
    {
      "epoch": 1.6229015351052225,
      "grad_norm": 0.3088446259498596,
      "learning_rate": 0.00034843609022556393,
      "loss": 3.1964,
      "step": 61000
    },
    {
      "epoch": 1.6362040067044457,
      "grad_norm": 0.30822110176086426,
      "learning_rate": 0.0003471829573934837,
      "loss": 3.1947,
      "step": 61500
    },
    {
      "epoch": 1.6495064783036688,
      "grad_norm": 0.32167914509773254,
      "learning_rate": 0.00034592982456140356,
      "loss": 3.1956,
      "step": 62000
    },
    {
      "epoch": 1.662808949902892,
      "grad_norm": 0.3086549639701843,
      "learning_rate": 0.00034467919799498745,
      "loss": 3.192,
      "step": 62500
    },
    {
      "epoch": 1.6761114215021151,
      "grad_norm": 0.31653547286987305,
      "learning_rate": 0.00034342606516290727,
      "loss": 3.1918,
      "step": 63000
    },
    {
      "epoch": 1.6894138931013383,
      "grad_norm": 0.3262191116809845,
      "learning_rate": 0.0003421729323308271,
      "loss": 3.1905,
      "step": 63500
    },
    {
      "epoch": 1.7027163647005614,
      "grad_norm": 0.3209543824195862,
      "learning_rate": 0.00034091979949874685,
      "loss": 3.1891,
      "step": 64000
    },
    {
      "epoch": 1.7027163647005614,
      "eval_loss": 3.188565254211426,
      "eval_runtime": 19.5816,
      "eval_samples_per_second": 2553.422,
      "eval_steps_per_second": 10.009,
      "step": 64000
    },
    {
      "epoch": 1.7160188362997846,
      "grad_norm": 0.31143370270729065,
      "learning_rate": 0.00033966917293233085,
      "loss": 3.1894,
      "step": 64500
    },
    {
      "epoch": 1.7293213078990077,
      "grad_norm": 0.3175596594810486,
      "learning_rate": 0.0003384160401002506,
      "loss": 3.189,
      "step": 65000
    },
    {
      "epoch": 1.7426237794982309,
      "grad_norm": 0.31534525752067566,
      "learning_rate": 0.00033716290726817043,
      "loss": 3.1848,
      "step": 65500
    },
    {
      "epoch": 1.755926251097454,
      "grad_norm": 0.3180321753025055,
      "learning_rate": 0.00033590977443609025,
      "loss": 3.1855,
      "step": 66000
    },
    {
      "epoch": 1.7692287226966772,
      "grad_norm": 0.32766690850257874,
      "learning_rate": 0.0003346591478696742,
      "loss": 3.1835,
      "step": 66500
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 0.31241023540496826,
      "learning_rate": 0.000333406015037594,
      "loss": 3.1845,
      "step": 67000
    },
    {
      "epoch": 1.7958336658951233,
      "grad_norm": 0.32326480746269226,
      "learning_rate": 0.00033215288220551383,
      "loss": 3.1845,
      "step": 67500
    },
    {
      "epoch": 1.8091361374943464,
      "grad_norm": 0.3458649814128876,
      "learning_rate": 0.0003308997493734336,
      "loss": 3.1818,
      "step": 68000
    },
    {
      "epoch": 1.8091361374943464,
      "eval_loss": 3.1808972358703613,
      "eval_runtime": 19.5714,
      "eval_samples_per_second": 2554.742,
      "eval_steps_per_second": 10.015,
      "step": 68000
    },
    {
      "epoch": 1.8224386090935696,
      "grad_norm": 0.3253987729549408,
      "learning_rate": 0.00032964912280701754,
      "loss": 3.1813,
      "step": 68500
    },
    {
      "epoch": 1.8357410806927927,
      "grad_norm": 0.3251855969429016,
      "learning_rate": 0.00032839598997493736,
      "loss": 3.1807,
      "step": 69000
    },
    {
      "epoch": 1.849043552292016,
      "grad_norm": 0.34172841906547546,
      "learning_rate": 0.0003271428571428571,
      "loss": 3.1807,
      "step": 69500
    },
    {
      "epoch": 1.862346023891239,
      "grad_norm": 0.320366233587265,
      "learning_rate": 0.00032588972431077693,
      "loss": 3.1781,
      "step": 70000
    },
    {
      "epoch": 1.875648495490462,
      "grad_norm": 0.32613369822502136,
      "learning_rate": 0.0003246390977443609,
      "loss": 3.1783,
      "step": 70500
    },
    {
      "epoch": 1.8889509670896851,
      "grad_norm": 0.3054637908935547,
      "learning_rate": 0.00032338596491228075,
      "loss": 3.1761,
      "step": 71000
    },
    {
      "epoch": 1.9022534386889083,
      "grad_norm": 0.3039521276950836,
      "learning_rate": 0.0003221328320802005,
      "loss": 3.1763,
      "step": 71500
    },
    {
      "epoch": 1.9155559102881314,
      "grad_norm": 0.31182920932769775,
      "learning_rate": 0.00032087969924812033,
      "loss": 3.1748,
      "step": 72000
    },
    {
      "epoch": 1.9155559102881314,
      "eval_loss": 3.173539638519287,
      "eval_runtime": 19.591,
      "eval_samples_per_second": 2552.194,
      "eval_steps_per_second": 10.005,
      "step": 72000
    },
    {
      "epoch": 1.9288583818873546,
      "grad_norm": 0.3158842623233795,
      "learning_rate": 0.0003196290726817043,
      "loss": 3.1747,
      "step": 72500
    },
    {
      "epoch": 1.9421608534865777,
      "grad_norm": 0.33248913288116455,
      "learning_rate": 0.00031837593984962404,
      "loss": 3.1763,
      "step": 73000
    },
    {
      "epoch": 1.955463325085801,
      "grad_norm": 0.3095184564590454,
      "learning_rate": 0.00031712280701754386,
      "loss": 3.1728,
      "step": 73500
    },
    {
      "epoch": 1.968765796685024,
      "grad_norm": 0.3183269202709198,
      "learning_rate": 0.0003158696741854636,
      "loss": 3.1725,
      "step": 74000
    },
    {
      "epoch": 1.9820682682842472,
      "grad_norm": 0.30429643392562866,
      "learning_rate": 0.0003146190476190476,
      "loss": 3.171,
      "step": 74500
    },
    {
      "epoch": 1.9953707398834704,
      "grad_norm": 0.3192163109779358,
      "learning_rate": 0.0003133659147869674,
      "loss": 3.1697,
      "step": 75000
    },
    {
      "epoch": 2.0086732114826935,
      "grad_norm": 0.31760478019714355,
      "learning_rate": 0.00031211278195488726,
      "loss": 3.167,
      "step": 75500
    },
    {
      "epoch": 2.0219756830819167,
      "grad_norm": 0.31830111145973206,
      "learning_rate": 0.000310859649122807,
      "loss": 3.1635,
      "step": 76000
    },
    {
      "epoch": 2.0219756830819167,
      "eval_loss": 3.167898654937744,
      "eval_runtime": 19.5798,
      "eval_samples_per_second": 2553.657,
      "eval_steps_per_second": 10.01,
      "step": 76000
    },
    {
      "epoch": 2.03527815468114,
      "grad_norm": 0.308186411857605,
      "learning_rate": 0.000309609022556391,
      "loss": 3.1633,
      "step": 76500
    },
    {
      "epoch": 2.048580626280363,
      "grad_norm": 0.31710562109947205,
      "learning_rate": 0.0003083558897243108,
      "loss": 3.1641,
      "step": 77000
    },
    {
      "epoch": 2.061883097879586,
      "grad_norm": 0.33204302191734314,
      "learning_rate": 0.0003071027568922306,
      "loss": 3.1636,
      "step": 77500
    },
    {
      "epoch": 2.0751855694788093,
      "grad_norm": 0.3158845603466034,
      "learning_rate": 0.00030584962406015036,
      "loss": 3.1627,
      "step": 78000
    },
    {
      "epoch": 2.0884880410780324,
      "grad_norm": 0.3224341571331024,
      "learning_rate": 0.0003045964912280702,
      "loss": 3.1621,
      "step": 78500
    },
    {
      "epoch": 2.1017905126772556,
      "grad_norm": 0.31016814708709717,
      "learning_rate": 0.00030334586466165413,
      "loss": 3.162,
      "step": 79000
    },
    {
      "epoch": 2.1150929842764787,
      "grad_norm": 0.32908615469932556,
      "learning_rate": 0.00030209273182957394,
      "loss": 3.1598,
      "step": 79500
    },
    {
      "epoch": 2.128395455875702,
      "grad_norm": 0.30917689204216003,
      "learning_rate": 0.00030083959899749376,
      "loss": 3.1607,
      "step": 80000
    },
    {
      "epoch": 2.128395455875702,
      "eval_loss": 3.1615521907806396,
      "eval_runtime": 19.5948,
      "eval_samples_per_second": 2551.699,
      "eval_steps_per_second": 10.003,
      "step": 80000
    },
    {
      "epoch": 2.141697927474925,
      "grad_norm": 0.34754160046577454,
      "learning_rate": 0.0002995864661654135,
      "loss": 3.1602,
      "step": 80500
    },
    {
      "epoch": 2.155000399074148,
      "grad_norm": 0.32438743114471436,
      "learning_rate": 0.0002983358395989975,
      "loss": 3.1589,
      "step": 81000
    },
    {
      "epoch": 2.168302870673371,
      "grad_norm": 0.32232528924942017,
      "learning_rate": 0.0002970827067669173,
      "loss": 3.1577,
      "step": 81500
    },
    {
      "epoch": 2.181605342272594,
      "grad_norm": 0.3151153028011322,
      "learning_rate": 0.0002958295739348371,
      "loss": 3.1566,
      "step": 82000
    },
    {
      "epoch": 2.194907813871817,
      "grad_norm": 0.31966862082481384,
      "learning_rate": 0.00029457644110275687,
      "loss": 3.1562,
      "step": 82500
    },
    {
      "epoch": 2.2082102854710404,
      "grad_norm": 0.3110522925853729,
      "learning_rate": 0.00029332581453634087,
      "loss": 3.1557,
      "step": 83000
    },
    {
      "epoch": 2.2215127570702635,
      "grad_norm": 0.3083953261375427,
      "learning_rate": 0.00029207268170426063,
      "loss": 3.1565,
      "step": 83500
    },
    {
      "epoch": 2.2348152286694867,
      "grad_norm": 0.3368976414203644,
      "learning_rate": 0.0002908195488721805,
      "loss": 3.156,
      "step": 84000
    },
    {
      "epoch": 2.2348152286694867,
      "eval_loss": 3.1562511920928955,
      "eval_runtime": 19.5916,
      "eval_samples_per_second": 2552.109,
      "eval_steps_per_second": 10.004,
      "step": 84000
    },
    {
      "epoch": 2.24811770026871,
      "grad_norm": 0.3175792992115021,
      "learning_rate": 0.00028956641604010026,
      "loss": 3.155,
      "step": 84500
    },
    {
      "epoch": 2.261420171867933,
      "grad_norm": 0.3071293234825134,
      "learning_rate": 0.0002883157894736842,
      "loss": 3.1552,
      "step": 85000
    },
    {
      "epoch": 2.274722643467156,
      "grad_norm": 0.3185690641403198,
      "learning_rate": 0.00028706265664160403,
      "loss": 3.1526,
      "step": 85500
    },
    {
      "epoch": 2.2880251150663793,
      "grad_norm": 0.32819226384162903,
      "learning_rate": 0.0002858095238095238,
      "loss": 3.1524,
      "step": 86000
    },
    {
      "epoch": 2.3013275866656024,
      "grad_norm": 0.31017005443573,
      "learning_rate": 0.0002845563909774436,
      "loss": 3.1531,
      "step": 86500
    },
    {
      "epoch": 2.3146300582648256,
      "grad_norm": 0.3145366907119751,
      "learning_rate": 0.00028330576441102756,
      "loss": 3.1533,
      "step": 87000
    },
    {
      "epoch": 2.3279325298640487,
      "grad_norm": 0.3090340495109558,
      "learning_rate": 0.0002820526315789474,
      "loss": 3.1511,
      "step": 87500
    },
    {
      "epoch": 2.341235001463272,
      "grad_norm": 0.3071154057979584,
      "learning_rate": 0.0002807994987468672,
      "loss": 3.1525,
      "step": 88000
    },
    {
      "epoch": 2.341235001463272,
      "eval_loss": 3.150902271270752,
      "eval_runtime": 19.5693,
      "eval_samples_per_second": 2555.022,
      "eval_steps_per_second": 10.016,
      "step": 88000
    },
    {
      "epoch": 2.354537473062495,
      "grad_norm": 0.3191307783126831,
      "learning_rate": 0.000279546365914787,
      "loss": 3.1504,
      "step": 88500
    },
    {
      "epoch": 2.367839944661718,
      "grad_norm": 0.31729111075401306,
      "learning_rate": 0.00027829573934837096,
      "loss": 3.149,
      "step": 89000
    },
    {
      "epoch": 2.3811424162609414,
      "grad_norm": 0.3221593201160431,
      "learning_rate": 0.0002770426065162907,
      "loss": 3.1499,
      "step": 89500
    },
    {
      "epoch": 2.3944448878601645,
      "grad_norm": 0.317265123128891,
      "learning_rate": 0.00027578947368421053,
      "loss": 3.1488,
      "step": 90000
    },
    {
      "epoch": 2.4077473594593877,
      "grad_norm": 0.311681866645813,
      "learning_rate": 0.0002745363408521303,
      "loss": 3.1453,
      "step": 90500
    },
    {
      "epoch": 2.421049831058611,
      "grad_norm": 0.3064727783203125,
      "learning_rate": 0.0002732857142857143,
      "loss": 3.146,
      "step": 91000
    },
    {
      "epoch": 2.434352302657834,
      "grad_norm": 0.31423282623291016,
      "learning_rate": 0.00027203258145363406,
      "loss": 3.1451,
      "step": 91500
    },
    {
      "epoch": 2.447654774257057,
      "grad_norm": 0.3216354250907898,
      "learning_rate": 0.0002707794486215539,
      "loss": 3.148,
      "step": 92000
    },
    {
      "epoch": 2.447654774257057,
      "eval_loss": 3.1460962295532227,
      "eval_runtime": 19.5697,
      "eval_samples_per_second": 2554.973,
      "eval_steps_per_second": 10.015,
      "step": 92000
    },
    {
      "epoch": 2.4609572458562803,
      "grad_norm": 0.2982686460018158,
      "learning_rate": 0.0002695263157894737,
      "loss": 3.1464,
      "step": 92500
    },
    {
      "epoch": 2.474259717455503,
      "grad_norm": 0.30815649032592773,
      "learning_rate": 0.0002682731829573935,
      "loss": 3.1437,
      "step": 93000
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.305797815322876,
      "learning_rate": 0.00026702255639097746,
      "loss": 3.1433,
      "step": 93500
    },
    {
      "epoch": 2.5008646606539493,
      "grad_norm": 0.3141656219959259,
      "learning_rate": 0.0002657694235588973,
      "loss": 3.1442,
      "step": 94000
    },
    {
      "epoch": 2.5141671322531725,
      "grad_norm": 0.3130144774913788,
      "learning_rate": 0.00026451629072681704,
      "loss": 3.1421,
      "step": 94500
    },
    {
      "epoch": 2.5274696038523956,
      "grad_norm": 0.3217674791812897,
      "learning_rate": 0.00026326315789473685,
      "loss": 3.1425,
      "step": 95000
    },
    {
      "epoch": 2.5407720754516188,
      "grad_norm": 0.30160075426101685,
      "learning_rate": 0.00026201002506265667,
      "loss": 3.1416,
      "step": 95500
    },
    {
      "epoch": 2.554074547050842,
      "grad_norm": 0.3126351237297058,
      "learning_rate": 0.00026075939849624056,
      "loss": 3.1393,
      "step": 96000
    },
    {
      "epoch": 2.554074547050842,
      "eval_loss": 3.1413655281066895,
      "eval_runtime": 19.5591,
      "eval_samples_per_second": 2556.351,
      "eval_steps_per_second": 10.021,
      "step": 96000
    },
    {
      "epoch": 2.567377018650065,
      "grad_norm": 0.3194520175457001,
      "learning_rate": 0.00025950626566416043,
      "loss": 3.1415,
      "step": 96500
    },
    {
      "epoch": 2.580679490249288,
      "grad_norm": 0.32109886407852173,
      "learning_rate": 0.0002582531328320802,
      "loss": 3.1391,
      "step": 97000
    },
    {
      "epoch": 2.5939819618485114,
      "grad_norm": 0.30853280425071716,
      "learning_rate": 0.000257,
      "loss": 3.1409,
      "step": 97500
    },
    {
      "epoch": 2.6072844334477345,
      "grad_norm": 0.3039124310016632,
      "learning_rate": 0.00025574937343358396,
      "loss": 3.139,
      "step": 98000
    },
    {
      "epoch": 2.6205869050469577,
      "grad_norm": 0.3140702545642853,
      "learning_rate": 0.0002544962406015038,
      "loss": 3.1373,
      "step": 98500
    },
    {
      "epoch": 2.633889376646181,
      "grad_norm": 0.31924474239349365,
      "learning_rate": 0.00025324310776942354,
      "loss": 3.136,
      "step": 99000
    },
    {
      "epoch": 2.647191848245404,
      "grad_norm": 0.3186270594596863,
      "learning_rate": 0.00025198997493734336,
      "loss": 3.1382,
      "step": 99500
    },
    {
      "epoch": 2.660494319844627,
      "grad_norm": 0.32386916875839233,
      "learning_rate": 0.0002507393483709273,
      "loss": 3.1345,
      "step": 100000
    },
    {
      "epoch": 2.660494319844627,
      "eval_loss": 3.1369030475616455,
      "eval_runtime": 19.5968,
      "eval_samples_per_second": 2551.441,
      "eval_steps_per_second": 10.002,
      "step": 100000
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 0.32064709067344666,
      "learning_rate": 0.0002494862155388471,
      "loss": 3.1349,
      "step": 100500
    },
    {
      "epoch": 2.6870992630430734,
      "grad_norm": 0.3104776442050934,
      "learning_rate": 0.00024823308270676694,
      "loss": 3.1355,
      "step": 101000
    },
    {
      "epoch": 2.7004017346422966,
      "grad_norm": 0.3163885772228241,
      "learning_rate": 0.0002469799498746867,
      "loss": 3.1349,
      "step": 101500
    },
    {
      "epoch": 2.7137042062415198,
      "grad_norm": 0.3054996430873871,
      "learning_rate": 0.0002457293233082707,
      "loss": 3.1337,
      "step": 102000
    },
    {
      "epoch": 2.727006677840743,
      "grad_norm": 0.3091946244239807,
      "learning_rate": 0.00024447619047619047,
      "loss": 3.1341,
      "step": 102500
    },
    {
      "epoch": 2.740309149439966,
      "grad_norm": 0.3061635494232178,
      "learning_rate": 0.00024322305764411028,
      "loss": 3.1326,
      "step": 103000
    },
    {
      "epoch": 2.753611621039189,
      "grad_norm": 0.30512329936027527,
      "learning_rate": 0.0002419699248120301,
      "loss": 3.1329,
      "step": 103500
    },
    {
      "epoch": 2.7669140926384124,
      "grad_norm": 0.3173483610153198,
      "learning_rate": 0.00024071929824561402,
      "loss": 3.1324,
      "step": 104000
    },
    {
      "epoch": 2.7669140926384124,
      "eval_loss": 3.1329431533813477,
      "eval_runtime": 19.5726,
      "eval_samples_per_second": 2554.597,
      "eval_steps_per_second": 10.014,
      "step": 104000
    },
    {
      "epoch": 2.7802165642376355,
      "grad_norm": 0.3168748617172241,
      "learning_rate": 0.00023946616541353384,
      "loss": 3.1319,
      "step": 104500
    },
    {
      "epoch": 2.7935190358368587,
      "grad_norm": 0.30457696318626404,
      "learning_rate": 0.00023821303258145363,
      "loss": 3.1301,
      "step": 105000
    },
    {
      "epoch": 2.806821507436082,
      "grad_norm": 0.3073803782463074,
      "learning_rate": 0.00023695989974937344,
      "loss": 3.1312,
      "step": 105500
    },
    {
      "epoch": 2.820123979035305,
      "grad_norm": 0.33323347568511963,
      "learning_rate": 0.00023570676691729323,
      "loss": 3.1296,
      "step": 106000
    },
    {
      "epoch": 2.833426450634528,
      "grad_norm": 0.3032225966453552,
      "learning_rate": 0.0002344561403508772,
      "loss": 3.1307,
      "step": 106500
    },
    {
      "epoch": 2.8467289222337513,
      "grad_norm": 0.31218644976615906,
      "learning_rate": 0.000233203007518797,
      "loss": 3.1309,
      "step": 107000
    },
    {
      "epoch": 2.860031393832974,
      "grad_norm": 0.31818917393684387,
      "learning_rate": 0.0002319498746867168,
      "loss": 3.1289,
      "step": 107500
    },
    {
      "epoch": 2.873333865432197,
      "grad_norm": 0.2944295406341553,
      "learning_rate": 0.0002306967418546366,
      "loss": 3.1303,
      "step": 108000
    },
    {
      "epoch": 2.873333865432197,
      "eval_loss": 3.128232479095459,
      "eval_runtime": 19.6543,
      "eval_samples_per_second": 2543.975,
      "eval_steps_per_second": 9.972,
      "step": 108000
    },
    {
      "epoch": 2.8866363370314203,
      "grad_norm": 0.32421523332595825,
      "learning_rate": 0.00022944611528822058,
      "loss": 3.1272,
      "step": 108500
    },
    {
      "epoch": 2.8999388086306435,
      "grad_norm": 0.3202386498451233,
      "learning_rate": 0.00022819298245614037,
      "loss": 3.1271,
      "step": 109000
    },
    {
      "epoch": 2.9132412802298666,
      "grad_norm": 0.30804044008255005,
      "learning_rate": 0.00022693984962406016,
      "loss": 3.1279,
      "step": 109500
    },
    {
      "epoch": 2.9265437518290898,
      "grad_norm": 0.3248635530471802,
      "learning_rate": 0.00022568671679197997,
      "loss": 3.1265,
      "step": 110000
    },
    {
      "epoch": 2.939846223428313,
      "grad_norm": 0.3191889524459839,
      "learning_rate": 0.00022443358395989976,
      "loss": 3.1261,
      "step": 110500
    },
    {
      "epoch": 2.953148695027536,
      "grad_norm": 0.32949334383010864,
      "learning_rate": 0.0002231829573934837,
      "loss": 3.1256,
      "step": 111000
    },
    {
      "epoch": 2.9664511666267592,
      "grad_norm": 0.31552281975746155,
      "learning_rate": 0.0002219298245614035,
      "loss": 3.1246,
      "step": 111500
    },
    {
      "epoch": 2.9797536382259824,
      "grad_norm": 0.3098946809768677,
      "learning_rate": 0.00022067669172932332,
      "loss": 3.1242,
      "step": 112000
    },
    {
      "epoch": 2.9797536382259824,
      "eval_loss": 3.124037742614746,
      "eval_runtime": 19.5677,
      "eval_samples_per_second": 2555.234,
      "eval_steps_per_second": 10.017,
      "step": 112000
    },
    {
      "epoch": 2.9930561098252055,
      "grad_norm": 0.3124469220638275,
      "learning_rate": 0.0002194235588972431,
      "loss": 3.1231,
      "step": 112500
    },
    {
      "epoch": 3.0063585814244287,
      "grad_norm": 0.3419000506401062,
      "learning_rate": 0.00021817293233082708,
      "loss": 3.121,
      "step": 113000
    },
    {
      "epoch": 3.019661053023652,
      "grad_norm": 0.31935787200927734,
      "learning_rate": 0.00021691979949874687,
      "loss": 3.1177,
      "step": 113500
    },
    {
      "epoch": 3.032963524622875,
      "grad_norm": 0.314191997051239,
      "learning_rate": 0.0002156666666666667,
      "loss": 3.1179,
      "step": 114000
    },
    {
      "epoch": 3.046265996222098,
      "grad_norm": 0.31049251556396484,
      "learning_rate": 0.00021441353383458648,
      "loss": 3.1172,
      "step": 114500
    },
    {
      "epoch": 3.0595684678213213,
      "grad_norm": 0.32368794083595276,
      "learning_rate": 0.00021316290726817043,
      "loss": 3.118,
      "step": 115000
    },
    {
      "epoch": 3.0728709394205445,
      "grad_norm": 0.30110692977905273,
      "learning_rate": 0.00021190977443609021,
      "loss": 3.1167,
      "step": 115500
    },
    {
      "epoch": 3.0861734110197676,
      "grad_norm": 0.32044103741645813,
      "learning_rate": 0.00021065664160401003,
      "loss": 3.1189,
      "step": 116000
    },
    {
      "epoch": 3.0861734110197676,
      "eval_loss": 3.1211612224578857,
      "eval_runtime": 19.551,
      "eval_samples_per_second": 2557.416,
      "eval_steps_per_second": 10.025,
      "step": 116000
    },
    {
      "epoch": 3.0994758826189908,
      "grad_norm": 0.32567623257637024,
      "learning_rate": 0.00020940350877192982,
      "loss": 3.1191,
      "step": 116500
    },
    {
      "epoch": 3.112778354218214,
      "grad_norm": 0.3131539821624756,
      "learning_rate": 0.0002081528822055138,
      "loss": 3.1174,
      "step": 117000
    },
    {
      "epoch": 3.126080825817437,
      "grad_norm": 0.32722991704940796,
      "learning_rate": 0.00020689974937343359,
      "loss": 3.1162,
      "step": 117500
    },
    {
      "epoch": 3.1393832974166602,
      "grad_norm": 0.31592851877212524,
      "learning_rate": 0.00020564661654135337,
      "loss": 3.1153,
      "step": 118000
    },
    {
      "epoch": 3.152685769015883,
      "grad_norm": 0.32393813133239746,
      "learning_rate": 0.0002043934837092732,
      "loss": 3.1139,
      "step": 118500
    },
    {
      "epoch": 3.165988240615106,
      "grad_norm": 0.30839383602142334,
      "learning_rate": 0.00020314285714285717,
      "loss": 3.115,
      "step": 119000
    },
    {
      "epoch": 3.1792907122143292,
      "grad_norm": 0.3319312334060669,
      "learning_rate": 0.00020188972431077696,
      "loss": 3.1141,
      "step": 119500
    },
    {
      "epoch": 3.1925931838135524,
      "grad_norm": 0.3247145116329193,
      "learning_rate": 0.00020063659147869674,
      "loss": 3.1133,
      "step": 120000
    },
    {
      "epoch": 3.1925931838135524,
      "eval_loss": 3.1175143718719482,
      "eval_runtime": 19.5728,
      "eval_samples_per_second": 2554.562,
      "eval_steps_per_second": 10.014,
      "step": 120000
    },
    {
      "epoch": 3.2058956554127755,
      "grad_norm": 0.30572235584259033,
      "learning_rate": 0.00019938345864661656,
      "loss": 3.1128,
      "step": 120500
    },
    {
      "epoch": 3.2191981270119987,
      "grad_norm": 0.3155190646648407,
      "learning_rate": 0.0001981328320802005,
      "loss": 3.1122,
      "step": 121000
    },
    {
      "epoch": 3.232500598611222,
      "grad_norm": 0.31735578179359436,
      "learning_rate": 0.0001968796992481203,
      "loss": 3.1132,
      "step": 121500
    },
    {
      "epoch": 3.245803070210445,
      "grad_norm": 0.3194480836391449,
      "learning_rate": 0.0001956265664160401,
      "loss": 3.1145,
      "step": 122000
    },
    {
      "epoch": 3.259105541809668,
      "grad_norm": 0.3126680850982666,
      "learning_rate": 0.0001943734335839599,
      "loss": 3.1137,
      "step": 122500
    },
    {
      "epoch": 3.2724080134088913,
      "grad_norm": 0.327234148979187,
      "learning_rate": 0.0001931203007518797,
      "loss": 3.1111,
      "step": 123000
    },
    {
      "epoch": 3.2857104850081145,
      "grad_norm": 0.3281016945838928,
      "learning_rate": 0.00019186967418546367,
      "loss": 3.1121,
      "step": 123500
    },
    {
      "epoch": 3.2990129566073376,
      "grad_norm": 0.3203783333301544,
      "learning_rate": 0.00019061654135338346,
      "loss": 3.1113,
      "step": 124000
    },
    {
      "epoch": 3.2990129566073376,
      "eval_loss": 3.114071846008301,
      "eval_runtime": 19.571,
      "eval_samples_per_second": 2554.804,
      "eval_steps_per_second": 10.015,
      "step": 124000
    },
    {
      "epoch": 3.3123154282065608,
      "grad_norm": 0.30854418873786926,
      "learning_rate": 0.00018936340852130328,
      "loss": 3.1121,
      "step": 124500
    },
    {
      "epoch": 3.325617899805784,
      "grad_norm": 0.3141186833381653,
      "learning_rate": 0.00018811027568922306,
      "loss": 3.1098,
      "step": 125000
    },
    {
      "epoch": 3.338920371405007,
      "grad_norm": 0.32038214802742004,
      "learning_rate": 0.00018685964912280704,
      "loss": 3.1108,
      "step": 125500
    },
    {
      "epoch": 3.3522228430042302,
      "grad_norm": 0.32487115263938904,
      "learning_rate": 0.00018560651629072683,
      "loss": 3.1099,
      "step": 126000
    },
    {
      "epoch": 3.3655253146034534,
      "grad_norm": 0.3131362795829773,
      "learning_rate": 0.00018435338345864665,
      "loss": 3.1073,
      "step": 126500
    },
    {
      "epoch": 3.3788277862026765,
      "grad_norm": 0.3170945346355438,
      "learning_rate": 0.00018310025062656644,
      "loss": 3.1069,
      "step": 127000
    },
    {
      "epoch": 3.3921302578018997,
      "grad_norm": 0.30289754271507263,
      "learning_rate": 0.00018184962406015038,
      "loss": 3.1092,
      "step": 127500
    },
    {
      "epoch": 3.405432729401123,
      "grad_norm": 0.3041054904460907,
      "learning_rate": 0.00018059649122807017,
      "loss": 3.1115,
      "step": 128000
    },
    {
      "epoch": 3.405432729401123,
      "eval_loss": 3.110522747039795,
      "eval_runtime": 19.5897,
      "eval_samples_per_second": 2552.359,
      "eval_steps_per_second": 10.005,
      "step": 128000
    },
    {
      "epoch": 3.418735201000346,
      "grad_norm": 0.32536497712135315,
      "learning_rate": 0.00017934335839598996,
      "loss": 3.1073,
      "step": 128500
    },
    {
      "epoch": 3.432037672599569,
      "grad_norm": 0.3223828077316284,
      "learning_rate": 0.00017809022556390978,
      "loss": 3.1073,
      "step": 129000
    },
    {
      "epoch": 3.4453401441987923,
      "grad_norm": 0.3230914771556854,
      "learning_rate": 0.00017683709273182957,
      "loss": 3.1066,
      "step": 129500
    },
    {
      "epoch": 3.4586426157980155,
      "grad_norm": 0.3430785834789276,
      "learning_rate": 0.00017558646616541354,
      "loss": 3.107,
      "step": 130000
    },
    {
      "epoch": 3.4719450873972386,
      "grad_norm": 0.3302646577358246,
      "learning_rate": 0.00017433333333333333,
      "loss": 3.1071,
      "step": 130500
    },
    {
      "epoch": 3.4852475589964618,
      "grad_norm": 0.3081996440887451,
      "learning_rate": 0.00017308020050125315,
      "loss": 3.1053,
      "step": 131000
    },
    {
      "epoch": 3.498550030595685,
      "grad_norm": 0.30955761671066284,
      "learning_rate": 0.00017182706766917294,
      "loss": 3.1064,
      "step": 131500
    },
    {
      "epoch": 3.511852502194908,
      "grad_norm": 0.34158721566200256,
      "learning_rate": 0.0001705764411027569,
      "loss": 3.1055,
      "step": 132000
    },
    {
      "epoch": 3.511852502194908,
      "eval_loss": 3.106775999069214,
      "eval_runtime": 19.6779,
      "eval_samples_per_second": 2540.918,
      "eval_steps_per_second": 9.96,
      "step": 132000
    },
    {
      "epoch": 3.525154973794131,
      "grad_norm": 0.31819048523902893,
      "learning_rate": 0.00016932330827067668,
      "loss": 3.102,
      "step": 132500
    },
    {
      "epoch": 3.538457445393354,
      "grad_norm": 0.31441524624824524,
      "learning_rate": 0.0001680701754385965,
      "loss": 3.1045,
      "step": 133000
    },
    {
      "epoch": 3.551759916992577,
      "grad_norm": 0.3105151653289795,
      "learning_rate": 0.00016681704260651628,
      "loss": 3.1035,
      "step": 133500
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.3074329197406769,
      "learning_rate": 0.00016556390977443607,
      "loss": 3.1055,
      "step": 134000
    },
    {
      "epoch": 3.5783648601910234,
      "grad_norm": 0.33061155676841736,
      "learning_rate": 0.00016431328320802005,
      "loss": 3.1051,
      "step": 134500
    },
    {
      "epoch": 3.5916673317902466,
      "grad_norm": 0.3171009421348572,
      "learning_rate": 0.00016306015037593986,
      "loss": 3.1014,
      "step": 135000
    },
    {
      "epoch": 3.6049698033894697,
      "grad_norm": 0.3226565718650818,
      "learning_rate": 0.00016180701754385965,
      "loss": 3.1031,
      "step": 135500
    },
    {
      "epoch": 3.618272274988693,
      "grad_norm": 0.32511913776397705,
      "learning_rate": 0.00016055388471177944,
      "loss": 3.1028,
      "step": 136000
    },
    {
      "epoch": 3.618272274988693,
      "eval_loss": 3.1033830642700195,
      "eval_runtime": 19.6032,
      "eval_samples_per_second": 2550.6,
      "eval_steps_per_second": 9.998,
      "step": 136000
    },
    {
      "epoch": 3.631574746587916,
      "grad_norm": 0.3310680389404297,
      "learning_rate": 0.00015930075187969926,
      "loss": 3.1015,
      "step": 136500
    },
    {
      "epoch": 3.644877218187139,
      "grad_norm": 0.31626418232917786,
      "learning_rate": 0.00015805012531328323,
      "loss": 3.0998,
      "step": 137000
    },
    {
      "epoch": 3.6581796897863623,
      "grad_norm": 0.31996938586235046,
      "learning_rate": 0.00015679699248120302,
      "loss": 3.1015,
      "step": 137500
    },
    {
      "epoch": 3.6714821613855855,
      "grad_norm": 0.3046712279319763,
      "learning_rate": 0.0001555438596491228,
      "loss": 3.1006,
      "step": 138000
    },
    {
      "epoch": 3.6847846329848086,
      "grad_norm": 0.30949416756629944,
      "learning_rate": 0.00015429072681704263,
      "loss": 3.1002,
      "step": 138500
    },
    {
      "epoch": 3.698087104584032,
      "grad_norm": 0.31306934356689453,
      "learning_rate": 0.00015304010025062655,
      "loss": 3.0988,
      "step": 139000
    },
    {
      "epoch": 3.711389576183255,
      "grad_norm": 0.3117833137512207,
      "learning_rate": 0.00015178696741854637,
      "loss": 3.099,
      "step": 139500
    },
    {
      "epoch": 3.724692047782478,
      "grad_norm": 0.32604315876960754,
      "learning_rate": 0.00015053383458646616,
      "loss": 3.0979,
      "step": 140000
    },
    {
      "epoch": 3.724692047782478,
      "eval_loss": 3.1006484031677246,
      "eval_runtime": 19.5854,
      "eval_samples_per_second": 2552.923,
      "eval_steps_per_second": 10.007,
      "step": 140000
    },
    {
      "epoch": 3.7379945193817012,
      "grad_norm": 0.30471277236938477,
      "learning_rate": 0.00014928070175438597,
      "loss": 3.0993,
      "step": 140500
    },
    {
      "epoch": 3.7512969909809244,
      "grad_norm": 0.32020384073257446,
      "learning_rate": 0.00014802756892230576,
      "loss": 3.0993,
      "step": 141000
    },
    {
      "epoch": 3.7645994625801475,
      "grad_norm": 0.33458411693573,
      "learning_rate": 0.00014677694235588974,
      "loss": 3.0973,
      "step": 141500
    },
    {
      "epoch": 3.7779019341793703,
      "grad_norm": 0.3132992684841156,
      "learning_rate": 0.00014552380952380953,
      "loss": 3.0979,
      "step": 142000
    },
    {
      "epoch": 3.7912044057785934,
      "grad_norm": 0.3187551200389862,
      "learning_rate": 0.00014427067669172934,
      "loss": 3.0966,
      "step": 142500
    },
    {
      "epoch": 3.8045068773778166,
      "grad_norm": 0.32982203364372253,
      "learning_rate": 0.00014301754385964913,
      "loss": 3.0961,
      "step": 143000
    },
    {
      "epoch": 3.8178093489770397,
      "grad_norm": 0.33269089460372925,
      "learning_rate": 0.00014176691729323308,
      "loss": 3.0969,
      "step": 143500
    },
    {
      "epoch": 3.831111820576263,
      "grad_norm": 0.3105117976665497,
      "learning_rate": 0.00014051378446115287,
      "loss": 3.0972,
      "step": 144000
    },
    {
      "epoch": 3.831111820576263,
      "eval_loss": 3.0975382328033447,
      "eval_runtime": 19.5912,
      "eval_samples_per_second": 2552.162,
      "eval_steps_per_second": 10.004,
      "step": 144000
    },
    {
      "epoch": 3.844414292175486,
      "grad_norm": 0.30554625391960144,
      "learning_rate": 0.00013926065162907266,
      "loss": 3.0976,
      "step": 144500
    },
    {
      "epoch": 3.857716763774709,
      "grad_norm": 0.32635441422462463,
      "learning_rate": 0.00013800751879699248,
      "loss": 3.093,
      "step": 145000
    },
    {
      "epoch": 3.8710192353739323,
      "grad_norm": 0.30663415789604187,
      "learning_rate": 0.00013675438596491226,
      "loss": 3.0954,
      "step": 145500
    },
    {
      "epoch": 3.8843217069731555,
      "grad_norm": 0.3109899163246155,
      "learning_rate": 0.00013550375939849624,
      "loss": 3.0943,
      "step": 146000
    },
    {
      "epoch": 3.8976241785723786,
      "grad_norm": 0.3085286617279053,
      "learning_rate": 0.00013425062656641603,
      "loss": 3.0937,
      "step": 146500
    },
    {
      "epoch": 3.910926650171602,
      "grad_norm": 0.310504287481308,
      "learning_rate": 0.00013299749373433585,
      "loss": 3.0948,
      "step": 147000
    },
    {
      "epoch": 3.924229121770825,
      "grad_norm": 0.29867810010910034,
      "learning_rate": 0.00013174436090225564,
      "loss": 3.0928,
      "step": 147500
    },
    {
      "epoch": 3.937531593370048,
      "grad_norm": 0.3137088119983673,
      "learning_rate": 0.00013049122807017545,
      "loss": 3.0917,
      "step": 148000
    },
    {
      "epoch": 3.937531593370048,
      "eval_loss": 3.094254970550537,
      "eval_runtime": 19.5547,
      "eval_samples_per_second": 2556.924,
      "eval_steps_per_second": 10.023,
      "step": 148000
    },
    {
      "epoch": 3.9508340649692713,
      "grad_norm": 0.32314732670783997,
      "learning_rate": 0.00012923809523809524,
      "loss": 3.0912,
      "step": 148500
    },
    {
      "epoch": 3.9641365365684944,
      "grad_norm": 0.3049749732017517,
      "learning_rate": 0.00012798746867167922,
      "loss": 3.0945,
      "step": 149000
    },
    {
      "epoch": 3.9774390081677176,
      "grad_norm": 0.3190063536167145,
      "learning_rate": 0.000126734335839599,
      "loss": 3.0916,
      "step": 149500
    },
    {
      "epoch": 3.9907414797669407,
      "grad_norm": 0.3138750493526459,
      "learning_rate": 0.0001254812030075188,
      "loss": 3.091,
      "step": 150000
    },
    {
      "epoch": 4.004043951366164,
      "grad_norm": 0.30693987011909485,
      "learning_rate": 0.00012422807017543858,
      "loss": 3.0884,
      "step": 150500
    },
    {
      "epoch": 4.017346422965387,
      "grad_norm": 0.3092058002948761,
      "learning_rate": 0.0001229749373433584,
      "loss": 3.0856,
      "step": 151000
    },
    {
      "epoch": 4.03064889456461,
      "grad_norm": 0.3069404661655426,
      "learning_rate": 0.00012172180451127819,
      "loss": 3.085,
      "step": 151500
    },
    {
      "epoch": 4.043951366163833,
      "grad_norm": 0.3214323818683624,
      "learning_rate": 0.00012046867167919799,
      "loss": 3.0857,
      "step": 152000
    },
    {
      "epoch": 4.043951366163833,
      "eval_loss": 3.0918219089508057,
      "eval_runtime": 19.5416,
      "eval_samples_per_second": 2558.64,
      "eval_steps_per_second": 10.03,
      "step": 152000
    },
    {
      "epoch": 4.0572538377630565,
      "grad_norm": 0.30695390701293945,
      "learning_rate": 0.00011921804511278195,
      "loss": 3.0862,
      "step": 152500
    },
    {
      "epoch": 4.07055630936228,
      "grad_norm": 0.3176322877407074,
      "learning_rate": 0.00011796491228070176,
      "loss": 3.085,
      "step": 153000
    },
    {
      "epoch": 4.083858780961503,
      "grad_norm": 0.3217230439186096,
      "learning_rate": 0.00011671177944862156,
      "loss": 3.0848,
      "step": 153500
    },
    {
      "epoch": 4.097161252560726,
      "grad_norm": 0.3163857161998749,
      "learning_rate": 0.00011545864661654136,
      "loss": 3.0871,
      "step": 154000
    },
    {
      "epoch": 4.110463724159949,
      "grad_norm": 0.32415494322776794,
      "learning_rate": 0.00011420551378446116,
      "loss": 3.0863,
      "step": 154500
    },
    {
      "epoch": 4.123766195759172,
      "grad_norm": 0.3073444068431854,
      "learning_rate": 0.00011295488721804511,
      "loss": 3.0861,
      "step": 155000
    },
    {
      "epoch": 4.137068667358395,
      "grad_norm": 0.3073331117630005,
      "learning_rate": 0.00011170175438596492,
      "loss": 3.0862,
      "step": 155500
    },
    {
      "epoch": 4.1503711389576186,
      "grad_norm": 0.32239001989364624,
      "learning_rate": 0.00011044862155388472,
      "loss": 3.0819,
      "step": 156000
    },
    {
      "epoch": 4.1503711389576186,
      "eval_loss": 3.0890777111053467,
      "eval_runtime": 19.572,
      "eval_samples_per_second": 2554.668,
      "eval_steps_per_second": 10.014,
      "step": 156000
    },
    {
      "epoch": 4.163673610556842,
      "grad_norm": 0.31264081597328186,
      "learning_rate": 0.00010919548872180451,
      "loss": 3.0865,
      "step": 156500
    },
    {
      "epoch": 4.176976082156065,
      "grad_norm": 0.3173728585243225,
      "learning_rate": 0.00010794486215538847,
      "loss": 3.0831,
      "step": 157000
    },
    {
      "epoch": 4.190278553755288,
      "grad_norm": 0.30741310119628906,
      "learning_rate": 0.00010669172932330827,
      "loss": 3.0831,
      "step": 157500
    },
    {
      "epoch": 4.203581025354511,
      "grad_norm": 0.31978631019592285,
      "learning_rate": 0.00010543859649122806,
      "loss": 3.0842,
      "step": 158000
    },
    {
      "epoch": 4.216883496953734,
      "grad_norm": 0.3161400556564331,
      "learning_rate": 0.00010418546365914787,
      "loss": 3.081,
      "step": 158500
    },
    {
      "epoch": 4.2301859685529575,
      "grad_norm": 0.3087206780910492,
      "learning_rate": 0.00010293233082706767,
      "loss": 3.0825,
      "step": 159000
    },
    {
      "epoch": 4.243488440152181,
      "grad_norm": 0.3050490617752075,
      "learning_rate": 0.00010168170426065163,
      "loss": 3.0821,
      "step": 159500
    },
    {
      "epoch": 4.256790911751404,
      "grad_norm": 0.3314412832260132,
      "learning_rate": 0.00010042857142857142,
      "loss": 3.0829,
      "step": 160000
    },
    {
      "epoch": 4.256790911751404,
      "eval_loss": 3.086442708969116,
      "eval_runtime": 19.568,
      "eval_samples_per_second": 2555.197,
      "eval_steps_per_second": 10.016,
      "step": 160000
    },
    {
      "epoch": 4.270093383350627,
      "grad_norm": 0.31716102361679077,
      "learning_rate": 9.917543859649122e-05,
      "loss": 3.082,
      "step": 160500
    },
    {
      "epoch": 4.28339585494985,
      "grad_norm": 0.3272186517715454,
      "learning_rate": 9.792230576441103e-05,
      "loss": 3.0812,
      "step": 161000
    },
    {
      "epoch": 4.296698326549073,
      "grad_norm": 0.3094928562641144,
      "learning_rate": 9.667167919799499e-05,
      "loss": 3.0814,
      "step": 161500
    },
    {
      "epoch": 4.310000798148296,
      "grad_norm": 0.31370511651039124,
      "learning_rate": 9.541854636591479e-05,
      "loss": 3.0808,
      "step": 162000
    },
    {
      "epoch": 4.3233032697475196,
      "grad_norm": 0.3111001253128052,
      "learning_rate": 9.41654135338346e-05,
      "loss": 3.0811,
      "step": 162500
    },
    {
      "epoch": 4.336605741346742,
      "grad_norm": 0.3123479187488556,
      "learning_rate": 9.29122807017544e-05,
      "loss": 3.0814,
      "step": 163000
    },
    {
      "epoch": 4.349908212945965,
      "grad_norm": 0.31481194496154785,
      "learning_rate": 9.166165413533835e-05,
      "loss": 3.0819,
      "step": 163500
    },
    {
      "epoch": 4.363210684545188,
      "grad_norm": 0.31679245829582214,
      "learning_rate": 9.040852130325815e-05,
      "loss": 3.079,
      "step": 164000
    },
    {
      "epoch": 4.363210684545188,
      "eval_loss": 3.0839922428131104,
      "eval_runtime": 19.5839,
      "eval_samples_per_second": 2553.118,
      "eval_steps_per_second": 10.008,
      "step": 164000
    },
    {
      "epoch": 4.376513156144411,
      "grad_norm": 0.31312304735183716,
      "learning_rate": 8.915538847117795e-05,
      "loss": 3.0784,
      "step": 164500
    },
    {
      "epoch": 4.389815627743634,
      "grad_norm": 0.31053397059440613,
      "learning_rate": 8.790225563909775e-05,
      "loss": 3.0792,
      "step": 165000
    },
    {
      "epoch": 4.403118099342858,
      "grad_norm": 0.3004021644592285,
      "learning_rate": 8.664912280701754e-05,
      "loss": 3.079,
      "step": 165500
    },
    {
      "epoch": 4.416420570942081,
      "grad_norm": 0.32865917682647705,
      "learning_rate": 8.53984962406015e-05,
      "loss": 3.079,
      "step": 166000
    },
    {
      "epoch": 4.429723042541304,
      "grad_norm": 0.31150373816490173,
      "learning_rate": 8.414536340852131e-05,
      "loss": 3.0785,
      "step": 166500
    },
    {
      "epoch": 4.443025514140527,
      "grad_norm": 0.3271271288394928,
      "learning_rate": 8.28922305764411e-05,
      "loss": 3.0788,
      "step": 167000
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.3115575909614563,
      "learning_rate": 8.16390977443609e-05,
      "loss": 3.0754,
      "step": 167500
    },
    {
      "epoch": 4.469630457338973,
      "grad_norm": 0.30128857493400574,
      "learning_rate": 8.03859649122807e-05,
      "loss": 3.0773,
      "step": 168000
    },
    {
      "epoch": 4.469630457338973,
      "eval_loss": 3.0808568000793457,
      "eval_runtime": 19.5793,
      "eval_samples_per_second": 2553.714,
      "eval_steps_per_second": 10.011,
      "step": 168000
    },
    {
      "epoch": 4.4829329289381965,
      "grad_norm": 0.32008761167526245,
      "learning_rate": 7.913533834586465e-05,
      "loss": 3.0756,
      "step": 168500
    },
    {
      "epoch": 4.49623540053742,
      "grad_norm": 0.30617228150367737,
      "learning_rate": 7.788220551378445e-05,
      "loss": 3.0775,
      "step": 169000
    },
    {
      "epoch": 4.509537872136643,
      "grad_norm": 0.30928805470466614,
      "learning_rate": 7.662907268170426e-05,
      "loss": 3.0768,
      "step": 169500
    },
    {
      "epoch": 4.522840343735866,
      "grad_norm": 0.31698089838027954,
      "learning_rate": 7.537593984962406e-05,
      "loss": 3.0763,
      "step": 170000
    },
    {
      "epoch": 4.536142815335089,
      "grad_norm": 0.3378213047981262,
      "learning_rate": 7.412531328320802e-05,
      "loss": 3.0758,
      "step": 170500
    },
    {
      "epoch": 4.549445286934312,
      "grad_norm": 0.3367142677307129,
      "learning_rate": 7.287218045112783e-05,
      "loss": 3.0759,
      "step": 171000
    },
    {
      "epoch": 4.562747758533535,
      "grad_norm": 0.3141349256038666,
      "learning_rate": 7.161904761904763e-05,
      "loss": 3.074,
      "step": 171500
    },
    {
      "epoch": 4.576050230132759,
      "grad_norm": 0.3072721064090729,
      "learning_rate": 7.036591478696743e-05,
      "loss": 3.0755,
      "step": 172000
    },
    {
      "epoch": 4.576050230132759,
      "eval_loss": 3.0784294605255127,
      "eval_runtime": 19.5359,
      "eval_samples_per_second": 2559.395,
      "eval_steps_per_second": 10.033,
      "step": 172000
    },
    {
      "epoch": 4.589352701731982,
      "grad_norm": 0.3085424602031708,
      "learning_rate": 6.911278195488722e-05,
      "loss": 3.076,
      "step": 172500
    },
    {
      "epoch": 4.602655173331205,
      "grad_norm": 0.31343314051628113,
      "learning_rate": 6.786215538847118e-05,
      "loss": 3.0724,
      "step": 173000
    },
    {
      "epoch": 4.615957644930428,
      "grad_norm": 0.30475878715515137,
      "learning_rate": 6.660902255639098e-05,
      "loss": 3.0739,
      "step": 173500
    },
    {
      "epoch": 4.629260116529651,
      "grad_norm": 0.3205333650112152,
      "learning_rate": 6.535588972431077e-05,
      "loss": 3.0724,
      "step": 174000
    },
    {
      "epoch": 4.642562588128874,
      "grad_norm": 0.31855952739715576,
      "learning_rate": 6.410275689223058e-05,
      "loss": 3.0742,
      "step": 174500
    },
    {
      "epoch": 4.6558650597280975,
      "grad_norm": 0.310423344373703,
      "learning_rate": 6.284962406015038e-05,
      "loss": 3.0731,
      "step": 175000
    },
    {
      "epoch": 4.669167531327321,
      "grad_norm": 0.3134373426437378,
      "learning_rate": 6.159649122807018e-05,
      "loss": 3.0721,
      "step": 175500
    },
    {
      "epoch": 4.682470002926544,
      "grad_norm": 0.3194875121116638,
      "learning_rate": 6.034335839598998e-05,
      "loss": 3.0733,
      "step": 176000
    },
    {
      "epoch": 4.682470002926544,
      "eval_loss": 3.07576584815979,
      "eval_runtime": 19.5724,
      "eval_samples_per_second": 2554.621,
      "eval_steps_per_second": 10.014,
      "step": 176000
    },
    {
      "epoch": 4.695772474525767,
      "grad_norm": 0.3207113444805145,
      "learning_rate": 5.9092731829573934e-05,
      "loss": 3.0728,
      "step": 176500
    },
    {
      "epoch": 4.70907494612499,
      "grad_norm": 0.3069468140602112,
      "learning_rate": 5.7839598997493736e-05,
      "loss": 3.0722,
      "step": 177000
    },
    {
      "epoch": 4.722377417724213,
      "grad_norm": 0.31646260619163513,
      "learning_rate": 5.658646616541353e-05,
      "loss": 3.0703,
      "step": 177500
    },
    {
      "epoch": 4.735679889323436,
      "grad_norm": 0.3141951262950897,
      "learning_rate": 5.5333333333333334e-05,
      "loss": 3.0695,
      "step": 178000
    },
    {
      "epoch": 4.74898236092266,
      "grad_norm": 0.3224964141845703,
      "learning_rate": 5.408020050125313e-05,
      "loss": 3.0677,
      "step": 178500
    },
    {
      "epoch": 4.762284832521883,
      "grad_norm": 0.3154028654098511,
      "learning_rate": 5.282706766917293e-05,
      "loss": 3.0696,
      "step": 179000
    },
    {
      "epoch": 4.775587304121106,
      "grad_norm": 0.317137748003006,
      "learning_rate": 5.157393483709273e-05,
      "loss": 3.0695,
      "step": 179500
    },
    {
      "epoch": 4.788889775720329,
      "grad_norm": 0.3228669762611389,
      "learning_rate": 5.032330827067669e-05,
      "loss": 3.0701,
      "step": 180000
    },
    {
      "epoch": 4.788889775720329,
      "eval_loss": 3.0733871459960938,
      "eval_runtime": 19.5688,
      "eval_samples_per_second": 2555.091,
      "eval_steps_per_second": 10.016,
      "step": 180000
    },
    {
      "epoch": 4.802192247319552,
      "grad_norm": 0.2938194274902344,
      "learning_rate": 4.9070175438596494e-05,
      "loss": 3.0697,
      "step": 180500
    },
    {
      "epoch": 4.815494718918775,
      "grad_norm": 0.30814942717552185,
      "learning_rate": 4.7817042606516297e-05,
      "loss": 3.0699,
      "step": 181000
    },
    {
      "epoch": 4.8287971905179985,
      "grad_norm": 0.30049028992652893,
      "learning_rate": 4.656390977443609e-05,
      "loss": 3.0698,
      "step": 181500
    },
    {
      "epoch": 4.842099662117222,
      "grad_norm": 0.33503594994544983,
      "learning_rate": 4.5310776942355895e-05,
      "loss": 3.0689,
      "step": 182000
    },
    {
      "epoch": 4.855402133716445,
      "grad_norm": 0.29820841550827026,
      "learning_rate": 4.405764411027569e-05,
      "loss": 3.0689,
      "step": 182500
    },
    {
      "epoch": 4.868704605315668,
      "grad_norm": 0.31077829003334045,
      "learning_rate": 4.280451127819549e-05,
      "loss": 3.0682,
      "step": 183000
    },
    {
      "epoch": 4.882007076914891,
      "grad_norm": 0.3071219325065613,
      "learning_rate": 4.155388471177945e-05,
      "loss": 3.0697,
      "step": 183500
    },
    {
      "epoch": 4.895309548514114,
      "grad_norm": 0.3097327947616577,
      "learning_rate": 4.0300751879699245e-05,
      "loss": 3.0674,
      "step": 184000
    },
    {
      "epoch": 4.895309548514114,
      "eval_loss": 3.070997476577759,
      "eval_runtime": 19.5627,
      "eval_samples_per_second": 2555.885,
      "eval_steps_per_second": 10.019,
      "step": 184000
    },
    {
      "epoch": 4.908612020113337,
      "grad_norm": 0.31980636715888977,
      "learning_rate": 3.904761904761905e-05,
      "loss": 3.0669,
      "step": 184500
    },
    {
      "epoch": 4.921914491712561,
      "grad_norm": 0.3275250494480133,
      "learning_rate": 3.7794486215538843e-05,
      "loss": 3.0675,
      "step": 185000
    },
    {
      "epoch": 4.935216963311783,
      "grad_norm": 0.3022431433200836,
      "learning_rate": 3.6541353383458646e-05,
      "loss": 3.0659,
      "step": 185500
    },
    {
      "epoch": 4.948519434911006,
      "grad_norm": 0.3048570156097412,
      "learning_rate": 3.528822055137845e-05,
      "loss": 3.068,
      "step": 186000
    },
    {
      "epoch": 4.961821906510229,
      "grad_norm": 0.31518954038619995,
      "learning_rate": 3.4035087719298244e-05,
      "loss": 3.0667,
      "step": 186500
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.30254825949668884,
      "learning_rate": 3.278446115288221e-05,
      "loss": 3.0671,
      "step": 187000
    },
    {
      "epoch": 4.9884268497086754,
      "grad_norm": 0.30001845955848694,
      "learning_rate": 3.153132832080201e-05,
      "loss": 3.0656,
      "step": 187500
    },
    {
      "epoch": 5.001729321307899,
      "grad_norm": 0.31138965487480164,
      "learning_rate": 3.0278195488721806e-05,
      "loss": 3.0662,
      "step": 188000
    },
    {
      "epoch": 5.001729321307899,
      "eval_loss": 3.0687737464904785,
      "eval_runtime": 19.5552,
      "eval_samples_per_second": 2556.862,
      "eval_steps_per_second": 10.023,
      "step": 188000
    },
    {
      "epoch": 5.015031792907122,
      "grad_norm": 0.30371689796447754,
      "learning_rate": 2.9025062656641605e-05,
      "loss": 3.0612,
      "step": 188500
    },
    {
      "epoch": 5.028334264506345,
      "grad_norm": 0.30528032779693604,
      "learning_rate": 2.7771929824561404e-05,
      "loss": 3.0605,
      "step": 189000
    },
    {
      "epoch": 5.041636736105568,
      "grad_norm": 0.2957574725151062,
      "learning_rate": 2.6518796992481203e-05,
      "loss": 3.0606,
      "step": 189500
    },
    {
      "epoch": 5.054939207704791,
      "grad_norm": 0.30264919996261597,
      "learning_rate": 2.5265664160401002e-05,
      "loss": 3.0604,
      "step": 190000
    },
    {
      "epoch": 5.068241679304014,
      "grad_norm": 0.3067187964916229,
      "learning_rate": 2.40125313283208e-05,
      "loss": 3.0605,
      "step": 190500
    },
    {
      "epoch": 5.0815441509032375,
      "grad_norm": 0.3024980425834656,
      "learning_rate": 2.276190476190476e-05,
      "loss": 3.0604,
      "step": 191000
    },
    {
      "epoch": 5.094846622502461,
      "grad_norm": 0.3089253604412079,
      "learning_rate": 2.150877192982456e-05,
      "loss": 3.0592,
      "step": 191500
    },
    {
      "epoch": 5.108149094101684,
      "grad_norm": 0.31023257970809937,
      "learning_rate": 2.025563909774436e-05,
      "loss": 3.0591,
      "step": 192000
    },
    {
      "epoch": 5.108149094101684,
      "eval_loss": 3.06703782081604,
      "eval_runtime": 19.5603,
      "eval_samples_per_second": 2556.2,
      "eval_steps_per_second": 10.02,
      "step": 192000
    },
    {
      "epoch": 5.121451565700907,
      "grad_norm": 0.3077425956726074,
      "learning_rate": 1.900250626566416e-05,
      "loss": 3.0596,
      "step": 192500
    },
    {
      "epoch": 5.13475403730013,
      "grad_norm": 0.29500508308410645,
      "learning_rate": 1.775187969924812e-05,
      "loss": 3.0623,
      "step": 193000
    },
    {
      "epoch": 5.148056508899353,
      "grad_norm": 0.30405759811401367,
      "learning_rate": 1.649874686716792e-05,
      "loss": 3.0584,
      "step": 193500
    },
    {
      "epoch": 5.161358980498576,
      "grad_norm": 0.2931915819644928,
      "learning_rate": 1.5245614035087718e-05,
      "loss": 3.0595,
      "step": 194000
    },
    {
      "epoch": 5.1746614520978,
      "grad_norm": 0.30315983295440674,
      "learning_rate": 1.3992481203007519e-05,
      "loss": 3.0599,
      "step": 194500
    },
    {
      "epoch": 5.187963923697023,
      "grad_norm": 0.2997300326824188,
      "learning_rate": 1.2741854636591479e-05,
      "loss": 3.0571,
      "step": 195000
    },
    {
      "epoch": 5.201266395296246,
      "grad_norm": 0.30272117257118225,
      "learning_rate": 1.1488721804511278e-05,
      "loss": 3.0596,
      "step": 195500
    },
    {
      "epoch": 5.214568866895469,
      "grad_norm": 0.2999793589115143,
      "learning_rate": 1.0235588972431077e-05,
      "loss": 3.0578,
      "step": 196000
    },
    {
      "epoch": 5.214568866895469,
      "eval_loss": 3.0652382373809814,
      "eval_runtime": 19.733,
      "eval_samples_per_second": 2533.83,
      "eval_steps_per_second": 9.933,
      "step": 196000
    },
    {
      "epoch": 5.227871338494692,
      "grad_norm": 0.30124589800834656,
      "learning_rate": 8.982456140350876e-06,
      "loss": 3.0579,
      "step": 196500
    },
    {
      "epoch": 5.241173810093915,
      "grad_norm": 0.31293436884880066,
      "learning_rate": 7.731829573934838e-06,
      "loss": 3.0592,
      "step": 197000
    },
    {
      "epoch": 5.2544762816931385,
      "grad_norm": 0.29941797256469727,
      "learning_rate": 6.478696741854637e-06,
      "loss": 3.0571,
      "step": 197500
    },
    {
      "epoch": 5.267778753292362,
      "grad_norm": 0.3000982701778412,
      "learning_rate": 5.225563909774436e-06,
      "loss": 3.0578,
      "step": 198000
    },
    {
      "epoch": 5.281081224891585,
      "grad_norm": 0.2982945442199707,
      "learning_rate": 3.972431077694236e-06,
      "loss": 3.0588,
      "step": 198500
    },
    {
      "epoch": 5.294383696490808,
      "grad_norm": 0.29859286546707153,
      "learning_rate": 2.7218045112781956e-06,
      "loss": 3.0578,
      "step": 199000
    },
    {
      "epoch": 5.307686168090031,
      "grad_norm": 0.30748534202575684,
      "learning_rate": 1.4686716791979949e-06,
      "loss": 3.0567,
      "step": 199500
    },
    {
      "epoch": 5.320988639689254,
      "grad_norm": 0.30567359924316406,
      "learning_rate": 2.155388471177945e-07,
      "loss": 3.0572,
      "step": 200000
    },
    {
      "epoch": 5.320988639689254,
      "eval_loss": 3.064025402069092,
      "eval_runtime": 19.5753,
      "eval_samples_per_second": 2554.243,
      "eval_steps_per_second": 10.013,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
