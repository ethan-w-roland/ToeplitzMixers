{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.320988639689254,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013302471599223136,
      "grad_norm": 3.903127431869507,
      "learning_rate": 0.0005,
      "loss": 9.1631,
      "step": 500
    },
    {
      "epoch": 0.026604943198446272,
      "grad_norm": 3.325054168701172,
      "learning_rate": 0.0004987468671679198,
      "loss": 5.693,
      "step": 1000
    },
    {
      "epoch": 0.039907414797669405,
      "grad_norm": 1.8400771617889404,
      "learning_rate": 0.0004974937343358396,
      "loss": 5.453,
      "step": 1500
    },
    {
      "epoch": 0.053209886396892545,
      "grad_norm": 0.6517442464828491,
      "learning_rate": 0.0004962406015037594,
      "loss": 5.2146,
      "step": 2000
    },
    {
      "epoch": 0.06651235799611568,
      "grad_norm": 0.9931004047393799,
      "learning_rate": 0.0004949874686716792,
      "loss": 4.7542,
      "step": 2500
    },
    {
      "epoch": 0.07981482959533881,
      "grad_norm": 0.4186268150806427,
      "learning_rate": 0.000493734335839599,
      "loss": 4.473,
      "step": 3000
    },
    {
      "epoch": 0.09311730119456195,
      "grad_norm": 0.4679548442363739,
      "learning_rate": 0.0004924812030075188,
      "loss": 4.3253,
      "step": 3500
    },
    {
      "epoch": 0.10641977279378509,
      "grad_norm": 0.5861209630966187,
      "learning_rate": 0.0004912280701754386,
      "loss": 4.2264,
      "step": 4000
    },
    {
      "epoch": 0.10641977279378509,
      "eval_loss": 4.0753607749938965,
      "eval_runtime": 25.2487,
      "eval_samples_per_second": 1980.301,
      "eval_steps_per_second": 7.763,
      "step": 4000
    },
    {
      "epoch": 0.11972224439300821,
      "grad_norm": 0.3882938623428345,
      "learning_rate": 0.0004899749373433584,
      "loss": 4.1558,
      "step": 4500
    },
    {
      "epoch": 0.13302471599223137,
      "grad_norm": 0.4147763252258301,
      "learning_rate": 0.0004887218045112781,
      "loss": 4.0979,
      "step": 5000
    },
    {
      "epoch": 0.1463271875914545,
      "grad_norm": 0.48223307728767395,
      "learning_rate": 0.000487468671679198,
      "loss": 4.0518,
      "step": 5500
    },
    {
      "epoch": 0.15962965919067762,
      "grad_norm": 0.42844557762145996,
      "learning_rate": 0.00048621553884711777,
      "loss": 4.0106,
      "step": 6000
    },
    {
      "epoch": 0.17293213078990077,
      "grad_norm": 0.3421134650707245,
      "learning_rate": 0.0004849624060150376,
      "loss": 3.9785,
      "step": 6500
    },
    {
      "epoch": 0.1862346023891239,
      "grad_norm": 0.42514654994010925,
      "learning_rate": 0.0004837092731829574,
      "loss": 3.9446,
      "step": 7000
    },
    {
      "epoch": 0.19953707398834702,
      "grad_norm": 0.561019778251648,
      "learning_rate": 0.0004824561403508772,
      "loss": 3.9184,
      "step": 7500
    },
    {
      "epoch": 0.21283954558757018,
      "grad_norm": 0.3154556453227997,
      "learning_rate": 0.000481203007518797,
      "loss": 3.8946,
      "step": 8000
    },
    {
      "epoch": 0.21283954558757018,
      "eval_loss": 3.7744696140289307,
      "eval_runtime": 25.2818,
      "eval_samples_per_second": 1977.708,
      "eval_steps_per_second": 7.753,
      "step": 8000
    },
    {
      "epoch": 0.2261420171867933,
      "grad_norm": 0.6576255559921265,
      "learning_rate": 0.0004799498746867168,
      "loss": 3.8716,
      "step": 8500
    },
    {
      "epoch": 0.23944448878601643,
      "grad_norm": 0.40400704741477966,
      "learning_rate": 0.00047869674185463656,
      "loss": 3.8492,
      "step": 9000
    },
    {
      "epoch": 0.2527469603852396,
      "grad_norm": 0.38810646533966064,
      "learning_rate": 0.00047744360902255643,
      "loss": 3.8327,
      "step": 9500
    },
    {
      "epoch": 0.26604943198446274,
      "grad_norm": 0.3074410855770111,
      "learning_rate": 0.0004761904761904762,
      "loss": 3.8127,
      "step": 10000
    },
    {
      "epoch": 0.27935190358368583,
      "grad_norm": 0.35480332374572754,
      "learning_rate": 0.000474937343358396,
      "loss": 3.7983,
      "step": 10500
    },
    {
      "epoch": 0.292654375182909,
      "grad_norm": 0.4399946928024292,
      "learning_rate": 0.00047368671679197996,
      "loss": 3.785,
      "step": 11000
    },
    {
      "epoch": 0.30595684678213214,
      "grad_norm": 0.5207913517951965,
      "learning_rate": 0.00047243358395989977,
      "loss": 3.7704,
      "step": 11500
    },
    {
      "epoch": 0.31925931838135524,
      "grad_norm": 0.7518011331558228,
      "learning_rate": 0.00047118045112781953,
      "loss": 3.7571,
      "step": 12000
    },
    {
      "epoch": 0.31925931838135524,
      "eval_loss": 3.645204782485962,
      "eval_runtime": 25.275,
      "eval_samples_per_second": 1978.242,
      "eval_steps_per_second": 7.755,
      "step": 12000
    },
    {
      "epoch": 0.3325617899805784,
      "grad_norm": 0.6925085783004761,
      "learning_rate": 0.00046992982456140354,
      "loss": 3.7458,
      "step": 12500
    },
    {
      "epoch": 0.34586426157980155,
      "grad_norm": 0.5911473035812378,
      "learning_rate": 0.0004686791979949875,
      "loss": 3.7333,
      "step": 13000
    },
    {
      "epoch": 0.35916673317902464,
      "grad_norm": 1.0090042352676392,
      "learning_rate": 0.00046742606516290725,
      "loss": 3.7229,
      "step": 13500
    },
    {
      "epoch": 0.3724692047782478,
      "grad_norm": 0.6799971461296082,
      "learning_rate": 0.00046617543859649125,
      "loss": 3.7128,
      "step": 14000
    },
    {
      "epoch": 0.38577167637747095,
      "grad_norm": 0.8681719303131104,
      "learning_rate": 0.000464922305764411,
      "loss": 3.7053,
      "step": 14500
    },
    {
      "epoch": 0.39907414797669405,
      "grad_norm": 0.3022431433200836,
      "learning_rate": 0.00046366917293233083,
      "loss": 3.6957,
      "step": 15000
    },
    {
      "epoch": 0.4123766195759172,
      "grad_norm": 0.4264296591281891,
      "learning_rate": 0.00046241604010025065,
      "loss": 3.6847,
      "step": 15500
    },
    {
      "epoch": 0.42567909117514036,
      "grad_norm": 0.32088202238082886,
      "learning_rate": 0.00046116290726817046,
      "loss": 3.6793,
      "step": 16000
    },
    {
      "epoch": 0.42567909117514036,
      "eval_loss": 3.5681397914886475,
      "eval_runtime": 25.2831,
      "eval_samples_per_second": 1977.603,
      "eval_steps_per_second": 7.752,
      "step": 16000
    },
    {
      "epoch": 0.43898156277436345,
      "grad_norm": 0.27886414527893066,
      "learning_rate": 0.0004599097744360902,
      "loss": 3.6708,
      "step": 16500
    },
    {
      "epoch": 0.4522840343735866,
      "grad_norm": 0.43578484654426575,
      "learning_rate": 0.00045865664160401004,
      "loss": 3.6625,
      "step": 17000
    },
    {
      "epoch": 0.46558650597280976,
      "grad_norm": 1.0414772033691406,
      "learning_rate": 0.0004574035087719298,
      "loss": 3.6571,
      "step": 17500
    },
    {
      "epoch": 0.47888897757203286,
      "grad_norm": 0.2939186990261078,
      "learning_rate": 0.0004561503759398497,
      "loss": 3.6496,
      "step": 18000
    },
    {
      "epoch": 0.492191449171256,
      "grad_norm": 0.3163709044456482,
      "learning_rate": 0.00045489724310776944,
      "loss": 3.643,
      "step": 18500
    },
    {
      "epoch": 0.5054939207704792,
      "grad_norm": 0.23990854620933533,
      "learning_rate": 0.00045364411027568925,
      "loss": 3.6373,
      "step": 19000
    },
    {
      "epoch": 0.5187963923697023,
      "grad_norm": 0.664289116859436,
      "learning_rate": 0.000452390977443609,
      "loss": 3.6315,
      "step": 19500
    },
    {
      "epoch": 0.5320988639689255,
      "grad_norm": 0.3169722557067871,
      "learning_rate": 0.00045113784461152883,
      "loss": 3.6286,
      "step": 20000
    },
    {
      "epoch": 0.5320988639689255,
      "eval_loss": 3.518122911453247,
      "eval_runtime": 25.3248,
      "eval_samples_per_second": 1974.352,
      "eval_steps_per_second": 7.739,
      "step": 20000
    },
    {
      "epoch": 0.5454013355681485,
      "grad_norm": 0.26303228735923767,
      "learning_rate": 0.00044988471177944865,
      "loss": 3.6214,
      "step": 20500
    },
    {
      "epoch": 0.5587038071673717,
      "grad_norm": 0.2791280150413513,
      "learning_rate": 0.00044863157894736846,
      "loss": 3.6164,
      "step": 21000
    },
    {
      "epoch": 0.5720062787665948,
      "grad_norm": 0.2826802730560303,
      "learning_rate": 0.0004473784461152882,
      "loss": 3.6127,
      "step": 21500
    },
    {
      "epoch": 0.585308750365818,
      "grad_norm": 0.3107582628726959,
      "learning_rate": 0.00044612531328320804,
      "loss": 3.6063,
      "step": 22000
    },
    {
      "epoch": 0.5986112219650411,
      "grad_norm": 0.4376996159553528,
      "learning_rate": 0.000444874686716792,
      "loss": 3.6041,
      "step": 22500
    },
    {
      "epoch": 0.6119136935642643,
      "grad_norm": 0.5595651865005493,
      "learning_rate": 0.0004436215538847118,
      "loss": 3.5959,
      "step": 23000
    },
    {
      "epoch": 0.6252161651634873,
      "grad_norm": 0.7040839791297913,
      "learning_rate": 0.00044237092731829575,
      "loss": 3.5915,
      "step": 23500
    },
    {
      "epoch": 0.6385186367627105,
      "grad_norm": 0.9148316979408264,
      "learning_rate": 0.0004411177944862155,
      "loss": 3.5885,
      "step": 24000
    },
    {
      "epoch": 0.6385186367627105,
      "eval_loss": 3.4789674282073975,
      "eval_runtime": 25.2827,
      "eval_samples_per_second": 1977.633,
      "eval_steps_per_second": 7.752,
      "step": 24000
    },
    {
      "epoch": 0.6518211083619336,
      "grad_norm": 0.4417407214641571,
      "learning_rate": 0.00043986466165413533,
      "loss": 3.5847,
      "step": 24500
    },
    {
      "epoch": 0.6651235799611568,
      "grad_norm": 0.8661063313484192,
      "learning_rate": 0.00043861152882205515,
      "loss": 3.5811,
      "step": 25000
    },
    {
      "epoch": 0.6784260515603799,
      "grad_norm": 0.26833677291870117,
      "learning_rate": 0.00043735839598997496,
      "loss": 3.5754,
      "step": 25500
    },
    {
      "epoch": 0.6917285231596031,
      "grad_norm": 0.36454957723617554,
      "learning_rate": 0.0004361052631578947,
      "loss": 3.5749,
      "step": 26000
    },
    {
      "epoch": 0.7050309947588261,
      "grad_norm": 0.28385624289512634,
      "learning_rate": 0.00043485213032581454,
      "loss": 3.5674,
      "step": 26500
    },
    {
      "epoch": 0.7183334663580493,
      "grad_norm": 0.39823395013809204,
      "learning_rate": 0.0004335989974937343,
      "loss": 3.5659,
      "step": 27000
    },
    {
      "epoch": 0.7316359379572724,
      "grad_norm": 0.31180593371391296,
      "learning_rate": 0.0004323458646616542,
      "loss": 3.5629,
      "step": 27500
    },
    {
      "epoch": 0.7449384095564956,
      "grad_norm": 0.6092885136604309,
      "learning_rate": 0.00043109273182957394,
      "loss": 3.5594,
      "step": 28000
    },
    {
      "epoch": 0.7449384095564956,
      "eval_loss": 3.4502015113830566,
      "eval_runtime": 25.2169,
      "eval_samples_per_second": 1982.8,
      "eval_steps_per_second": 7.773,
      "step": 28000
    },
    {
      "epoch": 0.7582408811557187,
      "grad_norm": 0.2965256869792938,
      "learning_rate": 0.00042984210526315794,
      "loss": 3.5567,
      "step": 28500
    },
    {
      "epoch": 0.7715433527549419,
      "grad_norm": 0.8552468419075012,
      "learning_rate": 0.0004285889724310777,
      "loss": 3.5513,
      "step": 29000
    },
    {
      "epoch": 0.7848458243541651,
      "grad_norm": 0.8610600829124451,
      "learning_rate": 0.0004273358395989975,
      "loss": 3.5511,
      "step": 29500
    },
    {
      "epoch": 0.7981482959533881,
      "grad_norm": 0.29098671674728394,
      "learning_rate": 0.0004260827067669173,
      "loss": 3.5471,
      "step": 30000
    },
    {
      "epoch": 0.8114507675526113,
      "grad_norm": 0.33450350165367126,
      "learning_rate": 0.0004248295739348371,
      "loss": 3.546,
      "step": 30500
    },
    {
      "epoch": 0.8247532391518344,
      "grad_norm": 0.2727876603603363,
      "learning_rate": 0.0004235764411027569,
      "loss": 3.5418,
      "step": 31000
    },
    {
      "epoch": 0.8380557107510576,
      "grad_norm": 0.33831560611724854,
      "learning_rate": 0.00042232581453634086,
      "loss": 3.5391,
      "step": 31500
    },
    {
      "epoch": 0.8513581823502807,
      "grad_norm": 0.49781522154808044,
      "learning_rate": 0.0004210751879699248,
      "loss": 3.538,
      "step": 32000
    },
    {
      "epoch": 0.8513581823502807,
      "eval_loss": 3.426564931869507,
      "eval_runtime": 25.3522,
      "eval_samples_per_second": 1972.218,
      "eval_steps_per_second": 7.731,
      "step": 32000
    },
    {
      "epoch": 0.8646606539495039,
      "grad_norm": 0.4205567538738251,
      "learning_rate": 0.00041982205513784463,
      "loss": 3.5347,
      "step": 32500
    },
    {
      "epoch": 0.8779631255487269,
      "grad_norm": 0.2920759320259094,
      "learning_rate": 0.00041856892230576444,
      "loss": 3.5325,
      "step": 33000
    },
    {
      "epoch": 0.8912655971479501,
      "grad_norm": 0.31045106053352356,
      "learning_rate": 0.0004173157894736842,
      "loss": 3.528,
      "step": 33500
    },
    {
      "epoch": 0.9045680687471732,
      "grad_norm": 0.24267864227294922,
      "learning_rate": 0.000416062656641604,
      "loss": 3.5259,
      "step": 34000
    },
    {
      "epoch": 0.9178705403463964,
      "grad_norm": 0.31859150528907776,
      "learning_rate": 0.0004148095238095238,
      "loss": 3.5266,
      "step": 34500
    },
    {
      "epoch": 0.9311730119456195,
      "grad_norm": 0.4501985013484955,
      "learning_rate": 0.00041355639097744365,
      "loss": 3.5251,
      "step": 35000
    },
    {
      "epoch": 0.9444754835448427,
      "grad_norm": 0.3211401104927063,
      "learning_rate": 0.00041230576441102755,
      "loss": 3.5218,
      "step": 35500
    },
    {
      "epoch": 0.9577779551440657,
      "grad_norm": 0.7187916040420532,
      "learning_rate": 0.0004110526315789474,
      "loss": 3.518,
      "step": 36000
    },
    {
      "epoch": 0.9577779551440657,
      "eval_loss": 3.407459259033203,
      "eval_runtime": 25.3331,
      "eval_samples_per_second": 1973.704,
      "eval_steps_per_second": 7.737,
      "step": 36000
    },
    {
      "epoch": 0.9710804267432889,
      "grad_norm": 0.31713196635246277,
      "learning_rate": 0.0004097994987468672,
      "loss": 3.5169,
      "step": 36500
    },
    {
      "epoch": 0.984382898342512,
      "grad_norm": 0.48146042227745056,
      "learning_rate": 0.000408546365914787,
      "loss": 3.5135,
      "step": 37000
    },
    {
      "epoch": 0.9976853699417352,
      "grad_norm": 0.5916080474853516,
      "learning_rate": 0.00040729323308270676,
      "loss": 3.5106,
      "step": 37500
    },
    {
      "epoch": 1.0109878415409583,
      "grad_norm": 0.3910110592842102,
      "learning_rate": 0.0004060401002506266,
      "loss": 3.5069,
      "step": 38000
    },
    {
      "epoch": 1.0242903131401815,
      "grad_norm": 0.5701686143875122,
      "learning_rate": 0.0004047869674185464,
      "loss": 3.5047,
      "step": 38500
    },
    {
      "epoch": 1.0375927847394046,
      "grad_norm": 0.5890455842018127,
      "learning_rate": 0.0004035338345864662,
      "loss": 3.5023,
      "step": 39000
    },
    {
      "epoch": 1.0508952563386278,
      "grad_norm": 0.5347648859024048,
      "learning_rate": 0.00040228320802005016,
      "loss": 3.5008,
      "step": 39500
    },
    {
      "epoch": 1.064197727937851,
      "grad_norm": 0.34169331192970276,
      "learning_rate": 0.0004010300751879699,
      "loss": 3.501,
      "step": 40000
    },
    {
      "epoch": 1.064197727937851,
      "eval_loss": 3.3910510540008545,
      "eval_runtime": 25.281,
      "eval_samples_per_second": 1977.768,
      "eval_steps_per_second": 7.753,
      "step": 40000
    },
    {
      "epoch": 1.077500199537074,
      "grad_norm": 0.39153069257736206,
      "learning_rate": 0.00039977694235588973,
      "loss": 3.4983,
      "step": 40500
    },
    {
      "epoch": 1.090802671136297,
      "grad_norm": 0.2924298346042633,
      "learning_rate": 0.0003985238095238095,
      "loss": 3.4956,
      "step": 41000
    },
    {
      "epoch": 1.1041051427355202,
      "grad_norm": 0.531481921672821,
      "learning_rate": 0.0003972706766917293,
      "loss": 3.4944,
      "step": 41500
    },
    {
      "epoch": 1.1174076143347433,
      "grad_norm": 0.5010088086128235,
      "learning_rate": 0.00039602005012531326,
      "loss": 3.494,
      "step": 42000
    },
    {
      "epoch": 1.1307100859339665,
      "grad_norm": 0.3011089265346527,
      "learning_rate": 0.00039476691729323313,
      "loss": 3.4923,
      "step": 42500
    },
    {
      "epoch": 1.1440125575331896,
      "grad_norm": 0.44141867756843567,
      "learning_rate": 0.0003935137844611529,
      "loss": 3.4916,
      "step": 43000
    },
    {
      "epoch": 1.1573150291324128,
      "grad_norm": 0.27962955832481384,
      "learning_rate": 0.0003922606516290727,
      "loss": 3.489,
      "step": 43500
    },
    {
      "epoch": 1.170617500731636,
      "grad_norm": 0.3141425549983978,
      "learning_rate": 0.00039100751879699247,
      "loss": 3.4864,
      "step": 44000
    },
    {
      "epoch": 1.170617500731636,
      "eval_loss": 3.3772244453430176,
      "eval_runtime": 25.2921,
      "eval_samples_per_second": 1976.898,
      "eval_steps_per_second": 7.749,
      "step": 44000
    },
    {
      "epoch": 1.183919972330859,
      "grad_norm": 0.28337082266807556,
      "learning_rate": 0.0003897568922305765,
      "loss": 3.4856,
      "step": 44500
    },
    {
      "epoch": 1.1972224439300823,
      "grad_norm": 0.5940676331520081,
      "learning_rate": 0.00038850375939849624,
      "loss": 3.4843,
      "step": 45000
    },
    {
      "epoch": 1.2105249155293054,
      "grad_norm": 0.24429373443126678,
      "learning_rate": 0.0003872531328320802,
      "loss": 3.4819,
      "step": 45500
    },
    {
      "epoch": 1.2238273871285286,
      "grad_norm": 0.6216019988059998,
      "learning_rate": 0.000386,
      "loss": 3.4802,
      "step": 46000
    },
    {
      "epoch": 1.2371298587277515,
      "grad_norm": 0.29419925808906555,
      "learning_rate": 0.00038474686716791977,
      "loss": 3.4799,
      "step": 46500
    },
    {
      "epoch": 1.2504323303269747,
      "grad_norm": 0.42774492502212524,
      "learning_rate": 0.00038349373433583964,
      "loss": 3.4782,
      "step": 47000
    },
    {
      "epoch": 1.2637348019261978,
      "grad_norm": 0.2695900499820709,
      "learning_rate": 0.0003822406015037594,
      "loss": 3.4761,
      "step": 47500
    },
    {
      "epoch": 1.277037273525421,
      "grad_norm": 0.4599855840206146,
      "learning_rate": 0.0003809874686716792,
      "loss": 3.4756,
      "step": 48000
    },
    {
      "epoch": 1.277037273525421,
      "eval_loss": 3.3651556968688965,
      "eval_runtime": 25.3045,
      "eval_samples_per_second": 1975.933,
      "eval_steps_per_second": 7.746,
      "step": 48000
    },
    {
      "epoch": 1.290339745124644,
      "grad_norm": 0.5140737295150757,
      "learning_rate": 0.00037973684210526316,
      "loss": 3.4742,
      "step": 48500
    },
    {
      "epoch": 1.3036422167238673,
      "grad_norm": 0.3031063973903656,
      "learning_rate": 0.000378483709273183,
      "loss": 3.4723,
      "step": 49000
    },
    {
      "epoch": 1.3169446883230904,
      "grad_norm": 0.2905990779399872,
      "learning_rate": 0.00037723057644110274,
      "loss": 3.4715,
      "step": 49500
    },
    {
      "epoch": 1.3302471599223136,
      "grad_norm": 0.3445412218570709,
      "learning_rate": 0.0003759799498746867,
      "loss": 3.4696,
      "step": 50000
    },
    {
      "epoch": 1.3435496315215367,
      "grad_norm": 0.3751280605792999,
      "learning_rate": 0.0003747268170426065,
      "loss": 3.4663,
      "step": 50500
    },
    {
      "epoch": 1.3568521031207599,
      "grad_norm": 0.2671540379524231,
      "learning_rate": 0.0003734736842105263,
      "loss": 3.4666,
      "step": 51000
    },
    {
      "epoch": 1.370154574719983,
      "grad_norm": 0.4646991789340973,
      "learning_rate": 0.00037222055137844614,
      "loss": 3.4649,
      "step": 51500
    },
    {
      "epoch": 1.3834570463192062,
      "grad_norm": 0.26728636026382446,
      "learning_rate": 0.0003709674185463659,
      "loss": 3.4639,
      "step": 52000
    },
    {
      "epoch": 1.3834570463192062,
      "eval_loss": 3.3529365062713623,
      "eval_runtime": 25.2389,
      "eval_samples_per_second": 1981.065,
      "eval_steps_per_second": 7.766,
      "step": 52000
    },
    {
      "epoch": 1.3967595179184293,
      "grad_norm": 0.2759397327899933,
      "learning_rate": 0.0003697142857142857,
      "loss": 3.4619,
      "step": 52500
    },
    {
      "epoch": 1.4100619895176525,
      "grad_norm": 0.4341931939125061,
      "learning_rate": 0.0003684611528822055,
      "loss": 3.4594,
      "step": 53000
    },
    {
      "epoch": 1.4233644611168756,
      "grad_norm": 0.2855916917324066,
      "learning_rate": 0.00036720802005012535,
      "loss": 3.4597,
      "step": 53500
    },
    {
      "epoch": 1.4366669327160986,
      "grad_norm": 0.2792855203151703,
      "learning_rate": 0.0003659548872180451,
      "loss": 3.4583,
      "step": 54000
    },
    {
      "epoch": 1.4499694043153217,
      "grad_norm": 0.2501398026943207,
      "learning_rate": 0.00036470175438596493,
      "loss": 3.4579,
      "step": 54500
    },
    {
      "epoch": 1.4632718759145449,
      "grad_norm": 0.36696818470954895,
      "learning_rate": 0.0003634486215538847,
      "loss": 3.4557,
      "step": 55000
    },
    {
      "epoch": 1.476574347513768,
      "grad_norm": 0.2811378240585327,
      "learning_rate": 0.0003621979949874687,
      "loss": 3.4555,
      "step": 55500
    },
    {
      "epoch": 1.4898768191129912,
      "grad_norm": 0.4252370595932007,
      "learning_rate": 0.00036094736842105264,
      "loss": 3.4546,
      "step": 56000
    },
    {
      "epoch": 1.4898768191129912,
      "eval_loss": 3.3423285484313965,
      "eval_runtime": 25.4374,
      "eval_samples_per_second": 1965.612,
      "eval_steps_per_second": 7.705,
      "step": 56000
    },
    {
      "epoch": 1.5031792907122143,
      "grad_norm": 0.23901575803756714,
      "learning_rate": 0.0003596967418546366,
      "loss": 3.4527,
      "step": 56500
    },
    {
      "epoch": 1.5164817623114375,
      "grad_norm": 0.2778807282447815,
      "learning_rate": 0.0003584436090225564,
      "loss": 3.4521,
      "step": 57000
    },
    {
      "epoch": 1.5297842339106607,
      "grad_norm": 0.2693440914154053,
      "learning_rate": 0.00035719047619047617,
      "loss": 3.4495,
      "step": 57500
    },
    {
      "epoch": 1.5430867055098836,
      "grad_norm": 0.49423882365226746,
      "learning_rate": 0.000355937343358396,
      "loss": 3.4505,
      "step": 58000
    },
    {
      "epoch": 1.5563891771091067,
      "grad_norm": 0.5826532244682312,
      "learning_rate": 0.0003546842105263158,
      "loss": 3.4499,
      "step": 58500
    },
    {
      "epoch": 1.56969164870833,
      "grad_norm": 0.5497268438339233,
      "learning_rate": 0.0003534310776942356,
      "loss": 3.4473,
      "step": 59000
    },
    {
      "epoch": 1.582994120307553,
      "grad_norm": 0.26813313364982605,
      "learning_rate": 0.0003521779448621554,
      "loss": 3.4471,
      "step": 59500
    },
    {
      "epoch": 1.5962965919067762,
      "grad_norm": 0.3571546673774719,
      "learning_rate": 0.0003509248120300752,
      "loss": 3.4462,
      "step": 60000
    },
    {
      "epoch": 1.5962965919067762,
      "eval_loss": 3.333644151687622,
      "eval_runtime": 25.2649,
      "eval_samples_per_second": 1979.033,
      "eval_steps_per_second": 7.758,
      "step": 60000
    },
    {
      "epoch": 1.6095990635059994,
      "grad_norm": 0.2880757451057434,
      "learning_rate": 0.00034967167919799496,
      "loss": 3.445,
      "step": 60500
    },
    {
      "epoch": 1.6229015351052225,
      "grad_norm": 0.42054978013038635,
      "learning_rate": 0.0003484185463659148,
      "loss": 3.4443,
      "step": 61000
    },
    {
      "epoch": 1.6362040067044457,
      "grad_norm": 0.9109841585159302,
      "learning_rate": 0.0003471654135338346,
      "loss": 3.4427,
      "step": 61500
    },
    {
      "epoch": 1.6495064783036688,
      "grad_norm": 0.26019352674484253,
      "learning_rate": 0.0003459122807017544,
      "loss": 3.4426,
      "step": 62000
    },
    {
      "epoch": 1.662808949902892,
      "grad_norm": 0.3310074806213379,
      "learning_rate": 0.00034465914786967417,
      "loss": 3.4394,
      "step": 62500
    },
    {
      "epoch": 1.6761114215021151,
      "grad_norm": 0.42557188868522644,
      "learning_rate": 0.000343406015037594,
      "loss": 3.4395,
      "step": 63000
    },
    {
      "epoch": 1.6894138931013383,
      "grad_norm": 0.26434439420700073,
      "learning_rate": 0.00034215288220551375,
      "loss": 3.4378,
      "step": 63500
    },
    {
      "epoch": 1.7027163647005614,
      "grad_norm": 0.4317793548107147,
      "learning_rate": 0.0003408997493734336,
      "loss": 3.4372,
      "step": 64000
    },
    {
      "epoch": 1.7027163647005614,
      "eval_loss": 3.324815273284912,
      "eval_runtime": 25.3301,
      "eval_samples_per_second": 1973.933,
      "eval_steps_per_second": 7.738,
      "step": 64000
    },
    {
      "epoch": 1.7160188362997846,
      "grad_norm": 0.5231684446334839,
      "learning_rate": 0.0003396466165413534,
      "loss": 3.4368,
      "step": 64500
    },
    {
      "epoch": 1.7293213078990077,
      "grad_norm": 0.27441099286079407,
      "learning_rate": 0.0003383959899749374,
      "loss": 3.4366,
      "step": 65000
    },
    {
      "epoch": 1.7426237794982309,
      "grad_norm": 0.29825836420059204,
      "learning_rate": 0.00033714285714285714,
      "loss": 3.4324,
      "step": 65500
    },
    {
      "epoch": 1.755926251097454,
      "grad_norm": 0.23523648083209991,
      "learning_rate": 0.00033588972431077696,
      "loss": 3.433,
      "step": 66000
    },
    {
      "epoch": 1.7692287226966772,
      "grad_norm": 0.26561465859413147,
      "learning_rate": 0.0003346365914786967,
      "loss": 3.4309,
      "step": 66500
    },
    {
      "epoch": 1.7825311942959001,
      "grad_norm": 0.4052411615848541,
      "learning_rate": 0.0003333834586466166,
      "loss": 3.4318,
      "step": 67000
    },
    {
      "epoch": 1.7958336658951233,
      "grad_norm": 0.28120100498199463,
      "learning_rate": 0.0003321328320802005,
      "loss": 3.4315,
      "step": 67500
    },
    {
      "epoch": 1.8091361374943464,
      "grad_norm": 0.4598378837108612,
      "learning_rate": 0.0003308796992481203,
      "loss": 3.4293,
      "step": 68000
    },
    {
      "epoch": 1.8091361374943464,
      "eval_loss": 3.3174538612365723,
      "eval_runtime": 25.2876,
      "eval_samples_per_second": 1977.254,
      "eval_steps_per_second": 7.751,
      "step": 68000
    },
    {
      "epoch": 1.8224386090935696,
      "grad_norm": 0.5189847946166992,
      "learning_rate": 0.0003296265664160401,
      "loss": 3.4288,
      "step": 68500
    },
    {
      "epoch": 1.8357410806927927,
      "grad_norm": 0.34797659516334534,
      "learning_rate": 0.0003283734335839599,
      "loss": 3.4281,
      "step": 69000
    },
    {
      "epoch": 1.849043552292016,
      "grad_norm": 0.47975778579711914,
      "learning_rate": 0.0003271228070175439,
      "loss": 3.428,
      "step": 69500
    },
    {
      "epoch": 1.862346023891239,
      "grad_norm": 0.2584032118320465,
      "learning_rate": 0.00032586967418546365,
      "loss": 3.4253,
      "step": 70000
    },
    {
      "epoch": 1.875648495490462,
      "grad_norm": 0.29241105914115906,
      "learning_rate": 0.00032461654135338346,
      "loss": 3.4251,
      "step": 70500
    },
    {
      "epoch": 1.8889509670896851,
      "grad_norm": 0.2614300847053528,
      "learning_rate": 0.0003233634085213032,
      "loss": 3.4232,
      "step": 71000
    },
    {
      "epoch": 1.9022534386889083,
      "grad_norm": 0.32762327790260315,
      "learning_rate": 0.0003221102756892231,
      "loss": 3.4234,
      "step": 71500
    },
    {
      "epoch": 1.9155559102881314,
      "grad_norm": 0.256344735622406,
      "learning_rate": 0.000320859649122807,
      "loss": 3.4217,
      "step": 72000
    },
    {
      "epoch": 1.9155559102881314,
      "eval_loss": 3.310128688812256,
      "eval_runtime": 25.3012,
      "eval_samples_per_second": 1976.19,
      "eval_steps_per_second": 7.747,
      "step": 72000
    },
    {
      "epoch": 1.9288583818873546,
      "grad_norm": 0.2743394374847412,
      "learning_rate": 0.00031960651629072686,
      "loss": 3.4215,
      "step": 72500
    },
    {
      "epoch": 1.9421608534865777,
      "grad_norm": 0.25391560792922974,
      "learning_rate": 0.0003183558897243108,
      "loss": 3.4233,
      "step": 73000
    },
    {
      "epoch": 1.955463325085801,
      "grad_norm": 0.27643394470214844,
      "learning_rate": 0.0003171027568922306,
      "loss": 3.42,
      "step": 73500
    },
    {
      "epoch": 1.968765796685024,
      "grad_norm": 0.27267616987228394,
      "learning_rate": 0.0003158496240601504,
      "loss": 3.4192,
      "step": 74000
    },
    {
      "epoch": 1.9820682682842472,
      "grad_norm": 0.4753129482269287,
      "learning_rate": 0.00031459649122807015,
      "loss": 3.4177,
      "step": 74500
    },
    {
      "epoch": 1.9953707398834704,
      "grad_norm": 0.6157755851745605,
      "learning_rate": 0.00031334335839598997,
      "loss": 3.4165,
      "step": 75000
    },
    {
      "epoch": 2.0086732114826935,
      "grad_norm": 0.2707383930683136,
      "learning_rate": 0.0003120902255639098,
      "loss": 3.4152,
      "step": 75500
    },
    {
      "epoch": 2.0219756830819167,
      "grad_norm": 0.34442028403282166,
      "learning_rate": 0.0003108370927318296,
      "loss": 3.4129,
      "step": 76000
    },
    {
      "epoch": 2.0219756830819167,
      "eval_loss": 3.3053231239318848,
      "eval_runtime": 25.2026,
      "eval_samples_per_second": 1983.922,
      "eval_steps_per_second": 7.777,
      "step": 76000
    },
    {
      "epoch": 2.03527815468114,
      "grad_norm": 0.28950968384742737,
      "learning_rate": 0.00030958395989974936,
      "loss": 3.4126,
      "step": 76500
    },
    {
      "epoch": 2.048580626280363,
      "grad_norm": 0.42443516850471497,
      "learning_rate": 0.00030833333333333337,
      "loss": 3.4129,
      "step": 77000
    },
    {
      "epoch": 2.061883097879586,
      "grad_norm": 0.2693597376346588,
      "learning_rate": 0.0003070802005012531,
      "loss": 3.4122,
      "step": 77500
    },
    {
      "epoch": 2.0751855694788093,
      "grad_norm": 0.6083993911743164,
      "learning_rate": 0.00030582706766917294,
      "loss": 3.4116,
      "step": 78000
    },
    {
      "epoch": 2.0884880410780324,
      "grad_norm": 0.535813570022583,
      "learning_rate": 0.0003045739348370927,
      "loss": 3.4107,
      "step": 78500
    },
    {
      "epoch": 2.1017905126772556,
      "grad_norm": 0.26231569051742554,
      "learning_rate": 0.0003033233082706767,
      "loss": 3.4106,
      "step": 79000
    },
    {
      "epoch": 2.1150929842764787,
      "grad_norm": 0.3205699324607849,
      "learning_rate": 0.00030207017543859647,
      "loss": 3.408,
      "step": 79500
    },
    {
      "epoch": 2.128395455875702,
      "grad_norm": 0.2962183356285095,
      "learning_rate": 0.00030081704260651634,
      "loss": 3.4088,
      "step": 80000
    },
    {
      "epoch": 2.128395455875702,
      "eval_loss": 3.2957634925842285,
      "eval_runtime": 25.2686,
      "eval_samples_per_second": 1978.739,
      "eval_steps_per_second": 7.757,
      "step": 80000
    },
    {
      "epoch": 2.141697927474925,
      "grad_norm": 0.250149667263031,
      "learning_rate": 0.0002995639097744361,
      "loss": 3.4082,
      "step": 80500
    },
    {
      "epoch": 2.155000399074148,
      "grad_norm": 0.2417747527360916,
      "learning_rate": 0.0002983107769423559,
      "loss": 3.4072,
      "step": 81000
    },
    {
      "epoch": 2.168302870673371,
      "grad_norm": 0.5906438231468201,
      "learning_rate": 0.0002970576441102757,
      "loss": 3.4059,
      "step": 81500
    },
    {
      "epoch": 2.181605342272594,
      "grad_norm": 0.4341309666633606,
      "learning_rate": 0.0002958045112781955,
      "loss": 3.4045,
      "step": 82000
    },
    {
      "epoch": 2.194907813871817,
      "grad_norm": 0.27886372804641724,
      "learning_rate": 0.0002945513784461153,
      "loss": 3.404,
      "step": 82500
    },
    {
      "epoch": 2.2082102854710404,
      "grad_norm": 0.28571629524230957,
      "learning_rate": 0.00029329824561403513,
      "loss": 3.4032,
      "step": 83000
    },
    {
      "epoch": 2.2215127570702635,
      "grad_norm": 0.637180507183075,
      "learning_rate": 0.0002920451127819549,
      "loss": 3.4047,
      "step": 83500
    },
    {
      "epoch": 2.2348152286694867,
      "grad_norm": 0.3336406648159027,
      "learning_rate": 0.0002907919799498747,
      "loss": 3.4032,
      "step": 84000
    },
    {
      "epoch": 2.2348152286694867,
      "eval_loss": 3.289689064025879,
      "eval_runtime": 25.4201,
      "eval_samples_per_second": 1966.95,
      "eval_steps_per_second": 7.71,
      "step": 84000
    },
    {
      "epoch": 2.24811770026871,
      "grad_norm": 0.2734309136867523,
      "learning_rate": 0.00028953884711779447,
      "loss": 3.4023,
      "step": 84500
    },
    {
      "epoch": 2.261420171867933,
      "grad_norm": 0.3662182688713074,
      "learning_rate": 0.00028828571428571434,
      "loss": 3.4022,
      "step": 85000
    },
    {
      "epoch": 2.274722643467156,
      "grad_norm": 0.2936663031578064,
      "learning_rate": 0.0002870325814536341,
      "loss": 3.4002,
      "step": 85500
    },
    {
      "epoch": 2.2880251150663793,
      "grad_norm": 0.2448946088552475,
      "learning_rate": 0.0002857794486215539,
      "loss": 3.3998,
      "step": 86000
    },
    {
      "epoch": 2.3013275866656024,
      "grad_norm": 0.2212468534708023,
      "learning_rate": 0.0002845263157894737,
      "loss": 3.4005,
      "step": 86500
    },
    {
      "epoch": 2.3146300582648256,
      "grad_norm": 0.44185131788253784,
      "learning_rate": 0.0002832731829573935,
      "loss": 3.4003,
      "step": 87000
    },
    {
      "epoch": 2.3279325298640487,
      "grad_norm": 0.2310268133878708,
      "learning_rate": 0.0002820200501253133,
      "loss": 3.3978,
      "step": 87500
    },
    {
      "epoch": 2.341235001463272,
      "grad_norm": 0.23246900737285614,
      "learning_rate": 0.0002807669172932331,
      "loss": 3.3988,
      "step": 88000
    },
    {
      "epoch": 2.341235001463272,
      "eval_loss": 3.2847540378570557,
      "eval_runtime": 25.2467,
      "eval_samples_per_second": 1980.458,
      "eval_steps_per_second": 7.763,
      "step": 88000
    },
    {
      "epoch": 2.354537473062495,
      "grad_norm": 0.5488669276237488,
      "learning_rate": 0.0002795137844611529,
      "loss": 3.397,
      "step": 88500
    },
    {
      "epoch": 2.367839944661718,
      "grad_norm": 0.2371227890253067,
      "learning_rate": 0.0002782606516290727,
      "loss": 3.3957,
      "step": 89000
    },
    {
      "epoch": 2.3811424162609414,
      "grad_norm": 0.3260801434516907,
      "learning_rate": 0.00027700751879699247,
      "loss": 3.3964,
      "step": 89500
    },
    {
      "epoch": 2.3944448878601645,
      "grad_norm": 0.2366471141576767,
      "learning_rate": 0.00027575438596491234,
      "loss": 3.3952,
      "step": 90000
    },
    {
      "epoch": 2.4077473594593877,
      "grad_norm": 0.341370165348053,
      "learning_rate": 0.00027450375939849623,
      "loss": 3.3917,
      "step": 90500
    },
    {
      "epoch": 2.421049831058611,
      "grad_norm": 0.23042230308055878,
      "learning_rate": 0.00027325062656641605,
      "loss": 3.3923,
      "step": 91000
    },
    {
      "epoch": 2.434352302657834,
      "grad_norm": 0.23229840397834778,
      "learning_rate": 0.00027199749373433586,
      "loss": 3.3917,
      "step": 91500
    },
    {
      "epoch": 2.447654774257057,
      "grad_norm": 0.5662930607795715,
      "learning_rate": 0.0002707443609022556,
      "loss": 3.394,
      "step": 92000
    },
    {
      "epoch": 2.447654774257057,
      "eval_loss": 3.2793078422546387,
      "eval_runtime": 25.4118,
      "eval_samples_per_second": 1967.586,
      "eval_steps_per_second": 7.713,
      "step": 92000
    },
    {
      "epoch": 2.4609572458562803,
      "grad_norm": 0.27042654156684875,
      "learning_rate": 0.00026949373433583963,
      "loss": 3.3924,
      "step": 92500
    },
    {
      "epoch": 2.474259717455503,
      "grad_norm": 0.2605212330818176,
      "learning_rate": 0.0002682406015037594,
      "loss": 3.3899,
      "step": 93000
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 0.4914969205856323,
      "learning_rate": 0.0002669874686716792,
      "loss": 3.3894,
      "step": 93500
    },
    {
      "epoch": 2.5008646606539493,
      "grad_norm": 0.4740413725376129,
      "learning_rate": 0.00026573433583959897,
      "loss": 3.3903,
      "step": 94000
    },
    {
      "epoch": 2.5141671322531725,
      "grad_norm": 0.2402483969926834,
      "learning_rate": 0.0002644837092731829,
      "loss": 3.3882,
      "step": 94500
    },
    {
      "epoch": 2.5274696038523956,
      "grad_norm": 0.5107657313346863,
      "learning_rate": 0.0002632305764411028,
      "loss": 3.3882,
      "step": 95000
    },
    {
      "epoch": 2.5407720754516188,
      "grad_norm": 0.25569382309913635,
      "learning_rate": 0.00026197744360902255,
      "loss": 3.3873,
      "step": 95500
    },
    {
      "epoch": 2.554074547050842,
      "grad_norm": 0.436981737613678,
      "learning_rate": 0.00026072431077694237,
      "loss": 3.3848,
      "step": 96000
    },
    {
      "epoch": 2.554074547050842,
      "eval_loss": 3.2733325958251953,
      "eval_runtime": 25.1899,
      "eval_samples_per_second": 1984.922,
      "eval_steps_per_second": 7.781,
      "step": 96000
    },
    {
      "epoch": 2.567377018650065,
      "grad_norm": 0.3246544599533081,
      "learning_rate": 0.0002594736842105263,
      "loss": 3.3868,
      "step": 96500
    },
    {
      "epoch": 2.580679490249288,
      "grad_norm": 0.28632423281669617,
      "learning_rate": 0.00025822055137844613,
      "loss": 3.3844,
      "step": 97000
    },
    {
      "epoch": 2.5939819618485114,
      "grad_norm": 0.40223896503448486,
      "learning_rate": 0.0002569674185463659,
      "loss": 3.3865,
      "step": 97500
    },
    {
      "epoch": 2.6072844334477345,
      "grad_norm": 0.5338722467422485,
      "learning_rate": 0.0002557167919799499,
      "loss": 3.3844,
      "step": 98000
    },
    {
      "epoch": 2.6205869050469577,
      "grad_norm": 0.2521054446697235,
      "learning_rate": 0.00025446365914786966,
      "loss": 3.3827,
      "step": 98500
    },
    {
      "epoch": 2.633889376646181,
      "grad_norm": 0.23231817781925201,
      "learning_rate": 0.0002532105263157895,
      "loss": 3.3811,
      "step": 99000
    },
    {
      "epoch": 2.647191848245404,
      "grad_norm": 0.27779480814933777,
      "learning_rate": 0.0002519573934837093,
      "loss": 3.3835,
      "step": 99500
    },
    {
      "epoch": 2.660494319844627,
      "grad_norm": 0.2641790807247162,
      "learning_rate": 0.0002507042606516291,
      "loss": 3.38,
      "step": 100000
    },
    {
      "epoch": 2.660494319844627,
      "eval_loss": 3.269312858581543,
      "eval_runtime": 25.5055,
      "eval_samples_per_second": 1960.362,
      "eval_steps_per_second": 7.685,
      "step": 100000
    },
    {
      "epoch": 2.6737967914438503,
      "grad_norm": 0.25996941328048706,
      "learning_rate": 0.00024945112781954887,
      "loss": 3.3799,
      "step": 100500
    },
    {
      "epoch": 2.6870992630430734,
      "grad_norm": 0.2524474263191223,
      "learning_rate": 0.0002481979949874687,
      "loss": 3.3806,
      "step": 101000
    },
    {
      "epoch": 2.7004017346422966,
      "grad_norm": 0.28802672028541565,
      "learning_rate": 0.00024694486215538845,
      "loss": 3.38,
      "step": 101500
    },
    {
      "epoch": 2.7137042062415198,
      "grad_norm": 0.659436821937561,
      "learning_rate": 0.00024569423558897245,
      "loss": 3.3791,
      "step": 102000
    },
    {
      "epoch": 2.727006677840743,
      "grad_norm": 0.39550453424453735,
      "learning_rate": 0.00024444110275689227,
      "loss": 3.3791,
      "step": 102500
    },
    {
      "epoch": 2.740309149439966,
      "grad_norm": 0.2212180346250534,
      "learning_rate": 0.00024318796992481203,
      "loss": 3.3774,
      "step": 103000
    },
    {
      "epoch": 2.753611621039189,
      "grad_norm": 0.3481553792953491,
      "learning_rate": 0.00024193483709273185,
      "loss": 3.3777,
      "step": 103500
    },
    {
      "epoch": 2.7669140926384124,
      "grad_norm": 0.22783911228179932,
      "learning_rate": 0.00024068671679197996,
      "loss": 3.3772,
      "step": 104000
    },
    {
      "epoch": 2.7669140926384124,
      "eval_loss": 3.264195203781128,
      "eval_runtime": 25.5106,
      "eval_samples_per_second": 1959.971,
      "eval_steps_per_second": 7.683,
      "step": 104000
    },
    {
      "epoch": 2.7802165642376355,
      "grad_norm": 0.23330433666706085,
      "learning_rate": 0.00023943358395989975,
      "loss": 3.3762,
      "step": 104500
    },
    {
      "epoch": 2.7935190358368587,
      "grad_norm": 0.23920562863349915,
      "learning_rate": 0.00023818045112781956,
      "loss": 3.3747,
      "step": 105000
    },
    {
      "epoch": 2.806821507436082,
      "grad_norm": 0.32594484090805054,
      "learning_rate": 0.00023692731829573935,
      "loss": 3.3757,
      "step": 105500
    },
    {
      "epoch": 2.820123979035305,
      "grad_norm": 0.253113329410553,
      "learning_rate": 0.00023567418546365914,
      "loss": 3.3742,
      "step": 106000
    },
    {
      "epoch": 2.833426450634528,
      "grad_norm": 0.24136416614055634,
      "learning_rate": 0.00023442105263157896,
      "loss": 3.3749,
      "step": 106500
    },
    {
      "epoch": 2.8467289222337513,
      "grad_norm": 0.30698105692863464,
      "learning_rate": 0.00023316791979949875,
      "loss": 3.3756,
      "step": 107000
    },
    {
      "epoch": 2.860031393832974,
      "grad_norm": 0.3451573848724365,
      "learning_rate": 0.00023191478696741856,
      "loss": 3.373,
      "step": 107500
    },
    {
      "epoch": 2.873333865432197,
      "grad_norm": 0.34948238730430603,
      "learning_rate": 0.0002306641604010025,
      "loss": 3.3744,
      "step": 108000
    },
    {
      "epoch": 2.873333865432197,
      "eval_loss": 3.259918689727783,
      "eval_runtime": 25.5099,
      "eval_samples_per_second": 1960.027,
      "eval_steps_per_second": 7.683,
      "step": 108000
    },
    {
      "epoch": 2.8866363370314203,
      "grad_norm": 0.37804096937179565,
      "learning_rate": 0.00022941102756892233,
      "loss": 3.3718,
      "step": 108500
    },
    {
      "epoch": 2.8999388086306435,
      "grad_norm": 0.27575477957725525,
      "learning_rate": 0.00022815789473684212,
      "loss": 3.3713,
      "step": 109000
    },
    {
      "epoch": 2.9132412802298666,
      "grad_norm": 0.2615892291069031,
      "learning_rate": 0.00022690476190476193,
      "loss": 3.3722,
      "step": 109500
    },
    {
      "epoch": 2.9265437518290898,
      "grad_norm": 0.40528959035873413,
      "learning_rate": 0.00022565162907268172,
      "loss": 3.3703,
      "step": 110000
    },
    {
      "epoch": 2.939846223428313,
      "grad_norm": 0.41514942049980164,
      "learning_rate": 0.00022440100250626567,
      "loss": 3.3698,
      "step": 110500
    },
    {
      "epoch": 2.953148695027536,
      "grad_norm": 0.25518515706062317,
      "learning_rate": 0.00022314786967418546,
      "loss": 3.3699,
      "step": 111000
    },
    {
      "epoch": 2.9664511666267592,
      "grad_norm": 0.24427974224090576,
      "learning_rate": 0.00022189473684210525,
      "loss": 3.3687,
      "step": 111500
    },
    {
      "epoch": 2.9797536382259824,
      "grad_norm": 0.25995293259620667,
      "learning_rate": 0.00022064160401002506,
      "loss": 3.3684,
      "step": 112000
    },
    {
      "epoch": 2.9797536382259824,
      "eval_loss": 3.255312442779541,
      "eval_runtime": 25.3391,
      "eval_samples_per_second": 1973.233,
      "eval_steps_per_second": 7.735,
      "step": 112000
    },
    {
      "epoch": 2.9930561098252055,
      "grad_norm": 0.34006261825561523,
      "learning_rate": 0.0002193934837092732,
      "loss": 3.3672,
      "step": 112500
    },
    {
      "epoch": 3.0063585814244287,
      "grad_norm": 0.2920742630958557,
      "learning_rate": 0.000218140350877193,
      "loss": 3.3662,
      "step": 113000
    },
    {
      "epoch": 3.019661053023652,
      "grad_norm": 0.3434138000011444,
      "learning_rate": 0.0002168872180451128,
      "loss": 3.3642,
      "step": 113500
    },
    {
      "epoch": 3.032963524622875,
      "grad_norm": 0.3365243375301361,
      "learning_rate": 0.0002156340852130326,
      "loss": 3.3637,
      "step": 114000
    },
    {
      "epoch": 3.046265996222098,
      "grad_norm": 0.560724139213562,
      "learning_rate": 0.0002143809523809524,
      "loss": 3.3629,
      "step": 114500
    },
    {
      "epoch": 3.0595684678213213,
      "grad_norm": 0.3431175947189331,
      "learning_rate": 0.0002131278195488722,
      "loss": 3.3639,
      "step": 115000
    },
    {
      "epoch": 3.0728709394205445,
      "grad_norm": 0.41147586703300476,
      "learning_rate": 0.000211874686716792,
      "loss": 3.3624,
      "step": 115500
    },
    {
      "epoch": 3.0861734110197676,
      "grad_norm": 0.43880322575569153,
      "learning_rate": 0.0002106215538847118,
      "loss": 3.3647,
      "step": 116000
    },
    {
      "epoch": 3.0861734110197676,
      "eval_loss": 3.250683069229126,
      "eval_runtime": 25.1877,
      "eval_samples_per_second": 1985.093,
      "eval_steps_per_second": 7.782,
      "step": 116000
    },
    {
      "epoch": 3.0994758826189908,
      "grad_norm": 0.2918992042541504,
      "learning_rate": 0.0002093684210526316,
      "loss": 3.3645,
      "step": 116500
    },
    {
      "epoch": 3.112778354218214,
      "grad_norm": 0.26954224705696106,
      "learning_rate": 0.00020811779448621554,
      "loss": 3.3622,
      "step": 117000
    },
    {
      "epoch": 3.126080825817437,
      "grad_norm": 0.28908824920654297,
      "learning_rate": 0.00020686466165413533,
      "loss": 3.3614,
      "step": 117500
    },
    {
      "epoch": 3.1393832974166602,
      "grad_norm": 0.3571993410587311,
      "learning_rate": 0.0002056140350877193,
      "loss": 3.3607,
      "step": 118000
    },
    {
      "epoch": 3.152685769015883,
      "grad_norm": 0.255942165851593,
      "learning_rate": 0.0002043609022556391,
      "loss": 3.3589,
      "step": 118500
    },
    {
      "epoch": 3.165988240615106,
      "grad_norm": 0.24093200266361237,
      "learning_rate": 0.00020310776942355892,
      "loss": 3.36,
      "step": 119000
    },
    {
      "epoch": 3.1792907122143292,
      "grad_norm": 0.26851409673690796,
      "learning_rate": 0.0002018546365914787,
      "loss": 3.359,
      "step": 119500
    },
    {
      "epoch": 3.1925931838135524,
      "grad_norm": 0.2757109999656677,
      "learning_rate": 0.0002006015037593985,
      "loss": 3.3578,
      "step": 120000
    },
    {
      "epoch": 3.1925931838135524,
      "eval_loss": 3.246619462966919,
      "eval_runtime": 25.2619,
      "eval_samples_per_second": 1979.264,
      "eval_steps_per_second": 7.759,
      "step": 120000
    },
    {
      "epoch": 3.2058956554127755,
      "grad_norm": 0.2668735682964325,
      "learning_rate": 0.0001993483709273183,
      "loss": 3.3574,
      "step": 120500
    },
    {
      "epoch": 3.2191981270119987,
      "grad_norm": 0.2646730840206146,
      "learning_rate": 0.0001980952380952381,
      "loss": 3.3569,
      "step": 121000
    },
    {
      "epoch": 3.232500598611222,
      "grad_norm": 0.29748594760894775,
      "learning_rate": 0.00019684210526315791,
      "loss": 3.3576,
      "step": 121500
    },
    {
      "epoch": 3.245803070210445,
      "grad_norm": 0.2343696653842926,
      "learning_rate": 0.00019559147869674184,
      "loss": 3.3593,
      "step": 122000
    },
    {
      "epoch": 3.259105541809668,
      "grad_norm": 0.21500886976718903,
      "learning_rate": 0.00019433834586466165,
      "loss": 3.358,
      "step": 122500
    },
    {
      "epoch": 3.2724080134088913,
      "grad_norm": 0.2833521366119385,
      "learning_rate": 0.00019308521303258144,
      "loss": 3.3562,
      "step": 123000
    },
    {
      "epoch": 3.2857104850081145,
      "grad_norm": 0.23846858739852905,
      "learning_rate": 0.00019183208020050126,
      "loss": 3.3562,
      "step": 123500
    },
    {
      "epoch": 3.2990129566073376,
      "grad_norm": 0.24399632215499878,
      "learning_rate": 0.00019057894736842105,
      "loss": 3.3556,
      "step": 124000
    },
    {
      "epoch": 3.2990129566073376,
      "eval_loss": 3.2425405979156494,
      "eval_runtime": 25.4844,
      "eval_samples_per_second": 1961.981,
      "eval_steps_per_second": 7.691,
      "step": 124000
    },
    {
      "epoch": 3.3123154282065608,
      "grad_norm": 0.22912035882472992,
      "learning_rate": 0.00018932581453634084,
      "loss": 3.3562,
      "step": 124500
    },
    {
      "epoch": 3.325617899805784,
      "grad_norm": 0.3270147442817688,
      "learning_rate": 0.00018807268170426065,
      "loss": 3.3536,
      "step": 125000
    },
    {
      "epoch": 3.338920371405007,
      "grad_norm": 0.24757544696331024,
      "learning_rate": 0.00018681954887218044,
      "loss": 3.3547,
      "step": 125500
    },
    {
      "epoch": 3.3522228430042302,
      "grad_norm": 0.2647550106048584,
      "learning_rate": 0.00018556641604010026,
      "loss": 3.354,
      "step": 126000
    },
    {
      "epoch": 3.3655253146034534,
      "grad_norm": 0.3819441497325897,
      "learning_rate": 0.0001843157894736842,
      "loss": 3.3518,
      "step": 126500
    },
    {
      "epoch": 3.3788277862026765,
      "grad_norm": 0.24086584150791168,
      "learning_rate": 0.00018306516290726818,
      "loss": 3.351,
      "step": 127000
    },
    {
      "epoch": 3.3921302578018997,
      "grad_norm": 0.22356143593788147,
      "learning_rate": 0.00018181203007518797,
      "loss": 3.3531,
      "step": 127500
    },
    {
      "epoch": 3.405432729401123,
      "grad_norm": 0.28856775164604187,
      "learning_rate": 0.0001805588972431078,
      "loss": 3.3551,
      "step": 128000
    },
    {
      "epoch": 3.405432729401123,
      "eval_loss": 3.239164113998413,
      "eval_runtime": 25.2159,
      "eval_samples_per_second": 1982.873,
      "eval_steps_per_second": 7.773,
      "step": 128000
    },
    {
      "epoch": 3.418735201000346,
      "grad_norm": 0.2226177304983139,
      "learning_rate": 0.00017930576441102758,
      "loss": 3.3511,
      "step": 128500
    },
    {
      "epoch": 3.432037672599569,
      "grad_norm": 0.2515501081943512,
      "learning_rate": 0.0001780526315789474,
      "loss": 3.3512,
      "step": 129000
    },
    {
      "epoch": 3.4453401441987923,
      "grad_norm": 0.2793140709400177,
      "learning_rate": 0.00017679949874686718,
      "loss": 3.3505,
      "step": 129500
    },
    {
      "epoch": 3.4586426157980155,
      "grad_norm": 0.22557666897773743,
      "learning_rate": 0.00017554636591478697,
      "loss": 3.3508,
      "step": 130000
    },
    {
      "epoch": 3.4719450873972386,
      "grad_norm": 0.24880404770374298,
      "learning_rate": 0.0001742932330827068,
      "loss": 3.3503,
      "step": 130500
    },
    {
      "epoch": 3.4852475589964618,
      "grad_norm": 0.47502508759498596,
      "learning_rate": 0.00017304010025062658,
      "loss": 3.3491,
      "step": 131000
    },
    {
      "epoch": 3.498550030595685,
      "grad_norm": 0.22407376766204834,
      "learning_rate": 0.0001717869674185464,
      "loss": 3.3499,
      "step": 131500
    },
    {
      "epoch": 3.511852502194908,
      "grad_norm": 0.24884983897209167,
      "learning_rate": 0.0001705388471177945,
      "loss": 3.3492,
      "step": 132000
    },
    {
      "epoch": 3.511852502194908,
      "eval_loss": 3.236098051071167,
      "eval_runtime": 25.2388,
      "eval_samples_per_second": 1981.076,
      "eval_steps_per_second": 7.766,
      "step": 132000
    },
    {
      "epoch": 3.525154973794131,
      "grad_norm": 0.30391398072242737,
      "learning_rate": 0.0001692857142857143,
      "loss": 3.3455,
      "step": 132500
    },
    {
      "epoch": 3.538457445393354,
      "grad_norm": 0.23840080201625824,
      "learning_rate": 0.00016803258145363408,
      "loss": 3.348,
      "step": 133000
    },
    {
      "epoch": 3.551759916992577,
      "grad_norm": 0.21890893578529358,
      "learning_rate": 0.0001667794486215539,
      "loss": 3.3472,
      "step": 133500
    },
    {
      "epoch": 3.5650623885918002,
      "grad_norm": 0.2562108635902405,
      "learning_rate": 0.00016552631578947369,
      "loss": 3.3488,
      "step": 134000
    },
    {
      "epoch": 3.5783648601910234,
      "grad_norm": 0.29540982842445374,
      "learning_rate": 0.0001642731829573935,
      "loss": 3.3488,
      "step": 134500
    },
    {
      "epoch": 3.5916673317902466,
      "grad_norm": 0.25860655307769775,
      "learning_rate": 0.0001630200501253133,
      "loss": 3.3447,
      "step": 135000
    },
    {
      "epoch": 3.6049698033894697,
      "grad_norm": 0.2519228458404541,
      "learning_rate": 0.00016176691729323308,
      "loss": 3.3464,
      "step": 135500
    },
    {
      "epoch": 3.618272274988693,
      "grad_norm": 0.2377224862575531,
      "learning_rate": 0.0001605137844611529,
      "loss": 3.3459,
      "step": 136000
    },
    {
      "epoch": 3.618272274988693,
      "eval_loss": 3.232142448425293,
      "eval_runtime": 25.2018,
      "eval_samples_per_second": 1983.983,
      "eval_steps_per_second": 7.777,
      "step": 136000
    },
    {
      "epoch": 3.631574746587916,
      "grad_norm": 0.23865604400634766,
      "learning_rate": 0.00015926315789473682,
      "loss": 3.3451,
      "step": 136500
    },
    {
      "epoch": 3.644877218187139,
      "grad_norm": 0.22600345313549042,
      "learning_rate": 0.00015801002506265663,
      "loss": 3.3429,
      "step": 137000
    },
    {
      "epoch": 3.6581796897863623,
      "grad_norm": 0.21724927425384521,
      "learning_rate": 0.00015675689223057642,
      "loss": 3.3447,
      "step": 137500
    },
    {
      "epoch": 3.6714821613855855,
      "grad_norm": 0.2693677246570587,
      "learning_rate": 0.00015550375939849624,
      "loss": 3.3436,
      "step": 138000
    },
    {
      "epoch": 3.6847846329848086,
      "grad_norm": 0.25258690118789673,
      "learning_rate": 0.0001542531328320802,
      "loss": 3.3434,
      "step": 138500
    },
    {
      "epoch": 3.698087104584032,
      "grad_norm": 0.2251686453819275,
      "learning_rate": 0.000153,
      "loss": 3.3421,
      "step": 139000
    },
    {
      "epoch": 3.711389576183255,
      "grad_norm": 0.2988027036190033,
      "learning_rate": 0.0001517468671679198,
      "loss": 3.3426,
      "step": 139500
    },
    {
      "epoch": 3.724692047782478,
      "grad_norm": 0.2419222593307495,
      "learning_rate": 0.00015049624060150377,
      "loss": 3.341,
      "step": 140000
    },
    {
      "epoch": 3.724692047782478,
      "eval_loss": 3.2286791801452637,
      "eval_runtime": 25.4022,
      "eval_samples_per_second": 1968.334,
      "eval_steps_per_second": 7.716,
      "step": 140000
    },
    {
      "epoch": 3.7379945193817012,
      "grad_norm": 0.2703106999397278,
      "learning_rate": 0.00014924310776942356,
      "loss": 3.3422,
      "step": 140500
    },
    {
      "epoch": 3.7512969909809244,
      "grad_norm": 0.25987863540649414,
      "learning_rate": 0.00014798997493734338,
      "loss": 3.3423,
      "step": 141000
    },
    {
      "epoch": 3.7645994625801475,
      "grad_norm": 0.2676261365413666,
      "learning_rate": 0.00014673684210526317,
      "loss": 3.34,
      "step": 141500
    },
    {
      "epoch": 3.7779019341793703,
      "grad_norm": 0.2569693922996521,
      "learning_rate": 0.00014548370927318298,
      "loss": 3.341,
      "step": 142000
    },
    {
      "epoch": 3.7912044057785934,
      "grad_norm": 0.29593098163604736,
      "learning_rate": 0.00014423057644110277,
      "loss": 3.3393,
      "step": 142500
    },
    {
      "epoch": 3.8045068773778166,
      "grad_norm": 0.3124125003814697,
      "learning_rate": 0.00014297744360902256,
      "loss": 3.3392,
      "step": 143000
    },
    {
      "epoch": 3.8178093489770397,
      "grad_norm": 0.22824329137802124,
      "learning_rate": 0.00014172431077694238,
      "loss": 3.3394,
      "step": 143500
    },
    {
      "epoch": 3.831111820576263,
      "grad_norm": 0.24051257967948914,
      "learning_rate": 0.0001404736842105263,
      "loss": 3.3402,
      "step": 144000
    },
    {
      "epoch": 3.831111820576263,
      "eval_loss": 3.2252037525177,
      "eval_runtime": 25.2122,
      "eval_samples_per_second": 1983.167,
      "eval_steps_per_second": 7.774,
      "step": 144000
    },
    {
      "epoch": 3.844414292175486,
      "grad_norm": 0.219036266207695,
      "learning_rate": 0.00013922305764411027,
      "loss": 3.3406,
      "step": 144500
    },
    {
      "epoch": 3.857716763774709,
      "grad_norm": 0.23273685574531555,
      "learning_rate": 0.0001379699248120301,
      "loss": 3.3361,
      "step": 145000
    },
    {
      "epoch": 3.8710192353739323,
      "grad_norm": 0.25578707456588745,
      "learning_rate": 0.00013671679197994988,
      "loss": 3.3381,
      "step": 145500
    },
    {
      "epoch": 3.8843217069731555,
      "grad_norm": 0.31603333353996277,
      "learning_rate": 0.00013546365914786967,
      "loss": 3.3374,
      "step": 146000
    },
    {
      "epoch": 3.8976241785723786,
      "grad_norm": 0.229444220662117,
      "learning_rate": 0.00013421052631578948,
      "loss": 3.3366,
      "step": 146500
    },
    {
      "epoch": 3.910926650171602,
      "grad_norm": 0.30753111839294434,
      "learning_rate": 0.00013295989974937343,
      "loss": 3.3372,
      "step": 147000
    },
    {
      "epoch": 3.924229121770825,
      "grad_norm": 0.2563047409057617,
      "learning_rate": 0.00013170676691729325,
      "loss": 3.3356,
      "step": 147500
    },
    {
      "epoch": 3.937531593370048,
      "grad_norm": 0.22426699101924896,
      "learning_rate": 0.0001304561403508772,
      "loss": 3.3347,
      "step": 148000
    },
    {
      "epoch": 3.937531593370048,
      "eval_loss": 3.2225708961486816,
      "eval_runtime": 25.2321,
      "eval_samples_per_second": 1981.603,
      "eval_steps_per_second": 7.768,
      "step": 148000
    },
    {
      "epoch": 3.9508340649692713,
      "grad_norm": 0.2533152103424072,
      "learning_rate": 0.00012920551378446115,
      "loss": 3.3344,
      "step": 148500
    },
    {
      "epoch": 3.9641365365684944,
      "grad_norm": 0.22225719690322876,
      "learning_rate": 0.00012795238095238097,
      "loss": 3.3374,
      "step": 149000
    },
    {
      "epoch": 3.9774390081677176,
      "grad_norm": 0.23985525965690613,
      "learning_rate": 0.00012669924812030076,
      "loss": 3.3345,
      "step": 149500
    },
    {
      "epoch": 3.9907414797669407,
      "grad_norm": 0.269557923078537,
      "learning_rate": 0.00012544611528822057,
      "loss": 3.3336,
      "step": 150000
    },
    {
      "epoch": 4.004043951366164,
      "grad_norm": 0.27507418394088745,
      "learning_rate": 0.00012419298245614036,
      "loss": 3.3322,
      "step": 150500
    },
    {
      "epoch": 4.017346422965387,
      "grad_norm": 0.2206943780183792,
      "learning_rate": 0.00012293984962406015,
      "loss": 3.331,
      "step": 151000
    },
    {
      "epoch": 4.03064889456461,
      "grad_norm": 0.2571825087070465,
      "learning_rate": 0.00012168671679197995,
      "loss": 3.3299,
      "step": 151500
    },
    {
      "epoch": 4.043951366163833,
      "grad_norm": 0.2508874237537384,
      "learning_rate": 0.00012043358395989975,
      "loss": 3.3306,
      "step": 152000
    },
    {
      "epoch": 4.043951366163833,
      "eval_loss": 3.219454288482666,
      "eval_runtime": 25.2799,
      "eval_samples_per_second": 1977.855,
      "eval_steps_per_second": 7.753,
      "step": 152000
    },
    {
      "epoch": 4.0572538377630565,
      "grad_norm": 0.36259207129478455,
      "learning_rate": 0.00011918045112781956,
      "loss": 3.331,
      "step": 152500
    },
    {
      "epoch": 4.07055630936228,
      "grad_norm": 0.26375487446784973,
      "learning_rate": 0.0001179298245614035,
      "loss": 3.33,
      "step": 153000
    },
    {
      "epoch": 4.083858780961503,
      "grad_norm": 0.27145153284072876,
      "learning_rate": 0.00011667669172932331,
      "loss": 3.3297,
      "step": 153500
    },
    {
      "epoch": 4.097161252560726,
      "grad_norm": 0.26531973481178284,
      "learning_rate": 0.00011542355889724311,
      "loss": 3.3316,
      "step": 154000
    },
    {
      "epoch": 4.110463724159949,
      "grad_norm": 0.22792620956897736,
      "learning_rate": 0.00011417042606516291,
      "loss": 3.3308,
      "step": 154500
    },
    {
      "epoch": 4.123766195759172,
      "grad_norm": 0.26792576909065247,
      "learning_rate": 0.00011291729323308272,
      "loss": 3.3304,
      "step": 155000
    },
    {
      "epoch": 4.137068667358395,
      "grad_norm": 0.24899107217788696,
      "learning_rate": 0.0001116641604010025,
      "loss": 3.3308,
      "step": 155500
    },
    {
      "epoch": 4.1503711389576186,
      "grad_norm": 0.2219262421131134,
      "learning_rate": 0.00011041102756892231,
      "loss": 3.3264,
      "step": 156000
    },
    {
      "epoch": 4.1503711389576186,
      "eval_loss": 3.2162275314331055,
      "eval_runtime": 25.2141,
      "eval_samples_per_second": 1983.019,
      "eval_steps_per_second": 7.773,
      "step": 156000
    },
    {
      "epoch": 4.163673610556842,
      "grad_norm": 0.2654021084308624,
      "learning_rate": 0.00010915789473684211,
      "loss": 3.3308,
      "step": 156500
    },
    {
      "epoch": 4.176976082156065,
      "grad_norm": 0.21479997038841248,
      "learning_rate": 0.00010790476190476191,
      "loss": 3.3275,
      "step": 157000
    },
    {
      "epoch": 4.190278553755288,
      "grad_norm": 0.2220572829246521,
      "learning_rate": 0.0001066516290726817,
      "loss": 3.3273,
      "step": 157500
    },
    {
      "epoch": 4.203581025354511,
      "grad_norm": 0.2223118543624878,
      "learning_rate": 0.0001053984962406015,
      "loss": 3.3286,
      "step": 158000
    },
    {
      "epoch": 4.216883496953734,
      "grad_norm": 0.21915970742702484,
      "learning_rate": 0.00010415037593984961,
      "loss": 3.3259,
      "step": 158500
    },
    {
      "epoch": 4.2301859685529575,
      "grad_norm": 0.23001201450824738,
      "learning_rate": 0.00010289724310776942,
      "loss": 3.3267,
      "step": 159000
    },
    {
      "epoch": 4.243488440152181,
      "grad_norm": 0.23046521842479706,
      "learning_rate": 0.00010164411027568922,
      "loss": 3.3264,
      "step": 159500
    },
    {
      "epoch": 4.256790911751404,
      "grad_norm": 0.27043214440345764,
      "learning_rate": 0.00010039097744360902,
      "loss": 3.3272,
      "step": 160000
    },
    {
      "epoch": 4.256790911751404,
      "eval_loss": 3.213559150695801,
      "eval_runtime": 25.2277,
      "eval_samples_per_second": 1981.95,
      "eval_steps_per_second": 7.769,
      "step": 160000
    },
    {
      "epoch": 4.270093383350627,
      "grad_norm": 0.2646247148513794,
      "learning_rate": 9.913784461152882e-05,
      "loss": 3.3261,
      "step": 160500
    },
    {
      "epoch": 4.28339585494985,
      "grad_norm": 0.2362334281206131,
      "learning_rate": 9.788471177944861e-05,
      "loss": 3.3254,
      "step": 161000
    },
    {
      "epoch": 4.296698326549073,
      "grad_norm": 0.2254258096218109,
      "learning_rate": 9.663157894736842e-05,
      "loss": 3.3254,
      "step": 161500
    },
    {
      "epoch": 4.310000798148296,
      "grad_norm": 0.24734997749328613,
      "learning_rate": 9.537844611528822e-05,
      "loss": 3.3252,
      "step": 162000
    },
    {
      "epoch": 4.3233032697475196,
      "grad_norm": 0.22436991333961487,
      "learning_rate": 9.412531328320802e-05,
      "loss": 3.3253,
      "step": 162500
    },
    {
      "epoch": 4.336605741346742,
      "grad_norm": 0.22508074343204498,
      "learning_rate": 9.287218045112781e-05,
      "loss": 3.3251,
      "step": 163000
    },
    {
      "epoch": 4.349908212945965,
      "grad_norm": 0.23219740390777588,
      "learning_rate": 9.161904761904761e-05,
      "loss": 3.326,
      "step": 163500
    },
    {
      "epoch": 4.363210684545188,
      "grad_norm": 0.2279973179101944,
      "learning_rate": 9.036591478696741e-05,
      "loss": 3.3234,
      "step": 164000
    },
    {
      "epoch": 4.363210684545188,
      "eval_loss": 3.2110729217529297,
      "eval_runtime": 25.3158,
      "eval_samples_per_second": 1975.05,
      "eval_steps_per_second": 7.742,
      "step": 164000
    },
    {
      "epoch": 4.376513156144411,
      "grad_norm": 0.24367764592170715,
      "learning_rate": 8.911278195488722e-05,
      "loss": 3.3226,
      "step": 164500
    },
    {
      "epoch": 4.389815627743634,
      "grad_norm": 0.282830148935318,
      "learning_rate": 8.786215538847118e-05,
      "loss": 3.3234,
      "step": 165000
    },
    {
      "epoch": 4.403118099342858,
      "grad_norm": 0.22041630744934082,
      "learning_rate": 8.660902255639098e-05,
      "loss": 3.3232,
      "step": 165500
    },
    {
      "epoch": 4.416420570942081,
      "grad_norm": 0.2353130578994751,
      "learning_rate": 8.535588972431079e-05,
      "loss": 3.3232,
      "step": 166000
    },
    {
      "epoch": 4.429723042541304,
      "grad_norm": 0.2570043206214905,
      "learning_rate": 8.410275689223059e-05,
      "loss": 3.3228,
      "step": 166500
    },
    {
      "epoch": 4.443025514140527,
      "grad_norm": 0.3325293958187103,
      "learning_rate": 8.284962406015038e-05,
      "loss": 3.3229,
      "step": 167000
    },
    {
      "epoch": 4.45632798573975,
      "grad_norm": 0.23916667699813843,
      "learning_rate": 8.159899749373434e-05,
      "loss": 3.32,
      "step": 167500
    },
    {
      "epoch": 4.469630457338973,
      "grad_norm": 0.32040032744407654,
      "learning_rate": 8.034586466165414e-05,
      "loss": 3.3214,
      "step": 168000
    },
    {
      "epoch": 4.469630457338973,
      "eval_loss": 3.2088656425476074,
      "eval_runtime": 25.2351,
      "eval_samples_per_second": 1981.364,
      "eval_steps_per_second": 7.767,
      "step": 168000
    },
    {
      "epoch": 4.4829329289381965,
      "grad_norm": 0.23219144344329834,
      "learning_rate": 7.909273182957393e-05,
      "loss": 3.3202,
      "step": 168500
    },
    {
      "epoch": 4.49623540053742,
      "grad_norm": 0.2314750999212265,
      "learning_rate": 7.783959899749373e-05,
      "loss": 3.3216,
      "step": 169000
    },
    {
      "epoch": 4.509537872136643,
      "grad_norm": 0.26068955659866333,
      "learning_rate": 7.658646616541354e-05,
      "loss": 3.3209,
      "step": 169500
    },
    {
      "epoch": 4.522840343735866,
      "grad_norm": 0.2570347785949707,
      "learning_rate": 7.53358395989975e-05,
      "loss": 3.3205,
      "step": 170000
    },
    {
      "epoch": 4.536142815335089,
      "grad_norm": 0.26298728585243225,
      "learning_rate": 7.408521303258145e-05,
      "loss": 3.3201,
      "step": 170500
    },
    {
      "epoch": 4.549445286934312,
      "grad_norm": 0.22769629955291748,
      "learning_rate": 7.283208020050125e-05,
      "loss": 3.3202,
      "step": 171000
    },
    {
      "epoch": 4.562747758533535,
      "grad_norm": 0.23857411742210388,
      "learning_rate": 7.157894736842105e-05,
      "loss": 3.3183,
      "step": 171500
    },
    {
      "epoch": 4.576050230132759,
      "grad_norm": 0.22625267505645752,
      "learning_rate": 7.032581453634084e-05,
      "loss": 3.3202,
      "step": 172000
    },
    {
      "epoch": 4.576050230132759,
      "eval_loss": 3.206228494644165,
      "eval_runtime": 25.2831,
      "eval_samples_per_second": 1977.609,
      "eval_steps_per_second": 7.752,
      "step": 172000
    },
    {
      "epoch": 4.589352701731982,
      "grad_norm": 0.2322521060705185,
      "learning_rate": 6.907268170426065e-05,
      "loss": 3.3203,
      "step": 172500
    },
    {
      "epoch": 4.602655173331205,
      "grad_norm": 0.23700584471225739,
      "learning_rate": 6.782205513784462e-05,
      "loss": 3.317,
      "step": 173000
    },
    {
      "epoch": 4.615957644930428,
      "grad_norm": 0.22298631072044373,
      "learning_rate": 6.656892230576441e-05,
      "loss": 3.3183,
      "step": 173500
    },
    {
      "epoch": 4.629260116529651,
      "grad_norm": 0.2600976526737213,
      "learning_rate": 6.531578947368421e-05,
      "loss": 3.3169,
      "step": 174000
    },
    {
      "epoch": 4.642562588128874,
      "grad_norm": 0.2658131718635559,
      "learning_rate": 6.406265664160402e-05,
      "loss": 3.3189,
      "step": 174500
    },
    {
      "epoch": 4.6558650597280975,
      "grad_norm": 0.2623346447944641,
      "learning_rate": 6.280952380952382e-05,
      "loss": 3.3178,
      "step": 175000
    },
    {
      "epoch": 4.669167531327321,
      "grad_norm": 0.22519555687904358,
      "learning_rate": 6.155639097744361e-05,
      "loss": 3.3163,
      "step": 175500
    },
    {
      "epoch": 4.682470002926544,
      "grad_norm": 0.21665841341018677,
      "learning_rate": 6.030325814536341e-05,
      "loss": 3.3182,
      "step": 176000
    },
    {
      "epoch": 4.682470002926544,
      "eval_loss": 3.203559637069702,
      "eval_runtime": 25.4231,
      "eval_samples_per_second": 1966.713,
      "eval_steps_per_second": 7.71,
      "step": 176000
    },
    {
      "epoch": 4.695772474525767,
      "grad_norm": 0.23697201907634735,
      "learning_rate": 5.905012531328321e-05,
      "loss": 3.3179,
      "step": 176500
    },
    {
      "epoch": 4.70907494612499,
      "grad_norm": 0.2473437488079071,
      "learning_rate": 5.779699248120301e-05,
      "loss": 3.3163,
      "step": 177000
    },
    {
      "epoch": 4.722377417724213,
      "grad_norm": 0.2277250438928604,
      "learning_rate": 5.654887218045113e-05,
      "loss": 3.3155,
      "step": 177500
    },
    {
      "epoch": 4.735679889323436,
      "grad_norm": 0.22207820415496826,
      "learning_rate": 5.529573934837093e-05,
      "loss": 3.3147,
      "step": 178000
    },
    {
      "epoch": 4.74898236092266,
      "grad_norm": 0.24581654369831085,
      "learning_rate": 5.4042606516290725e-05,
      "loss": 3.3124,
      "step": 178500
    },
    {
      "epoch": 4.762284832521883,
      "grad_norm": 0.23710276186466217,
      "learning_rate": 5.278947368421053e-05,
      "loss": 3.3146,
      "step": 179000
    },
    {
      "epoch": 4.775587304121106,
      "grad_norm": 0.22904396057128906,
      "learning_rate": 5.153634085213032e-05,
      "loss": 3.3147,
      "step": 179500
    },
    {
      "epoch": 4.788889775720329,
      "grad_norm": 0.22029753029346466,
      "learning_rate": 5.0283208020050126e-05,
      "loss": 3.3149,
      "step": 180000
    },
    {
      "epoch": 4.788889775720329,
      "eval_loss": 3.2013609409332275,
      "eval_runtime": 25.2615,
      "eval_samples_per_second": 1979.297,
      "eval_steps_per_second": 7.759,
      "step": 180000
    },
    {
      "epoch": 4.802192247319552,
      "grad_norm": 0.2605054974555969,
      "learning_rate": 4.903508771929824e-05,
      "loss": 3.3141,
      "step": 180500
    },
    {
      "epoch": 4.815494718918775,
      "grad_norm": 0.2298874706029892,
      "learning_rate": 4.7781954887218045e-05,
      "loss": 3.315,
      "step": 181000
    },
    {
      "epoch": 4.8287971905179985,
      "grad_norm": 0.2241845279932022,
      "learning_rate": 4.652882205513784e-05,
      "loss": 3.3145,
      "step": 181500
    },
    {
      "epoch": 4.842099662117222,
      "grad_norm": 0.24295175075531006,
      "learning_rate": 4.5275689223057644e-05,
      "loss": 3.3144,
      "step": 182000
    },
    {
      "epoch": 4.855402133716445,
      "grad_norm": 0.21829760074615479,
      "learning_rate": 4.4022556390977446e-05,
      "loss": 3.3139,
      "step": 182500
    },
    {
      "epoch": 4.868704605315668,
      "grad_norm": 0.23031526803970337,
      "learning_rate": 4.276942355889724e-05,
      "loss": 3.3132,
      "step": 183000
    },
    {
      "epoch": 4.882007076914891,
      "grad_norm": 0.23988167941570282,
      "learning_rate": 4.1516290726817044e-05,
      "loss": 3.315,
      "step": 183500
    },
    {
      "epoch": 4.895309548514114,
      "grad_norm": 0.23293982446193695,
      "learning_rate": 4.026315789473684e-05,
      "loss": 3.3127,
      "step": 184000
    },
    {
      "epoch": 4.895309548514114,
      "eval_loss": 3.1991965770721436,
      "eval_runtime": 25.1981,
      "eval_samples_per_second": 1984.278,
      "eval_steps_per_second": 7.778,
      "step": 184000
    },
    {
      "epoch": 4.908612020113337,
      "grad_norm": 0.22156530618667603,
      "learning_rate": 3.901002506265664e-05,
      "loss": 3.3121,
      "step": 184500
    },
    {
      "epoch": 4.921914491712561,
      "grad_norm": 0.23996223509311676,
      "learning_rate": 3.775689223057644e-05,
      "loss": 3.3129,
      "step": 185000
    },
    {
      "epoch": 4.935216963311783,
      "grad_norm": 0.2282983511686325,
      "learning_rate": 3.650375939849624e-05,
      "loss": 3.3115,
      "step": 185500
    },
    {
      "epoch": 4.948519434911006,
      "grad_norm": 0.223312646150589,
      "learning_rate": 3.525062656641604e-05,
      "loss": 3.3135,
      "step": 186000
    },
    {
      "epoch": 4.961821906510229,
      "grad_norm": 0.25093117356300354,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 3.3118,
      "step": 186500
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.22836095094680786,
      "learning_rate": 3.27468671679198e-05,
      "loss": 3.3124,
      "step": 187000
    },
    {
      "epoch": 4.9884268497086754,
      "grad_norm": 0.22715573012828827,
      "learning_rate": 3.1493734335839605e-05,
      "loss": 3.3105,
      "step": 187500
    },
    {
      "epoch": 5.001729321307899,
      "grad_norm": 0.22589804232120514,
      "learning_rate": 3.0240601503759397e-05,
      "loss": 3.3119,
      "step": 188000
    },
    {
      "epoch": 5.001729321307899,
      "eval_loss": 3.197326898574829,
      "eval_runtime": 25.2006,
      "eval_samples_per_second": 1984.078,
      "eval_steps_per_second": 7.778,
      "step": 188000
    },
    {
      "epoch": 5.015031792907122,
      "grad_norm": 0.22553060948848724,
      "learning_rate": 2.8987468671679196e-05,
      "loss": 3.3087,
      "step": 188500
    },
    {
      "epoch": 5.028334264506345,
      "grad_norm": 0.24009086191654205,
      "learning_rate": 2.7739348370927317e-05,
      "loss": 3.3079,
      "step": 189000
    },
    {
      "epoch": 5.041636736105568,
      "grad_norm": 0.22356034815311432,
      "learning_rate": 2.6486215538847116e-05,
      "loss": 3.3082,
      "step": 189500
    },
    {
      "epoch": 5.054939207704791,
      "grad_norm": 0.22693881392478943,
      "learning_rate": 2.5233082706766915e-05,
      "loss": 3.3081,
      "step": 190000
    },
    {
      "epoch": 5.068241679304014,
      "grad_norm": 0.2533213198184967,
      "learning_rate": 2.3979949874686718e-05,
      "loss": 3.3079,
      "step": 190500
    },
    {
      "epoch": 5.0815441509032375,
      "grad_norm": 0.2354244589805603,
      "learning_rate": 2.2726817042606517e-05,
      "loss": 3.3077,
      "step": 191000
    },
    {
      "epoch": 5.094846622502461,
      "grad_norm": 0.22201277315616608,
      "learning_rate": 2.1476190476190477e-05,
      "loss": 3.3063,
      "step": 191500
    },
    {
      "epoch": 5.108149094101684,
      "grad_norm": 0.22368256747722626,
      "learning_rate": 2.0223057644110276e-05,
      "loss": 3.3065,
      "step": 192000
    },
    {
      "epoch": 5.108149094101684,
      "eval_loss": 3.195924997329712,
      "eval_runtime": 25.1683,
      "eval_samples_per_second": 1986.628,
      "eval_steps_per_second": 7.788,
      "step": 192000
    },
    {
      "epoch": 5.121451565700907,
      "grad_norm": 0.2293877750635147,
      "learning_rate": 1.8969924812030075e-05,
      "loss": 3.3078,
      "step": 192500
    },
    {
      "epoch": 5.13475403730013,
      "grad_norm": 0.22615770995616913,
      "learning_rate": 1.7716791979949874e-05,
      "loss": 3.3098,
      "step": 193000
    },
    {
      "epoch": 5.148056508899353,
      "grad_norm": 0.2612323760986328,
      "learning_rate": 1.6463659147869673e-05,
      "loss": 3.3058,
      "step": 193500
    },
    {
      "epoch": 5.161358980498576,
      "grad_norm": 0.21617741882801056,
      "learning_rate": 1.5210526315789474e-05,
      "loss": 3.3077,
      "step": 194000
    },
    {
      "epoch": 5.1746614520978,
      "grad_norm": 0.2293473482131958,
      "learning_rate": 1.3957393483709273e-05,
      "loss": 3.3076,
      "step": 194500
    },
    {
      "epoch": 5.187963923697023,
      "grad_norm": 0.21948570013046265,
      "learning_rate": 1.2704260651629072e-05,
      "loss": 3.3045,
      "step": 195000
    },
    {
      "epoch": 5.201266395296246,
      "grad_norm": 0.22863902151584625,
      "learning_rate": 1.1451127819548871e-05,
      "loss": 3.3078,
      "step": 195500
    },
    {
      "epoch": 5.214568866895469,
      "grad_norm": 0.21691346168518066,
      "learning_rate": 1.0197994987468672e-05,
      "loss": 3.3052,
      "step": 196000
    },
    {
      "epoch": 5.214568866895469,
      "eval_loss": 3.1943275928497314,
      "eval_runtime": 25.5238,
      "eval_samples_per_second": 1958.96,
      "eval_steps_per_second": 7.679,
      "step": 196000
    },
    {
      "epoch": 5.227871338494692,
      "grad_norm": 0.22291909158229828,
      "learning_rate": 8.944862155388471e-06,
      "loss": 3.3059,
      "step": 196500
    },
    {
      "epoch": 5.241173810093915,
      "grad_norm": 0.22683288156986237,
      "learning_rate": 7.694235588972431e-06,
      "loss": 3.3073,
      "step": 197000
    },
    {
      "epoch": 5.2544762816931385,
      "grad_norm": 0.22162023186683655,
      "learning_rate": 6.441102756892231e-06,
      "loss": 3.3056,
      "step": 197500
    },
    {
      "epoch": 5.267778753292362,
      "grad_norm": 0.26675549149513245,
      "learning_rate": 5.18796992481203e-06,
      "loss": 3.3059,
      "step": 198000
    },
    {
      "epoch": 5.281081224891585,
      "grad_norm": 0.22286410629749298,
      "learning_rate": 3.934837092731829e-06,
      "loss": 3.3066,
      "step": 198500
    },
    {
      "epoch": 5.294383696490808,
      "grad_norm": 0.2332528531551361,
      "learning_rate": 2.681704260651629e-06,
      "loss": 3.3056,
      "step": 199000
    },
    {
      "epoch": 5.307686168090031,
      "grad_norm": 0.2260362207889557,
      "learning_rate": 1.431077694235589e-06,
      "loss": 3.3046,
      "step": 199500
    },
    {
      "epoch": 5.320988639689254,
      "grad_norm": 0.22470879554748535,
      "learning_rate": 1.7794486215538848e-07,
      "loss": 3.3057,
      "step": 200000
    },
    {
      "epoch": 5.320988639689254,
      "eval_loss": 3.1934287548065186,
      "eval_runtime": 25.501,
      "eval_samples_per_second": 1960.711,
      "eval_steps_per_second": 7.686,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
