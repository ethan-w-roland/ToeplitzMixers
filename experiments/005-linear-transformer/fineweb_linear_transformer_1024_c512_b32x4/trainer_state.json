{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 0.6393293142318726,
      "learning_rate": 0.0002,
      "loss": 6.3141,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 0.4763757586479187,
      "learning_rate": 0.00019949874686716793,
      "loss": 4.7728,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.4296724796295166,
      "learning_rate": 0.00019899749373433585,
      "loss": 4.4362,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.42641904950141907,
      "learning_rate": 0.00019849624060150375,
      "loss": 4.2563,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.4344063401222229,
      "learning_rate": 0.0001979949874686717,
      "loss": 4.1381,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.42054158449172974,
      "learning_rate": 0.0001974937343358396,
      "loss": 4.049,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.43715474009513855,
      "learning_rate": 0.00019699248120300754,
      "loss": 3.9809,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.3962908089160919,
      "learning_rate": 0.00019649122807017543,
      "loss": 3.9276,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.896899938583374,
      "eval_runtime": 80.9111,
      "eval_samples_per_second": 617.962,
      "eval_steps_per_second": 4.832,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.38551464676856995,
      "learning_rate": 0.00019598997493734338,
      "loss": 3.8822,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.3666131794452667,
      "learning_rate": 0.00019548872180451127,
      "loss": 3.8473,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.3897085189819336,
      "learning_rate": 0.00019498746867167922,
      "loss": 3.813,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.4048456847667694,
      "learning_rate": 0.0001944862155388471,
      "loss": 3.7848,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.3777778446674347,
      "learning_rate": 0.00019398496240601503,
      "loss": 3.759,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.38888171315193176,
      "learning_rate": 0.00019348370927318296,
      "loss": 3.7383,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.384746253490448,
      "learning_rate": 0.00019298245614035088,
      "loss": 3.7143,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.38577231764793396,
      "learning_rate": 0.0001924812030075188,
      "loss": 3.6982,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.685492753982544,
      "eval_runtime": 80.9702,
      "eval_samples_per_second": 617.511,
      "eval_steps_per_second": 4.829,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.3717748522758484,
      "learning_rate": 0.00019198095238095238,
      "loss": 3.6823,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.3661819398403168,
      "learning_rate": 0.0001914796992481203,
      "loss": 3.6672,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.37529972195625305,
      "learning_rate": 0.00019097844611528822,
      "loss": 3.6503,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.3586243689060211,
      "learning_rate": 0.00019047719298245615,
      "loss": 3.6392,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.36309728026390076,
      "learning_rate": 0.00018997694235588973,
      "loss": 3.6263,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.362719863653183,
      "learning_rate": 0.00018947568922305765,
      "loss": 3.6167,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.372944176197052,
      "learning_rate": 0.00018897443609022557,
      "loss": 3.6013,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.3658941984176636,
      "learning_rate": 0.0001884731829573935,
      "loss": 3.5929,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.5834667682647705,
      "eval_runtime": 80.7989,
      "eval_samples_per_second": 618.821,
      "eval_steps_per_second": 4.839,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.3484383225440979,
      "learning_rate": 0.00018797293233082708,
      "loss": 3.5844,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.3578977584838867,
      "learning_rate": 0.000187471679197995,
      "loss": 3.5777,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.35644057393074036,
      "learning_rate": 0.0001869704260651629,
      "loss": 3.5621,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.343645840883255,
      "learning_rate": 0.00018646917293233084,
      "loss": 3.5571,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.34867462515830994,
      "learning_rate": 0.00018596892230576443,
      "loss": 3.5495,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.33941298723220825,
      "learning_rate": 0.00018546766917293235,
      "loss": 3.5416,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.34898990392684937,
      "learning_rate": 0.00018496641604010024,
      "loss": 3.5337,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.34145766496658325,
      "learning_rate": 0.0001844651629072682,
      "loss": 3.5286,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.5196919441223145,
      "eval_runtime": 80.8538,
      "eval_samples_per_second": 618.4,
      "eval_steps_per_second": 4.836,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.35659125447273254,
      "learning_rate": 0.00018396491228070175,
      "loss": 3.522,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.35637912154197693,
      "learning_rate": 0.0001834636591478697,
      "loss": 3.514,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.34840014576911926,
      "learning_rate": 0.0001829624060150376,
      "loss": 3.5088,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.3423081040382385,
      "learning_rate": 0.00018246115288220554,
      "loss": 3.498,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.33377140760421753,
      "learning_rate": 0.0001819609022556391,
      "loss": 3.4958,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.33436793088912964,
      "learning_rate": 0.00018145964912280702,
      "loss": 3.4932,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.3545295000076294,
      "learning_rate": 0.00018095839598997494,
      "loss": 3.4806,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.365265816450119,
      "learning_rate": 0.00018045714285714286,
      "loss": 3.4784,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.473365545272827,
      "eval_runtime": 80.6559,
      "eval_samples_per_second": 619.917,
      "eval_steps_per_second": 4.848,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.34362897276878357,
      "learning_rate": 0.00017995689223057645,
      "loss": 3.4734,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.3697415292263031,
      "learning_rate": 0.00017945563909774437,
      "loss": 3.4685,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.33813732862472534,
      "learning_rate": 0.0001789543859649123,
      "loss": 3.466,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.3419634699821472,
      "learning_rate": 0.0001784531328320802,
      "loss": 3.4593,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.3403005301952362,
      "learning_rate": 0.0001779528822055138,
      "loss": 3.4562,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.34113651514053345,
      "learning_rate": 0.00017745162907268171,
      "loss": 3.4501,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.3377000391483307,
      "learning_rate": 0.0001769503759398496,
      "loss": 3.4457,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.32653844356536865,
      "learning_rate": 0.00017644912280701756,
      "loss": 3.4419,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.4366402626037598,
      "eval_runtime": 80.729,
      "eval_samples_per_second": 619.356,
      "eval_steps_per_second": 4.843,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.3519042432308197,
      "learning_rate": 0.00017594786967418545,
      "loss": 3.4384,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.346136212348938,
      "learning_rate": 0.00017544761904761906,
      "loss": 3.4321,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.35759997367858887,
      "learning_rate": 0.00017494636591478696,
      "loss": 3.4287,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.35060083866119385,
      "learning_rate": 0.0001744451127819549,
      "loss": 3.4251,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.3575131595134735,
      "learning_rate": 0.0001739438596491228,
      "loss": 3.4209,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.3556435704231262,
      "learning_rate": 0.0001734436090225564,
      "loss": 3.4171,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.3651668429374695,
      "learning_rate": 0.0001729423558897243,
      "loss": 3.415,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.35469532012939453,
      "learning_rate": 0.00017244110275689225,
      "loss": 3.4098,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.406325578689575,
      "eval_runtime": 80.8447,
      "eval_samples_per_second": 618.469,
      "eval_steps_per_second": 4.836,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.3463006913661957,
      "learning_rate": 0.00017193984962406015,
      "loss": 3.41,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.3661889135837555,
      "learning_rate": 0.00017143959899749373,
      "loss": 3.4042,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.35280343890190125,
      "learning_rate": 0.00017093834586466165,
      "loss": 3.4024,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.3337860107421875,
      "learning_rate": 0.00017043709273182957,
      "loss": 3.3977,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.338640958070755,
      "learning_rate": 0.0001699358395989975,
      "loss": 3.3926,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.36369791626930237,
      "learning_rate": 0.00016943558897243108,
      "loss": 3.389,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.3240712285041809,
      "learning_rate": 0.000168934335839599,
      "loss": 3.3873,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.35297656059265137,
      "learning_rate": 0.00016843308270676692,
      "loss": 3.3866,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.3809683322906494,
      "eval_runtime": 80.6803,
      "eval_samples_per_second": 619.73,
      "eval_steps_per_second": 4.846,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.34703949093818665,
      "learning_rate": 0.00016793182957393484,
      "loss": 3.3811,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.3574269711971283,
      "learning_rate": 0.00016743157894736843,
      "loss": 3.3796,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.3245440125465393,
      "learning_rate": 0.00016693032581453635,
      "loss": 3.3734,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.35338106751441956,
      "learning_rate": 0.00016642907268170427,
      "loss": 3.373,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.3397770822048187,
      "learning_rate": 0.0001659278195488722,
      "loss": 3.3723,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.3187669813632965,
      "learning_rate": 0.00016542756892230578,
      "loss": 3.3675,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.3353961110115051,
      "learning_rate": 0.00016492631578947367,
      "loss": 3.3646,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.3480134606361389,
      "learning_rate": 0.00016442506265664162,
      "loss": 3.3617,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 3.3572909832000732,
      "eval_runtime": 80.6652,
      "eval_samples_per_second": 619.846,
      "eval_steps_per_second": 4.847,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.34312179684638977,
      "learning_rate": 0.0001639238095238095,
      "loss": 3.3593,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.3218487799167633,
      "learning_rate": 0.00016342355889724313,
      "loss": 3.3568,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.34269800782203674,
      "learning_rate": 0.00016292230576441102,
      "loss": 3.353,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.32048672437667847,
      "learning_rate": 0.00016242105263157897,
      "loss": 3.3536,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.32829612493515015,
      "learning_rate": 0.00016191979949874686,
      "loss": 3.3514,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.31897199153900146,
      "learning_rate": 0.0001614185463659148,
      "loss": 3.3473,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.32346877455711365,
      "learning_rate": 0.00016091829573934837,
      "loss": 3.3479,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.33741244673728943,
      "learning_rate": 0.0001604170426065163,
      "loss": 3.3457,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 3.338146448135376,
      "eval_runtime": 80.8907,
      "eval_samples_per_second": 618.118,
      "eval_steps_per_second": 4.834,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.3109130263328552,
      "learning_rate": 0.0001599157894736842,
      "loss": 3.3412,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.3239154517650604,
      "learning_rate": 0.00015941453634085213,
      "loss": 3.3386,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.3132423162460327,
      "learning_rate": 0.00015891328320802005,
      "loss": 3.3385,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.36513179540634155,
      "learning_rate": 0.00015841303258145364,
      "loss": 3.3325,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.32198837399482727,
      "learning_rate": 0.00015791177944862156,
      "loss": 3.3342,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.3355514705181122,
      "learning_rate": 0.00015741052631578948,
      "loss": 3.3288,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.3238030970096588,
      "learning_rate": 0.0001569092731829574,
      "loss": 3.3283,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.3003300428390503,
      "learning_rate": 0.00015640902255639099,
      "loss": 3.3231,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 3.320925712585449,
      "eval_runtime": 80.6475,
      "eval_samples_per_second": 619.982,
      "eval_steps_per_second": 4.848,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.31126829981803894,
      "learning_rate": 0.0001559077694235589,
      "loss": 3.3268,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.32832595705986023,
      "learning_rate": 0.00015540651629072683,
      "loss": 3.3227,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.3347722589969635,
      "learning_rate": 0.00015490526315789475,
      "loss": 3.3158,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.31469640135765076,
      "learning_rate": 0.00015440401002506267,
      "loss": 3.3169,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.31227433681488037,
      "learning_rate": 0.00015390375939849623,
      "loss": 3.3156,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.29973265528678894,
      "learning_rate": 0.00015340250626566418,
      "loss": 3.3092,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.2960859537124634,
      "learning_rate": 0.00015290125313283207,
      "loss": 3.3132,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.29450705647468567,
      "learning_rate": 0.00015240000000000002,
      "loss": 3.3082,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 3.305605888366699,
      "eval_runtime": 80.6377,
      "eval_samples_per_second": 620.057,
      "eval_steps_per_second": 4.849,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.29060599207878113,
      "learning_rate": 0.0001518987468671679,
      "loss": 3.3083,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.3237017095088959,
      "learning_rate": 0.00015139749373433586,
      "loss": 3.3041,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.31133532524108887,
      "learning_rate": 0.00015089724310776942,
      "loss": 3.3051,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.31276217103004456,
      "learning_rate": 0.00015039598997493737,
      "loss": 3.3016,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.3024876117706299,
      "learning_rate": 0.00014989473684210526,
      "loss": 3.2995,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.29998254776000977,
      "learning_rate": 0.0001493934837092732,
      "loss": 3.2971,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.3056023120880127,
      "learning_rate": 0.0001488922305764411,
      "loss": 3.2993,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.3063976764678955,
      "learning_rate": 0.00014839097744360902,
      "loss": 3.2957,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 3.2914416790008545,
      "eval_runtime": 80.6897,
      "eval_samples_per_second": 619.657,
      "eval_steps_per_second": 4.846,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.3169093430042267,
      "learning_rate": 0.00014788972431077694,
      "loss": 3.2909,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.2833276689052582,
      "learning_rate": 0.00014738847117794487,
      "loss": 3.2902,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.3072968125343323,
      "learning_rate": 0.00014688922305764411,
      "loss": 3.2883,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.3020819425582886,
      "learning_rate": 0.00014638796992481204,
      "loss": 3.2899,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.2875494360923767,
      "learning_rate": 0.00014588671679197996,
      "loss": 3.2883,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.29709067940711975,
      "learning_rate": 0.00014538546365914788,
      "loss": 3.2834,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.30178236961364746,
      "learning_rate": 0.00014488521303258146,
      "loss": 3.282,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.29377004504203796,
      "learning_rate": 0.00014438395989974938,
      "loss": 3.2827,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 3.2783617973327637,
      "eval_runtime": 80.7826,
      "eval_samples_per_second": 618.945,
      "eval_steps_per_second": 4.84,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.2824574112892151,
      "learning_rate": 0.0001438827067669173,
      "loss": 3.2802,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.2996860146522522,
      "learning_rate": 0.00014338145363408523,
      "loss": 3.2796,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.300558865070343,
      "learning_rate": 0.00014288020050125315,
      "loss": 3.275,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.2972143888473511,
      "learning_rate": 0.00014237894736842107,
      "loss": 3.2747,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.2908172011375427,
      "learning_rate": 0.00014187869674185463,
      "loss": 3.2753,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.30051857233047485,
      "learning_rate": 0.00014137744360902257,
      "loss": 3.2736,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.29861605167388916,
      "learning_rate": 0.00014087619047619047,
      "loss": 3.27,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.2781941890716553,
      "learning_rate": 0.00014037493734335842,
      "loss": 3.2709,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 3.2665469646453857,
      "eval_runtime": 80.6461,
      "eval_samples_per_second": 619.993,
      "eval_steps_per_second": 4.848,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.2803155481815338,
      "learning_rate": 0.00013987468671679197,
      "loss": 3.2712,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.28949809074401855,
      "learning_rate": 0.00013937343358395992,
      "loss": 3.2672,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.2854090929031372,
      "learning_rate": 0.00013887218045112782,
      "loss": 3.2654,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.2817249000072479,
      "learning_rate": 0.00013837092731829574,
      "loss": 3.265,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.28293856978416443,
      "learning_rate": 0.00013786967418546366,
      "loss": 3.2634,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.28101682662963867,
      "learning_rate": 0.00013736842105263158,
      "loss": 3.2617,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.2749670445919037,
      "learning_rate": 0.0001368671679197995,
      "loss": 3.2615,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.29074716567993164,
      "learning_rate": 0.00013636591478696742,
      "loss": 3.2615,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 3.256014585494995,
      "eval_runtime": 80.8236,
      "eval_samples_per_second": 618.631,
      "eval_steps_per_second": 4.838,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.2737289369106293,
      "learning_rate": 0.000135865664160401,
      "loss": 3.2589,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.29338163137435913,
      "learning_rate": 0.00013536441102756893,
      "loss": 3.2565,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.2865602374076843,
      "learning_rate": 0.00013486315789473685,
      "loss": 3.2553,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.2748047709465027,
      "learning_rate": 0.00013436190476190477,
      "loss": 3.2541,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.2673375606536865,
      "learning_rate": 0.00013386165413533836,
      "loss": 3.2525,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.27448609471321106,
      "learning_rate": 0.00013336040100250628,
      "loss": 3.249,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.2746482193470001,
      "learning_rate": 0.0001328591478696742,
      "loss": 3.2512,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.27981775999069214,
      "learning_rate": 0.0001323578947368421,
      "loss": 3.2467,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 3.2445077896118164,
      "eval_runtime": 80.6287,
      "eval_samples_per_second": 620.127,
      "eval_steps_per_second": 4.849,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.2702174186706543,
      "learning_rate": 0.00013185664160401004,
      "loss": 3.2493,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.2682780921459198,
      "learning_rate": 0.00013135538847117793,
      "loss": 3.2494,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.27520951628685,
      "learning_rate": 0.00013085413533834588,
      "loss": 3.2475,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.2726559042930603,
      "learning_rate": 0.00013035288220551378,
      "loss": 3.2467,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.2779358923435211,
      "learning_rate": 0.0001298526315789474,
      "loss": 3.2433,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.27767086029052734,
      "learning_rate": 0.00012935137844611528,
      "loss": 3.2447,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.27672508358955383,
      "learning_rate": 0.00012885012531328323,
      "loss": 3.2436,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.27243709564208984,
      "learning_rate": 0.00012834887218045112,
      "loss": 3.2374,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 3.2345895767211914,
      "eval_runtime": 80.6628,
      "eval_samples_per_second": 619.865,
      "eval_steps_per_second": 4.847,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.2726103961467743,
      "learning_rate": 0.00012784862155388474,
      "loss": 3.2399,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.2707577347755432,
      "learning_rate": 0.00012734736842105263,
      "loss": 3.2363,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.27639487385749817,
      "learning_rate": 0.00012684611528822058,
      "loss": 3.2338,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.27534663677215576,
      "learning_rate": 0.00012634486215538847,
      "loss": 3.2365,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.2733483612537384,
      "learning_rate": 0.00012584461152882206,
      "loss": 3.2313,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.290691077709198,
      "learning_rate": 0.00012534335839598998,
      "loss": 3.2324,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.27805209159851074,
      "learning_rate": 0.0001248421052631579,
      "loss": 3.2182,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.27174487709999084,
      "learning_rate": 0.00012434085213032582,
      "loss": 3.2116,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 3.2257025241851807,
      "eval_runtime": 80.7439,
      "eval_samples_per_second": 619.242,
      "eval_steps_per_second": 4.842,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.27906543016433716,
      "learning_rate": 0.0001238406015037594,
      "loss": 3.2104,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.274734765291214,
      "learning_rate": 0.00012333934837092733,
      "loss": 3.2111,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.2659490406513214,
      "learning_rate": 0.00012283809523809525,
      "loss": 3.2089,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.2791793942451477,
      "learning_rate": 0.00012233684210526317,
      "loss": 3.208,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.27210232615470886,
      "learning_rate": 0.00012183659147869675,
      "loss": 3.2057,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.2782818078994751,
      "learning_rate": 0.00012133533834586466,
      "loss": 3.2104,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.26613229513168335,
      "learning_rate": 0.00012083408521303258,
      "loss": 3.2075,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.27720364928245544,
      "learning_rate": 0.0001203328320802005,
      "loss": 3.2092,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 3.2182071208953857,
      "eval_runtime": 80.7248,
      "eval_samples_per_second": 619.388,
      "eval_steps_per_second": 4.844,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.2747557461261749,
      "learning_rate": 0.0001198325814536341,
      "loss": 3.205,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.27120545506477356,
      "learning_rate": 0.00011933132832080201,
      "loss": 3.2066,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.2654401659965515,
      "learning_rate": 0.00011883007518796993,
      "loss": 3.2034,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.28035616874694824,
      "learning_rate": 0.00011832882205513784,
      "loss": 3.205,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.2806577682495117,
      "learning_rate": 0.00011782857142857145,
      "loss": 3.2019,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.26986366510391235,
      "learning_rate": 0.00011732731829573936,
      "loss": 3.2039,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.2770348787307739,
      "learning_rate": 0.00011682606516290728,
      "loss": 3.2016,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.27314698696136475,
      "learning_rate": 0.00011632481203007519,
      "loss": 3.2024,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 3.2111921310424805,
      "eval_runtime": 80.5875,
      "eval_samples_per_second": 620.444,
      "eval_steps_per_second": 4.852,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.28274503350257874,
      "learning_rate": 0.00011582456140350877,
      "loss": 3.2028,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.27172455191612244,
      "learning_rate": 0.0001153233082706767,
      "loss": 3.2006,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.26918622851371765,
      "learning_rate": 0.00011482205513784461,
      "loss": 3.2016,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.27266982197761536,
      "learning_rate": 0.00011432080200501253,
      "loss": 3.1989,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.2752343714237213,
      "learning_rate": 0.00011381954887218044,
      "loss": 3.1957,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.266064316034317,
      "learning_rate": 0.00011331829573934838,
      "loss": 3.1992,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.2712610960006714,
      "learning_rate": 0.00011281704260651628,
      "loss": 3.1939,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.2753801941871643,
      "learning_rate": 0.00011231578947368422,
      "loss": 3.1972,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 3.2032322883605957,
      "eval_runtime": 80.7561,
      "eval_samples_per_second": 619.148,
      "eval_steps_per_second": 4.842,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.27903634309768677,
      "learning_rate": 0.00011181553884711779,
      "loss": 3.1953,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.26842591166496277,
      "learning_rate": 0.00011131428571428572,
      "loss": 3.1933,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.27648019790649414,
      "learning_rate": 0.00011081303258145363,
      "loss": 3.1942,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.2629658877849579,
      "learning_rate": 0.00011031177944862157,
      "loss": 3.1921,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.2769309878349304,
      "learning_rate": 0.00010981152882205514,
      "loss": 3.192,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.2778424918651581,
      "learning_rate": 0.00010931027568922307,
      "loss": 3.1897,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.2666785418987274,
      "learning_rate": 0.00010880902255639098,
      "loss": 3.1895,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.28160780668258667,
      "learning_rate": 0.00010830776942355889,
      "loss": 3.1894,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 3.1967666149139404,
      "eval_runtime": 80.7414,
      "eval_samples_per_second": 619.261,
      "eval_steps_per_second": 4.843,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.2833816111087799,
      "learning_rate": 0.00010780751879699249,
      "loss": 3.1912,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.26280146837234497,
      "learning_rate": 0.0001073062656641604,
      "loss": 3.1875,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.26213422417640686,
      "learning_rate": 0.00010680501253132833,
      "loss": 3.1849,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.2698739469051361,
      "learning_rate": 0.00010630375939849624,
      "loss": 3.1887,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.271433025598526,
      "learning_rate": 0.00010580350877192984,
      "loss": 3.1858,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.27806520462036133,
      "learning_rate": 0.00010530225563909774,
      "loss": 3.1852,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.2685605585575104,
      "learning_rate": 0.00010480100250626568,
      "loss": 3.1854,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.27795878052711487,
      "learning_rate": 0.00010429974937343358,
      "loss": 3.1823,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 3.190321207046509,
      "eval_runtime": 80.6749,
      "eval_samples_per_second": 619.772,
      "eval_steps_per_second": 4.847,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.2811286747455597,
      "learning_rate": 0.00010379949874686716,
      "loss": 3.1806,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.2628304362297058,
      "learning_rate": 0.00010329824561403509,
      "loss": 3.1855,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.2652014493942261,
      "learning_rate": 0.000102796992481203,
      "loss": 3.1802,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.26783013343811035,
      "learning_rate": 0.00010229573934837093,
      "loss": 3.1811,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.26915258169174194,
      "learning_rate": 0.0001017954887218045,
      "loss": 3.1783,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.2658139765262604,
      "learning_rate": 0.00010129423558897244,
      "loss": 3.1795,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.2732164263725281,
      "learning_rate": 0.00010079298245614035,
      "loss": 3.1783,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.2649522125720978,
      "learning_rate": 0.00010029172932330828,
      "loss": 3.1775,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 3.183502435684204,
      "eval_runtime": 80.7525,
      "eval_samples_per_second": 619.176,
      "eval_steps_per_second": 4.842,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.26727721095085144,
      "learning_rate": 9.979147869674185e-05,
      "loss": 3.174,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.26413387060165405,
      "learning_rate": 9.929022556390977e-05,
      "loss": 3.1758,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.28160980343818665,
      "learning_rate": 9.87889724310777e-05,
      "loss": 3.1757,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.26640501618385315,
      "learning_rate": 9.828771929824562e-05,
      "loss": 3.1737,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.254975289106369,
      "learning_rate": 9.77874686716792e-05,
      "loss": 3.1744,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.2642420828342438,
      "learning_rate": 9.728621553884712e-05,
      "loss": 3.172,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.2855026125907898,
      "learning_rate": 9.678496240601504e-05,
      "loss": 3.1727,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.2603466510772705,
      "learning_rate": 9.628370927318296e-05,
      "loss": 3.1703,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 3.1771678924560547,
      "eval_runtime": 80.6421,
      "eval_samples_per_second": 620.023,
      "eval_steps_per_second": 4.849,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.2676493525505066,
      "learning_rate": 9.578345864661654e-05,
      "loss": 3.1724,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.25904953479766846,
      "learning_rate": 9.528220551378446e-05,
      "loss": 3.1685,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.2636949419975281,
      "learning_rate": 9.478095238095238e-05,
      "loss": 3.1663,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.27243703603744507,
      "learning_rate": 9.42796992481203e-05,
      "loss": 3.1677,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.2716819941997528,
      "learning_rate": 9.377944862155388e-05,
      "loss": 3.1686,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.25851142406463623,
      "learning_rate": 9.32781954887218e-05,
      "loss": 3.1661,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.257361501455307,
      "learning_rate": 9.277694235588973e-05,
      "loss": 3.1676,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.2577238380908966,
      "learning_rate": 9.227568922305765e-05,
      "loss": 3.1649,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 3.170949697494507,
      "eval_runtime": 80.7152,
      "eval_samples_per_second": 619.462,
      "eval_steps_per_second": 4.844,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.26452189683914185,
      "learning_rate": 9.177543859649123e-05,
      "loss": 3.1652,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.26409804821014404,
      "learning_rate": 9.127418546365915e-05,
      "loss": 3.1635,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.26284855604171753,
      "learning_rate": 9.077293233082707e-05,
      "loss": 3.1608,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.25944289565086365,
      "learning_rate": 9.0271679197995e-05,
      "loss": 3.1655,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.26101154088974,
      "learning_rate": 8.977142857142857e-05,
      "loss": 3.1611,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.282385915517807,
      "learning_rate": 8.927017543859649e-05,
      "loss": 3.1632,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.25571438670158386,
      "learning_rate": 8.876892230576441e-05,
      "loss": 3.1615,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.25638172030448914,
      "learning_rate": 8.826766917293233e-05,
      "loss": 3.1608,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 3.1657049655914307,
      "eval_runtime": 80.692,
      "eval_samples_per_second": 619.64,
      "eval_steps_per_second": 4.846,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.26326262950897217,
      "learning_rate": 8.776741854636592e-05,
      "loss": 3.1599,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.26221051812171936,
      "learning_rate": 8.726616541353384e-05,
      "loss": 3.1587,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.2694754898548126,
      "learning_rate": 8.676491228070176e-05,
      "loss": 3.1594,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.26170048117637634,
      "learning_rate": 8.626365914786968e-05,
      "loss": 3.1584,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.2602813243865967,
      "learning_rate": 8.576340852130325e-05,
      "loss": 3.1583,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.2737440764904022,
      "learning_rate": 8.526215538847117e-05,
      "loss": 3.1538,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.2698269188404083,
      "learning_rate": 8.476090225563909e-05,
      "loss": 3.1565,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.2658143639564514,
      "learning_rate": 8.425964912280701e-05,
      "loss": 3.1569,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 3.1604809761047363,
      "eval_runtime": 80.7102,
      "eval_samples_per_second": 619.501,
      "eval_steps_per_second": 4.844,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.2711680233478546,
      "learning_rate": 8.37593984962406e-05,
      "loss": 3.1578,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.2686902582645416,
      "learning_rate": 8.325814536340852e-05,
      "loss": 3.1543,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.26893508434295654,
      "learning_rate": 8.275689223057644e-05,
      "loss": 3.1529,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.26462388038635254,
      "learning_rate": 8.225563909774436e-05,
      "loss": 3.1534,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.2645367681980133,
      "learning_rate": 8.175538847117795e-05,
      "loss": 3.1546,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.2707096338272095,
      "learning_rate": 8.125413533834587e-05,
      "loss": 3.1507,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.2680162191390991,
      "learning_rate": 8.075288220551379e-05,
      "loss": 3.1511,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.2643798291683197,
      "learning_rate": 8.025162907268171e-05,
      "loss": 3.1524,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 3.1551218032836914,
      "eval_runtime": 80.6932,
      "eval_samples_per_second": 619.631,
      "eval_steps_per_second": 4.846,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.2810239791870117,
      "learning_rate": 7.975137844611528e-05,
      "loss": 3.1487,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.26517823338508606,
      "learning_rate": 7.92501253132832e-05,
      "loss": 3.1505,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.2602017819881439,
      "learning_rate": 7.874887218045112e-05,
      "loss": 3.1481,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.26336753368377686,
      "learning_rate": 7.824761904761905e-05,
      "loss": 3.1492,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.2612251341342926,
      "learning_rate": 7.774736842105263e-05,
      "loss": 3.1492,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.266674280166626,
      "learning_rate": 7.724611528822055e-05,
      "loss": 3.1445,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.2609531879425049,
      "learning_rate": 7.674486215538847e-05,
      "loss": 3.1492,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.26699259877204895,
      "learning_rate": 7.62436090225564e-05,
      "loss": 3.146,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 3.1496784687042236,
      "eval_runtime": 80.7644,
      "eval_samples_per_second": 619.084,
      "eval_steps_per_second": 4.841,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.26246362924575806,
      "learning_rate": 7.574335839598998e-05,
      "loss": 3.1437,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.26320546865463257,
      "learning_rate": 7.52421052631579e-05,
      "loss": 3.1434,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.2589544355869293,
      "learning_rate": 7.474085213032582e-05,
      "loss": 3.1421,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.2787337899208069,
      "learning_rate": 7.423959899749374e-05,
      "loss": 3.144,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.26255032420158386,
      "learning_rate": 7.373934837092731e-05,
      "loss": 3.1409,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.260955810546875,
      "learning_rate": 7.323809523809523e-05,
      "loss": 3.1431,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.2717885673046112,
      "learning_rate": 7.273684210526316e-05,
      "loss": 3.1407,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.25518807768821716,
      "learning_rate": 7.223558897243108e-05,
      "loss": 3.1403,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 3.144500970840454,
      "eval_runtime": 80.6859,
      "eval_samples_per_second": 619.687,
      "eval_steps_per_second": 4.846,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.27284711599349976,
      "learning_rate": 7.173533834586466e-05,
      "loss": 3.1409,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.2619912326335907,
      "learning_rate": 7.123408521303258e-05,
      "loss": 3.1406,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.26999416947364807,
      "learning_rate": 7.07328320802005e-05,
      "loss": 3.1415,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.2592010498046875,
      "learning_rate": 7.023157894736842e-05,
      "loss": 3.1379,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.25722166895866394,
      "learning_rate": 6.9731328320802e-05,
      "loss": 3.1344,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.2625137269496918,
      "learning_rate": 6.923007518796992e-05,
      "loss": 3.1371,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.25966677069664,
      "learning_rate": 6.872882205513784e-05,
      "loss": 3.1356,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.2586727440357208,
      "learning_rate": 6.822756892230576e-05,
      "loss": 3.1351,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 3.1398754119873047,
      "eval_runtime": 80.8189,
      "eval_samples_per_second": 618.667,
      "eval_steps_per_second": 4.838,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.267837792634964,
      "learning_rate": 6.772731829573934e-05,
      "loss": 3.1327,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.26617977023124695,
      "learning_rate": 6.722606516290727e-05,
      "loss": 3.1337,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.26297834515571594,
      "learning_rate": 6.672481203007519e-05,
      "loss": 3.1346,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.2623985707759857,
      "learning_rate": 6.622355889724311e-05,
      "loss": 3.1332,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.2682346999645233,
      "learning_rate": 6.572330827067669e-05,
      "loss": 3.1345,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.26472464203834534,
      "learning_rate": 6.522205513784461e-05,
      "loss": 3.134,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.27203676104545593,
      "learning_rate": 6.472080200501254e-05,
      "loss": 3.1327,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.25984352827072144,
      "learning_rate": 6.421954887218046e-05,
      "loss": 3.1303,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 3.135612726211548,
      "eval_runtime": 80.6925,
      "eval_samples_per_second": 619.636,
      "eval_steps_per_second": 4.846,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.2629314661026001,
      "learning_rate": 6.371929824561403e-05,
      "loss": 3.1298,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.2775190472602844,
      "learning_rate": 6.321804511278195e-05,
      "loss": 3.1309,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.2612551152706146,
      "learning_rate": 6.271679197994987e-05,
      "loss": 3.1282,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.2624172568321228,
      "learning_rate": 6.221553884711779e-05,
      "loss": 3.1294,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.25608688592910767,
      "learning_rate": 6.171528822055138e-05,
      "loss": 3.1273,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.26351067423820496,
      "learning_rate": 6.12140350877193e-05,
      "loss": 3.1305,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.270401269197464,
      "learning_rate": 6.071278195488722e-05,
      "loss": 3.1251,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.265872985124588,
      "learning_rate": 6.021152882205514e-05,
      "loss": 3.1274,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 3.1302661895751953,
      "eval_runtime": 80.7099,
      "eval_samples_per_second": 619.502,
      "eval_steps_per_second": 4.845,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.2868219316005707,
      "learning_rate": 5.971027568922306e-05,
      "loss": 3.1268,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.27114519476890564,
      "learning_rate": 5.9210025062656646e-05,
      "loss": 3.1259,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.26864317059516907,
      "learning_rate": 5.8708771929824567e-05,
      "loss": 3.126,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.2692893147468567,
      "learning_rate": 5.820751879699249e-05,
      "loss": 3.1226,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.26756757497787476,
      "learning_rate": 5.770626566416041e-05,
      "loss": 3.1246,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.27590709924697876,
      "learning_rate": 5.720601503759399e-05,
      "loss": 3.1215,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.2702520191669464,
      "learning_rate": 5.670576441102757e-05,
      "loss": 3.1232,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.2688494324684143,
      "learning_rate": 5.6204511278195493e-05,
      "loss": 3.1222,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 3.1259474754333496,
      "eval_runtime": 80.658,
      "eval_samples_per_second": 619.901,
      "eval_steps_per_second": 4.848,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.25846219062805176,
      "learning_rate": 5.5703258145363414e-05,
      "loss": 3.122,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.2556634545326233,
      "learning_rate": 5.5202005012531335e-05,
      "loss": 3.1222,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.2926878035068512,
      "learning_rate": 5.470075187969925e-05,
      "loss": 3.1247,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.26489871740341187,
      "learning_rate": 5.419949874686717e-05,
      "loss": 3.1208,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.2646144926548004,
      "learning_rate": 5.369824561403509e-05,
      "loss": 3.1182,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.2758113741874695,
      "learning_rate": 5.319699248120301e-05,
      "loss": 3.1197,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.278857558965683,
      "learning_rate": 5.269674185463659e-05,
      "loss": 3.1194,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.2744389772415161,
      "learning_rate": 5.2195488721804505e-05,
      "loss": 3.1171,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 3.121584177017212,
      "eval_runtime": 80.6592,
      "eval_samples_per_second": 619.892,
      "eval_steps_per_second": 4.848,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.27965784072875977,
      "learning_rate": 5.1694235588972426e-05,
      "loss": 3.118,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.2656947672367096,
      "learning_rate": 5.119298245614035e-05,
      "loss": 3.1166,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.2673690617084503,
      "learning_rate": 5.069172932330827e-05,
      "loss": 3.1149,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.27027395367622375,
      "learning_rate": 5.0191478696741854e-05,
      "loss": 3.116,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.2631096839904785,
      "learning_rate": 4.9690225563909775e-05,
      "loss": 3.1099,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.2623443603515625,
      "learning_rate": 4.9188972431077696e-05,
      "loss": 3.0921,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.2806033194065094,
      "learning_rate": 4.868771929824562e-05,
      "loss": 3.0921,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.26886290311813354,
      "learning_rate": 4.8187468671679195e-05,
      "loss": 3.0876,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 3.1181318759918213,
      "eval_runtime": 80.7085,
      "eval_samples_per_second": 619.514,
      "eval_steps_per_second": 4.845,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.2795649766921997,
      "learning_rate": 4.7686215538847116e-05,
      "loss": 3.0918,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.27576643228530884,
      "learning_rate": 4.718496240601504e-05,
      "loss": 3.0894,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.27414777874946594,
      "learning_rate": 4.668370927318296e-05,
      "loss": 3.0919,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.27238258719444275,
      "learning_rate": 4.6183458646616544e-05,
      "loss": 3.0902,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.272613525390625,
      "learning_rate": 4.5682205513784465e-05,
      "loss": 3.0918,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.27630773186683655,
      "learning_rate": 4.5180952380952386e-05,
      "loss": 3.0892,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.26308032870292664,
      "learning_rate": 4.4679699248120307e-05,
      "loss": 3.0893,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.2758803367614746,
      "learning_rate": 4.4179448621553885e-05,
      "loss": 3.089,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 3.115109920501709,
      "eval_runtime": 80.6178,
      "eval_samples_per_second": 620.21,
      "eval_steps_per_second": 4.85,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.2657589614391327,
      "learning_rate": 4.3678195488721806e-05,
      "loss": 3.0903,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.2932814657688141,
      "learning_rate": 4.317694235588973e-05,
      "loss": 3.0886,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.269450306892395,
      "learning_rate": 4.267568922305765e-05,
      "loss": 3.0899,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.28299033641815186,
      "learning_rate": 4.217543859649123e-05,
      "loss": 3.0893,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.27607908844947815,
      "learning_rate": 4.167418546365915e-05,
      "loss": 3.0867,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.27973875403404236,
      "learning_rate": 4.117293233082707e-05,
      "loss": 3.0877,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.2709253430366516,
      "learning_rate": 4.067167919799499e-05,
      "loss": 3.0884,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.27546435594558716,
      "learning_rate": 4.017142857142857e-05,
      "loss": 3.0872,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 3.1108686923980713,
      "eval_runtime": 80.6185,
      "eval_samples_per_second": 620.205,
      "eval_steps_per_second": 4.85,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.28470250964164734,
      "learning_rate": 3.967017543859649e-05,
      "loss": 3.0878,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.27415013313293457,
      "learning_rate": 3.916892230576441e-05,
      "loss": 3.0875,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.2718019187450409,
      "learning_rate": 3.866766917293233e-05,
      "loss": 3.0864,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.2662031352519989,
      "learning_rate": 3.8167418546365917e-05,
      "loss": 3.0842,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.2796083986759186,
      "learning_rate": 3.766616541353384e-05,
      "loss": 3.0862,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.283122181892395,
      "learning_rate": 3.716491228070176e-05,
      "loss": 3.0826,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.27997490763664246,
      "learning_rate": 3.666365914786968e-05,
      "loss": 3.0823,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.26778271794319153,
      "learning_rate": 3.616340852130326e-05,
      "loss": 3.0854,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 3.1078219413757324,
      "eval_runtime": 80.6639,
      "eval_samples_per_second": 619.856,
      "eval_steps_per_second": 4.847,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.2757772207260132,
      "learning_rate": 3.566215538847118e-05,
      "loss": 3.0844,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.2830483317375183,
      "learning_rate": 3.51609022556391e-05,
      "loss": 3.083,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.27129942178726196,
      "learning_rate": 3.465964912280702e-05,
      "loss": 3.0837,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.26862767338752747,
      "learning_rate": 3.41593984962406e-05,
      "loss": 3.0803,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.2774132490158081,
      "learning_rate": 3.365814536340852e-05,
      "loss": 3.0853,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.28661200404167175,
      "learning_rate": 3.3157894736842106e-05,
      "loss": 3.0824,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.29148587584495544,
      "learning_rate": 3.265664160401003e-05,
      "loss": 3.0847,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.2727712392807007,
      "learning_rate": 3.215538847117794e-05,
      "loss": 3.0799,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 3.104149341583252,
      "eval_runtime": 80.5485,
      "eval_samples_per_second": 620.744,
      "eval_steps_per_second": 4.854,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.27191856503486633,
      "learning_rate": 3.165413533834586e-05,
      "loss": 3.0803,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.2829609215259552,
      "learning_rate": 3.115288220551378e-05,
      "loss": 3.0833,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.2790537178516388,
      "learning_rate": 3.0651629072681704e-05,
      "loss": 3.0814,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.2784740626811981,
      "learning_rate": 3.0150375939849622e-05,
      "loss": 3.0822,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.28699207305908203,
      "learning_rate": 2.965012531328321e-05,
      "loss": 3.08,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.27674636244773865,
      "learning_rate": 2.914887218045113e-05,
      "loss": 3.0779,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.2696203589439392,
      "learning_rate": 2.8647619047619052e-05,
      "loss": 3.0777,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.2805020809173584,
      "learning_rate": 2.814636591478697e-05,
      "loss": 3.0789,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 3.100858688354492,
      "eval_runtime": 80.7027,
      "eval_samples_per_second": 619.558,
      "eval_steps_per_second": 4.845,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.2707240581512451,
      "learning_rate": 2.764511278195489e-05,
      "loss": 3.0781,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.2684120535850525,
      "learning_rate": 2.714385964912281e-05,
      "loss": 3.0799,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.2722252905368805,
      "learning_rate": 2.664260651629073e-05,
      "loss": 3.0814,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.2786383032798767,
      "learning_rate": 2.614135338345865e-05,
      "loss": 3.0771,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.2788696885108948,
      "learning_rate": 2.5641102756892233e-05,
      "loss": 3.0804,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.2771252393722534,
      "learning_rate": 2.5139849624060154e-05,
      "loss": 3.0738,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.279792845249176,
      "learning_rate": 2.463859649122807e-05,
      "loss": 3.0772,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.2822708785533905,
      "learning_rate": 2.4137343358395992e-05,
      "loss": 3.0787,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 3.097672700881958,
      "eval_runtime": 80.644,
      "eval_samples_per_second": 620.009,
      "eval_steps_per_second": 4.848,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.2888319492340088,
      "learning_rate": 2.3637092731829574e-05,
      "loss": 3.0772,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.2758091390132904,
      "learning_rate": 2.3135839598997495e-05,
      "loss": 3.0742,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.2852272093296051,
      "learning_rate": 2.2634586466165413e-05,
      "loss": 3.0734,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.27467796206474304,
      "learning_rate": 2.2133333333333334e-05,
      "loss": 3.0745,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.2768303453922272,
      "learning_rate": 2.163308270676692e-05,
      "loss": 3.0755,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.2826170027256012,
      "learning_rate": 2.113182957393484e-05,
      "loss": 3.0742,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.27485114336013794,
      "learning_rate": 2.0630576441102758e-05,
      "loss": 3.0759,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.27675187587738037,
      "learning_rate": 2.012932330827068e-05,
      "loss": 3.0724,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 3.0944771766662598,
      "eval_runtime": 80.6389,
      "eval_samples_per_second": 620.048,
      "eval_steps_per_second": 4.849,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.280841588973999,
      "learning_rate": 1.962907268170426e-05,
      "loss": 3.0693,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.2746657133102417,
      "learning_rate": 1.912781954887218e-05,
      "loss": 3.071,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.28251582384109497,
      "learning_rate": 1.86265664160401e-05,
      "loss": 3.0716,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.2781495749950409,
      "learning_rate": 1.812531328320802e-05,
      "loss": 3.0709,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.2847459614276886,
      "learning_rate": 1.7625062656641606e-05,
      "loss": 3.0689,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.2927994728088379,
      "learning_rate": 1.7123809523809527e-05,
      "loss": 3.0705,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.2749600112438202,
      "learning_rate": 1.6622556390977444e-05,
      "loss": 3.0717,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.2720162868499756,
      "learning_rate": 1.6121303258145365e-05,
      "loss": 3.0732,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 3.0915377140045166,
      "eval_runtime": 80.5672,
      "eval_samples_per_second": 620.6,
      "eval_steps_per_second": 4.853,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.29173895716667175,
      "learning_rate": 1.5621052631578947e-05,
      "loss": 3.0704,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.28704676032066345,
      "learning_rate": 1.5119799498746866e-05,
      "loss": 3.0705,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.27997276186943054,
      "learning_rate": 1.4618546365914787e-05,
      "loss": 3.069,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.28474825620651245,
      "learning_rate": 1.4117293233082707e-05,
      "loss": 3.0675,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.28157615661621094,
      "learning_rate": 1.3617042606516292e-05,
      "loss": 3.0689,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.28350353240966797,
      "learning_rate": 1.3115789473684211e-05,
      "loss": 3.0664,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.27942678332328796,
      "learning_rate": 1.2614536340852132e-05,
      "loss": 3.0679,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.2872137427330017,
      "learning_rate": 1.211328320802005e-05,
      "loss": 3.0701,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 3.0885465145111084,
      "eval_runtime": 80.6919,
      "eval_samples_per_second": 619.641,
      "eval_steps_per_second": 4.846,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.2806835472583771,
      "learning_rate": 1.1613032581453635e-05,
      "loss": 3.0648,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.27580884099006653,
      "learning_rate": 1.1111779448621555e-05,
      "loss": 3.0677,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.27677014470100403,
      "learning_rate": 1.0610526315789474e-05,
      "loss": 3.0663,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.2835004925727844,
      "learning_rate": 1.0109273182957393e-05,
      "loss": 3.0668,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.27911001443862915,
      "learning_rate": 9.609022556390978e-06,
      "loss": 3.0662,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.2803049385547638,
      "learning_rate": 9.107769423558898e-06,
      "loss": 3.0651,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.28634563088417053,
      "learning_rate": 8.606516290726817e-06,
      "loss": 3.0638,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.274071604013443,
      "learning_rate": 8.105263157894736e-06,
      "loss": 3.0646,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 3.086124897003174,
      "eval_runtime": 80.6241,
      "eval_samples_per_second": 620.162,
      "eval_steps_per_second": 4.85,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.278215229511261,
      "learning_rate": 7.605012531328321e-06,
      "loss": 3.0647,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.28091174364089966,
      "learning_rate": 7.10375939849624e-06,
      "loss": 3.0657,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.29196587204933167,
      "learning_rate": 6.60250626566416e-06,
      "loss": 3.0621,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.27814367413520813,
      "learning_rate": 6.1012531328320804e-06,
      "loss": 3.065,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.2873389422893524,
      "learning_rate": 5.601002506265664e-06,
      "loss": 3.0664,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.2791581451892853,
      "learning_rate": 5.099749373433584e-06,
      "loss": 3.0639,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.28756287693977356,
      "learning_rate": 4.598496240601504e-06,
      "loss": 3.0608,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.2792743444442749,
      "learning_rate": 4.097243107769424e-06,
      "loss": 3.064,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 3.0840413570404053,
      "eval_runtime": 80.6962,
      "eval_samples_per_second": 619.608,
      "eval_steps_per_second": 4.845,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.27614259719848633,
      "learning_rate": 3.5969924812030077e-06,
      "loss": 3.0596,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.2830777168273926,
      "learning_rate": 3.0957393483709274e-06,
      "loss": 3.0625,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.27699974179267883,
      "learning_rate": 2.594486215538847e-06,
      "loss": 3.0584,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.2803332805633545,
      "learning_rate": 2.0942355889724312e-06,
      "loss": 3.0629,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.27155014872550964,
      "learning_rate": 1.592982456140351e-06,
      "loss": 3.0602,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.27476632595062256,
      "learning_rate": 1.0917293233082709e-06,
      "loss": 3.0647,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.26978859305381775,
      "learning_rate": 5.904761904761905e-07,
      "loss": 3.0591,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.2802722156047821,
      "learning_rate": 8.922305764411028e-08,
      "loss": 3.0601,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 3.082892417907715,
      "eval_runtime": 80.5737,
      "eval_samples_per_second": 620.55,
      "eval_steps_per_second": 4.853,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 4000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
