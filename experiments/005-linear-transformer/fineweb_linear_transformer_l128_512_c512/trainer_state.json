{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 0.5094148516654968,
      "learning_rate": 0.0002,
      "loss": 6.874,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 0.5426596999168396,
      "learning_rate": 0.00019949874686716793,
      "loss": 5.2326,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.5801562666893005,
      "learning_rate": 0.00019899749373433585,
      "loss": 4.6458,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.563838541507721,
      "learning_rate": 0.00019849624060150375,
      "loss": 4.2365,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.5758657455444336,
      "learning_rate": 0.0001979949874686717,
      "loss": 4.0049,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.5277881622314453,
      "learning_rate": 0.0001974937343358396,
      "loss": 3.8572,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.5394179821014404,
      "learning_rate": 0.00019699248120300754,
      "loss": 3.7501,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.5678505301475525,
      "learning_rate": 0.00019649122807017543,
      "loss": 3.6719,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.6375129222869873,
      "eval_runtime": 43.8679,
      "eval_samples_per_second": 1139.786,
      "eval_steps_per_second": 8.913,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.5148686766624451,
      "learning_rate": 0.00019598997493734338,
      "loss": 3.6103,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.4998272657394409,
      "learning_rate": 0.00019548872180451127,
      "loss": 3.5592,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.521234929561615,
      "learning_rate": 0.00019498746867167922,
      "loss": 3.5152,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.5020177960395813,
      "learning_rate": 0.0001944862155388471,
      "loss": 3.477,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.5291814208030701,
      "learning_rate": 0.00019398496240601503,
      "loss": 3.4443,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.5331148505210876,
      "learning_rate": 0.00019348370927318296,
      "loss": 3.4176,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.48608624935150146,
      "learning_rate": 0.00019298245614035088,
      "loss": 3.389,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.4961760938167572,
      "learning_rate": 0.0001924812030075188,
      "loss": 3.3691,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.3541674613952637,
      "eval_runtime": 43.7002,
      "eval_samples_per_second": 1144.159,
      "eval_steps_per_second": 8.947,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.48621800541877747,
      "learning_rate": 0.00019197994987468672,
      "loss": 3.3477,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.4926784336566925,
      "learning_rate": 0.00019147869674185464,
      "loss": 3.3281,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.4782387912273407,
      "learning_rate": 0.00019097744360902256,
      "loss": 3.308,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.48709890246391296,
      "learning_rate": 0.00019047619047619048,
      "loss": 3.2949,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.5030699372291565,
      "learning_rate": 0.00018997593984962407,
      "loss": 3.2788,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.4829704761505127,
      "learning_rate": 0.000189474686716792,
      "loss": 3.2674,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.48649924993515015,
      "learning_rate": 0.0001889734335839599,
      "loss": 3.2507,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.4559277892112732,
      "learning_rate": 0.00018847218045112783,
      "loss": 3.2399,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.234288215637207,
      "eval_runtime": 43.735,
      "eval_samples_per_second": 1143.25,
      "eval_steps_per_second": 8.94,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.45807862281799316,
      "learning_rate": 0.00018797192982456142,
      "loss": 3.2303,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.472464919090271,
      "learning_rate": 0.00018747067669172934,
      "loss": 3.2215,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.4496246874332428,
      "learning_rate": 0.00018696942355889726,
      "loss": 3.2045,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.45488855242729187,
      "learning_rate": 0.00018646817042606518,
      "loss": 3.1992,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.44939061999320984,
      "learning_rate": 0.00018596791979949874,
      "loss": 3.1895,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.4421457052230835,
      "learning_rate": 0.00018546666666666668,
      "loss": 3.1822,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.4503263533115387,
      "learning_rate": 0.00018496641604010024,
      "loss": 3.1707,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.4484526216983795,
      "learning_rate": 0.0001844651629072682,
      "loss": 3.1656,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.1579296588897705,
      "eval_runtime": 43.7161,
      "eval_samples_per_second": 1143.743,
      "eval_steps_per_second": 8.944,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.44835978746414185,
      "learning_rate": 0.00018396390977443608,
      "loss": 3.1577,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.45736443996429443,
      "learning_rate": 0.00018346265664160403,
      "loss": 3.1503,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.45455580949783325,
      "learning_rate": 0.00018296140350877193,
      "loss": 3.1443,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.4448179006576538,
      "learning_rate": 0.00018246015037593987,
      "loss": 3.1333,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.44222256541252136,
      "learning_rate": 0.00018195889724310777,
      "loss": 3.1305,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.4598183333873749,
      "learning_rate": 0.00018145764411027572,
      "loss": 3.1263,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.4554477632045746,
      "learning_rate": 0.00018095739348370927,
      "loss": 3.1155,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.43232959508895874,
      "learning_rate": 0.00018045714285714286,
      "loss": 3.1112,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.1091487407684326,
      "eval_runtime": 43.7367,
      "eval_samples_per_second": 1143.205,
      "eval_steps_per_second": 8.94,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.4370407462120056,
      "learning_rate": 0.00017995588972431078,
      "loss": 3.1075,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.43532517552375793,
      "learning_rate": 0.0001794546365914787,
      "loss": 3.1025,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.45287513732910156,
      "learning_rate": 0.00017895338345864662,
      "loss": 3.0981,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.4317934215068817,
      "learning_rate": 0.0001784531328320802,
      "loss": 3.0911,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.4640533924102783,
      "learning_rate": 0.00017795187969924813,
      "loss": 3.0882,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.4181681275367737,
      "learning_rate": 0.00017745062656641605,
      "loss": 3.0821,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.43196508288383484,
      "learning_rate": 0.00017694937343358397,
      "loss": 3.0773,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.4402000904083252,
      "learning_rate": 0.00017644912280701756,
      "loss": 3.0738,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.0701534748077393,
      "eval_runtime": 43.8594,
      "eval_samples_per_second": 1140.008,
      "eval_steps_per_second": 8.915,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.43026697635650635,
      "learning_rate": 0.00017594786967418545,
      "loss": 3.07,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.4355687201023102,
      "learning_rate": 0.0001754466165413534,
      "loss": 3.0636,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.45734789967536926,
      "learning_rate": 0.0001749453634085213,
      "loss": 3.0604,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.45445531606674194,
      "learning_rate": 0.00017444411027568924,
      "loss": 3.0548,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.44037508964538574,
      "learning_rate": 0.0001739438596491228,
      "loss": 3.0536,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.4590218663215637,
      "learning_rate": 0.00017344260651629075,
      "loss": 3.0489,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.4502079486846924,
      "learning_rate": 0.00017294135338345864,
      "loss": 3.0461,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.4370653033256531,
      "learning_rate": 0.0001724401002506266,
      "loss": 3.0411,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.0396220684051514,
      "eval_runtime": 43.649,
      "eval_samples_per_second": 1145.502,
      "eval_steps_per_second": 8.958,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.43306219577789307,
      "learning_rate": 0.00017193984962406015,
      "loss": 3.0413,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.42959392070770264,
      "learning_rate": 0.0001714385964912281,
      "loss": 3.0369,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.43633759021759033,
      "learning_rate": 0.000170937343358396,
      "loss": 3.0334,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.4426649510860443,
      "learning_rate": 0.00017043609022556394,
      "loss": 3.0282,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.4296224117279053,
      "learning_rate": 0.00016993483709273183,
      "loss": 3.0245,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.44769883155822754,
      "learning_rate": 0.00016943458646616542,
      "loss": 3.0209,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.43781763315200806,
      "learning_rate": 0.00016893333333333334,
      "loss": 3.019,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.44802209734916687,
      "learning_rate": 0.00016843208020050126,
      "loss": 3.0191,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.0138370990753174,
      "eval_runtime": 43.7039,
      "eval_samples_per_second": 1144.063,
      "eval_steps_per_second": 8.947,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.42578670382499695,
      "learning_rate": 0.00016793082706766918,
      "loss": 3.0139,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.4272690713405609,
      "learning_rate": 0.00016743057644110277,
      "loss": 3.0123,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.4172497093677521,
      "learning_rate": 0.00016692932330827069,
      "loss": 3.0052,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.4406090974807739,
      "learning_rate": 0.0001664280701754386,
      "loss": 3.0063,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.4333668649196625,
      "learning_rate": 0.00016592681704260653,
      "loss": 3.005,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.4295385479927063,
      "learning_rate": 0.0001654265664160401,
      "loss": 3.0013,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.4498324990272522,
      "learning_rate": 0.00016492531328320803,
      "loss": 2.998,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.43344148993492126,
      "learning_rate": 0.00016442406015037596,
      "loss": 2.9957,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 2.9927384853363037,
      "eval_runtime": 43.7347,
      "eval_samples_per_second": 1143.256,
      "eval_steps_per_second": 8.94,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.4461829364299774,
      "learning_rate": 0.00016392280701754388,
      "loss": 2.9918,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.0001634215538847118,
      "loss": 2.991,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.4375080466270447,
      "learning_rate": 0.00016292130325814536,
      "loss": 2.9866,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.42418572306632996,
      "learning_rate": 0.0001624200501253133,
      "loss": 2.9875,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.4150018095970154,
      "learning_rate": 0.0001619187969924812,
      "loss": 2.9856,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.42458686232566833,
      "learning_rate": 0.00016141754385964915,
      "loss": 2.9808,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.43245670199394226,
      "learning_rate": 0.0001609172932330827,
      "loss": 2.9813,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.4223591089248657,
      "learning_rate": 0.00016041604010025065,
      "loss": 2.9789,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 2.9745821952819824,
      "eval_runtime": 43.6866,
      "eval_samples_per_second": 1144.514,
      "eval_steps_per_second": 8.95,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.42482122778892517,
      "learning_rate": 0.00015991478696741855,
      "loss": 2.9766,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.45339465141296387,
      "learning_rate": 0.0001594135338345865,
      "loss": 2.9743,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.44467854499816895,
      "learning_rate": 0.00015891328320802005,
      "loss": 2.9734,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.4646386206150055,
      "learning_rate": 0.00015841203007518797,
      "loss": 2.9678,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.4362000524997711,
      "learning_rate": 0.0001579107769423559,
      "loss": 2.9696,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.431102454662323,
      "learning_rate": 0.00015740952380952382,
      "loss": 2.9664,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.44298315048217773,
      "learning_rate": 0.00015690827067669174,
      "loss": 2.9648,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.42575857043266296,
      "learning_rate": 0.00015640802005012532,
      "loss": 2.9595,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 2.9584550857543945,
      "eval_runtime": 43.7785,
      "eval_samples_per_second": 1142.112,
      "eval_steps_per_second": 8.931,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.44513970613479614,
      "learning_rate": 0.00015590676691729324,
      "loss": 2.9635,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.40471121668815613,
      "learning_rate": 0.00015540551378446116,
      "loss": 2.9592,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.4609752595424652,
      "learning_rate": 0.00015490426065162908,
      "loss": 2.9541,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.4232732057571411,
      "learning_rate": 0.000154403007518797,
      "loss": 2.9549,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.430193692445755,
      "learning_rate": 0.0001539027568922306,
      "loss": 2.9521,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.40723398327827454,
      "learning_rate": 0.0001534015037593985,
      "loss": 2.9469,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.4358430504798889,
      "learning_rate": 0.00015290025062656643,
      "loss": 2.9511,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.42690742015838623,
      "learning_rate": 0.00015239899749373435,
      "loss": 2.9467,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 2.9444727897644043,
      "eval_runtime": 43.7024,
      "eval_samples_per_second": 1144.101,
      "eval_steps_per_second": 8.947,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.4105178713798523,
      "learning_rate": 0.0001518987468671679,
      "loss": 2.9458,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.44244202971458435,
      "learning_rate": 0.00015139749373433586,
      "loss": 2.9441,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.42071232199668884,
      "learning_rate": 0.00015089624060150375,
      "loss": 2.9433,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.42898255586624146,
      "learning_rate": 0.0001503949874686717,
      "loss": 2.9411,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.41136816143989563,
      "learning_rate": 0.00014989473684210526,
      "loss": 2.9398,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.4090268909931183,
      "learning_rate": 0.0001493934837092732,
      "loss": 2.935,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.43730807304382324,
      "learning_rate": 0.0001488922305764411,
      "loss": 2.9396,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.4444643259048462,
      "learning_rate": 0.00014839097744360902,
      "loss": 2.9352,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 2.9318032264709473,
      "eval_runtime": 43.7044,
      "eval_samples_per_second": 1144.048,
      "eval_steps_per_second": 8.946,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.4072420299053192,
      "learning_rate": 0.00014788972431077694,
      "loss": 2.931,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.43779584765434265,
      "learning_rate": 0.00014738947368421056,
      "loss": 2.9296,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.42815980315208435,
      "learning_rate": 0.00014688822055137845,
      "loss": 2.9284,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.4098178744316101,
      "learning_rate": 0.00014638696741854637,
      "loss": 2.9302,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.44011634588241577,
      "learning_rate": 0.0001458857142857143,
      "loss": 2.9297,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.4192306399345398,
      "learning_rate": 0.00014538446115288221,
      "loss": 2.9248,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.43244242668151855,
      "learning_rate": 0.0001448842105263158,
      "loss": 2.9235,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.4117450714111328,
      "learning_rate": 0.00014438295739348372,
      "loss": 2.9233,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 2.9207396507263184,
      "eval_runtime": 43.7366,
      "eval_samples_per_second": 1143.207,
      "eval_steps_per_second": 8.94,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.42611435055732727,
      "learning_rate": 0.00014388170426065164,
      "loss": 2.9212,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.420998215675354,
      "learning_rate": 0.00014338045112781953,
      "loss": 2.9216,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.4325411319732666,
      "learning_rate": 0.00014287919799498748,
      "loss": 2.9169,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.424468994140625,
      "learning_rate": 0.00014237794486215538,
      "loss": 2.916,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.42468515038490295,
      "learning_rate": 0.000141877694235589,
      "loss": 2.918,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.41465651988983154,
      "learning_rate": 0.00014137644110275688,
      "loss": 2.9157,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.421223908662796,
      "learning_rate": 0.00014087518796992483,
      "loss": 2.9132,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.43013209104537964,
      "learning_rate": 0.00014037393483709273,
      "loss": 2.9121,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 2.9103007316589355,
      "eval_runtime": 43.7074,
      "eval_samples_per_second": 1143.971,
      "eval_steps_per_second": 8.946,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.4311369061470032,
      "learning_rate": 0.00013987268170426067,
      "loss": 2.9137,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.43138939142227173,
      "learning_rate": 0.00013937142857142857,
      "loss": 2.9105,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.44125136733055115,
      "learning_rate": 0.00013887017543859652,
      "loss": 2.9089,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.43119919300079346,
      "learning_rate": 0.00013836992481203007,
      "loss": 2.9073,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.4021197557449341,
      "learning_rate": 0.000137868671679198,
      "loss": 2.907,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.4259616434574127,
      "learning_rate": 0.00013736741854636592,
      "loss": 2.9049,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.45989951491355896,
      "learning_rate": 0.00013686616541353384,
      "loss": 2.9048,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.42218446731567383,
      "learning_rate": 0.00013636491228070176,
      "loss": 2.9065,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.9004440307617188,
      "eval_runtime": 43.6648,
      "eval_samples_per_second": 1145.086,
      "eval_steps_per_second": 8.955,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.42514434456825256,
      "learning_rate": 0.00013586365914786968,
      "loss": 2.9034,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.4234555661678314,
      "learning_rate": 0.00013536340852130326,
      "loss": 2.9009,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.4251376986503601,
      "learning_rate": 0.00013486215538847118,
      "loss": 2.8991,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.41338348388671875,
      "learning_rate": 0.0001343609022556391,
      "loss": 2.8982,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.3996320962905884,
      "learning_rate": 0.00013385964912280703,
      "loss": 2.8973,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.39920905232429504,
      "learning_rate": 0.00013335839598997495,
      "loss": 2.8941,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.3972565233707428,
      "learning_rate": 0.00013285714285714287,
      "loss": 2.8963,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.42681291699409485,
      "learning_rate": 0.0001323558897243108,
      "loss": 2.8934,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.8918099403381348,
      "eval_runtime": 43.7248,
      "eval_samples_per_second": 1143.516,
      "eval_steps_per_second": 8.942,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.43292927742004395,
      "learning_rate": 0.0001318546365914787,
      "loss": 2.8945,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.39752113819122314,
      "learning_rate": 0.0001313543859649123,
      "loss": 2.8954,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.409145325422287,
      "learning_rate": 0.00013085413533834588,
      "loss": 2.8938,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.4129504859447479,
      "learning_rate": 0.00013035288220551378,
      "loss": 2.8932,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.40001001954078674,
      "learning_rate": 0.00012985162907268172,
      "loss": 2.8894,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.40116557478904724,
      "learning_rate": 0.00012935037593984962,
      "loss": 2.8907,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.41929522156715393,
      "learning_rate": 0.00012884912280701757,
      "loss": 2.8898,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.42253705859184265,
      "learning_rate": 0.00012834887218045112,
      "loss": 2.8848,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.8839592933654785,
      "eval_runtime": 43.7433,
      "eval_samples_per_second": 1143.033,
      "eval_steps_per_second": 8.939,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.42814451456069946,
      "learning_rate": 0.00012784761904761907,
      "loss": 2.8864,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.42187952995300293,
      "learning_rate": 0.00012734636591478697,
      "loss": 2.8839,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.4126649498939514,
      "learning_rate": 0.0001268451127819549,
      "loss": 2.8812,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.41556316614151,
      "learning_rate": 0.0001263438596491228,
      "loss": 2.8848,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.39922893047332764,
      "learning_rate": 0.00012584260651629073,
      "loss": 2.8799,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.4348706901073456,
      "learning_rate": 0.00012534135338345865,
      "loss": 2.8802,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.4425645172595978,
      "learning_rate": 0.00012484110275689223,
      "loss": 2.8736,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.4177336096763611,
      "learning_rate": 0.00012433984962406016,
      "loss": 2.8701,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.87666654586792,
      "eval_runtime": 43.6533,
      "eval_samples_per_second": 1145.389,
      "eval_steps_per_second": 8.957,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.41266271471977234,
      "learning_rate": 0.00012383859649122808,
      "loss": 2.8702,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.412299245595932,
      "learning_rate": 0.000123337343358396,
      "loss": 2.8691,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.42249754071235657,
      "learning_rate": 0.00012283609022556392,
      "loss": 2.8677,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.42303189635276794,
      "learning_rate": 0.0001223358395989975,
      "loss": 2.8663,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.4043821394443512,
      "learning_rate": 0.00012183458646616541,
      "loss": 2.864,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.42656320333480835,
      "learning_rate": 0.00012133333333333335,
      "loss": 2.868,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.41730478405952454,
      "learning_rate": 0.00012083208020050125,
      "loss": 2.8645,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.42238104343414307,
      "learning_rate": 0.00012033082706766919,
      "loss": 2.8662,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.869556188583374,
      "eval_runtime": 43.8653,
      "eval_samples_per_second": 1139.852,
      "eval_steps_per_second": 8.914,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.4090224504470825,
      "learning_rate": 0.0001198295739348371,
      "loss": 2.8635,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.4090379774570465,
      "learning_rate": 0.00011932832080200502,
      "loss": 2.8651,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.40491268038749695,
      "learning_rate": 0.00011882706766917294,
      "loss": 2.8609,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.41339075565338135,
      "learning_rate": 0.00011832681704260654,
      "loss": 2.8636,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.4013896882534027,
      "learning_rate": 0.00011782556390977444,
      "loss": 2.8608,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.40503358840942383,
      "learning_rate": 0.00011732431077694236,
      "loss": 2.8622,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.4118412137031555,
      "learning_rate": 0.00011682305764411027,
      "loss": 2.8595,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.395020067691803,
      "learning_rate": 0.00011632180451127821,
      "loss": 2.8602,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.862605333328247,
      "eval_runtime": 43.6945,
      "eval_samples_per_second": 1144.308,
      "eval_steps_per_second": 8.948,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.4074491858482361,
      "learning_rate": 0.00011582055137844611,
      "loss": 2.8609,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.41576769948005676,
      "learning_rate": 0.00011531929824561405,
      "loss": 2.8582,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.42416912317276,
      "learning_rate": 0.00011481804511278196,
      "loss": 2.8592,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.40877825021743774,
      "learning_rate": 0.00011431779448621553,
      "loss": 2.8589,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.45434579253196716,
      "learning_rate": 0.00011381654135338346,
      "loss": 2.8551,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.4051659107208252,
      "learning_rate": 0.00011331528822055137,
      "loss": 2.857,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.4149322509765625,
      "learning_rate": 0.00011281503759398497,
      "loss": 2.8526,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.42853352427482605,
      "learning_rate": 0.00011231378446115288,
      "loss": 2.8559,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.8569633960723877,
      "eval_runtime": 43.6941,
      "eval_samples_per_second": 1144.319,
      "eval_steps_per_second": 8.949,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.4072911739349365,
      "learning_rate": 0.00011181253132832081,
      "loss": 2.8528,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.410623162984848,
      "learning_rate": 0.00011131127819548872,
      "loss": 2.8532,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.4179266691207886,
      "learning_rate": 0.00011081102756892232,
      "loss": 2.8528,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.40309298038482666,
      "learning_rate": 0.00011030977443609022,
      "loss": 2.8513,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.4124443829059601,
      "learning_rate": 0.00010980852130325816,
      "loss": 2.8496,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.4232868254184723,
      "learning_rate": 0.00010930726817042607,
      "loss": 2.849,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.433739572763443,
      "learning_rate": 0.000108806015037594,
      "loss": 2.8486,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.42187178134918213,
      "learning_rate": 0.00010830476190476191,
      "loss": 2.8494,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.850558042526245,
      "eval_runtime": 43.6717,
      "eval_samples_per_second": 1144.907,
      "eval_steps_per_second": 8.953,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.4224601089954376,
      "learning_rate": 0.00010780350877192984,
      "loss": 2.8507,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.40884849429130554,
      "learning_rate": 0.00010730225563909775,
      "loss": 2.8477,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.4137892723083496,
      "learning_rate": 0.00010680200501253132,
      "loss": 2.8454,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.4479408860206604,
      "learning_rate": 0.00010630075187969926,
      "loss": 2.8493,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.42311719059944153,
      "learning_rate": 0.00010579949874686716,
      "loss": 2.8462,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.4418245255947113,
      "learning_rate": 0.0001052982456140351,
      "loss": 2.8448,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.4331984519958496,
      "learning_rate": 0.00010479799498746867,
      "loss": 2.8461,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.4218393564224243,
      "learning_rate": 0.0001042967418546366,
      "loss": 2.8419,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.8449203968048096,
      "eval_runtime": 43.7108,
      "eval_samples_per_second": 1143.882,
      "eval_steps_per_second": 8.945,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.41464105248451233,
      "learning_rate": 0.00010379548872180451,
      "loss": 2.8405,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.4314459562301636,
      "learning_rate": 0.00010329523809523808,
      "loss": 2.845,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.4035472571849823,
      "learning_rate": 0.00010279398496240602,
      "loss": 2.8402,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.4344470798969269,
      "learning_rate": 0.00010229273182957393,
      "loss": 2.8418,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.41312336921691895,
      "learning_rate": 0.00010179147869674186,
      "loss": 2.8392,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.4442536234855652,
      "learning_rate": 0.00010129022556390977,
      "loss": 2.8406,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.43160295486450195,
      "learning_rate": 0.0001007889724310777,
      "loss": 2.8379,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.42223620414733887,
      "learning_rate": 0.00010028771929824561,
      "loss": 2.8381,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.8400261402130127,
      "eval_runtime": 43.8154,
      "eval_samples_per_second": 1141.151,
      "eval_steps_per_second": 8.924,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.42336663603782654,
      "learning_rate": 9.978646616541355e-05,
      "loss": 2.8341,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.4216296076774597,
      "learning_rate": 9.928621553884713e-05,
      "loss": 2.8359,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.419185608625412,
      "learning_rate": 9.878496240601505e-05,
      "loss": 2.8364,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.4080204963684082,
      "learning_rate": 9.828370927318297e-05,
      "loss": 2.8349,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.4168456792831421,
      "learning_rate": 9.778245614035088e-05,
      "loss": 2.8349,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.413575142621994,
      "learning_rate": 9.728320802005013e-05,
      "loss": 2.8337,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.41907137632369995,
      "learning_rate": 9.678195488721805e-05,
      "loss": 2.8342,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.4184757173061371,
      "learning_rate": 9.628070175438597e-05,
      "loss": 2.8312,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 2.834503650665283,
      "eval_runtime": 43.6852,
      "eval_samples_per_second": 1144.554,
      "eval_steps_per_second": 8.95,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.416768878698349,
      "learning_rate": 9.577944862155389e-05,
      "loss": 2.8342,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.4117617905139923,
      "learning_rate": 9.527819548872181e-05,
      "loss": 2.8305,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.43434712290763855,
      "learning_rate": 9.477694235588973e-05,
      "loss": 2.8279,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.4002894461154938,
      "learning_rate": 9.427568922305766e-05,
      "loss": 2.8306,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.43374326825141907,
      "learning_rate": 9.377443609022558e-05,
      "loss": 2.8296,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.4149820804595947,
      "learning_rate": 9.327418546365915e-05,
      "loss": 2.8293,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.40496233105659485,
      "learning_rate": 9.277293233082707e-05,
      "loss": 2.8284,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.4347686767578125,
      "learning_rate": 9.227167919799499e-05,
      "loss": 2.8262,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 2.829472303390503,
      "eval_runtime": 43.6937,
      "eval_samples_per_second": 1144.328,
      "eval_steps_per_second": 8.949,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.419475793838501,
      "learning_rate": 9.177042606516291e-05,
      "loss": 2.8282,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.43192198872566223,
      "learning_rate": 9.12701754385965e-05,
      "loss": 2.8266,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.412879079580307,
      "learning_rate": 9.076892230576442e-05,
      "loss": 2.8231,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.40066954493522644,
      "learning_rate": 9.026766917293234e-05,
      "loss": 2.8271,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.40732696652412415,
      "learning_rate": 8.976641604010026e-05,
      "loss": 2.8231,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.4253338575363159,
      "learning_rate": 8.926616541353384e-05,
      "loss": 2.8262,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.41454488039016724,
      "learning_rate": 8.876491228070177e-05,
      "loss": 2.824,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.40215474367141724,
      "learning_rate": 8.826365914786969e-05,
      "loss": 2.8233,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 2.824896812438965,
      "eval_runtime": 43.7006,
      "eval_samples_per_second": 1144.15,
      "eval_steps_per_second": 8.947,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.4151962101459503,
      "learning_rate": 8.776240601503761e-05,
      "loss": 2.8233,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.4225151836872101,
      "learning_rate": 8.726215538847118e-05,
      "loss": 2.8223,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.416637659072876,
      "learning_rate": 8.67609022556391e-05,
      "loss": 2.8229,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.4193698763847351,
      "learning_rate": 8.625964912280702e-05,
      "loss": 2.8213,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.4151623845100403,
      "learning_rate": 8.575839598997494e-05,
      "loss": 2.8215,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.4192184805870056,
      "learning_rate": 8.525814536340853e-05,
      "loss": 2.8176,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.4466206133365631,
      "learning_rate": 8.475689223057645e-05,
      "loss": 2.8205,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.4208296835422516,
      "learning_rate": 8.425563909774437e-05,
      "loss": 2.8195,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 2.82037615776062,
      "eval_runtime": 43.6438,
      "eval_samples_per_second": 1145.639,
      "eval_steps_per_second": 8.959,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.40852630138397217,
      "learning_rate": 8.375438596491229e-05,
      "loss": 2.8207,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.4198901057243347,
      "learning_rate": 8.325413533834588e-05,
      "loss": 2.818,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.4096662998199463,
      "learning_rate": 8.27528822055138e-05,
      "loss": 2.8175,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.4238375723361969,
      "learning_rate": 8.225162907268172e-05,
      "loss": 2.8163,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.41867512464523315,
      "learning_rate": 8.175037593984964e-05,
      "loss": 2.8177,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.4265291690826416,
      "learning_rate": 8.125012531328321e-05,
      "loss": 2.8154,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.43291139602661133,
      "learning_rate": 8.074887218045113e-05,
      "loss": 2.8158,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.42796504497528076,
      "learning_rate": 8.024761904761905e-05,
      "loss": 2.8157,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 2.8158774375915527,
      "eval_runtime": 43.7633,
      "eval_samples_per_second": 1142.51,
      "eval_steps_per_second": 8.934,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.43251997232437134,
      "learning_rate": 7.974636591478697e-05,
      "loss": 2.8135,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.4122486710548401,
      "learning_rate": 7.924611528822056e-05,
      "loss": 2.8157,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.4180392920970917,
      "learning_rate": 7.874486215538848e-05,
      "loss": 2.812,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.415377140045166,
      "learning_rate": 7.82436090225564e-05,
      "loss": 2.8137,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.4441535174846649,
      "learning_rate": 7.774335839598997e-05,
      "loss": 2.8146,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.4335833787918091,
      "learning_rate": 7.72421052631579e-05,
      "loss": 2.8102,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.4361402988433838,
      "learning_rate": 7.674085213032582e-05,
      "loss": 2.8137,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.43388301134109497,
      "learning_rate": 7.623959899749374e-05,
      "loss": 2.8112,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 2.8119518756866455,
      "eval_runtime": 43.6613,
      "eval_samples_per_second": 1145.18,
      "eval_steps_per_second": 8.955,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.4179491400718689,
      "learning_rate": 7.573834586466166e-05,
      "loss": 2.8098,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.4227807819843292,
      "learning_rate": 7.523709273182958e-05,
      "loss": 2.8088,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.41420796513557434,
      "learning_rate": 7.47358395989975e-05,
      "loss": 2.8071,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.4246467649936676,
      "learning_rate": 7.42345864661654e-05,
      "loss": 2.8102,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.41970279812812805,
      "learning_rate": 7.3734335839599e-05,
      "loss": 2.8068,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.4209412634372711,
      "learning_rate": 7.323308270676693e-05,
      "loss": 2.8088,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.40152478218078613,
      "learning_rate": 7.273182957393483e-05,
      "loss": 2.8069,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.41387632489204407,
      "learning_rate": 7.223057644110275e-05,
      "loss": 2.8061,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 2.807777166366577,
      "eval_runtime": 43.6608,
      "eval_samples_per_second": 1145.193,
      "eval_steps_per_second": 8.955,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.4295719265937805,
      "learning_rate": 7.173032581453635e-05,
      "loss": 2.8072,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.4372546970844269,
      "learning_rate": 7.122907268170426e-05,
      "loss": 2.807,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.43246617913246155,
      "learning_rate": 7.072781954887218e-05,
      "loss": 2.8083,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.4234906733036041,
      "learning_rate": 7.02265664160401e-05,
      "loss": 2.8038,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.4264982044696808,
      "learning_rate": 6.972631578947369e-05,
      "loss": 2.7999,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.4166553318500519,
      "learning_rate": 6.922606516290727e-05,
      "loss": 2.8029,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.42346709966659546,
      "learning_rate": 6.87248120300752e-05,
      "loss": 2.8029,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.4206879734992981,
      "learning_rate": 6.822355889724312e-05,
      "loss": 2.8021,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 2.803668737411499,
      "eval_runtime": 43.724,
      "eval_samples_per_second": 1143.537,
      "eval_steps_per_second": 8.942,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.44708237051963806,
      "learning_rate": 6.772230576441104e-05,
      "loss": 2.8006,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.4347052574157715,
      "learning_rate": 6.722105263157896e-05,
      "loss": 2.8007,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.42241939902305603,
      "learning_rate": 6.671979949874687e-05,
      "loss": 2.8011,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.4294212758541107,
      "learning_rate": 6.621854636591479e-05,
      "loss": 2.8001,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.4525716304779053,
      "learning_rate": 6.571729323308271e-05,
      "loss": 2.8012,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.41881635785102844,
      "learning_rate": 6.521704260651629e-05,
      "loss": 2.802,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.4364733397960663,
      "learning_rate": 6.471578947368421e-05,
      "loss": 2.8,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.4043421447277069,
      "learning_rate": 6.421453634085213e-05,
      "loss": 2.7974,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 2.7997446060180664,
      "eval_runtime": 43.7237,
      "eval_samples_per_second": 1143.545,
      "eval_steps_per_second": 8.943,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.4369373023509979,
      "learning_rate": 6.371328320802006e-05,
      "loss": 2.798,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.45444661378860474,
      "learning_rate": 6.321303258145364e-05,
      "loss": 2.7983,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.41315096616744995,
      "learning_rate": 6.271177944862155e-05,
      "loss": 2.7972,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.4092448055744171,
      "learning_rate": 6.221052631578947e-05,
      "loss": 2.797,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.42311957478523254,
      "learning_rate": 6.170927318295739e-05,
      "loss": 2.795,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.44104915857315063,
      "learning_rate": 6.120902255639099e-05,
      "loss": 2.7994,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.4256063997745514,
      "learning_rate": 6.0707769423558903e-05,
      "loss": 2.7941,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.4351346492767334,
      "learning_rate": 6.0206516290726824e-05,
      "loss": 2.7954,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 2.7956647872924805,
      "eval_runtime": 43.7783,
      "eval_samples_per_second": 1142.118,
      "eval_steps_per_second": 8.931,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.43623706698417664,
      "learning_rate": 5.970526315789474e-05,
      "loss": 2.7967,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.42177218198776245,
      "learning_rate": 5.920501253132832e-05,
      "loss": 2.7941,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.4220607578754425,
      "learning_rate": 5.870375939849624e-05,
      "loss": 2.794,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.4338257312774658,
      "learning_rate": 5.820250626566416e-05,
      "loss": 2.7909,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.43235114216804504,
      "learning_rate": 5.770125313283208e-05,
      "loss": 2.7944,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.4347846806049347,
      "learning_rate": 5.7201002506265666e-05,
      "loss": 2.791,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.43910643458366394,
      "learning_rate": 5.6699749373433587e-05,
      "loss": 2.7919,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.4417611360549927,
      "learning_rate": 5.619849624060151e-05,
      "loss": 2.7914,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 2.791975975036621,
      "eval_runtime": 43.7144,
      "eval_samples_per_second": 1143.787,
      "eval_steps_per_second": 8.944,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.42387399077415466,
      "learning_rate": 5.569724310776943e-05,
      "loss": 2.7904,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.4334605634212494,
      "learning_rate": 5.5196992481203014e-05,
      "loss": 2.7918,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.4348064363002777,
      "learning_rate": 5.4695739348370935e-05,
      "loss": 2.7929,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.4359590709209442,
      "learning_rate": 5.4194486215538856e-05,
      "loss": 2.7896,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.4182392358779907,
      "learning_rate": 5.369323308270677e-05,
      "loss": 2.7885,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.4330717921257019,
      "learning_rate": 5.319298245614035e-05,
      "loss": 2.7898,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.4513636529445648,
      "learning_rate": 5.269172932330827e-05,
      "loss": 2.7896,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.44799673557281494,
      "learning_rate": 5.219047619047619e-05,
      "loss": 2.7868,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 2.788764476776123,
      "eval_runtime": 43.7206,
      "eval_samples_per_second": 1143.625,
      "eval_steps_per_second": 8.943,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.43382903933525085,
      "learning_rate": 5.168922305764411e-05,
      "loss": 2.7873,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.431728333234787,
      "learning_rate": 5.11889724310777e-05,
      "loss": 2.7869,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.429962694644928,
      "learning_rate": 5.068771929824562e-05,
      "loss": 2.7845,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.43109604716300964,
      "learning_rate": 5.018646616541354e-05,
      "loss": 2.7867,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.43316537141799927,
      "learning_rate": 4.968521303258146e-05,
      "loss": 2.7854,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.42623209953308105,
      "learning_rate": 4.918496240601504e-05,
      "loss": 2.7762,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.4407917559146881,
      "learning_rate": 4.868370927318296e-05,
      "loss": 2.7765,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.44574061036109924,
      "learning_rate": 4.818245614035088e-05,
      "loss": 2.7724,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 2.7858448028564453,
      "eval_runtime": 43.7115,
      "eval_samples_per_second": 1143.863,
      "eval_steps_per_second": 8.945,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.453158974647522,
      "learning_rate": 4.76812030075188e-05,
      "loss": 2.7759,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.42216283082962036,
      "learning_rate": 4.718095238095238e-05,
      "loss": 2.7747,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.4230997562408447,
      "learning_rate": 4.66796992481203e-05,
      "loss": 2.7757,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.445696622133255,
      "learning_rate": 4.617844611528822e-05,
      "loss": 2.7745,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.44262856245040894,
      "learning_rate": 4.567719298245614e-05,
      "loss": 2.7769,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.45180073380470276,
      "learning_rate": 4.517694235588973e-05,
      "loss": 2.7733,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.4289986789226532,
      "learning_rate": 4.467568922305765e-05,
      "loss": 2.7734,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.43674471974372864,
      "learning_rate": 4.417443609022557e-05,
      "loss": 2.7734,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 2.782923460006714,
      "eval_runtime": 43.662,
      "eval_samples_per_second": 1145.161,
      "eval_steps_per_second": 8.955,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.42911404371261597,
      "learning_rate": 4.367318295739349e-05,
      "loss": 2.7736,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.4299134910106659,
      "learning_rate": 4.317293233082707e-05,
      "loss": 2.7727,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.47458258271217346,
      "learning_rate": 4.267167919799499e-05,
      "loss": 2.7734,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.44311147928237915,
      "learning_rate": 4.217042606516291e-05,
      "loss": 2.7733,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.43292152881622314,
      "learning_rate": 4.166917293233083e-05,
      "loss": 2.7712,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.450711727142334,
      "learning_rate": 4.116892230576441e-05,
      "loss": 2.7715,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.4403713643550873,
      "learning_rate": 4.066766917293233e-05,
      "loss": 2.7717,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.47152698040008545,
      "learning_rate": 4.0166416040100253e-05,
      "loss": 2.7711,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 2.7795228958129883,
      "eval_runtime": 43.6959,
      "eval_samples_per_second": 1144.273,
      "eval_steps_per_second": 8.948,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.43345755338668823,
      "learning_rate": 3.9665162907268174e-05,
      "loss": 2.7718,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.4433572590351105,
      "learning_rate": 3.916491228070175e-05,
      "loss": 2.7713,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.4319378137588501,
      "learning_rate": 3.8663659147869674e-05,
      "loss": 2.7702,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.43359488248825073,
      "learning_rate": 3.8162406015037595e-05,
      "loss": 2.7695,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.44381844997406006,
      "learning_rate": 3.7661152882205516e-05,
      "loss": 2.771,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.4441624879837036,
      "learning_rate": 3.71609022556391e-05,
      "loss": 2.7675,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.4412131905555725,
      "learning_rate": 3.665964912280702e-05,
      "loss": 2.7656,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.42532387375831604,
      "learning_rate": 3.615839598997494e-05,
      "loss": 2.7692,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 2.777012586593628,
      "eval_runtime": 43.7403,
      "eval_samples_per_second": 1143.111,
      "eval_steps_per_second": 8.939,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.4485291838645935,
      "learning_rate": 3.5657142857142864e-05,
      "loss": 2.768,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.4526616036891937,
      "learning_rate": 3.515588972431078e-05,
      "loss": 2.7678,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.4361492693424225,
      "learning_rate": 3.46546365914787e-05,
      "loss": 2.7676,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.43221208453178406,
      "learning_rate": 3.415338345864662e-05,
      "loss": 2.7649,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.4333505630493164,
      "learning_rate": 3.365213032581454e-05,
      "loss": 2.7697,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.45295146107673645,
      "learning_rate": 3.315187969924812e-05,
      "loss": 2.7657,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.45071542263031006,
      "learning_rate": 3.265062656641604e-05,
      "loss": 2.768,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.43129968643188477,
      "learning_rate": 3.214937343358396e-05,
      "loss": 2.7649,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 2.77358341217041,
      "eval_runtime": 43.8875,
      "eval_samples_per_second": 1139.276,
      "eval_steps_per_second": 8.909,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.4508228003978729,
      "learning_rate": 3.164812030075188e-05,
      "loss": 2.7647,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.45036715269088745,
      "learning_rate": 3.114786967418546e-05,
      "loss": 2.7676,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.43535420298576355,
      "learning_rate": 3.064661654135338e-05,
      "loss": 2.7664,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.44864746928215027,
      "learning_rate": 3.0145363408521304e-05,
      "loss": 2.7654,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.4712783694267273,
      "learning_rate": 2.9644110275689225e-05,
      "loss": 2.7638,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.4390889108181,
      "learning_rate": 2.9143859649122806e-05,
      "loss": 2.7624,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.43837761878967285,
      "learning_rate": 2.8642606516290727e-05,
      "loss": 2.7628,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.4446928799152374,
      "learning_rate": 2.8141353383458645e-05,
      "loss": 2.7626,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 2.770751953125,
      "eval_runtime": 43.7704,
      "eval_samples_per_second": 1142.323,
      "eval_steps_per_second": 8.933,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.44302618503570557,
      "learning_rate": 2.7640100250626566e-05,
      "loss": 2.7627,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.44481706619262695,
      "learning_rate": 2.7139849624060155e-05,
      "loss": 2.7639,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.45762157440185547,
      "learning_rate": 2.6638596491228072e-05,
      "loss": 2.7651,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.4419200122356415,
      "learning_rate": 2.6137343358395993e-05,
      "loss": 2.7622,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.4507136642932892,
      "learning_rate": 2.5636090225563914e-05,
      "loss": 2.7643,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.44251516461372375,
      "learning_rate": 2.5135839598997496e-05,
      "loss": 2.7598,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.45040860772132874,
      "learning_rate": 2.4634586466165417e-05,
      "loss": 2.7628,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.4478965103626251,
      "learning_rate": 2.4133333333333335e-05,
      "loss": 2.7638,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.767885208129883,
      "eval_runtime": 43.7323,
      "eval_samples_per_second": 1143.32,
      "eval_steps_per_second": 8.941,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.4615945518016815,
      "learning_rate": 2.3632080200501256e-05,
      "loss": 2.762,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.43201667070388794,
      "learning_rate": 2.3131829573934838e-05,
      "loss": 2.7591,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.45894482731819153,
      "learning_rate": 2.263057644110276e-05,
      "loss": 2.759,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.4406612515449524,
      "learning_rate": 2.2129323308270676e-05,
      "loss": 2.7604,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.4416237771511078,
      "learning_rate": 2.1628070175438597e-05,
      "loss": 2.7601,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.46210581064224243,
      "learning_rate": 2.1127819548872183e-05,
      "loss": 2.759,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.4486055374145508,
      "learning_rate": 2.0626566416040104e-05,
      "loss": 2.7618,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.4575183391571045,
      "learning_rate": 2.0126315789473686e-05,
      "loss": 2.7576,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.765087604522705,
      "eval_runtime": 43.7206,
      "eval_samples_per_second": 1143.626,
      "eval_steps_per_second": 8.943,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.45547401905059814,
      "learning_rate": 1.9625062656641603e-05,
      "loss": 2.7545,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.45359477400779724,
      "learning_rate": 1.9123809523809524e-05,
      "loss": 2.757,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.4501037895679474,
      "learning_rate": 1.8622556390977445e-05,
      "loss": 2.7568,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.4462500512599945,
      "learning_rate": 1.8121303258145363e-05,
      "loss": 2.7557,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.4538014829158783,
      "learning_rate": 1.7620050125313284e-05,
      "loss": 2.7541,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.4571416676044464,
      "learning_rate": 1.7118796992481205e-05,
      "loss": 2.7562,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.43917611241340637,
      "learning_rate": 1.6617543859649123e-05,
      "loss": 2.7574,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.4465729594230652,
      "learning_rate": 1.6117293233082708e-05,
      "loss": 2.7589,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.762582778930664,
      "eval_runtime": 43.7385,
      "eval_samples_per_second": 1143.158,
      "eval_steps_per_second": 8.939,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.459146648645401,
      "learning_rate": 1.561604010025063e-05,
      "loss": 2.7552,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.44768664240837097,
      "learning_rate": 1.5114786967418548e-05,
      "loss": 2.7569,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.4436008632183075,
      "learning_rate": 1.4613533834586467e-05,
      "loss": 2.7549,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.45354199409484863,
      "learning_rate": 1.4113283208020051e-05,
      "loss": 2.7539,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.4493066072463989,
      "learning_rate": 1.361203007518797e-05,
      "loss": 2.755,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.4614025056362152,
      "learning_rate": 1.311077694235589e-05,
      "loss": 2.7523,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.44882842898368835,
      "learning_rate": 1.260952380952381e-05,
      "loss": 2.7539,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.46454334259033203,
      "learning_rate": 1.2109273182957394e-05,
      "loss": 2.7545,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.760195016860962,
      "eval_runtime": 43.8079,
      "eval_samples_per_second": 1141.346,
      "eval_steps_per_second": 8.925,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.4398568272590637,
      "learning_rate": 1.1608020050125314e-05,
      "loss": 2.7491,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.4361601173877716,
      "learning_rate": 1.1106766917293233e-05,
      "loss": 2.7542,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.439132422208786,
      "learning_rate": 1.0605513784461154e-05,
      "loss": 2.7523,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.451913058757782,
      "learning_rate": 1.0105263157894738e-05,
      "loss": 2.7532,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.43466416001319885,
      "learning_rate": 9.604010025062657e-06,
      "loss": 2.7524,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.4422047436237335,
      "learning_rate": 9.102756892230576e-06,
      "loss": 2.7507,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.4530524015426636,
      "learning_rate": 8.601503759398497e-06,
      "loss": 2.7487,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.4420955181121826,
      "learning_rate": 8.10125313283208e-06,
      "loss": 2.7503,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.7579309940338135,
      "eval_runtime": 43.7584,
      "eval_samples_per_second": 1142.638,
      "eval_steps_per_second": 8.935,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.445046067237854,
      "learning_rate": 7.6e-06,
      "loss": 2.7511,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.44679418206214905,
      "learning_rate": 7.09874686716792e-06,
      "loss": 2.7527,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.4718640446662903,
      "learning_rate": 6.598496240601504e-06,
      "loss": 2.7474,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.43719539046287537,
      "learning_rate": 6.097243107769424e-06,
      "loss": 2.7516,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.4605780839920044,
      "learning_rate": 5.595989974937343e-06,
      "loss": 2.7518,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.45494359731674194,
      "learning_rate": 5.0947368421052635e-06,
      "loss": 2.7499,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.4431896507740021,
      "learning_rate": 4.593483709273183e-06,
      "loss": 2.7473,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.4476928114891052,
      "learning_rate": 4.092230576441103e-06,
      "loss": 2.7507,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.7560513019561768,
      "eval_runtime": 43.7247,
      "eval_samples_per_second": 1143.52,
      "eval_steps_per_second": 8.942,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.4425533413887024,
      "learning_rate": 3.5909774436090226e-06,
      "loss": 2.7472,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.4620860517024994,
      "learning_rate": 3.0897243107769424e-06,
      "loss": 2.7479,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.44773149490356445,
      "learning_rate": 2.5894736842105264e-06,
      "loss": 2.7451,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.4416287839412689,
      "learning_rate": 2.088220551378446e-06,
      "loss": 2.7485,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.4471067190170288,
      "learning_rate": 1.5869674185463659e-06,
      "loss": 2.7466,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.43939408659935,
      "learning_rate": 1.0857142857142858e-06,
      "loss": 2.7508,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.43503695726394653,
      "learning_rate": 5.854636591478697e-07,
      "loss": 2.7457,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.4381886124610901,
      "learning_rate": 8.421052631578949e-08,
      "loss": 2.7471,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.7548820972442627,
      "eval_runtime": 43.6977,
      "eval_samples_per_second": 1144.226,
      "eval_steps_per_second": 8.948,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 4000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
