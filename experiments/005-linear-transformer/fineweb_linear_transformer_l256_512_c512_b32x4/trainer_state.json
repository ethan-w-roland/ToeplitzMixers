{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 0.570198118686676,
      "learning_rate": 0.0002,
      "loss": 6.8839,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 0.7525261044502258,
      "learning_rate": 0.00019949874686716793,
      "loss": 5.2871,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.6089336276054382,
      "learning_rate": 0.00019899749373433585,
      "loss": 4.732,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.6733120679855347,
      "learning_rate": 0.00019849624060150375,
      "loss": 4.311,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.620130181312561,
      "learning_rate": 0.0001979949874686717,
      "loss": 4.0366,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.6499727964401245,
      "learning_rate": 0.0001974937343358396,
      "loss": 3.8753,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.5812602043151855,
      "learning_rate": 0.00019699248120300754,
      "loss": 3.7643,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.620279848575592,
      "learning_rate": 0.00019649122807017543,
      "loss": 3.6867,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.6516618728637695,
      "eval_runtime": 49.4379,
      "eval_samples_per_second": 1011.37,
      "eval_steps_per_second": 7.909,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.577505886554718,
      "learning_rate": 0.00019598997493734338,
      "loss": 3.6265,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.5623771548271179,
      "learning_rate": 0.00019548872180451127,
      "loss": 3.5769,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.5695666670799255,
      "learning_rate": 0.00019498746867167922,
      "loss": 3.5336,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.5465672612190247,
      "learning_rate": 0.0001944862155388471,
      "loss": 3.4955,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.533403754234314,
      "learning_rate": 0.00019398496240601503,
      "loss": 3.4628,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.5361206531524658,
      "learning_rate": 0.00019348471177944862,
      "loss": 3.4358,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.5273955464363098,
      "learning_rate": 0.00019298345864661657,
      "loss": 3.4064,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.5024681687355042,
      "learning_rate": 0.00019248220551378446,
      "loss": 3.3849,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.3703653812408447,
      "eval_runtime": 49.3287,
      "eval_samples_per_second": 1013.609,
      "eval_steps_per_second": 7.926,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.5084287524223328,
      "learning_rate": 0.00019198095238095238,
      "loss": 3.3626,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.5073356032371521,
      "learning_rate": 0.0001914796992481203,
      "loss": 3.3422,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.5146462917327881,
      "learning_rate": 0.00019097844611528822,
      "loss": 3.3212,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.502566933631897,
      "learning_rate": 0.00019047719298245615,
      "loss": 3.3071,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.541551947593689,
      "learning_rate": 0.00018997593984962407,
      "loss": 3.2899,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.5149763822555542,
      "learning_rate": 0.000189474686716792,
      "loss": 3.2778,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.4958208501338959,
      "learning_rate": 0.00018897443609022557,
      "loss": 3.2602,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.491047739982605,
      "learning_rate": 0.0001884731829573935,
      "loss": 3.2488,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.242785930633545,
      "eval_runtime": 49.3847,
      "eval_samples_per_second": 1012.46,
      "eval_steps_per_second": 7.917,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.485621839761734,
      "learning_rate": 0.00018797192982456142,
      "loss": 3.2385,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.48633116483688354,
      "learning_rate": 0.00018747067669172934,
      "loss": 3.2292,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.4861207604408264,
      "learning_rate": 0.0001869704260651629,
      "loss": 3.2113,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.47165316343307495,
      "learning_rate": 0.00018646917293233084,
      "loss": 3.2056,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.4782024621963501,
      "learning_rate": 0.00018596791979949874,
      "loss": 3.1952,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.4662759602069855,
      "learning_rate": 0.00018546666666666668,
      "loss": 3.1871,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.46422088146209717,
      "learning_rate": 0.00018496641604010024,
      "loss": 3.1754,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.47101300954818726,
      "learning_rate": 0.0001844651629072682,
      "loss": 3.169,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.162235975265503,
      "eval_runtime": 49.3304,
      "eval_samples_per_second": 1013.573,
      "eval_steps_per_second": 7.926,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.4842965006828308,
      "learning_rate": 0.00018396390977443608,
      "loss": 3.1613,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.4629786014556885,
      "learning_rate": 0.00018346265664160403,
      "loss": 3.1527,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.4731050729751587,
      "learning_rate": 0.00018296140350877193,
      "loss": 3.146,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.46883624792099,
      "learning_rate": 0.00018246115288220554,
      "loss": 3.135,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.471729576587677,
      "learning_rate": 0.00018195989974937343,
      "loss": 3.1322,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.46905529499053955,
      "learning_rate": 0.00018145864661654138,
      "loss": 3.1271,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.4589967727661133,
      "learning_rate": 0.00018095739348370927,
      "loss": 3.1159,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.44424691796302795,
      "learning_rate": 0.00018045714285714286,
      "loss": 3.1111,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.1086678504943848,
      "eval_runtime": 49.3446,
      "eval_samples_per_second": 1013.282,
      "eval_steps_per_second": 7.924,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.45420709252357483,
      "learning_rate": 0.00017995588972431078,
      "loss": 3.107,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.468768835067749,
      "learning_rate": 0.00017945563909774437,
      "loss": 3.102,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.4629817306995392,
      "learning_rate": 0.0001789543859649123,
      "loss": 3.0969,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.4640120267868042,
      "learning_rate": 0.0001784531328320802,
      "loss": 3.0894,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.4824903607368469,
      "learning_rate": 0.00017795187969924813,
      "loss": 3.0864,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.4449152648448944,
      "learning_rate": 0.00017745062656641605,
      "loss": 3.0803,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.45039838552474976,
      "learning_rate": 0.00017694937343358397,
      "loss": 3.0746,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.44510969519615173,
      "learning_rate": 0.0001764481203007519,
      "loss": 3.071,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.0668303966522217,
      "eval_runtime": 49.3339,
      "eval_samples_per_second": 1013.503,
      "eval_steps_per_second": 7.926,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.46524250507354736,
      "learning_rate": 0.0001759468671679198,
      "loss": 3.0667,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.4562043845653534,
      "learning_rate": 0.0001754466165413534,
      "loss": 3.0604,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.4826384484767914,
      "learning_rate": 0.00017494636591478696,
      "loss": 3.0566,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.4700910151004791,
      "learning_rate": 0.0001744451127819549,
      "loss": 3.0514,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.47025322914123535,
      "learning_rate": 0.0001739438596491228,
      "loss": 3.0497,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.47642821073532104,
      "learning_rate": 0.00017344260651629075,
      "loss": 3.0446,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.44723668694496155,
      "learning_rate": 0.00017294135338345864,
      "loss": 3.0411,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.44108203053474426,
      "learning_rate": 0.0001724401002506266,
      "loss": 3.0362,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.035517930984497,
      "eval_runtime": 49.342,
      "eval_samples_per_second": 1013.336,
      "eval_steps_per_second": 7.924,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.46205323934555054,
      "learning_rate": 0.00017193884711779448,
      "loss": 3.0367,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.47981539368629456,
      "learning_rate": 0.00017143759398496243,
      "loss": 3.0315,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.47197163105010986,
      "learning_rate": 0.000170937343358396,
      "loss": 3.0277,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.4477008581161499,
      "learning_rate": 0.00017043609022556394,
      "loss": 3.0225,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.4674312174320221,
      "learning_rate": 0.0001699358395989975,
      "loss": 3.0187,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.47371241450309753,
      "learning_rate": 0.00016943558897243108,
      "loss": 3.0145,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.46591296792030334,
      "learning_rate": 0.000168934335839599,
      "loss": 3.0131,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.474002867937088,
      "learning_rate": 0.00016843308270676692,
      "loss": 3.013,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.007591485977173,
      "eval_runtime": 49.3776,
      "eval_samples_per_second": 1012.604,
      "eval_steps_per_second": 7.919,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.44097980856895447,
      "learning_rate": 0.00016793182957393484,
      "loss": 3.0076,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.4540800452232361,
      "learning_rate": 0.00016743057644110277,
      "loss": 3.0054,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.4569825828075409,
      "learning_rate": 0.00016692932330827069,
      "loss": 2.9985,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.4724251925945282,
      "learning_rate": 0.0001664280701754386,
      "loss": 2.9995,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.4427734613418579,
      "learning_rate": 0.00016592681704260653,
      "loss": 2.9981,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.44141921401023865,
      "learning_rate": 0.00016542556390977445,
      "loss": 2.9938,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.49344906210899353,
      "learning_rate": 0.00016492531328320803,
      "loss": 2.9907,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.4652463495731354,
      "learning_rate": 0.00016442406015037596,
      "loss": 2.9886,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 2.986027717590332,
      "eval_runtime": 49.383,
      "eval_samples_per_second": 1012.494,
      "eval_steps_per_second": 7.918,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.4548181891441345,
      "learning_rate": 0.00016392280701754388,
      "loss": 2.9841,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.4481204152107239,
      "learning_rate": 0.0001634215538847118,
      "loss": 2.9833,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.47155335545539856,
      "learning_rate": 0.00016292030075187972,
      "loss": 2.9788,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.45406851172447205,
      "learning_rate": 0.00016241904761904764,
      "loss": 2.9798,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.4341546595096588,
      "learning_rate": 0.0001619187969924812,
      "loss": 2.9772,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.4599888324737549,
      "learning_rate": 0.00016141754385964915,
      "loss": 2.9724,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.44736048579216003,
      "learning_rate": 0.00016091629072681704,
      "loss": 2.973,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.46442919969558716,
      "learning_rate": 0.00016041503759398496,
      "loss": 2.9701,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 2.9665944576263428,
      "eval_runtime": 49.3931,
      "eval_samples_per_second": 1012.287,
      "eval_steps_per_second": 7.916,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.4500311017036438,
      "learning_rate": 0.00015991378446115288,
      "loss": 2.9678,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.46233367919921875,
      "learning_rate": 0.0001594135338345865,
      "loss": 2.9654,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.47022050619125366,
      "learning_rate": 0.0001589122807017544,
      "loss": 2.9648,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.48367393016815186,
      "learning_rate": 0.0001584110275689223,
      "loss": 2.9585,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.47004684805870056,
      "learning_rate": 0.00015790977443609023,
      "loss": 2.9609,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.45485278964042664,
      "learning_rate": 0.00015740952380952382,
      "loss": 2.9569,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.4850807189941406,
      "learning_rate": 0.00015690827067669174,
      "loss": 2.9556,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.4634867012500763,
      "learning_rate": 0.00015640701754385966,
      "loss": 2.9503,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 2.9499073028564453,
      "eval_runtime": 49.4067,
      "eval_samples_per_second": 1012.008,
      "eval_steps_per_second": 7.914,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.45257121324539185,
      "learning_rate": 0.00015590576441102758,
      "loss": 2.9543,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.4330444037914276,
      "learning_rate": 0.0001554045112781955,
      "loss": 2.9495,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.4769555628299713,
      "learning_rate": 0.00015490325814536342,
      "loss": 2.9448,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.43909236788749695,
      "learning_rate": 0.00015440200501253131,
      "loss": 2.9451,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.4414643347263336,
      "learning_rate": 0.00015390075187969926,
      "loss": 2.9426,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.43177637457847595,
      "learning_rate": 0.00015339949874686716,
      "loss": 2.9369,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.46221762895584106,
      "learning_rate": 0.00015289924812030077,
      "loss": 2.9413,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.4350132644176483,
      "learning_rate": 0.00015239799498746866,
      "loss": 2.9365,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 2.934677839279175,
      "eval_runtime": 49.3513,
      "eval_samples_per_second": 1013.144,
      "eval_steps_per_second": 7.923,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.4435933232307434,
      "learning_rate": 0.0001518967418546366,
      "loss": 2.9358,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.451922208070755,
      "learning_rate": 0.0001513954887218045,
      "loss": 2.9343,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.4675293266773224,
      "learning_rate": 0.00015089423558897245,
      "loss": 2.933,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.44621533155441284,
      "learning_rate": 0.000150393984962406,
      "loss": 2.9312,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.4401741921901703,
      "learning_rate": 0.00014989273182957396,
      "loss": 2.9295,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.41989776492118835,
      "learning_rate": 0.00014939147869674185,
      "loss": 2.9247,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.4562460482120514,
      "learning_rate": 0.0001488902255639098,
      "loss": 2.9291,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.4937339425086975,
      "learning_rate": 0.00014838997493734336,
      "loss": 2.9248,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 2.921308755874634,
      "eval_runtime": 49.3826,
      "eval_samples_per_second": 1012.503,
      "eval_steps_per_second": 7.918,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.4147510528564453,
      "learning_rate": 0.00014788872180451128,
      "loss": 2.9207,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.46638476848602295,
      "learning_rate": 0.0001473874686716792,
      "loss": 2.919,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.44557642936706543,
      "learning_rate": 0.00014688621553884712,
      "loss": 2.9178,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.4217783510684967,
      "learning_rate": 0.00014638496240601504,
      "loss": 2.9194,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.4582664966583252,
      "learning_rate": 0.00014588370927318296,
      "loss": 2.9188,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.4299473166465759,
      "learning_rate": 0.00014538345864661655,
      "loss": 2.9138,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.44266200065612793,
      "learning_rate": 0.00014488220551378447,
      "loss": 2.9124,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.43348607420921326,
      "learning_rate": 0.0001443809523809524,
      "loss": 2.9123,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 2.9094369411468506,
      "eval_runtime": 49.3972,
      "eval_samples_per_second": 1012.204,
      "eval_steps_per_second": 7.915,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.43888866901397705,
      "learning_rate": 0.0001438796992481203,
      "loss": 2.9102,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.4228101074695587,
      "learning_rate": 0.00014337844611528823,
      "loss": 2.9109,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.4443526268005371,
      "learning_rate": 0.00014287819548872182,
      "loss": 2.9057,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.44607990980148315,
      "learning_rate": 0.00014237694235588974,
      "loss": 2.9049,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.4360790550708771,
      "learning_rate": 0.00014187568922305766,
      "loss": 2.907,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.44198060035705566,
      "learning_rate": 0.00014137443609022558,
      "loss": 2.9048,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.4248991310596466,
      "learning_rate": 0.00014087418546365917,
      "loss": 2.9021,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.43629327416419983,
      "learning_rate": 0.00014037293233082706,
      "loss": 2.9005,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 2.8993752002716064,
      "eval_runtime": 49.3727,
      "eval_samples_per_second": 1012.706,
      "eval_steps_per_second": 7.919,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.4445126950740814,
      "learning_rate": 0.000139871679197995,
      "loss": 2.9022,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.4673774838447571,
      "learning_rate": 0.0001393704260651629,
      "loss": 2.8993,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.47284606099128723,
      "learning_rate": 0.00013886917293233085,
      "loss": 2.8974,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.43354904651641846,
      "learning_rate": 0.00013836791979949874,
      "loss": 2.8956,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.4454838037490845,
      "learning_rate": 0.00013786766917293236,
      "loss": 2.8953,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.44579145312309265,
      "learning_rate": 0.00013736641604010025,
      "loss": 2.8931,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.45827817916870117,
      "learning_rate": 0.00013686616541353384,
      "loss": 2.8928,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.44990289211273193,
      "learning_rate": 0.00013636491228070176,
      "loss": 2.8949,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.8892433643341064,
      "eval_runtime": 49.4028,
      "eval_samples_per_second": 1012.089,
      "eval_steps_per_second": 7.915,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.42325305938720703,
      "learning_rate": 0.00013586365914786968,
      "loss": 2.8915,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.43582865595817566,
      "learning_rate": 0.0001353624060150376,
      "loss": 2.8896,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.4462158977985382,
      "learning_rate": 0.00013486115288220552,
      "loss": 2.887,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.425049751996994,
      "learning_rate": 0.0001343609022556391,
      "loss": 2.8863,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.4331948161125183,
      "learning_rate": 0.00013385964912280703,
      "loss": 2.8853,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.4298287630081177,
      "learning_rate": 0.00013335839598997495,
      "loss": 2.8824,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.4262866973876953,
      "learning_rate": 0.00013285714285714287,
      "loss": 2.8844,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.44524240493774414,
      "learning_rate": 0.0001323558897243108,
      "loss": 2.8812,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.880206346511841,
      "eval_runtime": 49.3764,
      "eval_samples_per_second": 1012.63,
      "eval_steps_per_second": 7.919,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.42801377177238464,
      "learning_rate": 0.0001318546365914787,
      "loss": 2.8825,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.4230726659297943,
      "learning_rate": 0.00013135338345864663,
      "loss": 2.8834,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.43114352226257324,
      "learning_rate": 0.00013085213032581453,
      "loss": 2.8814,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.43334856629371643,
      "learning_rate": 0.00013035187969924814,
      "loss": 2.8811,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.4266577661037445,
      "learning_rate": 0.00012985062656641603,
      "loss": 2.877,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.43920522928237915,
      "learning_rate": 0.00012934937343358398,
      "loss": 2.8786,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.44733768701553345,
      "learning_rate": 0.00012884812030075187,
      "loss": 2.8775,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.44106316566467285,
      "learning_rate": 0.00012834786967418546,
      "loss": 2.8723,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.8726577758789062,
      "eval_runtime": 49.4005,
      "eval_samples_per_second": 1012.135,
      "eval_steps_per_second": 7.915,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.45096731185913086,
      "learning_rate": 0.00012784661654135338,
      "loss": 2.8738,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.43375974893569946,
      "learning_rate": 0.0001273453634085213,
      "loss": 2.8715,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.4427873194217682,
      "learning_rate": 0.00012684411027568922,
      "loss": 2.8687,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.41539159417152405,
      "learning_rate": 0.00012634285714285714,
      "loss": 2.8724,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.4145837724208832,
      "learning_rate": 0.00012584260651629073,
      "loss": 2.8671,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.45007041096687317,
      "learning_rate": 0.00012534135338345865,
      "loss": 2.8678,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.46730488538742065,
      "learning_rate": 0.00012484010025062657,
      "loss": 2.8612,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.43704888224601746,
      "learning_rate": 0.00012433984962406016,
      "loss": 2.8577,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.8640053272247314,
      "eval_runtime": 49.4178,
      "eval_samples_per_second": 1011.781,
      "eval_steps_per_second": 7.912,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.4368559420108795,
      "learning_rate": 0.00012383859649122808,
      "loss": 2.8581,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.43630149960517883,
      "learning_rate": 0.000123337343358396,
      "loss": 2.8572,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.4280783534049988,
      "learning_rate": 0.00012283609022556392,
      "loss": 2.855,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.4393155574798584,
      "learning_rate": 0.00012233483709273184,
      "loss": 2.8541,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.4432111084461212,
      "learning_rate": 0.00012183358395989975,
      "loss": 2.8518,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.45829612016677856,
      "learning_rate": 0.00012133233082706767,
      "loss": 2.8554,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.43240925669670105,
      "learning_rate": 0.00012083107769423559,
      "loss": 2.8517,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.43047812581062317,
      "learning_rate": 0.00012033082706766919,
      "loss": 2.8536,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.8569018840789795,
      "eval_runtime": 49.4168,
      "eval_samples_per_second": 1011.801,
      "eval_steps_per_second": 7.912,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.4339069128036499,
      "learning_rate": 0.0001198295739348371,
      "loss": 2.851,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.42420464754104614,
      "learning_rate": 0.00011932832080200502,
      "loss": 2.8526,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.47036415338516235,
      "learning_rate": 0.00011882706766917294,
      "loss": 2.8485,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.41581833362579346,
      "learning_rate": 0.00011832581453634086,
      "loss": 2.8512,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.4230213761329651,
      "learning_rate": 0.00011782556390977444,
      "loss": 2.8482,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.4367639720439911,
      "learning_rate": 0.00011732431077694236,
      "loss": 2.8495,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.4362601041793823,
      "learning_rate": 0.00011682305764411027,
      "loss": 2.8468,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.4207648038864136,
      "learning_rate": 0.00011632180451127821,
      "loss": 2.8473,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.850456476211548,
      "eval_runtime": 49.3921,
      "eval_samples_per_second": 1012.309,
      "eval_steps_per_second": 7.916,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.44179490208625793,
      "learning_rate": 0.00011582155388471179,
      "loss": 2.8482,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.4500964283943176,
      "learning_rate": 0.0001153203007518797,
      "loss": 2.8453,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.4436880946159363,
      "learning_rate": 0.00011481904761904762,
      "loss": 2.8462,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.42239853739738464,
      "learning_rate": 0.00011431779448621553,
      "loss": 2.8459,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.489855021238327,
      "learning_rate": 0.00011381654135338346,
      "loss": 2.8425,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.42032596468925476,
      "learning_rate": 0.00011331629072681705,
      "loss": 2.8442,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.4300878942012787,
      "learning_rate": 0.00011281503759398497,
      "loss": 2.8396,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.4366875886917114,
      "learning_rate": 0.00011231378446115288,
      "loss": 2.843,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.843846559524536,
      "eval_runtime": 49.3527,
      "eval_samples_per_second": 1013.115,
      "eval_steps_per_second": 7.923,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.4328237473964691,
      "learning_rate": 0.00011181253132832081,
      "loss": 2.84,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.4287613034248352,
      "learning_rate": 0.0001113122807017544,
      "loss": 2.8403,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.42776674032211304,
      "learning_rate": 0.00011081102756892232,
      "loss": 2.8396,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.4474624693393707,
      "learning_rate": 0.0001103107769423559,
      "loss": 2.8383,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.43701598048210144,
      "learning_rate": 0.00010980952380952381,
      "loss": 2.8364,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.43264612555503845,
      "learning_rate": 0.00010930827067669173,
      "loss": 2.8358,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.45171141624450684,
      "learning_rate": 0.00010880701754385965,
      "loss": 2.8354,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.42236730456352234,
      "learning_rate": 0.00010830576441102757,
      "loss": 2.8359,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.8375425338745117,
      "eval_runtime": 49.3451,
      "eval_samples_per_second": 1013.273,
      "eval_steps_per_second": 7.924,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.43868693709373474,
      "learning_rate": 0.00010780451127819548,
      "loss": 2.8374,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.43994924426078796,
      "learning_rate": 0.00010730325814536342,
      "loss": 2.8348,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.43520763516426086,
      "learning_rate": 0.00010680200501253132,
      "loss": 2.8326,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.4600503146648407,
      "learning_rate": 0.00010630075187969926,
      "loss": 2.836,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.4312608540058136,
      "learning_rate": 0.00010580050125313283,
      "loss": 2.8327,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.43928322196006775,
      "learning_rate": 0.00010529924812030076,
      "loss": 2.8314,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.42440304160118103,
      "learning_rate": 0.00010479799498746867,
      "loss": 2.8325,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.42523327469825745,
      "learning_rate": 0.0001042967418546366,
      "loss": 2.8288,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.831932783126831,
      "eval_runtime": 49.4045,
      "eval_samples_per_second": 1012.054,
      "eval_steps_per_second": 7.914,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.43076032400131226,
      "learning_rate": 0.00010379548872180451,
      "loss": 2.8271,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.43490198254585266,
      "learning_rate": 0.00010329423558897245,
      "loss": 2.8314,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.4328664541244507,
      "learning_rate": 0.00010279298245614035,
      "loss": 2.8268,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.48635390400886536,
      "learning_rate": 0.00010229373433583959,
      "loss": 2.8287,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.4366079866886139,
      "learning_rate": 0.00010179248120300753,
      "loss": 2.826,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.460317462682724,
      "learning_rate": 0.00010129122807017543,
      "loss": 2.8268,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.4241977334022522,
      "learning_rate": 0.00010078997493734337,
      "loss": 2.8241,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.4415217936038971,
      "learning_rate": 0.00010028872180451127,
      "loss": 2.8245,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.826413154602051,
      "eval_runtime": 49.3416,
      "eval_samples_per_second": 1013.343,
      "eval_steps_per_second": 7.924,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.409457266330719,
      "learning_rate": 9.978746867167921e-05,
      "loss": 2.8206,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.44404807686805725,
      "learning_rate": 9.928721804511278e-05,
      "loss": 2.8224,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.4460499584674835,
      "learning_rate": 9.87859649122807e-05,
      "loss": 2.823,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.42559322714805603,
      "learning_rate": 9.828471177944862e-05,
      "loss": 2.8214,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.41664597392082214,
      "learning_rate": 9.778345864661654e-05,
      "loss": 2.8215,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.4325540065765381,
      "learning_rate": 9.728220551378447e-05,
      "loss": 2.8198,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.43893173336982727,
      "learning_rate": 9.678195488721805e-05,
      "loss": 2.8205,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.4386519193649292,
      "learning_rate": 9.628070175438597e-05,
      "loss": 2.8175,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 2.821157455444336,
      "eval_runtime": 49.3774,
      "eval_samples_per_second": 1012.609,
      "eval_steps_per_second": 7.919,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.4431248903274536,
      "learning_rate": 9.577944862155389e-05,
      "loss": 2.8206,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.4318045973777771,
      "learning_rate": 9.527819548872181e-05,
      "loss": 2.8169,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.4476931393146515,
      "learning_rate": 9.477794486215539e-05,
      "loss": 2.814,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.435200572013855,
      "learning_rate": 9.42766917293233e-05,
      "loss": 2.8168,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.47359082102775574,
      "learning_rate": 9.377543859649123e-05,
      "loss": 2.8158,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.4131055474281311,
      "learning_rate": 9.327418546365915e-05,
      "loss": 2.8155,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.4210047423839569,
      "learning_rate": 9.277293233082707e-05,
      "loss": 2.8149,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.4382534325122833,
      "learning_rate": 9.227167919799499e-05,
      "loss": 2.8125,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 2.8158552646636963,
      "eval_runtime": 49.3813,
      "eval_samples_per_second": 1012.528,
      "eval_steps_per_second": 7.918,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.449375182390213,
      "learning_rate": 9.177042606516291e-05,
      "loss": 2.8142,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.48025017976760864,
      "learning_rate": 9.126917293233083e-05,
      "loss": 2.8125,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.43890446424484253,
      "learning_rate": 9.076791979949874e-05,
      "loss": 2.8097,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.42149627208709717,
      "learning_rate": 9.026766917293234e-05,
      "loss": 2.8131,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.41983240842819214,
      "learning_rate": 8.976641604010026e-05,
      "loss": 2.8091,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.4461164176464081,
      "learning_rate": 8.926516290726818e-05,
      "loss": 2.8122,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.44060060381889343,
      "learning_rate": 8.876390977443609e-05,
      "loss": 2.8102,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.4452691674232483,
      "learning_rate": 8.826265664160401e-05,
      "loss": 2.8093,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 2.8110969066619873,
      "eval_runtime": 49.3741,
      "eval_samples_per_second": 1012.678,
      "eval_steps_per_second": 7.919,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.4295593202114105,
      "learning_rate": 8.776240601503761e-05,
      "loss": 2.8089,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.43136969208717346,
      "learning_rate": 8.726215538847118e-05,
      "loss": 2.808,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.45007583498954773,
      "learning_rate": 8.67609022556391e-05,
      "loss": 2.8087,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.44089028239250183,
      "learning_rate": 8.625964912280702e-05,
      "loss": 2.8071,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.43192362785339355,
      "learning_rate": 8.575839598997494e-05,
      "loss": 2.8075,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.44698649644851685,
      "learning_rate": 8.525714285714286e-05,
      "loss": 2.8035,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.45113319158554077,
      "learning_rate": 8.475588972431077e-05,
      "loss": 2.8067,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.4375021457672119,
      "learning_rate": 8.425463659147869e-05,
      "loss": 2.8056,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 2.8063738346099854,
      "eval_runtime": 49.3531,
      "eval_samples_per_second": 1013.107,
      "eval_steps_per_second": 7.922,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.4295075237751007,
      "learning_rate": 8.375338345864661e-05,
      "loss": 2.8067,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.42580410838127136,
      "learning_rate": 8.325213032581453e-05,
      "loss": 2.804,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.4385039210319519,
      "learning_rate": 8.275187969924812e-05,
      "loss": 2.8032,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.438020259141922,
      "learning_rate": 8.225062656641604e-05,
      "loss": 2.8018,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.43791332840919495,
      "learning_rate": 8.174937343358396e-05,
      "loss": 2.8034,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.44641759991645813,
      "learning_rate": 8.124812030075188e-05,
      "loss": 2.8017,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.4522641599178314,
      "learning_rate": 8.074786967418547e-05,
      "loss": 2.8018,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.4458613991737366,
      "learning_rate": 8.024661654135339e-05,
      "loss": 2.8014,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 2.8018808364868164,
      "eval_runtime": 49.3704,
      "eval_samples_per_second": 1012.753,
      "eval_steps_per_second": 7.92,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.4425092041492462,
      "learning_rate": 7.974536340852131e-05,
      "loss": 2.7992,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.4464157819747925,
      "learning_rate": 7.924411027568923e-05,
      "loss": 2.8016,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.4234004020690918,
      "learning_rate": 7.874285714285715e-05,
      "loss": 2.7979,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.43126755952835083,
      "learning_rate": 7.824260651629072e-05,
      "loss": 2.7996,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.4469067454338074,
      "learning_rate": 7.774135338345864e-05,
      "loss": 2.8004,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.4740400016307831,
      "learning_rate": 7.724010025062657e-05,
      "loss": 2.7959,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.46188464760780334,
      "learning_rate": 7.673884711779449e-05,
      "loss": 2.7994,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.44765809178352356,
      "learning_rate": 7.623859649122807e-05,
      "loss": 2.7971,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 2.7977371215820312,
      "eval_runtime": 49.3856,
      "eval_samples_per_second": 1012.44,
      "eval_steps_per_second": 7.917,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.42742568254470825,
      "learning_rate": 7.573734335839599e-05,
      "loss": 2.7954,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.44690001010894775,
      "learning_rate": 7.523609022556391e-05,
      "loss": 2.7945,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.42832404375076294,
      "learning_rate": 7.473483709273183e-05,
      "loss": 2.7926,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.463997483253479,
      "learning_rate": 7.423358395989976e-05,
      "loss": 2.796,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.4360266625881195,
      "learning_rate": 7.373333333333333e-05,
      "loss": 2.792,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.4454171657562256,
      "learning_rate": 7.323208020050125e-05,
      "loss": 2.7945,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.42602190375328064,
      "learning_rate": 7.273082706766917e-05,
      "loss": 2.7927,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.4207629859447479,
      "learning_rate": 7.222957393483709e-05,
      "loss": 2.7919,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 2.7935690879821777,
      "eval_runtime": 49.3595,
      "eval_samples_per_second": 1012.977,
      "eval_steps_per_second": 7.921,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.45008957386016846,
      "learning_rate": 7.172832080200501e-05,
      "loss": 2.7926,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.4556320607662201,
      "learning_rate": 7.12280701754386e-05,
      "loss": 2.7925,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.44795671105384827,
      "learning_rate": 7.072681704260652e-05,
      "loss": 2.7941,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.4286613464355469,
      "learning_rate": 7.022556390977444e-05,
      "loss": 2.7895,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.451915979385376,
      "learning_rate": 6.972431077694236e-05,
      "loss": 2.7856,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.4456482529640198,
      "learning_rate": 6.922406015037595e-05,
      "loss": 2.7887,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.4359695613384247,
      "learning_rate": 6.872280701754387e-05,
      "loss": 2.7883,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.44918739795684814,
      "learning_rate": 6.822155388471179e-05,
      "loss": 2.7876,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 2.7895619869232178,
      "eval_runtime": 49.3698,
      "eval_samples_per_second": 1012.764,
      "eval_steps_per_second": 7.92,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.4644852876663208,
      "learning_rate": 6.772030075187971e-05,
      "loss": 2.786,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.44712725281715393,
      "learning_rate": 6.721904761904763e-05,
      "loss": 2.786,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.42817214131355286,
      "learning_rate": 6.67187969924812e-05,
      "loss": 2.7867,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.45279550552368164,
      "learning_rate": 6.621754385964912e-05,
      "loss": 2.7858,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.45282310247421265,
      "learning_rate": 6.571629072681704e-05,
      "loss": 2.7867,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.4383164048194885,
      "learning_rate": 6.521503759398496e-05,
      "loss": 2.7872,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.4582933783531189,
      "learning_rate": 6.471478696741855e-05,
      "loss": 2.7855,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.4375706613063812,
      "learning_rate": 6.421453634085213e-05,
      "loss": 2.7827,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 2.7854397296905518,
      "eval_runtime": 49.3534,
      "eval_samples_per_second": 1013.101,
      "eval_steps_per_second": 7.922,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.4410087466239929,
      "learning_rate": 6.371328320802006e-05,
      "loss": 2.7833,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.4670538902282715,
      "learning_rate": 6.321203007518798e-05,
      "loss": 2.7843,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.43787911534309387,
      "learning_rate": 6.27107769423559e-05,
      "loss": 2.7828,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.4221600890159607,
      "learning_rate": 6.220952380952382e-05,
      "loss": 2.7827,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.4486722946166992,
      "learning_rate": 6.170827067669174e-05,
      "loss": 2.7806,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.4609127640724182,
      "learning_rate": 6.120701754385966e-05,
      "loss": 2.7848,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.44283515214920044,
      "learning_rate": 6.0705764411027575e-05,
      "loss": 2.7796,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.4492391049861908,
      "learning_rate": 6.020551378446115e-05,
      "loss": 2.7807,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 2.7813029289245605,
      "eval_runtime": 49.3856,
      "eval_samples_per_second": 1012.44,
      "eval_steps_per_second": 7.917,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.43878206610679626,
      "learning_rate": 5.9704260651629074e-05,
      "loss": 2.7819,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.4336804747581482,
      "learning_rate": 5.9203007518796995e-05,
      "loss": 2.7794,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.4514494836330414,
      "learning_rate": 5.8701754385964916e-05,
      "loss": 2.7795,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.45782360434532166,
      "learning_rate": 5.82015037593985e-05,
      "loss": 2.7765,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.44667842984199524,
      "learning_rate": 5.770025062656642e-05,
      "loss": 2.7797,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.47021326422691345,
      "learning_rate": 5.7198997493734344e-05,
      "loss": 2.7761,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.44867923855781555,
      "learning_rate": 5.669774436090226e-05,
      "loss": 2.7771,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.4397301971912384,
      "learning_rate": 5.619649122807018e-05,
      "loss": 2.7764,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 2.777867078781128,
      "eval_runtime": 49.352,
      "eval_samples_per_second": 1013.13,
      "eval_steps_per_second": 7.923,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.44723349809646606,
      "learning_rate": 5.569624060150376e-05,
      "loss": 2.7758,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.4469377100467682,
      "learning_rate": 5.519498746867168e-05,
      "loss": 2.7771,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.43982183933258057,
      "learning_rate": 5.46937343358396e-05,
      "loss": 2.7781,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.4502946436405182,
      "learning_rate": 5.4192481203007514e-05,
      "loss": 2.7749,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.451113224029541,
      "learning_rate": 5.3692230576441106e-05,
      "loss": 2.7739,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.4366084933280945,
      "learning_rate": 5.319097744360903e-05,
      "loss": 2.7747,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.4598430395126343,
      "learning_rate": 5.268972431077695e-05,
      "loss": 2.7749,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.4543938934803009,
      "learning_rate": 5.218847117794486e-05,
      "loss": 2.7721,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 2.7742974758148193,
      "eval_runtime": 49.3867,
      "eval_samples_per_second": 1012.418,
      "eval_steps_per_second": 7.917,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.45317208766937256,
      "learning_rate": 5.168721804511278e-05,
      "loss": 2.7727,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.4536348283290863,
      "learning_rate": 5.1186967418546375e-05,
      "loss": 2.7723,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.45539456605911255,
      "learning_rate": 5.068571428571429e-05,
      "loss": 2.7699,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.4726937413215637,
      "learning_rate": 5.018446115288221e-05,
      "loss": 2.7718,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.446904718875885,
      "learning_rate": 4.9683208020050125e-05,
      "loss": 2.7706,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.4548986256122589,
      "learning_rate": 4.9181954887218046e-05,
      "loss": 2.7614,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.44984933733940125,
      "learning_rate": 4.868170426065163e-05,
      "loss": 2.7617,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.46264731884002686,
      "learning_rate": 4.818045112781955e-05,
      "loss": 2.7577,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 2.77065372467041,
      "eval_runtime": 49.3197,
      "eval_samples_per_second": 1013.793,
      "eval_steps_per_second": 7.928,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.45471659302711487,
      "learning_rate": 4.767919799498747e-05,
      "loss": 2.7613,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.4429563581943512,
      "learning_rate": 4.7177944862155394e-05,
      "loss": 2.7598,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.4386296570301056,
      "learning_rate": 4.6676691729323315e-05,
      "loss": 2.7612,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.48056498169898987,
      "learning_rate": 4.617644110275689e-05,
      "loss": 2.7599,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.4655163586139679,
      "learning_rate": 4.5675187969924814e-05,
      "loss": 2.7623,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.48309579491615295,
      "learning_rate": 4.5173934837092735e-05,
      "loss": 2.7587,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.43969160318374634,
      "learning_rate": 4.4672681704260656e-05,
      "loss": 2.7586,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.46230506896972656,
      "learning_rate": 4.417142857142858e-05,
      "loss": 2.759,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 2.768322467803955,
      "eval_runtime": 49.364,
      "eval_samples_per_second": 1012.884,
      "eval_steps_per_second": 7.921,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.45330050587654114,
      "learning_rate": 4.3671177944862156e-05,
      "loss": 2.7593,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.4471002221107483,
      "learning_rate": 4.316992481203008e-05,
      "loss": 2.7584,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.4609421193599701,
      "learning_rate": 4.2668671679198e-05,
      "loss": 2.7588,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.4516927897930145,
      "learning_rate": 4.216741854636592e-05,
      "loss": 2.7587,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.4591464102268219,
      "learning_rate": 4.166616541353383e-05,
      "loss": 2.7564,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.46769189834594727,
      "learning_rate": 4.116591478696742e-05,
      "loss": 2.7567,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.45420128107070923,
      "learning_rate": 4.066466165413534e-05,
      "loss": 2.757,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.4827192723751068,
      "learning_rate": 4.016340852130326e-05,
      "loss": 2.7565,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 2.7648966312408447,
      "eval_runtime": 49.3411,
      "eval_samples_per_second": 1013.354,
      "eval_steps_per_second": 7.924,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.454823762178421,
      "learning_rate": 3.966215538847118e-05,
      "loss": 2.7571,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.4582090675830841,
      "learning_rate": 3.916190476190477e-05,
      "loss": 2.7569,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.46431854367256165,
      "learning_rate": 3.866065162907269e-05,
      "loss": 2.7555,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.43829411268234253,
      "learning_rate": 3.815939849624061e-05,
      "loss": 2.755,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.46197953820228577,
      "learning_rate": 3.765814536340852e-05,
      "loss": 2.7567,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.4481591582298279,
      "learning_rate": 3.715789473684211e-05,
      "loss": 2.7526,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.4700230062007904,
      "learning_rate": 3.665664160401003e-05,
      "loss": 2.7508,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.44600680470466614,
      "learning_rate": 3.615538847117795e-05,
      "loss": 2.7543,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 2.7619822025299072,
      "eval_runtime": 49.3532,
      "eval_samples_per_second": 1013.105,
      "eval_steps_per_second": 7.922,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.45809346437454224,
      "learning_rate": 3.5654135338345865e-05,
      "loss": 2.7532,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.47560667991638184,
      "learning_rate": 3.5152882205513786e-05,
      "loss": 2.753,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.45053383708000183,
      "learning_rate": 3.465263157894737e-05,
      "loss": 2.7528,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.43405911326408386,
      "learning_rate": 3.415137844611529e-05,
      "loss": 2.7501,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.4542330801486969,
      "learning_rate": 3.365012531328321e-05,
      "loss": 2.7547,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.46224817633628845,
      "learning_rate": 3.314887218045113e-05,
      "loss": 2.7508,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.4608026146888733,
      "learning_rate": 3.264862155388471e-05,
      "loss": 2.7535,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.4507109224796295,
      "learning_rate": 3.214736842105263e-05,
      "loss": 2.7504,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 2.7587172985076904,
      "eval_runtime": 49.3735,
      "eval_samples_per_second": 1012.69,
      "eval_steps_per_second": 7.919,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.4686630368232727,
      "learning_rate": 3.1646115288220554e-05,
      "loss": 2.7498,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.46691277623176575,
      "learning_rate": 3.114486215538847e-05,
      "loss": 2.7528,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.4393503963947296,
      "learning_rate": 3.064461152882206e-05,
      "loss": 2.7513,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.46299058198928833,
      "learning_rate": 3.0143358395989978e-05,
      "loss": 2.7509,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.48929792642593384,
      "learning_rate": 2.964310776942356e-05,
      "loss": 2.7489,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.4613209664821625,
      "learning_rate": 2.914185463659148e-05,
      "loss": 2.7478,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.45809099078178406,
      "learning_rate": 2.8640601503759402e-05,
      "loss": 2.7484,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.4697454869747162,
      "learning_rate": 2.813934837092732e-05,
      "loss": 2.748,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 2.75588321685791,
      "eval_runtime": 49.4703,
      "eval_samples_per_second": 1010.708,
      "eval_steps_per_second": 7.904,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.4618159532546997,
      "learning_rate": 2.763809523809524e-05,
      "loss": 2.7477,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.4500683546066284,
      "learning_rate": 2.7136842105263162e-05,
      "loss": 2.7489,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.46456608176231384,
      "learning_rate": 2.663558897243108e-05,
      "loss": 2.7503,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.4587520658969879,
      "learning_rate": 2.6134335839599e-05,
      "loss": 2.7473,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.46738454699516296,
      "learning_rate": 2.563308270676692e-05,
      "loss": 2.7499,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.48622840642929077,
      "learning_rate": 2.5132832080200503e-05,
      "loss": 2.7452,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.46354228258132935,
      "learning_rate": 2.463157894736842e-05,
      "loss": 2.7478,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.46022677421569824,
      "learning_rate": 2.4130325814536342e-05,
      "loss": 2.7489,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.7528722286224365,
      "eval_runtime": 49.3285,
      "eval_samples_per_second": 1013.613,
      "eval_steps_per_second": 7.926,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.46563613414764404,
      "learning_rate": 2.3629072681704263e-05,
      "loss": 2.747,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.45703476667404175,
      "learning_rate": 2.3128822055137848e-05,
      "loss": 2.744,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.477649986743927,
      "learning_rate": 2.2627568922305766e-05,
      "loss": 2.7441,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.46915870904922485,
      "learning_rate": 2.2126315789473683e-05,
      "loss": 2.7456,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.45781174302101135,
      "learning_rate": 2.1625062656641604e-05,
      "loss": 2.7454,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.48015472292900085,
      "learning_rate": 2.1123809523809522e-05,
      "loss": 2.7442,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.45186662673950195,
      "learning_rate": 2.0622556390977443e-05,
      "loss": 2.7473,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.48192113637924194,
      "learning_rate": 2.012230576441103e-05,
      "loss": 2.7429,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.7501752376556396,
      "eval_runtime": 49.4839,
      "eval_samples_per_second": 1010.43,
      "eval_steps_per_second": 7.902,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.4714931547641754,
      "learning_rate": 1.962105263157895e-05,
      "loss": 2.7393,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.47320306301116943,
      "learning_rate": 1.9119799498746867e-05,
      "loss": 2.7423,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.4632922112941742,
      "learning_rate": 1.8618546365914788e-05,
      "loss": 2.742,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.4658677875995636,
      "learning_rate": 1.811729323308271e-05,
      "loss": 2.7407,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.4720647931098938,
      "learning_rate": 1.761704260651629e-05,
      "loss": 2.7393,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.486204594373703,
      "learning_rate": 1.711578947368421e-05,
      "loss": 2.7412,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.4526083469390869,
      "learning_rate": 1.661453634085213e-05,
      "loss": 2.743,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.4595693051815033,
      "learning_rate": 1.611328320802005e-05,
      "loss": 2.7438,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.7476906776428223,
      "eval_runtime": 49.4098,
      "eval_samples_per_second": 1011.945,
      "eval_steps_per_second": 7.913,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.4906870126724243,
      "learning_rate": 1.5613032581453636e-05,
      "loss": 2.7399,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.4578242897987366,
      "learning_rate": 1.5111779448621555e-05,
      "loss": 2.7421,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.4550294578075409,
      "learning_rate": 1.4610526315789474e-05,
      "loss": 2.7397,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.46999046206474304,
      "learning_rate": 1.4109273182957394e-05,
      "loss": 2.7391,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.4709415137767792,
      "learning_rate": 1.3608020050125315e-05,
      "loss": 2.7399,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.4742773473262787,
      "learning_rate": 1.3107769423558897e-05,
      "loss": 2.7373,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.46235254406929016,
      "learning_rate": 1.2606516290726816e-05,
      "loss": 2.7389,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.47508856654167175,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 2.7397,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.7452099323272705,
      "eval_runtime": 49.338,
      "eval_samples_per_second": 1013.418,
      "eval_steps_per_second": 7.925,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.45706138014793396,
      "learning_rate": 1.1604010025062658e-05,
      "loss": 2.734,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.4531872868537903,
      "learning_rate": 1.1103759398496242e-05,
      "loss": 2.7395,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.4474889934062958,
      "learning_rate": 1.0602506265664161e-05,
      "loss": 2.7373,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.46401605010032654,
      "learning_rate": 1.010125313283208e-05,
      "loss": 2.7385,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.46429967880249023,
      "learning_rate": 9.600000000000001e-06,
      "loss": 2.7373,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.46794867515563965,
      "learning_rate": 9.099749373433585e-06,
      "loss": 2.7355,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.46077409386634827,
      "learning_rate": 8.598496240601504e-06,
      "loss": 2.7338,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.467372864484787,
      "learning_rate": 8.097243107769423e-06,
      "loss": 2.7351,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.742964744567871,
      "eval_runtime": 49.3406,
      "eval_samples_per_second": 1013.365,
      "eval_steps_per_second": 7.925,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.45668596029281616,
      "learning_rate": 7.595989974937344e-06,
      "loss": 2.7364,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.46406587958335876,
      "learning_rate": 7.095739348370928e-06,
      "loss": 2.7378,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.49529483914375305,
      "learning_rate": 6.594486215538847e-06,
      "loss": 2.733,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.45749619603157043,
      "learning_rate": 6.094235588972431e-06,
      "loss": 2.7368,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.4692920744419098,
      "learning_rate": 5.592982456140351e-06,
      "loss": 2.7367,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.47085079550743103,
      "learning_rate": 5.091729323308271e-06,
      "loss": 2.735,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.4585631191730499,
      "learning_rate": 4.590476190476191e-06,
      "loss": 2.7323,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.4686276912689209,
      "learning_rate": 4.089223057644111e-06,
      "loss": 2.7355,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.7410941123962402,
      "eval_runtime": 49.395,
      "eval_samples_per_second": 1012.249,
      "eval_steps_per_second": 7.916,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.4537983238697052,
      "learning_rate": 3.5879699248120305e-06,
      "loss": 2.7325,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.47505033016204834,
      "learning_rate": 3.08671679197995e-06,
      "loss": 2.7332,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.4755919277667999,
      "learning_rate": 2.5854636591478696e-06,
      "loss": 2.7307,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.4516446888446808,
      "learning_rate": 2.0842105263157897e-06,
      "loss": 2.7335,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.4583365023136139,
      "learning_rate": 1.5839598997493733e-06,
      "loss": 2.7316,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.4387438893318176,
      "learning_rate": 1.0827067669172933e-06,
      "loss": 2.7359,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.4473658502101898,
      "learning_rate": 5.814536340852131e-07,
      "loss": 2.731,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.4587293863296509,
      "learning_rate": 8.020050125313284e-08,
      "loss": 2.732,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.739865303039551,
      "eval_runtime": 49.3812,
      "eval_samples_per_second": 1012.531,
      "eval_steps_per_second": 7.918,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 4000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
