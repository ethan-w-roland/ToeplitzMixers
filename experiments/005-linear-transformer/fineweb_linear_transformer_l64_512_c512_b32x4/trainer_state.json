{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 0.6531682014465332,
      "learning_rate": 0.0002,
      "loss": 6.9934,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 0.5577749609947205,
      "learning_rate": 0.00019949874686716793,
      "loss": 5.1858,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.4350006878376007,
      "learning_rate": 0.00019899749373433585,
      "loss": 4.5475,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.5115264654159546,
      "learning_rate": 0.00019849624060150375,
      "loss": 4.2397,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.47239458560943604,
      "learning_rate": 0.0001979949874686717,
      "loss": 4.0603,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.4327657222747803,
      "learning_rate": 0.0001974937343358396,
      "loss": 3.9331,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.43540579080581665,
      "learning_rate": 0.00019699248120300754,
      "loss": 3.8349,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.47495946288108826,
      "learning_rate": 0.00019649122807017543,
      "loss": 3.7614,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.72810697555542,
      "eval_runtime": 42.5132,
      "eval_samples_per_second": 1176.104,
      "eval_steps_per_second": 9.197,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.4126492142677307,
      "learning_rate": 0.00019598997493734338,
      "loss": 3.7016,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.4087408185005188,
      "learning_rate": 0.00019548872180451127,
      "loss": 3.6517,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.42700251936912537,
      "learning_rate": 0.00019498746867167922,
      "loss": 3.6081,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.40534645318984985,
      "learning_rate": 0.0001944862155388471,
      "loss": 3.5701,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.4286695718765259,
      "learning_rate": 0.00019398496240601503,
      "loss": 3.5377,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.41132766008377075,
      "learning_rate": 0.00019348370927318296,
      "loss": 3.5107,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.3894828259944916,
      "learning_rate": 0.00019298245614035088,
      "loss": 3.4817,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.40178966522216797,
      "learning_rate": 0.0001924812030075188,
      "loss": 3.4614,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.4461469650268555,
      "eval_runtime": 42.5275,
      "eval_samples_per_second": 1175.71,
      "eval_steps_per_second": 9.194,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.3855610489845276,
      "learning_rate": 0.00019197994987468672,
      "loss": 3.44,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.38539519906044006,
      "learning_rate": 0.00019147869674185464,
      "loss": 3.4209,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.39581677317619324,
      "learning_rate": 0.00019097744360902256,
      "loss": 3.3997,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.3951544463634491,
      "learning_rate": 0.00019047619047619048,
      "loss": 3.3869,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.4058075249195099,
      "learning_rate": 0.00018997593984962407,
      "loss": 3.3708,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.38570672273635864,
      "learning_rate": 0.000189474686716792,
      "loss": 3.3596,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.3850478231906891,
      "learning_rate": 0.0001889734335839599,
      "loss": 3.3423,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.38138777017593384,
      "learning_rate": 0.00018847218045112783,
      "loss": 3.3317,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.325772523880005,
      "eval_runtime": 42.5365,
      "eval_samples_per_second": 1175.462,
      "eval_steps_per_second": 9.192,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.3826320469379425,
      "learning_rate": 0.00018797192982456142,
      "loss": 3.3219,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.38489478826522827,
      "learning_rate": 0.00018747067669172934,
      "loss": 3.3131,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.38066214323043823,
      "learning_rate": 0.00018696942355889726,
      "loss": 3.296,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.37459224462509155,
      "learning_rate": 0.00018646817042606518,
      "loss": 3.291,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.3702036440372467,
      "learning_rate": 0.00018596791979949874,
      "loss": 3.2811,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.37252944707870483,
      "learning_rate": 0.00018546666666666668,
      "loss": 3.2733,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.37347981333732605,
      "learning_rate": 0.00018496641604010024,
      "loss": 3.2624,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.37760233879089355,
      "learning_rate": 0.0001844651629072682,
      "loss": 3.2569,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.249647855758667,
      "eval_runtime": 42.5406,
      "eval_samples_per_second": 1175.348,
      "eval_steps_per_second": 9.191,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.37150028347969055,
      "learning_rate": 0.00018396390977443608,
      "loss": 3.2494,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.38049376010894775,
      "learning_rate": 0.00018346265664160403,
      "loss": 3.2414,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.3884562849998474,
      "learning_rate": 0.00018296140350877193,
      "loss": 3.2359,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.37112244963645935,
      "learning_rate": 0.00018246015037593987,
      "loss": 3.2247,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.37461623549461365,
      "learning_rate": 0.00018195889724310777,
      "loss": 3.2218,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.37200358510017395,
      "learning_rate": 0.00018145764411027572,
      "loss": 3.2176,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.37102729082107544,
      "learning_rate": 0.00018095739348370927,
      "loss": 3.2065,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.36769595742225647,
      "learning_rate": 0.00018045614035087722,
      "loss": 3.2028,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.1999027729034424,
      "eval_runtime": 42.598,
      "eval_samples_per_second": 1173.763,
      "eval_steps_per_second": 9.179,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.37753650546073914,
      "learning_rate": 0.00017995488721804512,
      "loss": 3.1989,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.3553616404533386,
      "learning_rate": 0.00017945363408521307,
      "loss": 3.1939,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.3660512864589691,
      "learning_rate": 0.00017895338345864662,
      "loss": 3.1899,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.3663286864757538,
      "learning_rate": 0.00017845213032581454,
      "loss": 3.1827,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.36914384365081787,
      "learning_rate": 0.00017795187969924813,
      "loss": 3.1798,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.35867127776145935,
      "learning_rate": 0.00017745062656641605,
      "loss": 3.1745,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.3631594479084015,
      "learning_rate": 0.00017694937343358397,
      "loss": 3.1686,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.35249093174934387,
      "learning_rate": 0.0001764481203007519,
      "loss": 3.165,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.1609511375427246,
      "eval_runtime": 42.596,
      "eval_samples_per_second": 1173.82,
      "eval_steps_per_second": 9.179,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.37630486488342285,
      "learning_rate": 0.00017594786967418545,
      "loss": 3.1618,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.3765040934085846,
      "learning_rate": 0.0001754466165413534,
      "loss": 3.1552,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.37372881174087524,
      "learning_rate": 0.0001749453634085213,
      "loss": 3.1522,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.3666699528694153,
      "learning_rate": 0.00017444411027568924,
      "loss": 3.1468,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.3767176866531372,
      "learning_rate": 0.0001739438596491228,
      "loss": 3.1452,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.3742690682411194,
      "learning_rate": 0.00017344260651629075,
      "loss": 3.1404,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.37345823645591736,
      "learning_rate": 0.00017294135338345864,
      "loss": 3.1377,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.36037859320640564,
      "learning_rate": 0.0001724401002506266,
      "loss": 3.133,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.1305840015411377,
      "eval_runtime": 42.552,
      "eval_samples_per_second": 1175.034,
      "eval_steps_per_second": 9.189,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.3699079751968384,
      "learning_rate": 0.00017193884711779448,
      "loss": 3.133,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.36651015281677246,
      "learning_rate": 0.00017143759398496243,
      "loss": 3.1282,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.3582843840122223,
      "learning_rate": 0.00017093634085213033,
      "loss": 3.1248,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.3678961992263794,
      "learning_rate": 0.00017043508771929825,
      "loss": 3.1198,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.3696233332157135,
      "learning_rate": 0.0001699358395989975,
      "loss": 3.1163,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.37152424454689026,
      "learning_rate": 0.00016943458646616542,
      "loss": 3.1124,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.3613850176334381,
      "learning_rate": 0.00016893333333333334,
      "loss": 3.1108,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.37853971123695374,
      "learning_rate": 0.00016843208020050126,
      "loss": 3.1105,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 3.104984998703003,
      "eval_runtime": 42.5376,
      "eval_samples_per_second": 1175.431,
      "eval_steps_per_second": 9.192,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.3507092595100403,
      "learning_rate": 0.00016793082706766918,
      "loss": 3.1054,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.34976014494895935,
      "learning_rate": 0.00016743057644110277,
      "loss": 3.1034,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.3710629940032959,
      "learning_rate": 0.00016692932330827069,
      "loss": 3.0968,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.35570138692855835,
      "learning_rate": 0.0001664280701754386,
      "loss": 3.0977,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.35098522901535034,
      "learning_rate": 0.00016592681704260653,
      "loss": 3.0966,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.3627661466598511,
      "learning_rate": 0.00016542556390977445,
      "loss": 3.0925,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.3725385367870331,
      "learning_rate": 0.00016492431077694237,
      "loss": 3.0891,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.3846169412136078,
      "learning_rate": 0.00016442406015037596,
      "loss": 3.0871,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 3.084336519241333,
      "eval_runtime": 42.5352,
      "eval_samples_per_second": 1175.496,
      "eval_steps_per_second": 9.192,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.3598308265209198,
      "learning_rate": 0.00016392280701754388,
      "loss": 3.0839,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.3584085702896118,
      "learning_rate": 0.0001634215538847118,
      "loss": 3.082,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.36178407073020935,
      "learning_rate": 0.00016292030075187972,
      "loss": 3.0778,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.380755752325058,
      "learning_rate": 0.00016241904761904764,
      "loss": 3.0792,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.35534733533859253,
      "learning_rate": 0.0001619187969924812,
      "loss": 3.0771,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.3615538477897644,
      "learning_rate": 0.00016141754385964915,
      "loss": 3.0723,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.36868658661842346,
      "learning_rate": 0.00016091629072681704,
      "loss": 3.0724,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.3530004322528839,
      "learning_rate": 0.00016041503759398496,
      "loss": 3.0698,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 3.0648391246795654,
      "eval_runtime": 42.5857,
      "eval_samples_per_second": 1174.103,
      "eval_steps_per_second": 9.181,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.35573190450668335,
      "learning_rate": 0.00015991478696741855,
      "loss": 3.0674,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.3697983920574188,
      "learning_rate": 0.0001594135338345865,
      "loss": 3.0653,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.364860475063324,
      "learning_rate": 0.0001589122807017544,
      "loss": 3.0647,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.3735276162624359,
      "learning_rate": 0.0001584110275689223,
      "loss": 3.0586,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.35321298241615295,
      "learning_rate": 0.00015790977443609023,
      "loss": 3.061,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.37054988741874695,
      "learning_rate": 0.00015740952380952382,
      "loss": 3.0569,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.402166485786438,
      "learning_rate": 0.00015690827067669174,
      "loss": 3.0555,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.36400356888771057,
      "learning_rate": 0.00015640701754385966,
      "loss": 3.0509,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 3.049638032913208,
      "eval_runtime": 42.6189,
      "eval_samples_per_second": 1173.188,
      "eval_steps_per_second": 9.174,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.37695422768592834,
      "learning_rate": 0.00015590576441102758,
      "loss": 3.0544,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.3667050004005432,
      "learning_rate": 0.0001554045112781955,
      "loss": 3.0498,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.37158825993537903,
      "learning_rate": 0.00015490325814536342,
      "loss": 3.0452,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.3558637499809265,
      "learning_rate": 0.00015440200501253131,
      "loss": 3.0456,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.3606683313846588,
      "learning_rate": 0.00015390075187969926,
      "loss": 3.0431,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.3568868339061737,
      "learning_rate": 0.00015340050125313282,
      "loss": 3.0379,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.3662615716457367,
      "learning_rate": 0.00015289924812030077,
      "loss": 3.0416,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.36419087648391724,
      "learning_rate": 0.00015239799498746866,
      "loss": 3.0372,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 3.0346908569335938,
      "eval_runtime": 42.5939,
      "eval_samples_per_second": 1173.878,
      "eval_steps_per_second": 9.18,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.3623066544532776,
      "learning_rate": 0.00015189774436090227,
      "loss": 3.0364,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.3628249764442444,
      "learning_rate": 0.00015139649122807017,
      "loss": 3.0349,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.3606994152069092,
      "learning_rate": 0.00015089523809523812,
      "loss": 3.0339,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.3569142520427704,
      "learning_rate": 0.000150393984962406,
      "loss": 3.0314,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.35957634449005127,
      "learning_rate": 0.00014989273182957396,
      "loss": 3.0302,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.35082903504371643,
      "learning_rate": 0.00014939147869674185,
      "loss": 3.0259,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.3741081953048706,
      "learning_rate": 0.00014889122807017544,
      "loss": 3.0303,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.37149345874786377,
      "learning_rate": 0.00014838997493734336,
      "loss": 3.0259,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 3.02173113822937,
      "eval_runtime": 42.5639,
      "eval_samples_per_second": 1174.705,
      "eval_steps_per_second": 9.186,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.3510705828666687,
      "learning_rate": 0.00014788872180451128,
      "loss": 3.0214,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.35207226872444153,
      "learning_rate": 0.0001473874686716792,
      "loss": 3.0202,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.358568400144577,
      "learning_rate": 0.00014688621553884712,
      "loss": 3.0189,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.3484443724155426,
      "learning_rate": 0.0001463859649122807,
      "loss": 3.0207,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.36885735392570496,
      "learning_rate": 0.00014588471177944863,
      "loss": 3.02,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.3528296649456024,
      "learning_rate": 0.00014538345864661655,
      "loss": 3.0152,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.3623180091381073,
      "learning_rate": 0.00014488220551378447,
      "loss": 3.0137,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.3549368381500244,
      "learning_rate": 0.0001443809523809524,
      "loss": 3.014,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 3.0105578899383545,
      "eval_runtime": 42.5519,
      "eval_samples_per_second": 1175.035,
      "eval_steps_per_second": 9.189,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.34514057636260986,
      "learning_rate": 0.0001438796992481203,
      "loss": 3.0119,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.34944337606430054,
      "learning_rate": 0.00014337844611528823,
      "loss": 3.0127,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.3542458713054657,
      "learning_rate": 0.00014287719298245615,
      "loss": 3.0075,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.35181188583374023,
      "learning_rate": 0.00014237694235588974,
      "loss": 3.007,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.36462101340293884,
      "learning_rate": 0.00014187568922305766,
      "loss": 3.0083,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.3558711111545563,
      "learning_rate": 0.00014137443609022558,
      "loss": 3.0066,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.3474990725517273,
      "learning_rate": 0.0001408731829573935,
      "loss": 3.004,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.35384881496429443,
      "learning_rate": 0.00014037293233082706,
      "loss": 3.0023,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 3.000114917755127,
      "eval_runtime": 42.5633,
      "eval_samples_per_second": 1174.721,
      "eval_steps_per_second": 9.186,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.3763822615146637,
      "learning_rate": 0.000139871679197995,
      "loss": 3.0044,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.3737773001194,
      "learning_rate": 0.0001393704260651629,
      "loss": 3.0012,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.3579683005809784,
      "learning_rate": 0.00013887017543859652,
      "loss": 2.9991,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.3530963063240051,
      "learning_rate": 0.0001383689223057644,
      "loss": 2.9976,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.35341379046440125,
      "learning_rate": 0.00013786766917293236,
      "loss": 2.9975,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.37065041065216064,
      "learning_rate": 0.00013736641604010025,
      "loss": 2.996,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.3638492822647095,
      "learning_rate": 0.00013686516290726817,
      "loss": 2.9952,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.36216264963150024,
      "learning_rate": 0.0001363639097744361,
      "loss": 2.9967,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.990415096282959,
      "eval_runtime": 40.6039,
      "eval_samples_per_second": 1231.409,
      "eval_steps_per_second": 9.63,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.35671305656433105,
      "learning_rate": 0.00013586265664160401,
      "loss": 2.9937,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.3469259738922119,
      "learning_rate": 0.00013536140350877194,
      "loss": 2.9911,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.3643677234649658,
      "learning_rate": 0.00013486115288220552,
      "loss": 2.9899,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.35498547554016113,
      "learning_rate": 0.00013435989974937344,
      "loss": 2.9891,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.341947078704834,
      "learning_rate": 0.00013385964912280703,
      "loss": 2.9877,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.342180997133255,
      "learning_rate": 0.00013335839598997495,
      "loss": 2.9845,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.3320685625076294,
      "learning_rate": 0.00013285714285714287,
      "loss": 2.9867,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.3531060814857483,
      "learning_rate": 0.0001323558897243108,
      "loss": 2.9833,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.9814536571502686,
      "eval_runtime": 40.6004,
      "eval_samples_per_second": 1231.516,
      "eval_steps_per_second": 9.63,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.3681446313858032,
      "learning_rate": 0.0001318546365914787,
      "loss": 2.985,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.3467855155467987,
      "learning_rate": 0.00013135338345864663,
      "loss": 2.9856,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.3565111756324768,
      "learning_rate": 0.00013085213032581453,
      "loss": 2.9842,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.34843310713768005,
      "learning_rate": 0.00013035087719298247,
      "loss": 2.9835,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.35504233837127686,
      "learning_rate": 0.00012985062656641603,
      "loss": 2.9799,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.3446250259876251,
      "learning_rate": 0.00012934937343358398,
      "loss": 2.9811,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.35850048065185547,
      "learning_rate": 0.00012884812030075187,
      "loss": 2.9804,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.37903475761413574,
      "learning_rate": 0.00012834786967418546,
      "loss": 2.975,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.9738221168518066,
      "eval_runtime": 40.5764,
      "eval_samples_per_second": 1232.244,
      "eval_steps_per_second": 9.636,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.35953113436698914,
      "learning_rate": 0.00012784661654135338,
      "loss": 2.9771,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.3562517762184143,
      "learning_rate": 0.0001273453634085213,
      "loss": 2.9745,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.3431647717952728,
      "learning_rate": 0.00012684411027568922,
      "loss": 2.9717,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.33925166726112366,
      "learning_rate": 0.00012634285714285714,
      "loss": 2.975,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.3409006893634796,
      "learning_rate": 0.00012584160401002506,
      "loss": 2.9701,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.35622018575668335,
      "learning_rate": 0.00012534035087719299,
      "loss": 2.9709,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.36200305819511414,
      "learning_rate": 0.00012484010025062657,
      "loss": 2.9634,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.3367369771003723,
      "learning_rate": 0.0001243388471177945,
      "loss": 2.9598,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.9659321308135986,
      "eval_runtime": 40.5842,
      "eval_samples_per_second": 1232.006,
      "eval_steps_per_second": 9.634,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.35070428252220154,
      "learning_rate": 0.0001238375939849624,
      "loss": 2.9598,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.33779048919677734,
      "learning_rate": 0.00012333634085213033,
      "loss": 2.9591,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.34776023030281067,
      "learning_rate": 0.00012283508771929825,
      "loss": 2.9573,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.35435038805007935,
      "learning_rate": 0.00012233383458646618,
      "loss": 2.9561,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.34183356165885925,
      "learning_rate": 0.0001218325814536341,
      "loss": 2.954,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.3565880358219147,
      "learning_rate": 0.000121331328320802,
      "loss": 2.9581,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.35622015595436096,
      "learning_rate": 0.00012083107769423559,
      "loss": 2.9548,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.3491898775100708,
      "learning_rate": 0.00012032982456140351,
      "loss": 2.9564,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.959510326385498,
      "eval_runtime": 40.6059,
      "eval_samples_per_second": 1231.349,
      "eval_steps_per_second": 9.629,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.3553600013256073,
      "learning_rate": 0.00011982857142857142,
      "loss": 2.9536,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.3323543667793274,
      "learning_rate": 0.00011932731829573935,
      "loss": 2.9552,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.34992319345474243,
      "learning_rate": 0.00011882706766917294,
      "loss": 2.951,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.3417477309703827,
      "learning_rate": 0.00011832581453634086,
      "loss": 2.9537,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.33790063858032227,
      "learning_rate": 0.00011782456140350877,
      "loss": 2.9505,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.3430812656879425,
      "learning_rate": 0.0001173233082706767,
      "loss": 2.9522,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.3583839535713196,
      "learning_rate": 0.00011682305764411027,
      "loss": 2.9498,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.33185121417045593,
      "learning_rate": 0.00011632180451127821,
      "loss": 2.9504,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.95339035987854,
      "eval_runtime": 40.5756,
      "eval_samples_per_second": 1232.267,
      "eval_steps_per_second": 9.636,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.3485907018184662,
      "learning_rate": 0.00011582055137844611,
      "loss": 2.9512,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.3540928363800049,
      "learning_rate": 0.00011531929824561405,
      "loss": 2.9485,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.3459911048412323,
      "learning_rate": 0.00011481904761904762,
      "loss": 2.9495,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.3437250554561615,
      "learning_rate": 0.00011431779448621553,
      "loss": 2.9489,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.3687743842601776,
      "learning_rate": 0.00011381654135338346,
      "loss": 2.9455,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.3369714915752411,
      "learning_rate": 0.00011331528822055137,
      "loss": 2.9474,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.33930888772010803,
      "learning_rate": 0.00011281503759398497,
      "loss": 2.9428,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.3504384458065033,
      "learning_rate": 0.00011231378446115288,
      "loss": 2.9464,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.947376012802124,
      "eval_runtime": 40.6109,
      "eval_samples_per_second": 1231.198,
      "eval_steps_per_second": 9.628,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.33128589391708374,
      "learning_rate": 0.00011181253132832081,
      "loss": 2.9402,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.343877911567688,
      "learning_rate": 0.00011131127819548872,
      "loss": 2.9419,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.3380536735057831,
      "learning_rate": 0.00011081102756892232,
      "loss": 2.9417,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.3462485074996948,
      "learning_rate": 0.00011030977443609022,
      "loss": 2.9433,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.3430907130241394,
      "learning_rate": 0.00010980852130325816,
      "loss": 2.9394,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.3504488468170166,
      "learning_rate": 0.00010930726817042607,
      "loss": 2.9387,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.36404696106910706,
      "learning_rate": 0.00010880701754385965,
      "loss": 2.94,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.35159656405448914,
      "learning_rate": 0.00010830576441102757,
      "loss": 2.9381,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.9417495727539062,
      "eval_runtime": 42.5259,
      "eval_samples_per_second": 1175.754,
      "eval_steps_per_second": 9.194,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.3359529972076416,
      "learning_rate": 0.00010780451127819548,
      "loss": 2.9395,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.3402707576751709,
      "learning_rate": 0.00010730325814536342,
      "loss": 2.9367,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.3486328125,
      "learning_rate": 0.00010680300751879699,
      "loss": 2.9346,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.34016919136047363,
      "learning_rate": 0.00010630175438596492,
      "loss": 2.9373,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.353229820728302,
      "learning_rate": 0.00010580050125313283,
      "loss": 2.9348,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.35115453600883484,
      "learning_rate": 0.00010529924812030076,
      "loss": 2.9337,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.3445541262626648,
      "learning_rate": 0.00010479799498746867,
      "loss": 2.9346,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.3430584669113159,
      "learning_rate": 0.0001042967418546366,
      "loss": 2.9327,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.9363434314727783,
      "eval_runtime": 42.5269,
      "eval_samples_per_second": 1175.726,
      "eval_steps_per_second": 9.194,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.3403328061103821,
      "learning_rate": 0.00010379548872180451,
      "loss": 2.9341,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.36187976598739624,
      "learning_rate": 0.00010329423558897245,
      "loss": 2.9325,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.3358142673969269,
      "learning_rate": 0.00010279398496240602,
      "loss": 2.9309,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.34400829672813416,
      "learning_rate": 0.00010229373433583959,
      "loss": 2.9333,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.3490241765975952,
      "learning_rate": 0.00010179248120300753,
      "loss": 2.9285,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.3415106534957886,
      "learning_rate": 0.00010129122807017543,
      "loss": 2.9298,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.3369187116622925,
      "learning_rate": 0.00010078997493734337,
      "loss": 2.931,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.3495531976222992,
      "learning_rate": 0.00010028872180451127,
      "loss": 2.9257,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.9309444427490234,
      "eval_runtime": 42.5182,
      "eval_samples_per_second": 1175.968,
      "eval_steps_per_second": 9.196,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.34247705340385437,
      "learning_rate": 9.978746867167921e-05,
      "loss": 2.9251,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.36112356185913086,
      "learning_rate": 9.928621553884713e-05,
      "loss": 2.9268,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.3654150366783142,
      "learning_rate": 9.878496240601505e-05,
      "loss": 2.9236,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.3340033292770386,
      "learning_rate": 9.828471177944862e-05,
      "loss": 2.9273,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.33417004346847534,
      "learning_rate": 9.778345864661654e-05,
      "loss": 2.9237,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.33245140314102173,
      "learning_rate": 9.728220551378447e-05,
      "loss": 2.924,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.34204575419425964,
      "learning_rate": 9.678095238095239e-05,
      "loss": 2.9249,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.35560375452041626,
      "learning_rate": 9.628070175438597e-05,
      "loss": 2.9246,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 2.9263827800750732,
      "eval_runtime": 42.545,
      "eval_samples_per_second": 1175.225,
      "eval_steps_per_second": 9.19,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.3494468927383423,
      "learning_rate": 9.577944862155389e-05,
      "loss": 2.9242,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.3484792113304138,
      "learning_rate": 9.527819548872181e-05,
      "loss": 2.9211,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.33410000801086426,
      "learning_rate": 9.477694235588973e-05,
      "loss": 2.9191,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.3383182883262634,
      "learning_rate": 9.42766917293233e-05,
      "loss": 2.9201,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.3487342596054077,
      "learning_rate": 9.377543859649123e-05,
      "loss": 2.917,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.3549879491329193,
      "learning_rate": 9.327418546365915e-05,
      "loss": 2.9218,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.34648552536964417,
      "learning_rate": 9.277293233082707e-05,
      "loss": 2.9181,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.35054811835289,
      "learning_rate": 9.227268170426065e-05,
      "loss": 2.9184,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 2.9214463233947754,
      "eval_runtime": 42.5209,
      "eval_samples_per_second": 1175.894,
      "eval_steps_per_second": 9.195,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.33820387721061707,
      "learning_rate": 9.177142857142858e-05,
      "loss": 2.9155,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.3328677713871002,
      "learning_rate": 9.12701754385965e-05,
      "loss": 2.9162,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.34063851833343506,
      "learning_rate": 9.076892230576442e-05,
      "loss": 2.9171,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.3494608700275421,
      "learning_rate": 9.0268671679198e-05,
      "loss": 2.9165,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.3412875533103943,
      "learning_rate": 8.976741854636592e-05,
      "loss": 2.9137,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.34122028946876526,
      "learning_rate": 8.926616541353384e-05,
      "loss": 2.9158,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.342459112405777,
      "learning_rate": 8.876491228070177e-05,
      "loss": 2.9126,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.34410977363586426,
      "learning_rate": 8.826466165413534e-05,
      "loss": 2.9143,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 2.9167399406433105,
      "eval_runtime": 42.5927,
      "eval_samples_per_second": 1173.909,
      "eval_steps_per_second": 9.18,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.35191208124160767,
      "learning_rate": 8.776340852130326e-05,
      "loss": 2.9122,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.3404618799686432,
      "learning_rate": 8.726215538847118e-05,
      "loss": 2.9122,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.3450833857059479,
      "learning_rate": 8.67609022556391e-05,
      "loss": 2.9138,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.35363680124282837,
      "learning_rate": 8.626065162907269e-05,
      "loss": 2.9117,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.34930726885795593,
      "learning_rate": 8.575939849624061e-05,
      "loss": 2.9112,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.3489009439945221,
      "learning_rate": 8.525814536340853e-05,
      "loss": 2.9112,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.34823673963546753,
      "learning_rate": 8.475689223057645e-05,
      "loss": 2.9115,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.3589633107185364,
      "learning_rate": 8.425563909774437e-05,
      "loss": 2.9086,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 2.912567615509033,
      "eval_runtime": 42.568,
      "eval_samples_per_second": 1174.59,
      "eval_steps_per_second": 9.185,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.3548535406589508,
      "learning_rate": 8.375438596491229e-05,
      "loss": 2.9125,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.34977176785469055,
      "learning_rate": 8.32531328320802e-05,
      "loss": 2.9066,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.35611391067504883,
      "learning_rate": 8.275187969924812e-05,
      "loss": 2.9081,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.3323539197444916,
      "learning_rate": 8.225162907268172e-05,
      "loss": 2.9095,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.343424916267395,
      "learning_rate": 8.175037593984964e-05,
      "loss": 2.9062,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.3435307443141937,
      "learning_rate": 8.124912280701755e-05,
      "loss": 2.9055,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.3434220254421234,
      "learning_rate": 8.074786967418547e-05,
      "loss": 2.9084,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.3351711928844452,
      "learning_rate": 8.024761904761905e-05,
      "loss": 2.9051,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 2.9081199169158936,
      "eval_runtime": 42.6245,
      "eval_samples_per_second": 1173.033,
      "eval_steps_per_second": 9.173,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.3489189147949219,
      "learning_rate": 7.974636591478697e-05,
      "loss": 2.9041,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.3597504794597626,
      "learning_rate": 7.92451127819549e-05,
      "loss": 2.9026,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.34213584661483765,
      "learning_rate": 7.87438596491228e-05,
      "loss": 2.9039,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.35337352752685547,
      "learning_rate": 7.82436090225564e-05,
      "loss": 2.8982,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.3414493501186371,
      "learning_rate": 7.774235588972432e-05,
      "loss": 2.9043,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.3305935561656952,
      "learning_rate": 7.724110275689223e-05,
      "loss": 2.9022,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.3439234495162964,
      "learning_rate": 7.673984962406015e-05,
      "loss": 2.8992,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.35151100158691406,
      "learning_rate": 7.623959899749374e-05,
      "loss": 2.9001,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 2.9042675495147705,
      "eval_runtime": 42.5438,
      "eval_samples_per_second": 1175.259,
      "eval_steps_per_second": 9.191,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.35192790627479553,
      "learning_rate": 7.573834586466166e-05,
      "loss": 2.9008,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.3340674042701721,
      "learning_rate": 7.523709273182958e-05,
      "loss": 2.9015,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.3448140621185303,
      "learning_rate": 7.47358395989975e-05,
      "loss": 2.8994,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.35247305035591125,
      "learning_rate": 7.423558897243108e-05,
      "loss": 2.8958,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.32942020893096924,
      "learning_rate": 7.3734335839599e-05,
      "loss": 2.9011,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.35754191875457764,
      "learning_rate": 7.323308270676693e-05,
      "loss": 2.8971,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.3461284041404724,
      "learning_rate": 7.273182957393483e-05,
      "loss": 2.8965,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.34626251459121704,
      "learning_rate": 7.223157894736843e-05,
      "loss": 2.8953,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 2.900799036026001,
      "eval_runtime": 42.5795,
      "eval_samples_per_second": 1174.274,
      "eval_steps_per_second": 9.183,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.364016592502594,
      "learning_rate": 7.173032581453635e-05,
      "loss": 2.8939,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.36181896924972534,
      "learning_rate": 7.122907268170426e-05,
      "loss": 2.8957,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.3388550281524658,
      "learning_rate": 7.072781954887218e-05,
      "loss": 2.8974,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.3360620439052582,
      "learning_rate": 7.022756892230577e-05,
      "loss": 2.8957,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.3389407694339752,
      "learning_rate": 6.972631578947369e-05,
      "loss": 2.8916,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.34698206186294556,
      "learning_rate": 6.922506265664161e-05,
      "loss": 2.8945,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.33417803049087524,
      "learning_rate": 6.872380952380952e-05,
      "loss": 2.8926,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.34146901965141296,
      "learning_rate": 6.822355889724312e-05,
      "loss": 2.892,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 2.8967068195343018,
      "eval_runtime": 42.5638,
      "eval_samples_per_second": 1174.706,
      "eval_steps_per_second": 9.186,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.34785133600234985,
      "learning_rate": 6.772230576441104e-05,
      "loss": 2.8932,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.34931203722953796,
      "learning_rate": 6.722105263157896e-05,
      "loss": 2.8898,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.3364274799823761,
      "learning_rate": 6.671979949874687e-05,
      "loss": 2.892,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.3484099209308624,
      "learning_rate": 6.621954887218046e-05,
      "loss": 2.8931,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.33841776847839355,
      "learning_rate": 6.571829573934839e-05,
      "loss": 2.8903,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.3467394709587097,
      "learning_rate": 6.521704260651629e-05,
      "loss": 2.8889,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.344921350479126,
      "learning_rate": 6.471578947368421e-05,
      "loss": 2.8921,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.34316131472587585,
      "learning_rate": 6.42155388471178e-05,
      "loss": 2.8884,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 2.893108367919922,
      "eval_runtime": 42.5387,
      "eval_samples_per_second": 1175.399,
      "eval_steps_per_second": 9.192,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.3579457700252533,
      "learning_rate": 6.371428571428572e-05,
      "loss": 2.8877,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.3490384519100189,
      "learning_rate": 6.321303258145364e-05,
      "loss": 2.8897,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.34215232729911804,
      "learning_rate": 6.271177944862155e-05,
      "loss": 2.8871,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.3416575789451599,
      "learning_rate": 6.221152882205515e-05,
      "loss": 2.8883,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.3548232913017273,
      "learning_rate": 6.171027568922307e-05,
      "loss": 2.8865,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.3582453429698944,
      "learning_rate": 6.120902255639099e-05,
      "loss": 2.8887,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.34225237369537354,
      "learning_rate": 6.0707769423558903e-05,
      "loss": 2.8892,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.35867634415626526,
      "learning_rate": 6.020751879699248e-05,
      "loss": 2.8846,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 2.890245199203491,
      "eval_runtime": 42.627,
      "eval_samples_per_second": 1172.966,
      "eval_steps_per_second": 9.173,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.3519795835018158,
      "learning_rate": 5.9706265664160396e-05,
      "loss": 2.885,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.36660125851631165,
      "learning_rate": 5.920501253132832e-05,
      "loss": 2.8845,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.3465745151042938,
      "learning_rate": 5.870375939849624e-05,
      "loss": 2.884,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.34866806864738464,
      "learning_rate": 5.8203508771929824e-05,
      "loss": 2.8817,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.34438952803611755,
      "learning_rate": 5.7702255639097745e-05,
      "loss": 2.8855,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.36417096853256226,
      "learning_rate": 5.7201002506265666e-05,
      "loss": 2.8816,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.3474898636341095,
      "learning_rate": 5.6699749373433587e-05,
      "loss": 2.8824,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.34184694290161133,
      "learning_rate": 5.619949874686717e-05,
      "loss": 2.8852,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 2.8865702152252197,
      "eval_runtime": 42.5516,
      "eval_samples_per_second": 1175.043,
      "eval_steps_per_second": 9.189,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.3464982807636261,
      "learning_rate": 5.569824561403509e-05,
      "loss": 2.8856,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.3437519967556,
      "learning_rate": 5.5196992481203014e-05,
      "loss": 2.884,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.36062851548194885,
      "learning_rate": 5.4695739348370935e-05,
      "loss": 2.8807,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.355376273393631,
      "learning_rate": 5.4195488721804513e-05,
      "loss": 2.8839,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.3535647392272949,
      "learning_rate": 5.369423558897243e-05,
      "loss": 2.8832,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.34481510519981384,
      "learning_rate": 5.319298245614035e-05,
      "loss": 2.8801,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.35398513078689575,
      "learning_rate": 5.269172932330827e-05,
      "loss": 2.8792,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.3564501106739044,
      "learning_rate": 5.2191478696741855e-05,
      "loss": 2.8787,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 2.883622169494629,
      "eval_runtime": 42.5665,
      "eval_samples_per_second": 1174.633,
      "eval_steps_per_second": 9.186,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.34197235107421875,
      "learning_rate": 5.1690225563909776e-05,
      "loss": 2.8788,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.34249743819236755,
      "learning_rate": 5.11889724310777e-05,
      "loss": 2.8788,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.3666112422943115,
      "learning_rate": 5.068771929824562e-05,
      "loss": 2.8763,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.36504900455474854,
      "learning_rate": 5.01874686716792e-05,
      "loss": 2.877,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.3477405309677124,
      "learning_rate": 4.968621553884712e-05,
      "loss": 2.8753,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.35198989510536194,
      "learning_rate": 4.918496240601504e-05,
      "loss": 2.8706,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.3569049537181854,
      "learning_rate": 4.868370927318296e-05,
      "loss": 2.8715,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.35432901978492737,
      "learning_rate": 4.8183458646616545e-05,
      "loss": 2.8672,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 2.8805246353149414,
      "eval_runtime": 42.5299,
      "eval_samples_per_second": 1175.643,
      "eval_steps_per_second": 9.194,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.36055871844291687,
      "learning_rate": 4.768220551378446e-05,
      "loss": 2.8706,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.347337007522583,
      "learning_rate": 4.718095238095238e-05,
      "loss": 2.8691,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.3442867398262024,
      "learning_rate": 4.66796992481203e-05,
      "loss": 2.8704,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.3572351634502411,
      "learning_rate": 4.6179448621553886e-05,
      "loss": 2.869,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.35382261872291565,
      "learning_rate": 4.567819548872181e-05,
      "loss": 2.8716,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.36660826206207275,
      "learning_rate": 4.517694235588973e-05,
      "loss": 2.8679,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.3476634621620178,
      "learning_rate": 4.467568922305765e-05,
      "loss": 2.8683,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.36102572083473206,
      "learning_rate": 4.417543859649123e-05,
      "loss": 2.8683,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 2.878046989440918,
      "eval_runtime": 42.5,
      "eval_samples_per_second": 1176.471,
      "eval_steps_per_second": 9.2,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.345205157995224,
      "learning_rate": 4.367418546365915e-05,
      "loss": 2.8689,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.3594115972518921,
      "learning_rate": 4.317293233082707e-05,
      "loss": 2.8677,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.35675135254859924,
      "learning_rate": 4.267167919799499e-05,
      "loss": 2.8682,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.35307273268699646,
      "learning_rate": 4.2171428571428576e-05,
      "loss": 2.8682,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.3504753112792969,
      "learning_rate": 4.167017543859649e-05,
      "loss": 2.8661,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.3620392680168152,
      "learning_rate": 4.116892230576441e-05,
      "loss": 2.8665,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.34582704305648804,
      "learning_rate": 4.066766917293233e-05,
      "loss": 2.8669,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.35498517751693726,
      "learning_rate": 4.016741854636592e-05,
      "loss": 2.8665,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 2.8752195835113525,
      "eval_runtime": 42.5337,
      "eval_samples_per_second": 1175.538,
      "eval_steps_per_second": 9.193,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.3591434359550476,
      "learning_rate": 3.966616541353383e-05,
      "loss": 2.8672,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.3460233807563782,
      "learning_rate": 3.916491228070175e-05,
      "loss": 2.8669,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.35463806986808777,
      "learning_rate": 3.8663659147869674e-05,
      "loss": 2.8655,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.34745070338249207,
      "learning_rate": 3.816340852130326e-05,
      "loss": 2.8647,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.35307884216308594,
      "learning_rate": 3.766215538847118e-05,
      "loss": 2.8664,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.359920471906662,
      "learning_rate": 3.71609022556391e-05,
      "loss": 2.8628,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.36011606454849243,
      "learning_rate": 3.665964912280702e-05,
      "loss": 2.8613,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.3469601571559906,
      "learning_rate": 3.61593984962406e-05,
      "loss": 2.8648,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 2.8727378845214844,
      "eval_runtime": 42.5392,
      "eval_samples_per_second": 1175.386,
      "eval_steps_per_second": 9.192,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.3562924265861511,
      "learning_rate": 3.565814536340852e-05,
      "loss": 2.8638,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.3633703589439392,
      "learning_rate": 3.515689223057644e-05,
      "loss": 2.8633,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.3540104627609253,
      "learning_rate": 3.4655639097744364e-05,
      "loss": 2.8633,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.3480605185031891,
      "learning_rate": 3.415538847117795e-05,
      "loss": 2.8606,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.35904648900032043,
      "learning_rate": 3.365413533834586e-05,
      "loss": 2.8653,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": 0.3571895956993103,
      "learning_rate": 3.3152882205513784e-05,
      "loss": 2.8617,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.36654043197631836,
      "learning_rate": 3.2651629072681705e-05,
      "loss": 2.8639,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.3496796190738678,
      "learning_rate": 3.215137844611529e-05,
      "loss": 2.861,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 2.870018720626831,
      "eval_runtime": 42.4893,
      "eval_samples_per_second": 1176.768,
      "eval_steps_per_second": 9.202,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.3572632372379303,
      "learning_rate": 3.1650125313283205e-05,
      "loss": 2.8608,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.3586544692516327,
      "learning_rate": 3.1148872180451126e-05,
      "loss": 2.8635,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.34689533710479736,
      "learning_rate": 3.064761904761905e-05,
      "loss": 2.8623,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.36107137799263,
      "learning_rate": 3.0147368421052636e-05,
      "loss": 2.8616,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.3853383958339691,
      "learning_rate": 2.9646115288220557e-05,
      "loss": 2.86,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.3635697662830353,
      "learning_rate": 2.9144862155388474e-05,
      "loss": 2.8587,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.35251522064208984,
      "learning_rate": 2.8643609022556395e-05,
      "loss": 2.8589,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.36133402585983276,
      "learning_rate": 2.8143358395989977e-05,
      "loss": 2.8588,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 2.86726713180542,
      "eval_runtime": 42.5726,
      "eval_samples_per_second": 1174.463,
      "eval_steps_per_second": 9.184,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.35544514656066895,
      "learning_rate": 2.7642105263157898e-05,
      "loss": 2.8591,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.35416778922080994,
      "learning_rate": 2.7140852130325816e-05,
      "loss": 2.8605,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.3542421758174896,
      "learning_rate": 2.6639598997493737e-05,
      "loss": 2.8617,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.3565475642681122,
      "learning_rate": 2.613934837092732e-05,
      "loss": 2.8584,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.35737958550453186,
      "learning_rate": 2.563809523809524e-05,
      "loss": 2.861,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.35428139567375183,
      "learning_rate": 2.5136842105263157e-05,
      "loss": 2.8565,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.37165772914886475,
      "learning_rate": 2.4635588972431078e-05,
      "loss": 2.859,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.3547934889793396,
      "learning_rate": 2.4135338345864664e-05,
      "loss": 2.8602,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.864788770675659,
      "eval_runtime": 42.6484,
      "eval_samples_per_second": 1172.377,
      "eval_steps_per_second": 9.168,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.3596501350402832,
      "learning_rate": 2.3634085213032585e-05,
      "loss": 2.8589,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.3495168387889862,
      "learning_rate": 2.3132832080200502e-05,
      "loss": 2.856,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.37650972604751587,
      "learning_rate": 2.2631578947368423e-05,
      "loss": 2.8556,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.35812580585479736,
      "learning_rate": 2.2131328320802005e-05,
      "loss": 2.8571,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.35672295093536377,
      "learning_rate": 2.1630075187969926e-05,
      "loss": 2.8572,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.3574832081794739,
      "learning_rate": 2.1128822055137844e-05,
      "loss": 2.8558,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.3552541434764862,
      "learning_rate": 2.0627568922305765e-05,
      "loss": 2.8586,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.3637098968029022,
      "learning_rate": 2.012731829573935e-05,
      "loss": 2.8547,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.8625428676605225,
      "eval_runtime": 42.5145,
      "eval_samples_per_second": 1176.07,
      "eval_steps_per_second": 9.197,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.3601036071777344,
      "learning_rate": 1.962606516290727e-05,
      "loss": 2.8518,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.354923278093338,
      "learning_rate": 1.912481203007519e-05,
      "loss": 2.8541,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.36354801058769226,
      "learning_rate": 1.862355889724311e-05,
      "loss": 2.8544,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.3601016104221344,
      "learning_rate": 1.812330827067669e-05,
      "loss": 2.8534,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.3651590943336487,
      "learning_rate": 1.7622055137844613e-05,
      "loss": 2.8515,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.372260183095932,
      "learning_rate": 1.712080200501253e-05,
      "loss": 2.8533,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.3496548533439636,
      "learning_rate": 1.661954887218045e-05,
      "loss": 2.8548,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.3531300723552704,
      "learning_rate": 1.6119298245614036e-05,
      "loss": 2.8563,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.8602519035339355,
      "eval_runtime": 42.564,
      "eval_samples_per_second": 1174.702,
      "eval_steps_per_second": 9.186,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.36165034770965576,
      "learning_rate": 1.5618045112781957e-05,
      "loss": 2.8531,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.36004024744033813,
      "learning_rate": 1.5116791979949877e-05,
      "loss": 2.8545,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.3625737726688385,
      "learning_rate": 1.4615538847117796e-05,
      "loss": 2.8519,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.361538827419281,
      "learning_rate": 1.4115288220551378e-05,
      "loss": 2.8512,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.3591541051864624,
      "learning_rate": 1.3614035087719299e-05,
      "loss": 2.8524,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.3630771338939667,
      "learning_rate": 1.3112781954887218e-05,
      "loss": 2.8495,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.3648235499858856,
      "learning_rate": 1.2611528822055138e-05,
      "loss": 2.8516,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.36556851863861084,
      "learning_rate": 1.2111278195488721e-05,
      "loss": 2.8526,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.8582186698913574,
      "eval_runtime": 42.56,
      "eval_samples_per_second": 1174.811,
      "eval_steps_per_second": 9.187,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.3532089591026306,
      "learning_rate": 1.1610025062656642e-05,
      "loss": 2.8468,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.3620295822620392,
      "learning_rate": 1.1108771929824562e-05,
      "loss": 2.8522,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.35429784655570984,
      "learning_rate": 1.0607518796992481e-05,
      "loss": 2.8499,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.356930136680603,
      "learning_rate": 1.0107268170426064e-05,
      "loss": 2.8513,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.3532523512840271,
      "learning_rate": 9.606015037593985e-06,
      "loss": 2.8499,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.35344502329826355,
      "learning_rate": 9.104761904761905e-06,
      "loss": 2.8485,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.35950225591659546,
      "learning_rate": 8.603508771929824e-06,
      "loss": 2.8467,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.35195329785346985,
      "learning_rate": 8.103258145363408e-06,
      "loss": 2.848,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.8563687801361084,
      "eval_runtime": 42.5438,
      "eval_samples_per_second": 1175.26,
      "eval_steps_per_second": 9.191,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.35791581869125366,
      "learning_rate": 7.602005012531328e-06,
      "loss": 2.8493,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.3634210228919983,
      "learning_rate": 7.100751879699248e-06,
      "loss": 2.8509,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.3643234372138977,
      "learning_rate": 6.600501253132832e-06,
      "loss": 2.8457,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.3530697822570801,
      "learning_rate": 6.099248120300753e-06,
      "loss": 2.8498,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.36961427330970764,
      "learning_rate": 5.597994987468672e-06,
      "loss": 2.8496,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.3587225377559662,
      "learning_rate": 5.096741854636592e-06,
      "loss": 2.8484,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.355110228061676,
      "learning_rate": 4.595488721804511e-06,
      "loss": 2.8455,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.3611205518245697,
      "learning_rate": 4.094235588972431e-06,
      "loss": 2.849,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.854808807373047,
      "eval_runtime": 42.541,
      "eval_samples_per_second": 1175.336,
      "eval_steps_per_second": 9.191,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.35853099822998047,
      "learning_rate": 3.592982456140351e-06,
      "loss": 2.8456,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.37128278613090515,
      "learning_rate": 3.091729323308271e-06,
      "loss": 2.8468,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.3634951114654541,
      "learning_rate": 2.5914786967418546e-06,
      "loss": 2.8438,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.3552957773208618,
      "learning_rate": 2.090225563909775e-06,
      "loss": 2.8472,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.35611045360565186,
      "learning_rate": 1.5889724310776943e-06,
      "loss": 2.8452,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.3478717803955078,
      "learning_rate": 1.087719298245614e-06,
      "loss": 2.8495,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.3471571207046509,
      "learning_rate": 5.87468671679198e-07,
      "loss": 2.8442,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.3541695475578308,
      "learning_rate": 8.62155388471178e-08,
      "loss": 2.8455,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.853804588317871,
      "eval_runtime": 42.5962,
      "eval_samples_per_second": 1173.812,
      "eval_steps_per_second": 9.179,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 4000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
