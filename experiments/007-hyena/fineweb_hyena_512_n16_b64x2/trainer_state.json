{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.6605297114655526,
  "eval_steps": 4000,
  "global_step": 200000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006651324278663882,
      "grad_norm": 0.5832024812698364,
      "learning_rate": 0.000499,
      "loss": 5.8313,
      "step": 500
    },
    {
      "epoch": 0.013302648557327764,
      "grad_norm": 0.46799397468566895,
      "learning_rate": 0.0004987493734335839,
      "loss": 4.3772,
      "step": 1000
    },
    {
      "epoch": 0.019953972835991644,
      "grad_norm": 0.4341648817062378,
      "learning_rate": 0.0004974962406015038,
      "loss": 4.0294,
      "step": 1500
    },
    {
      "epoch": 0.026605297114655528,
      "grad_norm": 0.41431736946105957,
      "learning_rate": 0.0004962431077694235,
      "loss": 3.8473,
      "step": 2000
    },
    {
      "epoch": 0.03325662139331941,
      "grad_norm": 0.4035409986972809,
      "learning_rate": 0.0004949899749373434,
      "loss": 3.7301,
      "step": 2500
    },
    {
      "epoch": 0.03990794567198329,
      "grad_norm": 0.36851704120635986,
      "learning_rate": 0.0004937368421052632,
      "loss": 3.643,
      "step": 3000
    },
    {
      "epoch": 0.04655926995064717,
      "grad_norm": 0.36038750410079956,
      "learning_rate": 0.000492483709273183,
      "loss": 3.5748,
      "step": 3500
    },
    {
      "epoch": 0.053210594229311056,
      "grad_norm": 0.35429221391677856,
      "learning_rate": 0.0004912305764411028,
      "loss": 3.5253,
      "step": 4000
    },
    {
      "epoch": 0.053210594229311056,
      "eval_loss": 3.4992165565490723,
      "eval_runtime": 30.1894,
      "eval_samples_per_second": 1656.212,
      "eval_steps_per_second": 12.952,
      "step": 4000
    },
    {
      "epoch": 0.05986191850797494,
      "grad_norm": 0.34513694047927856,
      "learning_rate": 0.0004899774436090226,
      "loss": 3.4813,
      "step": 4500
    },
    {
      "epoch": 0.06651324278663882,
      "grad_norm": 0.34952467679977417,
      "learning_rate": 0.0004887243107769423,
      "loss": 3.4466,
      "step": 5000
    },
    {
      "epoch": 0.07316456706530271,
      "grad_norm": 0.3520272374153137,
      "learning_rate": 0.0004874711779448622,
      "loss": 3.4133,
      "step": 5500
    },
    {
      "epoch": 0.07981589134396658,
      "grad_norm": 0.3387697637081146,
      "learning_rate": 0.00048621804511278196,
      "loss": 3.384,
      "step": 6000
    },
    {
      "epoch": 0.08646721562263046,
      "grad_norm": 0.3231383264064789,
      "learning_rate": 0.0004849649122807018,
      "loss": 3.359,
      "step": 6500
    },
    {
      "epoch": 0.09311853990129434,
      "grad_norm": 0.33264368772506714,
      "learning_rate": 0.0004837142857142857,
      "loss": 3.3377,
      "step": 7000
    },
    {
      "epoch": 0.09976986417995823,
      "grad_norm": 0.3170904815196991,
      "learning_rate": 0.00048246115288220554,
      "loss": 3.3128,
      "step": 7500
    },
    {
      "epoch": 0.10642118845862211,
      "grad_norm": 0.32483989000320435,
      "learning_rate": 0.0004812080200501253,
      "loss": 3.297,
      "step": 8000
    },
    {
      "epoch": 0.10642118845862211,
      "eval_loss": 3.2840962409973145,
      "eval_runtime": 30.0847,
      "eval_samples_per_second": 1661.972,
      "eval_steps_per_second": 12.997,
      "step": 8000
    },
    {
      "epoch": 0.113072512737286,
      "grad_norm": 0.31738659739494324,
      "learning_rate": 0.0004799548872180451,
      "loss": 3.28,
      "step": 8500
    },
    {
      "epoch": 0.11972383701594988,
      "grad_norm": 0.3224848806858063,
      "learning_rate": 0.00047870175438596493,
      "loss": 3.2631,
      "step": 9000
    },
    {
      "epoch": 0.12637516129461376,
      "grad_norm": 0.3199506103992462,
      "learning_rate": 0.00047744862155388475,
      "loss": 3.2461,
      "step": 9500
    },
    {
      "epoch": 0.13302648557327765,
      "grad_norm": 0.31285980343818665,
      "learning_rate": 0.0004761954887218045,
      "loss": 3.2362,
      "step": 10000
    },
    {
      "epoch": 0.13967780985194153,
      "grad_norm": 0.30872368812561035,
      "learning_rate": 0.00047494235588972433,
      "loss": 3.2216,
      "step": 10500
    },
    {
      "epoch": 0.14632913413060541,
      "grad_norm": 0.2992085814476013,
      "learning_rate": 0.0004736917293233083,
      "loss": 3.2123,
      "step": 11000
    },
    {
      "epoch": 0.1529804584092693,
      "grad_norm": 0.297094464302063,
      "learning_rate": 0.00047243859649122804,
      "loss": 3.1969,
      "step": 11500
    },
    {
      "epoch": 0.15963178268793315,
      "grad_norm": 0.29764166474342346,
      "learning_rate": 0.0004711854636591479,
      "loss": 3.1882,
      "step": 12000
    },
    {
      "epoch": 0.15963178268793315,
      "eval_loss": 3.181550979614258,
      "eval_runtime": 30.0982,
      "eval_samples_per_second": 1661.228,
      "eval_steps_per_second": 12.991,
      "step": 12000
    },
    {
      "epoch": 0.16628310696659704,
      "grad_norm": 0.2971211075782776,
      "learning_rate": 0.00046993233082706767,
      "loss": 3.1795,
      "step": 12500
    },
    {
      "epoch": 0.17293443124526092,
      "grad_norm": 0.30743545293807983,
      "learning_rate": 0.0004686791979949875,
      "loss": 3.1725,
      "step": 13000
    },
    {
      "epoch": 0.1795857555239248,
      "grad_norm": 0.310247004032135,
      "learning_rate": 0.00046742606516290725,
      "loss": 3.1563,
      "step": 13500
    },
    {
      "epoch": 0.1862370798025887,
      "grad_norm": 0.29754939675331116,
      "learning_rate": 0.00046617293233082707,
      "loss": 3.1524,
      "step": 14000
    },
    {
      "epoch": 0.19288840408125257,
      "grad_norm": 0.2965259253978729,
      "learning_rate": 0.00046491979949874683,
      "loss": 3.1441,
      "step": 14500
    },
    {
      "epoch": 0.19953972835991646,
      "grad_norm": 0.30004531145095825,
      "learning_rate": 0.00046366917293233083,
      "loss": 3.1379,
      "step": 15000
    },
    {
      "epoch": 0.20619105263858034,
      "grad_norm": 0.28283703327178955,
      "learning_rate": 0.00046241604010025065,
      "loss": 3.1286,
      "step": 15500
    },
    {
      "epoch": 0.21284237691724422,
      "grad_norm": 0.29606130719184875,
      "learning_rate": 0.00046116290726817046,
      "loss": 3.1244,
      "step": 16000
    },
    {
      "epoch": 0.21284237691724422,
      "eval_loss": 3.120244026184082,
      "eval_runtime": 30.0664,
      "eval_samples_per_second": 1662.988,
      "eval_steps_per_second": 13.005,
      "step": 16000
    },
    {
      "epoch": 0.2194937011959081,
      "grad_norm": 0.28121447563171387,
      "learning_rate": 0.0004599097744360902,
      "loss": 3.1171,
      "step": 16500
    },
    {
      "epoch": 0.226145025474572,
      "grad_norm": 0.2860868275165558,
      "learning_rate": 0.00045865914786967423,
      "loss": 3.1101,
      "step": 17000
    },
    {
      "epoch": 0.23279634975323588,
      "grad_norm": 0.3100256323814392,
      "learning_rate": 0.000457406015037594,
      "loss": 3.1054,
      "step": 17500
    },
    {
      "epoch": 0.23944767403189976,
      "grad_norm": 0.2759132981300354,
      "learning_rate": 0.0004561528822055138,
      "loss": 3.0952,
      "step": 18000
    },
    {
      "epoch": 0.24609899831056364,
      "grad_norm": 0.29034027457237244,
      "learning_rate": 0.00045490225563909776,
      "loss": 3.0933,
      "step": 18500
    },
    {
      "epoch": 0.2527503225892275,
      "grad_norm": 0.28397130966186523,
      "learning_rate": 0.0004536516290726817,
      "loss": 3.0895,
      "step": 19000
    },
    {
      "epoch": 0.2594016468678914,
      "grad_norm": 0.2803719937801361,
      "learning_rate": 0.0004523984962406015,
      "loss": 3.0791,
      "step": 19500
    },
    {
      "epoch": 0.2660529711465553,
      "grad_norm": 0.2747691571712494,
      "learning_rate": 0.0004511453634085213,
      "loss": 3.0763,
      "step": 20000
    },
    {
      "epoch": 0.2660529711465553,
      "eval_loss": 3.098520517349243,
      "eval_runtime": 30.0524,
      "eval_samples_per_second": 1663.761,
      "eval_steps_per_second": 13.011,
      "step": 20000
    },
    {
      "epoch": 0.2727042954252192,
      "grad_norm": 0.260363906621933,
      "learning_rate": 0.00044989223057644115,
      "loss": 3.0725,
      "step": 20500
    },
    {
      "epoch": 0.27935561970388306,
      "grad_norm": 0.2710437774658203,
      "learning_rate": 0.0004486390977443609,
      "loss": 3.0685,
      "step": 21000
    },
    {
      "epoch": 0.28600694398254695,
      "grad_norm": 0.2692532241344452,
      "learning_rate": 0.00044738596491228073,
      "loss": 3.0653,
      "step": 21500
    },
    {
      "epoch": 0.29265826826121083,
      "grad_norm": 0.26396289467811584,
      "learning_rate": 0.0004461328320802005,
      "loss": 3.0589,
      "step": 22000
    },
    {
      "epoch": 0.2993095925398747,
      "grad_norm": 0.26540806889533997,
      "learning_rate": 0.0004448796992481203,
      "loss": 3.0558,
      "step": 22500
    },
    {
      "epoch": 0.3059609168185386,
      "grad_norm": 0.2682139575481415,
      "learning_rate": 0.0004436265664160401,
      "loss": 3.0508,
      "step": 23000
    },
    {
      "epoch": 0.3126122410972024,
      "grad_norm": 0.26749029755592346,
      "learning_rate": 0.00044237343358395994,
      "loss": 3.0461,
      "step": 23500
    },
    {
      "epoch": 0.3192635653758663,
      "grad_norm": 0.26670223474502563,
      "learning_rate": 0.0004411203007518797,
      "loss": 3.0429,
      "step": 24000
    },
    {
      "epoch": 0.3192635653758663,
      "eval_loss": 3.0512120723724365,
      "eval_runtime": 30.0721,
      "eval_samples_per_second": 1662.669,
      "eval_steps_per_second": 13.002,
      "step": 24000
    },
    {
      "epoch": 0.3259148896545302,
      "grad_norm": 0.2615874707698822,
      "learning_rate": 0.0004398671679197995,
      "loss": 3.0402,
      "step": 24500
    },
    {
      "epoch": 0.3325662139331941,
      "grad_norm": 0.26901495456695557,
      "learning_rate": 0.0004386140350877193,
      "loss": 3.0347,
      "step": 25000
    },
    {
      "epoch": 0.33921753821185796,
      "grad_norm": 0.2762179374694824,
      "learning_rate": 0.00043736090225563915,
      "loss": 3.0311,
      "step": 25500
    },
    {
      "epoch": 0.34586886249052184,
      "grad_norm": 0.26309654116630554,
      "learning_rate": 0.00043611027568922305,
      "loss": 3.0291,
      "step": 26000
    },
    {
      "epoch": 0.35252018676918573,
      "grad_norm": 0.2620624303817749,
      "learning_rate": 0.00043485714285714286,
      "loss": 3.0248,
      "step": 26500
    },
    {
      "epoch": 0.3591715110478496,
      "grad_norm": 0.2677137553691864,
      "learning_rate": 0.0004336065162907268,
      "loss": 3.0208,
      "step": 27000
    },
    {
      "epoch": 0.3658228353265135,
      "grad_norm": 0.261574923992157,
      "learning_rate": 0.00043235338345864663,
      "loss": 3.0193,
      "step": 27500
    },
    {
      "epoch": 0.3724741596051774,
      "grad_norm": 0.26787132024765015,
      "learning_rate": 0.00043110025062656645,
      "loss": 3.0143,
      "step": 28000
    },
    {
      "epoch": 0.3724741596051774,
      "eval_loss": 3.0117194652557373,
      "eval_runtime": 30.0806,
      "eval_samples_per_second": 1662.203,
      "eval_steps_per_second": 12.998,
      "step": 28000
    },
    {
      "epoch": 0.37912548388384126,
      "grad_norm": 0.24738338589668274,
      "learning_rate": 0.0004298471177944862,
      "loss": 3.0144,
      "step": 28500
    },
    {
      "epoch": 0.38577680816250515,
      "grad_norm": 0.2648863196372986,
      "learning_rate": 0.000428593984962406,
      "loss": 3.0098,
      "step": 29000
    },
    {
      "epoch": 0.39242813244116903,
      "grad_norm": 0.2553372085094452,
      "learning_rate": 0.0004273408521303258,
      "loss": 3.0084,
      "step": 29500
    },
    {
      "epoch": 0.3990794567198329,
      "grad_norm": 0.26479607820510864,
      "learning_rate": 0.00042608771929824566,
      "loss": 3.003,
      "step": 30000
    },
    {
      "epoch": 0.4057307809984968,
      "grad_norm": 0.2713666260242462,
      "learning_rate": 0.0004248345864661654,
      "loss": 2.9995,
      "step": 30500
    },
    {
      "epoch": 0.4123821052771607,
      "grad_norm": 0.2583105266094208,
      "learning_rate": 0.0004235839598997494,
      "loss": 2.9957,
      "step": 31000
    },
    {
      "epoch": 0.41903342955582457,
      "grad_norm": 0.2609019875526428,
      "learning_rate": 0.0004223308270676692,
      "loss": 2.9947,
      "step": 31500
    },
    {
      "epoch": 0.42568475383448845,
      "grad_norm": 0.24833758175373077,
      "learning_rate": 0.000421077694235589,
      "loss": 2.9949,
      "step": 32000
    },
    {
      "epoch": 0.42568475383448845,
      "eval_loss": 2.9889698028564453,
      "eval_runtime": 30.0835,
      "eval_samples_per_second": 1662.042,
      "eval_steps_per_second": 12.997,
      "step": 32000
    },
    {
      "epoch": 0.43233607811315233,
      "grad_norm": 0.2426377683877945,
      "learning_rate": 0.00041982456140350876,
      "loss": 2.9893,
      "step": 32500
    },
    {
      "epoch": 0.4389874023918162,
      "grad_norm": 0.24519233405590057,
      "learning_rate": 0.0004185714285714286,
      "loss": 2.9883,
      "step": 33000
    },
    {
      "epoch": 0.4456387266704801,
      "grad_norm": 0.2494051605463028,
      "learning_rate": 0.0004173182957393484,
      "loss": 2.9817,
      "step": 33500
    },
    {
      "epoch": 0.452290050949144,
      "grad_norm": 0.2591889500617981,
      "learning_rate": 0.0004160651629072682,
      "loss": 2.9826,
      "step": 34000
    },
    {
      "epoch": 0.45894137522780787,
      "grad_norm": 0.24161402881145477,
      "learning_rate": 0.00041481203007518797,
      "loss": 2.9822,
      "step": 34500
    },
    {
      "epoch": 0.46559269950647175,
      "grad_norm": 0.24866965413093567,
      "learning_rate": 0.0004135588972431078,
      "loss": 2.978,
      "step": 35000
    },
    {
      "epoch": 0.47224402378513564,
      "grad_norm": 0.24840903282165527,
      "learning_rate": 0.00041230827067669174,
      "loss": 2.975,
      "step": 35500
    },
    {
      "epoch": 0.4788953480637995,
      "grad_norm": 0.24586844444274902,
      "learning_rate": 0.0004110551378446115,
      "loss": 2.9731,
      "step": 36000
    },
    {
      "epoch": 0.4788953480637995,
      "eval_loss": 2.970870018005371,
      "eval_runtime": 30.0781,
      "eval_samples_per_second": 1662.339,
      "eval_steps_per_second": 12.999,
      "step": 36000
    },
    {
      "epoch": 0.4855466723424634,
      "grad_norm": 0.24914556741714478,
      "learning_rate": 0.00040980200501253137,
      "loss": 2.9705,
      "step": 36500
    },
    {
      "epoch": 0.4921979966211273,
      "grad_norm": 0.278544157743454,
      "learning_rate": 0.00040854887218045113,
      "loss": 2.9688,
      "step": 37000
    },
    {
      "epoch": 0.49884932089979117,
      "grad_norm": 0.26155680418014526,
      "learning_rate": 0.00040729573934837095,
      "loss": 2.9647,
      "step": 37500
    },
    {
      "epoch": 0.505500645178455,
      "grad_norm": 0.24142365157604218,
      "learning_rate": 0.0004060451127819549,
      "loss": 2.9669,
      "step": 38000
    },
    {
      "epoch": 0.5121519694571189,
      "grad_norm": 0.25398221611976624,
      "learning_rate": 0.0004047919799498747,
      "loss": 2.965,
      "step": 38500
    },
    {
      "epoch": 0.5188032937357828,
      "grad_norm": 0.24403755366802216,
      "learning_rate": 0.0004035388471177945,
      "loss": 2.9599,
      "step": 39000
    },
    {
      "epoch": 0.5254546180144467,
      "grad_norm": 0.2619350552558899,
      "learning_rate": 0.0004022857142857143,
      "loss": 2.961,
      "step": 39500
    },
    {
      "epoch": 0.5321059422931106,
      "grad_norm": 0.24594275653362274,
      "learning_rate": 0.0004010325814536341,
      "loss": 2.9587,
      "step": 40000
    },
    {
      "epoch": 0.5321059422931106,
      "eval_loss": 2.9538512229919434,
      "eval_runtime": 30.1038,
      "eval_samples_per_second": 1660.92,
      "eval_steps_per_second": 12.988,
      "step": 40000
    },
    {
      "epoch": 0.5387572665717745,
      "grad_norm": 0.2676110863685608,
      "learning_rate": 0.0003997794486215539,
      "loss": 2.956,
      "step": 40500
    },
    {
      "epoch": 0.5454085908504384,
      "grad_norm": 0.3157419264316559,
      "learning_rate": 0.0003985263157894737,
      "loss": 2.9543,
      "step": 41000
    },
    {
      "epoch": 0.5520599151291022,
      "grad_norm": 0.268042653799057,
      "learning_rate": 0.0003972731829573935,
      "loss": 2.9538,
      "step": 41500
    },
    {
      "epoch": 0.5587112394077661,
      "grad_norm": 0.27836257219314575,
      "learning_rate": 0.00039602506265664164,
      "loss": 2.9492,
      "step": 42000
    },
    {
      "epoch": 0.56536256368643,
      "grad_norm": 0.25081488490104675,
      "learning_rate": 0.0003947719298245614,
      "loss": 2.9504,
      "step": 42500
    },
    {
      "epoch": 0.5720138879650939,
      "grad_norm": 0.29188936948776245,
      "learning_rate": 0.0003935187969924812,
      "loss": 2.9461,
      "step": 43000
    },
    {
      "epoch": 0.5786652122437578,
      "grad_norm": 0.2501489818096161,
      "learning_rate": 0.000392265664160401,
      "loss": 2.9454,
      "step": 43500
    },
    {
      "epoch": 0.5853165365224217,
      "grad_norm": 0.23720750212669373,
      "learning_rate": 0.0003910125313283208,
      "loss": 2.9399,
      "step": 44000
    },
    {
      "epoch": 0.5853165365224217,
      "eval_loss": 2.9408862590789795,
      "eval_runtime": 30.1228,
      "eval_samples_per_second": 1659.874,
      "eval_steps_per_second": 12.98,
      "step": 44000
    },
    {
      "epoch": 0.5919678608010855,
      "grad_norm": 0.24144481122493744,
      "learning_rate": 0.0003897593984962406,
      "loss": 2.9447,
      "step": 44500
    },
    {
      "epoch": 0.5986191850797494,
      "grad_norm": 0.2407371699810028,
      "learning_rate": 0.0003885062656641604,
      "loss": 2.9399,
      "step": 45000
    },
    {
      "epoch": 0.6052705093584133,
      "grad_norm": 0.2544230818748474,
      "learning_rate": 0.0003872531328320802,
      "loss": 2.9351,
      "step": 45500
    },
    {
      "epoch": 0.6119218336370772,
      "grad_norm": 0.25066766142845154,
      "learning_rate": 0.000386,
      "loss": 2.936,
      "step": 46000
    },
    {
      "epoch": 0.6185731579157411,
      "grad_norm": 0.2426493912935257,
      "learning_rate": 0.00038474686716791977,
      "loss": 2.9338,
      "step": 46500
    },
    {
      "epoch": 0.6252244821944049,
      "grad_norm": 0.23251768946647644,
      "learning_rate": 0.00038349373433583964,
      "loss": 2.9283,
      "step": 47000
    },
    {
      "epoch": 0.6318758064730687,
      "grad_norm": 0.2430475354194641,
      "learning_rate": 0.0003822406015037594,
      "loss": 2.9324,
      "step": 47500
    },
    {
      "epoch": 0.6385271307517326,
      "grad_norm": 0.23685264587402344,
      "learning_rate": 0.0003809899749373434,
      "loss": 2.9283,
      "step": 48000
    },
    {
      "epoch": 0.6385271307517326,
      "eval_loss": 2.9269187450408936,
      "eval_runtime": 30.0845,
      "eval_samples_per_second": 1661.984,
      "eval_steps_per_second": 12.997,
      "step": 48000
    },
    {
      "epoch": 0.6451784550303965,
      "grad_norm": 0.2464098185300827,
      "learning_rate": 0.00037973934837092735,
      "loss": 2.928,
      "step": 48500
    },
    {
      "epoch": 0.6518297793090604,
      "grad_norm": 0.23498333990573883,
      "learning_rate": 0.0003784862155388471,
      "loss": 2.9258,
      "step": 49000
    },
    {
      "epoch": 0.6584811035877243,
      "grad_norm": 0.24696362018585205,
      "learning_rate": 0.00037723308270676693,
      "loss": 2.9257,
      "step": 49500
    },
    {
      "epoch": 0.6651324278663882,
      "grad_norm": 0.24194152653217316,
      "learning_rate": 0.0003759799498746867,
      "loss": 2.9232,
      "step": 50000
    },
    {
      "epoch": 0.671783752145052,
      "grad_norm": 0.2338074892759323,
      "learning_rate": 0.0003747268170426065,
      "loss": 2.9215,
      "step": 50500
    },
    {
      "epoch": 0.6784350764237159,
      "grad_norm": 0.23460893332958221,
      "learning_rate": 0.0003734736842105263,
      "loss": 2.9179,
      "step": 51000
    },
    {
      "epoch": 0.6850864007023798,
      "grad_norm": 0.25009602308273315,
      "learning_rate": 0.0003722230576441103,
      "loss": 2.9222,
      "step": 51500
    },
    {
      "epoch": 0.6917377249810437,
      "grad_norm": 0.24109399318695068,
      "learning_rate": 0.0003709699248120301,
      "loss": 2.9175,
      "step": 52000
    },
    {
      "epoch": 0.6917377249810437,
      "eval_loss": 2.914490222930908,
      "eval_runtime": 30.0811,
      "eval_samples_per_second": 1662.174,
      "eval_steps_per_second": 12.998,
      "step": 52000
    },
    {
      "epoch": 0.6983890492597076,
      "grad_norm": 0.24315474927425385,
      "learning_rate": 0.0003697167919799499,
      "loss": 2.9136,
      "step": 52500
    },
    {
      "epoch": 0.7050403735383715,
      "grad_norm": 0.2585361897945404,
      "learning_rate": 0.00036846365914786967,
      "loss": 2.913,
      "step": 53000
    },
    {
      "epoch": 0.7116916978170353,
      "grad_norm": 0.23722994327545166,
      "learning_rate": 0.0003672105263157895,
      "loss": 2.9113,
      "step": 53500
    },
    {
      "epoch": 0.7183430220956992,
      "grad_norm": 0.26415932178497314,
      "learning_rate": 0.00036595739348370925,
      "loss": 2.9133,
      "step": 54000
    },
    {
      "epoch": 0.7249943463743631,
      "grad_norm": 0.24317321181297302,
      "learning_rate": 0.0003647042606516291,
      "loss": 2.9127,
      "step": 54500
    },
    {
      "epoch": 0.731645670653027,
      "grad_norm": 0.23651687800884247,
      "learning_rate": 0.000363453634085213,
      "loss": 2.9079,
      "step": 55000
    },
    {
      "epoch": 0.7382969949316909,
      "grad_norm": 0.25148847699165344,
      "learning_rate": 0.0003622005012531329,
      "loss": 2.9067,
      "step": 55500
    },
    {
      "epoch": 0.7449483192103548,
      "grad_norm": 0.22790883481502533,
      "learning_rate": 0.00036094736842105264,
      "loss": 2.9074,
      "step": 56000
    },
    {
      "epoch": 0.7449483192103548,
      "eval_loss": 2.9036142826080322,
      "eval_runtime": 30.1148,
      "eval_samples_per_second": 1660.311,
      "eval_steps_per_second": 12.984,
      "step": 56000
    },
    {
      "epoch": 0.7515996434890186,
      "grad_norm": 0.23235909640789032,
      "learning_rate": 0.00035969423558897246,
      "loss": 2.9051,
      "step": 56500
    },
    {
      "epoch": 0.7582509677676825,
      "grad_norm": 0.2524985373020172,
      "learning_rate": 0.0003584411027568922,
      "loss": 2.9051,
      "step": 57000
    },
    {
      "epoch": 0.7649022920463464,
      "grad_norm": 0.2387760579586029,
      "learning_rate": 0.00035719047619047617,
      "loss": 2.9007,
      "step": 57500
    },
    {
      "epoch": 0.7715536163250103,
      "grad_norm": 0.236821249127388,
      "learning_rate": 0.000355937343358396,
      "loss": 2.8998,
      "step": 58000
    },
    {
      "epoch": 0.7782049406036742,
      "grad_norm": 0.24235761165618896,
      "learning_rate": 0.0003546842105263158,
      "loss": 2.9016,
      "step": 58500
    },
    {
      "epoch": 0.7848562648823381,
      "grad_norm": 0.2374556064605713,
      "learning_rate": 0.0003534310776942356,
      "loss": 2.8997,
      "step": 59000
    },
    {
      "epoch": 0.791507589161002,
      "grad_norm": 0.26096290349960327,
      "learning_rate": 0.0003521779448621554,
      "loss": 2.8973,
      "step": 59500
    },
    {
      "epoch": 0.7981589134396658,
      "grad_norm": 0.24661825597286224,
      "learning_rate": 0.0003509273182957394,
      "loss": 2.8967,
      "step": 60000
    },
    {
      "epoch": 0.7981589134396658,
      "eval_loss": 2.8940112590789795,
      "eval_runtime": 30.1378,
      "eval_samples_per_second": 1659.048,
      "eval_steps_per_second": 12.974,
      "step": 60000
    },
    {
      "epoch": 0.8048102377183297,
      "grad_norm": 0.23876605927944183,
      "learning_rate": 0.00034967669172932333,
      "loss": 2.8978,
      "step": 60500
    },
    {
      "epoch": 0.8114615619969936,
      "grad_norm": 0.2643313407897949,
      "learning_rate": 0.00034842355889724315,
      "loss": 2.8951,
      "step": 61000
    },
    {
      "epoch": 0.8181128862756575,
      "grad_norm": 0.24540366232395172,
      "learning_rate": 0.0003471704260651629,
      "loss": 2.8937,
      "step": 61500
    },
    {
      "epoch": 0.8247642105543214,
      "grad_norm": 0.234710693359375,
      "learning_rate": 0.00034591729323308273,
      "loss": 2.8922,
      "step": 62000
    },
    {
      "epoch": 0.8314155348329852,
      "grad_norm": 0.24004533886909485,
      "learning_rate": 0.0003446641604010025,
      "loss": 2.892,
      "step": 62500
    },
    {
      "epoch": 0.8380668591116491,
      "grad_norm": 0.23498865962028503,
      "learning_rate": 0.00034341102756892236,
      "loss": 2.8897,
      "step": 63000
    },
    {
      "epoch": 0.844718183390313,
      "grad_norm": 0.2397494614124298,
      "learning_rate": 0.0003421578947368421,
      "loss": 2.8896,
      "step": 63500
    },
    {
      "epoch": 0.8513695076689769,
      "grad_norm": 0.2332708239555359,
      "learning_rate": 0.0003409047619047619,
      "loss": 2.8912,
      "step": 64000
    },
    {
      "epoch": 0.8513695076689769,
      "eval_loss": 2.8850343227386475,
      "eval_runtime": 30.0923,
      "eval_samples_per_second": 1661.556,
      "eval_steps_per_second": 12.993,
      "step": 64000
    },
    {
      "epoch": 0.8580208319476408,
      "grad_norm": 0.23942436277866364,
      "learning_rate": 0.0003396516290726817,
      "loss": 2.8875,
      "step": 64500
    },
    {
      "epoch": 0.8646721562263047,
      "grad_norm": 0.2332444190979004,
      "learning_rate": 0.00033840100250626565,
      "loss": 2.8857,
      "step": 65000
    },
    {
      "epoch": 0.8713234805049686,
      "grad_norm": 0.23234768211841583,
      "learning_rate": 0.00033714786967418547,
      "loss": 2.8842,
      "step": 65500
    },
    {
      "epoch": 0.8779748047836324,
      "grad_norm": 0.23399101197719574,
      "learning_rate": 0.00033589473684210523,
      "loss": 2.8834,
      "step": 66000
    },
    {
      "epoch": 0.8846261290622963,
      "grad_norm": 0.2891525328159332,
      "learning_rate": 0.0003346416040100251,
      "loss": 2.8821,
      "step": 66500
    },
    {
      "epoch": 0.8912774533409602,
      "grad_norm": 0.2391657680273056,
      "learning_rate": 0.00033338847117794486,
      "loss": 2.8791,
      "step": 67000
    },
    {
      "epoch": 0.8979287776196241,
      "grad_norm": 0.26090261340141296,
      "learning_rate": 0.00033213784461152886,
      "loss": 2.8815,
      "step": 67500
    },
    {
      "epoch": 0.904580101898288,
      "grad_norm": 0.257605642080307,
      "learning_rate": 0.0003308847117794486,
      "loss": 2.8782,
      "step": 68000
    },
    {
      "epoch": 0.904580101898288,
      "eval_loss": 2.877661943435669,
      "eval_runtime": 30.0825,
      "eval_samples_per_second": 1662.095,
      "eval_steps_per_second": 12.998,
      "step": 68000
    },
    {
      "epoch": 0.9112314261769519,
      "grad_norm": 0.23047791421413422,
      "learning_rate": 0.00032963157894736844,
      "loss": 2.88,
      "step": 68500
    },
    {
      "epoch": 0.9178827504556157,
      "grad_norm": 0.2557462751865387,
      "learning_rate": 0.0003283784461152882,
      "loss": 2.8815,
      "step": 69000
    },
    {
      "epoch": 0.9245340747342796,
      "grad_norm": 0.2366047352552414,
      "learning_rate": 0.0003271253132832081,
      "loss": 2.8787,
      "step": 69500
    },
    {
      "epoch": 0.9311853990129435,
      "grad_norm": 0.2750608026981354,
      "learning_rate": 0.00032587468671679197,
      "loss": 2.8786,
      "step": 70000
    },
    {
      "epoch": 0.9378367232916074,
      "grad_norm": 0.22917737066745758,
      "learning_rate": 0.0003246215538847118,
      "loss": 2.8752,
      "step": 70500
    },
    {
      "epoch": 0.9444880475702713,
      "grad_norm": 0.2492450624704361,
      "learning_rate": 0.0003233684210526316,
      "loss": 2.8763,
      "step": 71000
    },
    {
      "epoch": 0.9511393718489352,
      "grad_norm": 0.2795584201812744,
      "learning_rate": 0.00032211528822055136,
      "loss": 2.8761,
      "step": 71500
    },
    {
      "epoch": 0.957790696127599,
      "grad_norm": 0.24332714080810547,
      "learning_rate": 0.00032086466165413537,
      "loss": 2.8699,
      "step": 72000
    },
    {
      "epoch": 0.957790696127599,
      "eval_loss": 2.8686444759368896,
      "eval_runtime": 30.1175,
      "eval_samples_per_second": 1660.163,
      "eval_steps_per_second": 12.982,
      "step": 72000
    },
    {
      "epoch": 0.9644420204062629,
      "grad_norm": 0.2336469292640686,
      "learning_rate": 0.00031961152882205513,
      "loss": 2.8722,
      "step": 72500
    },
    {
      "epoch": 0.9710933446849268,
      "grad_norm": 0.227504700422287,
      "learning_rate": 0.00031835839598997495,
      "loss": 2.8699,
      "step": 73000
    },
    {
      "epoch": 0.9777446689635907,
      "grad_norm": 0.24621157348155975,
      "learning_rate": 0.0003171052631578947,
      "loss": 2.867,
      "step": 73500
    },
    {
      "epoch": 0.9843959932422546,
      "grad_norm": 0.23682211339473724,
      "learning_rate": 0.0003158546365914787,
      "loss": 2.8705,
      "step": 74000
    },
    {
      "epoch": 0.9910473175209185,
      "grad_norm": 0.23682433366775513,
      "learning_rate": 0.00031460150375939847,
      "loss": 2.8654,
      "step": 74500
    },
    {
      "epoch": 0.9976986417995823,
      "grad_norm": 0.2519873380661011,
      "learning_rate": 0.00031334837092731834,
      "loss": 2.8664,
      "step": 75000
    },
    {
      "epoch": 1.0043499660782462,
      "grad_norm": 0.25371649861335754,
      "learning_rate": 0.0003120952380952381,
      "loss": 2.8576,
      "step": 75500
    },
    {
      "epoch": 1.01100129035691,
      "grad_norm": 0.22704960405826569,
      "learning_rate": 0.00031084461152882205,
      "loss": 2.8534,
      "step": 76000
    },
    {
      "epoch": 1.01100129035691,
      "eval_loss": 2.861809492111206,
      "eval_runtime": 29.982,
      "eval_samples_per_second": 1667.667,
      "eval_steps_per_second": 13.041,
      "step": 76000
    },
    {
      "epoch": 1.017652614635574,
      "grad_norm": 0.23332522809505463,
      "learning_rate": 0.00030959147869674187,
      "loss": 2.8534,
      "step": 76500
    },
    {
      "epoch": 1.0243039389142379,
      "grad_norm": 0.26572340726852417,
      "learning_rate": 0.00030833834586466163,
      "loss": 2.8533,
      "step": 77000
    },
    {
      "epoch": 1.0309552631929018,
      "grad_norm": 0.24256476759910583,
      "learning_rate": 0.00030708521303258145,
      "loss": 2.8515,
      "step": 77500
    },
    {
      "epoch": 1.0376065874715656,
      "grad_norm": 0.24503299593925476,
      "learning_rate": 0.0003058345864661654,
      "loss": 2.8503,
      "step": 78000
    },
    {
      "epoch": 1.0442579117502295,
      "grad_norm": 0.2540816366672516,
      "learning_rate": 0.0003045814536340852,
      "loss": 2.8479,
      "step": 78500
    },
    {
      "epoch": 1.0509092360288934,
      "grad_norm": 0.24587418138980865,
      "learning_rate": 0.00030332832080200503,
      "loss": 2.8518,
      "step": 79000
    },
    {
      "epoch": 1.0575605603075573,
      "grad_norm": 0.24537606537342072,
      "learning_rate": 0.00030207518796992485,
      "loss": 2.8492,
      "step": 79500
    },
    {
      "epoch": 1.0642118845862212,
      "grad_norm": 0.23363187909126282,
      "learning_rate": 0.0003008220551378446,
      "loss": 2.8511,
      "step": 80000
    },
    {
      "epoch": 1.0642118845862212,
      "eval_loss": 2.8551878929138184,
      "eval_runtime": 30.0014,
      "eval_samples_per_second": 1666.591,
      "eval_steps_per_second": 13.033,
      "step": 80000
    },
    {
      "epoch": 1.070863208864885,
      "grad_norm": 0.2564435601234436,
      "learning_rate": 0.00029957142857142856,
      "loss": 2.848,
      "step": 80500
    },
    {
      "epoch": 1.077514533143549,
      "grad_norm": 0.2433570772409439,
      "learning_rate": 0.0002983182957393484,
      "loss": 2.8491,
      "step": 81000
    },
    {
      "epoch": 1.0841658574222128,
      "grad_norm": 0.27030012011528015,
      "learning_rate": 0.00029706516290726814,
      "loss": 2.8455,
      "step": 81500
    },
    {
      "epoch": 1.0908171817008767,
      "grad_norm": 0.25415733456611633,
      "learning_rate": 0.00029581203007518795,
      "loss": 2.8482,
      "step": 82000
    },
    {
      "epoch": 1.0974685059795406,
      "grad_norm": 0.22894258797168732,
      "learning_rate": 0.0002945614035087719,
      "loss": 2.8449,
      "step": 82500
    },
    {
      "epoch": 1.1041198302582045,
      "grad_norm": 0.2526264786720276,
      "learning_rate": 0.00029330827067669177,
      "loss": 2.8468,
      "step": 83000
    },
    {
      "epoch": 1.1107711545368684,
      "grad_norm": 0.27409499883651733,
      "learning_rate": 0.00029205764411027567,
      "loss": 2.8445,
      "step": 83500
    },
    {
      "epoch": 1.1174224788155322,
      "grad_norm": 0.23705154657363892,
      "learning_rate": 0.00029080451127819554,
      "loss": 2.8451,
      "step": 84000
    },
    {
      "epoch": 1.1174224788155322,
      "eval_loss": 2.8490378856658936,
      "eval_runtime": 29.9948,
      "eval_samples_per_second": 1666.953,
      "eval_steps_per_second": 13.036,
      "step": 84000
    },
    {
      "epoch": 1.1240738030941961,
      "grad_norm": 0.22429446876049042,
      "learning_rate": 0.00028955388471177943,
      "loss": 2.846,
      "step": 84500
    },
    {
      "epoch": 1.13072512737286,
      "grad_norm": 0.2342730611562729,
      "learning_rate": 0.00028830075187969925,
      "loss": 2.8435,
      "step": 85000
    },
    {
      "epoch": 1.137376451651524,
      "grad_norm": 0.2528415024280548,
      "learning_rate": 0.00028704761904761907,
      "loss": 2.8446,
      "step": 85500
    },
    {
      "epoch": 1.1440277759301878,
      "grad_norm": 0.22939199209213257,
      "learning_rate": 0.00028579448621553883,
      "loss": 2.8433,
      "step": 86000
    },
    {
      "epoch": 1.1506791002088517,
      "grad_norm": 0.23623138666152954,
      "learning_rate": 0.00028454135338345864,
      "loss": 2.8395,
      "step": 86500
    },
    {
      "epoch": 1.1573304244875156,
      "grad_norm": 0.24043066799640656,
      "learning_rate": 0.0002832882205513784,
      "loss": 2.8419,
      "step": 87000
    },
    {
      "epoch": 1.1639817487661794,
      "grad_norm": 0.23931947350502014,
      "learning_rate": 0.0002820350877192983,
      "loss": 2.8372,
      "step": 87500
    },
    {
      "epoch": 1.1706330730448433,
      "grad_norm": 0.24315236508846283,
      "learning_rate": 0.00028078195488721804,
      "loss": 2.841,
      "step": 88000
    },
    {
      "epoch": 1.1706330730448433,
      "eval_loss": 2.843505859375,
      "eval_runtime": 30.0513,
      "eval_samples_per_second": 1663.819,
      "eval_steps_per_second": 13.011,
      "step": 88000
    },
    {
      "epoch": 1.1772843973235072,
      "grad_norm": 0.24664132297039032,
      "learning_rate": 0.00027952882205513785,
      "loss": 2.8388,
      "step": 88500
    },
    {
      "epoch": 1.183935721602171,
      "grad_norm": 0.25842249393463135,
      "learning_rate": 0.0002782756892230576,
      "loss": 2.8377,
      "step": 89000
    },
    {
      "epoch": 1.190587045880835,
      "grad_norm": 0.26356565952301025,
      "learning_rate": 0.00027702255639097743,
      "loss": 2.8384,
      "step": 89500
    },
    {
      "epoch": 1.1972383701594986,
      "grad_norm": 0.24039319157600403,
      "learning_rate": 0.0002757719298245614,
      "loss": 2.8359,
      "step": 90000
    },
    {
      "epoch": 1.2038896944381627,
      "grad_norm": 0.25098535418510437,
      "learning_rate": 0.0002745187969924812,
      "loss": 2.8354,
      "step": 90500
    },
    {
      "epoch": 1.2105410187168264,
      "grad_norm": 0.24843913316726685,
      "learning_rate": 0.000273265664160401,
      "loss": 2.8341,
      "step": 91000
    },
    {
      "epoch": 1.2171923429954905,
      "grad_norm": 0.23838205635547638,
      "learning_rate": 0.00027201253132832083,
      "loss": 2.8332,
      "step": 91500
    },
    {
      "epoch": 1.2238436672741542,
      "grad_norm": 0.23440341651439667,
      "learning_rate": 0.0002707593984962406,
      "loss": 2.8337,
      "step": 92000
    },
    {
      "epoch": 1.2238436672741542,
      "eval_loss": 2.8376944065093994,
      "eval_runtime": 30.0258,
      "eval_samples_per_second": 1665.235,
      "eval_steps_per_second": 13.022,
      "step": 92000
    },
    {
      "epoch": 1.2304949915528183,
      "grad_norm": 0.24366484582424164,
      "learning_rate": 0.0002695087719298246,
      "loss": 2.8362,
      "step": 92500
    },
    {
      "epoch": 1.237146315831482,
      "grad_norm": 0.26294809579849243,
      "learning_rate": 0.00026825563909774436,
      "loss": 2.833,
      "step": 93000
    },
    {
      "epoch": 1.243797640110146,
      "grad_norm": 0.25063174962997437,
      "learning_rate": 0.00026700250626566417,
      "loss": 2.8303,
      "step": 93500
    },
    {
      "epoch": 1.2504489643888097,
      "grad_norm": 0.27450767159461975,
      "learning_rate": 0.000265749373433584,
      "loss": 2.8338,
      "step": 94000
    },
    {
      "epoch": 1.2571002886674738,
      "grad_norm": 0.26785147190093994,
      "learning_rate": 0.0002644962406015038,
      "loss": 2.8314,
      "step": 94500
    },
    {
      "epoch": 1.2637516129461375,
      "grad_norm": 0.2527156472206116,
      "learning_rate": 0.00026324310776942357,
      "loss": 2.8302,
      "step": 95000
    },
    {
      "epoch": 1.2704029372248016,
      "grad_norm": 0.2413206398487091,
      "learning_rate": 0.0002619924812030075,
      "loss": 2.8312,
      "step": 95500
    },
    {
      "epoch": 1.2770542615034652,
      "grad_norm": 0.23386619985103607,
      "learning_rate": 0.00026073934837092733,
      "loss": 2.8272,
      "step": 96000
    },
    {
      "epoch": 1.2770542615034652,
      "eval_loss": 2.8313052654266357,
      "eval_runtime": 30.0197,
      "eval_samples_per_second": 1665.575,
      "eval_steps_per_second": 13.025,
      "step": 96000
    },
    {
      "epoch": 1.2837055857821293,
      "grad_norm": 0.24825724959373474,
      "learning_rate": 0.0002594862155388471,
      "loss": 2.8257,
      "step": 96500
    },
    {
      "epoch": 1.290356910060793,
      "grad_norm": 0.24293604493141174,
      "learning_rate": 0.0002582330827067669,
      "loss": 2.8302,
      "step": 97000
    },
    {
      "epoch": 1.2970082343394571,
      "grad_norm": 0.22987686097621918,
      "learning_rate": 0.0002569799498746867,
      "loss": 2.8251,
      "step": 97500
    },
    {
      "epoch": 1.3036595586181208,
      "grad_norm": 0.23975981771945953,
      "learning_rate": 0.00025572681704260654,
      "loss": 2.8273,
      "step": 98000
    },
    {
      "epoch": 1.3103108828967849,
      "grad_norm": 0.22907090187072754,
      "learning_rate": 0.0002544736842105263,
      "loss": 2.824,
      "step": 98500
    },
    {
      "epoch": 1.3169622071754485,
      "grad_norm": 0.26046261191368103,
      "learning_rate": 0.0002532230576441103,
      "loss": 2.8254,
      "step": 99000
    },
    {
      "epoch": 1.3236135314541126,
      "grad_norm": 0.2607126533985138,
      "learning_rate": 0.00025196992481203007,
      "loss": 2.8236,
      "step": 99500
    },
    {
      "epoch": 1.3302648557327763,
      "grad_norm": 0.24882617592811584,
      "learning_rate": 0.0002507167919799499,
      "loss": 2.8231,
      "step": 100000
    },
    {
      "epoch": 1.3302648557327763,
      "eval_loss": 2.8266384601593018,
      "eval_runtime": 30.0435,
      "eval_samples_per_second": 1664.254,
      "eval_steps_per_second": 13.014,
      "step": 100000
    },
    {
      "epoch": 1.3369161800114404,
      "grad_norm": 0.2385272979736328,
      "learning_rate": 0.00024946365914786965,
      "loss": 2.8197,
      "step": 100500
    },
    {
      "epoch": 1.343567504290104,
      "grad_norm": 0.25960013270378113,
      "learning_rate": 0.00024821052631578946,
      "loss": 2.8216,
      "step": 101000
    },
    {
      "epoch": 1.350218828568768,
      "grad_norm": 0.23902647197246552,
      "learning_rate": 0.0002469573934837093,
      "loss": 2.8221,
      "step": 101500
    },
    {
      "epoch": 1.3568701528474318,
      "grad_norm": 0.24408051371574402,
      "learning_rate": 0.0002457042606516291,
      "loss": 2.8199,
      "step": 102000
    },
    {
      "epoch": 1.3635214771260957,
      "grad_norm": 0.22080965340137482,
      "learning_rate": 0.00024445112781954886,
      "loss": 2.8203,
      "step": 102500
    },
    {
      "epoch": 1.3701728014047596,
      "grad_norm": 0.24028708040714264,
      "learning_rate": 0.00024320050125313283,
      "loss": 2.8186,
      "step": 103000
    },
    {
      "epoch": 1.3768241256834235,
      "grad_norm": 0.24618007242679596,
      "learning_rate": 0.00024194736842105265,
      "loss": 2.8193,
      "step": 103500
    },
    {
      "epoch": 1.3834754499620874,
      "grad_norm": 0.23088790476322174,
      "learning_rate": 0.00024069423558897244,
      "loss": 2.8164,
      "step": 104000
    },
    {
      "epoch": 1.3834754499620874,
      "eval_loss": 2.8212146759033203,
      "eval_runtime": 30.095,
      "eval_samples_per_second": 1661.403,
      "eval_steps_per_second": 12.992,
      "step": 104000
    },
    {
      "epoch": 1.3901267742407513,
      "grad_norm": 0.24801477789878845,
      "learning_rate": 0.00023944110275689223,
      "loss": 2.8192,
      "step": 104500
    },
    {
      "epoch": 1.3967780985194151,
      "grad_norm": 0.25067010521888733,
      "learning_rate": 0.0002381904761904762,
      "loss": 2.8148,
      "step": 105000
    },
    {
      "epoch": 1.403429422798079,
      "grad_norm": 0.2495625913143158,
      "learning_rate": 0.000236937343358396,
      "loss": 2.8131,
      "step": 105500
    },
    {
      "epoch": 1.410080747076743,
      "grad_norm": 0.23498280346393585,
      "learning_rate": 0.0002356842105263158,
      "loss": 2.8153,
      "step": 106000
    },
    {
      "epoch": 1.4167320713554068,
      "grad_norm": 0.25349393486976624,
      "learning_rate": 0.0002344310776942356,
      "loss": 2.8156,
      "step": 106500
    },
    {
      "epoch": 1.4233833956340707,
      "grad_norm": 0.2626917064189911,
      "learning_rate": 0.00023318045112781955,
      "loss": 2.8141,
      "step": 107000
    },
    {
      "epoch": 1.4300347199127346,
      "grad_norm": 0.2581203877925873,
      "learning_rate": 0.00023192731829573934,
      "loss": 2.8144,
      "step": 107500
    },
    {
      "epoch": 1.4366860441913984,
      "grad_norm": 0.2518164813518524,
      "learning_rate": 0.00023067418546365915,
      "loss": 2.8124,
      "step": 108000
    },
    {
      "epoch": 1.4366860441913984,
      "eval_loss": 2.8157408237457275,
      "eval_runtime": 30.0955,
      "eval_samples_per_second": 1661.376,
      "eval_steps_per_second": 12.992,
      "step": 108000
    },
    {
      "epoch": 1.4433373684700623,
      "grad_norm": 0.2300146073102951,
      "learning_rate": 0.00022942105263157894,
      "loss": 2.813,
      "step": 108500
    },
    {
      "epoch": 1.4499886927487262,
      "grad_norm": 0.23999784886837006,
      "learning_rate": 0.00022817042606516292,
      "loss": 2.8115,
      "step": 109000
    },
    {
      "epoch": 1.45664001702739,
      "grad_norm": 0.23653380572795868,
      "learning_rate": 0.0002269172932330827,
      "loss": 2.8085,
      "step": 109500
    },
    {
      "epoch": 1.463291341306054,
      "grad_norm": 0.2344224750995636,
      "learning_rate": 0.00022566416040100252,
      "loss": 2.8128,
      "step": 110000
    },
    {
      "epoch": 1.4699426655847179,
      "grad_norm": 0.26636794209480286,
      "learning_rate": 0.00022441102756892231,
      "loss": 2.8083,
      "step": 110500
    },
    {
      "epoch": 1.4765939898633818,
      "grad_norm": 0.2901488244533539,
      "learning_rate": 0.00022316040100250626,
      "loss": 2.8116,
      "step": 111000
    },
    {
      "epoch": 1.4832453141420456,
      "grad_norm": 0.23644718527793884,
      "learning_rate": 0.00022190726817042605,
      "loss": 2.809,
      "step": 111500
    },
    {
      "epoch": 1.4898966384207095,
      "grad_norm": 0.24838724732398987,
      "learning_rate": 0.00022065413533834587,
      "loss": 2.8087,
      "step": 112000
    },
    {
      "epoch": 1.4898966384207095,
      "eval_loss": 2.8112246990203857,
      "eval_runtime": 30.0731,
      "eval_samples_per_second": 1662.614,
      "eval_steps_per_second": 13.002,
      "step": 112000
    },
    {
      "epoch": 1.4965479626993734,
      "grad_norm": 0.24584615230560303,
      "learning_rate": 0.00021940350877192982,
      "loss": 2.8078,
      "step": 112500
    },
    {
      "epoch": 1.5031992869780373,
      "grad_norm": 0.25177299976348877,
      "learning_rate": 0.00021815037593984963,
      "loss": 2.8068,
      "step": 113000
    },
    {
      "epoch": 1.5098506112567012,
      "grad_norm": 0.256226509809494,
      "learning_rate": 0.00021689724310776942,
      "loss": 2.8079,
      "step": 113500
    },
    {
      "epoch": 1.516501935535365,
      "grad_norm": 0.25978603959083557,
      "learning_rate": 0.00021564411027568924,
      "loss": 2.8067,
      "step": 114000
    },
    {
      "epoch": 1.523153259814029,
      "grad_norm": 0.2607308626174927,
      "learning_rate": 0.00021439097744360903,
      "loss": 2.807,
      "step": 114500
    },
    {
      "epoch": 1.5298045840926928,
      "grad_norm": 0.32148146629333496,
      "learning_rate": 0.000213140350877193,
      "loss": 2.8022,
      "step": 115000
    },
    {
      "epoch": 1.5364559083713567,
      "grad_norm": 0.22222121059894562,
      "learning_rate": 0.0002118872180451128,
      "loss": 2.8053,
      "step": 115500
    },
    {
      "epoch": 1.5431072326500206,
      "grad_norm": 0.23016266524791718,
      "learning_rate": 0.00021063408521303258,
      "loss": 2.8046,
      "step": 116000
    },
    {
      "epoch": 1.5431072326500206,
      "eval_loss": 2.805835247039795,
      "eval_runtime": 30.0396,
      "eval_samples_per_second": 1664.47,
      "eval_steps_per_second": 13.016,
      "step": 116000
    },
    {
      "epoch": 1.5497585569286845,
      "grad_norm": 0.27344992756843567,
      "learning_rate": 0.0002093809523809524,
      "loss": 2.8061,
      "step": 116500
    },
    {
      "epoch": 1.5564098812073484,
      "grad_norm": 0.22335773706436157,
      "learning_rate": 0.0002081278195488722,
      "loss": 2.8031,
      "step": 117000
    },
    {
      "epoch": 1.5630612054860122,
      "grad_norm": 0.24572308361530304,
      "learning_rate": 0.000206874686716792,
      "loss": 2.8021,
      "step": 117500
    },
    {
      "epoch": 1.5697125297646761,
      "grad_norm": 0.23036739230155945,
      "learning_rate": 0.0002056215538847118,
      "loss": 2.8018,
      "step": 118000
    },
    {
      "epoch": 1.57636385404334,
      "grad_norm": 0.24361729621887207,
      "learning_rate": 0.00020436842105263158,
      "loss": 2.8027,
      "step": 118500
    },
    {
      "epoch": 1.583015178322004,
      "grad_norm": 0.2742200791835785,
      "learning_rate": 0.00020311779448621553,
      "loss": 2.8004,
      "step": 119000
    },
    {
      "epoch": 1.5896665026006678,
      "grad_norm": 0.26813530921936035,
      "learning_rate": 0.00020186466165413532,
      "loss": 2.8006,
      "step": 119500
    },
    {
      "epoch": 1.5963178268793317,
      "grad_norm": 0.2863849103450775,
      "learning_rate": 0.0002006140350877193,
      "loss": 2.801,
      "step": 120000
    },
    {
      "epoch": 1.5963178268793317,
      "eval_loss": 2.8027355670928955,
      "eval_runtime": 30.0781,
      "eval_samples_per_second": 1662.339,
      "eval_steps_per_second": 12.999,
      "step": 120000
    },
    {
      "epoch": 1.6029691511579955,
      "grad_norm": 0.3254154324531555,
      "learning_rate": 0.00019936090225563911,
      "loss": 2.7987,
      "step": 120500
    },
    {
      "epoch": 1.6096204754366594,
      "grad_norm": 0.22934231162071228,
      "learning_rate": 0.0001981077694235589,
      "loss": 2.8004,
      "step": 121000
    },
    {
      "epoch": 1.6162717997153233,
      "grad_norm": 0.2805677056312561,
      "learning_rate": 0.0001968546365914787,
      "loss": 2.7967,
      "step": 121500
    },
    {
      "epoch": 1.6229231239939872,
      "grad_norm": 0.259686678647995,
      "learning_rate": 0.0001956015037593985,
      "loss": 2.7984,
      "step": 122000
    },
    {
      "epoch": 1.629574448272651,
      "grad_norm": 0.24697934091091156,
      "learning_rate": 0.00019435087719298248,
      "loss": 2.7994,
      "step": 122500
    },
    {
      "epoch": 1.636225772551315,
      "grad_norm": 0.2433057725429535,
      "learning_rate": 0.00019309774436090227,
      "loss": 2.7943,
      "step": 123000
    },
    {
      "epoch": 1.6428770968299788,
      "grad_norm": 0.2643001973628998,
      "learning_rate": 0.00019184461152882206,
      "loss": 2.7988,
      "step": 123500
    },
    {
      "epoch": 1.6495284211086427,
      "grad_norm": 0.27944689989089966,
      "learning_rate": 0.00019059147869674188,
      "loss": 2.7964,
      "step": 124000
    },
    {
      "epoch": 1.6495284211086427,
      "eval_loss": 2.7971808910369873,
      "eval_runtime": 30.0748,
      "eval_samples_per_second": 1662.523,
      "eval_steps_per_second": 13.001,
      "step": 124000
    },
    {
      "epoch": 1.6561797453873066,
      "grad_norm": 0.2577997148036957,
      "learning_rate": 0.00018933834586466167,
      "loss": 2.7939,
      "step": 124500
    },
    {
      "epoch": 1.6628310696659705,
      "grad_norm": 0.2613925635814667,
      "learning_rate": 0.00018808521303258148,
      "loss": 2.7933,
      "step": 125000
    },
    {
      "epoch": 1.6694823939446344,
      "grad_norm": 0.26056715846061707,
      "learning_rate": 0.00018683208020050127,
      "loss": 2.7919,
      "step": 125500
    },
    {
      "epoch": 1.6761337182232983,
      "grad_norm": 0.28891515731811523,
      "learning_rate": 0.00018558145363408522,
      "loss": 2.7945,
      "step": 126000
    },
    {
      "epoch": 1.6827850425019621,
      "grad_norm": 0.3745323419570923,
      "learning_rate": 0.000184328320802005,
      "loss": 2.7911,
      "step": 126500
    },
    {
      "epoch": 1.689436366780626,
      "grad_norm": 0.24197916686534882,
      "learning_rate": 0.0001830751879699248,
      "loss": 2.7936,
      "step": 127000
    },
    {
      "epoch": 1.69608769105929,
      "grad_norm": 0.2560480833053589,
      "learning_rate": 0.00018182205513784462,
      "loss": 2.7908,
      "step": 127500
    },
    {
      "epoch": 1.7027390153379538,
      "grad_norm": 0.27046144008636475,
      "learning_rate": 0.0001805714285714286,
      "loss": 2.7907,
      "step": 128000
    },
    {
      "epoch": 1.7027390153379538,
      "eval_loss": 2.7933168411254883,
      "eval_runtime": 30.0765,
      "eval_samples_per_second": 1662.429,
      "eval_steps_per_second": 13.0,
      "step": 128000
    },
    {
      "epoch": 1.7093903396166177,
      "grad_norm": 0.2437860071659088,
      "learning_rate": 0.00017931829573934838,
      "loss": 2.7912,
      "step": 128500
    },
    {
      "epoch": 1.7160416638952816,
      "grad_norm": 0.2598073482513428,
      "learning_rate": 0.00017806516290726817,
      "loss": 2.7908,
      "step": 129000
    },
    {
      "epoch": 1.7226929881739454,
      "grad_norm": 0.24372373521327972,
      "learning_rate": 0.000176812030075188,
      "loss": 2.7919,
      "step": 129500
    },
    {
      "epoch": 1.7293443124526093,
      "grad_norm": 0.30851954221725464,
      "learning_rate": 0.00017555889724310778,
      "loss": 2.7879,
      "step": 130000
    },
    {
      "epoch": 1.7359956367312732,
      "grad_norm": 0.2377108633518219,
      "learning_rate": 0.0001743057644110276,
      "loss": 2.7844,
      "step": 130500
    },
    {
      "epoch": 1.742646961009937,
      "grad_norm": 0.23650825023651123,
      "learning_rate": 0.00017305263157894738,
      "loss": 2.7873,
      "step": 131000
    },
    {
      "epoch": 1.749298285288601,
      "grad_norm": 0.23533174395561218,
      "learning_rate": 0.00017179949874686717,
      "loss": 2.7867,
      "step": 131500
    },
    {
      "epoch": 1.7559496095672649,
      "grad_norm": 0.23144792020320892,
      "learning_rate": 0.00017054887218045112,
      "loss": 2.7863,
      "step": 132000
    },
    {
      "epoch": 1.7559496095672649,
      "eval_loss": 2.788524627685547,
      "eval_runtime": 30.0704,
      "eval_samples_per_second": 1662.762,
      "eval_steps_per_second": 13.003,
      "step": 132000
    },
    {
      "epoch": 1.7626009338459288,
      "grad_norm": 0.2663257420063019,
      "learning_rate": 0.0001692957393483709,
      "loss": 2.7843,
      "step": 132500
    },
    {
      "epoch": 1.7692522581245926,
      "grad_norm": 0.2428954690694809,
      "learning_rate": 0.00016804260651629072,
      "loss": 2.7849,
      "step": 133000
    },
    {
      "epoch": 1.7759035824032565,
      "grad_norm": 0.23573265969753265,
      "learning_rate": 0.0001667894736842105,
      "loss": 2.7857,
      "step": 133500
    },
    {
      "epoch": 1.7825549066819204,
      "grad_norm": 0.23113968968391418,
      "learning_rate": 0.0001655388471177945,
      "loss": 2.784,
      "step": 134000
    },
    {
      "epoch": 1.7892062309605843,
      "grad_norm": 0.24481837451457977,
      "learning_rate": 0.00016428571428571428,
      "loss": 2.7854,
      "step": 134500
    },
    {
      "epoch": 1.7958575552392482,
      "grad_norm": 0.2460830956697464,
      "learning_rate": 0.0001630325814536341,
      "loss": 2.7861,
      "step": 135000
    },
    {
      "epoch": 1.802508879517912,
      "grad_norm": 0.255141943693161,
      "learning_rate": 0.00016177944862155388,
      "loss": 2.7841,
      "step": 135500
    },
    {
      "epoch": 1.809160203796576,
      "grad_norm": 0.2719344198703766,
      "learning_rate": 0.0001605263157894737,
      "loss": 2.7811,
      "step": 136000
    },
    {
      "epoch": 1.809160203796576,
      "eval_loss": 2.7855582237243652,
      "eval_runtime": 30.1096,
      "eval_samples_per_second": 1660.602,
      "eval_steps_per_second": 12.986,
      "step": 136000
    },
    {
      "epoch": 1.8158115280752398,
      "grad_norm": 0.23847097158432007,
      "learning_rate": 0.0001592731829573935,
      "loss": 2.7818,
      "step": 136500
    },
    {
      "epoch": 1.8224628523539037,
      "grad_norm": 0.2469271421432495,
      "learning_rate": 0.0001580250626566416,
      "loss": 2.7824,
      "step": 137000
    },
    {
      "epoch": 1.8291141766325676,
      "grad_norm": 0.24838705360889435,
      "learning_rate": 0.0001567719298245614,
      "loss": 2.7805,
      "step": 137500
    },
    {
      "epoch": 1.8357655009112315,
      "grad_norm": 0.2307502180337906,
      "learning_rate": 0.0001555187969924812,
      "loss": 2.7806,
      "step": 138000
    },
    {
      "epoch": 1.8424168251898954,
      "grad_norm": 0.23790663480758667,
      "learning_rate": 0.000154265664160401,
      "loss": 2.7789,
      "step": 138500
    },
    {
      "epoch": 1.8490681494685592,
      "grad_norm": 0.277530699968338,
      "learning_rate": 0.0001530125313283208,
      "loss": 2.7833,
      "step": 139000
    },
    {
      "epoch": 1.8557194737472231,
      "grad_norm": 0.26606616377830505,
      "learning_rate": 0.0001517593984962406,
      "loss": 2.7776,
      "step": 139500
    },
    {
      "epoch": 1.862370798025887,
      "grad_norm": 0.2502189576625824,
      "learning_rate": 0.0001505062656641604,
      "loss": 2.7793,
      "step": 140000
    },
    {
      "epoch": 1.862370798025887,
      "eval_loss": 2.7803103923797607,
      "eval_runtime": 30.118,
      "eval_samples_per_second": 1660.135,
      "eval_steps_per_second": 12.982,
      "step": 140000
    },
    {
      "epoch": 1.8690221223045507,
      "grad_norm": 0.26727330684661865,
      "learning_rate": 0.0001492531328320802,
      "loss": 2.7799,
      "step": 140500
    },
    {
      "epoch": 1.8756734465832148,
      "grad_norm": 0.24733228981494904,
      "learning_rate": 0.000148,
      "loss": 2.7777,
      "step": 141000
    },
    {
      "epoch": 1.8823247708618784,
      "grad_norm": 0.24528230726718903,
      "learning_rate": 0.0001467468671679198,
      "loss": 2.7775,
      "step": 141500
    },
    {
      "epoch": 1.8889760951405425,
      "grad_norm": 0.2424267679452896,
      "learning_rate": 0.00014549624060150376,
      "loss": 2.7743,
      "step": 142000
    },
    {
      "epoch": 1.8956274194192062,
      "grad_norm": 0.24483127892017365,
      "learning_rate": 0.00014424310776942357,
      "loss": 2.7774,
      "step": 142500
    },
    {
      "epoch": 1.9022787436978703,
      "grad_norm": 0.26230737566947937,
      "learning_rate": 0.00014298997493734336,
      "loss": 2.7736,
      "step": 143000
    },
    {
      "epoch": 1.908930067976534,
      "grad_norm": 0.2414989024400711,
      "learning_rate": 0.00014173684210526315,
      "loss": 2.7756,
      "step": 143500
    },
    {
      "epoch": 1.915581392255198,
      "grad_norm": 0.24382707476615906,
      "learning_rate": 0.00014048370927318297,
      "loss": 2.7747,
      "step": 144000
    },
    {
      "epoch": 1.915581392255198,
      "eval_loss": 2.7766306400299072,
      "eval_runtime": 30.0792,
      "eval_samples_per_second": 1662.278,
      "eval_steps_per_second": 12.999,
      "step": 144000
    },
    {
      "epoch": 1.9222327165338617,
      "grad_norm": 0.2514891028404236,
      "learning_rate": 0.00013923308270676695,
      "loss": 2.774,
      "step": 144500
    },
    {
      "epoch": 1.9288840408125258,
      "grad_norm": 0.2435077428817749,
      "learning_rate": 0.00013797994987468673,
      "loss": 2.7753,
      "step": 145000
    },
    {
      "epoch": 1.9355353650911895,
      "grad_norm": 0.2477046102285385,
      "learning_rate": 0.00013672681704260652,
      "loss": 2.7769,
      "step": 145500
    },
    {
      "epoch": 1.9421866893698536,
      "grad_norm": 0.2563606798648834,
      "learning_rate": 0.00013547368421052634,
      "loss": 2.7731,
      "step": 146000
    },
    {
      "epoch": 1.9488380136485173,
      "grad_norm": 0.23792777955532074,
      "learning_rate": 0.00013422305764411026,
      "loss": 2.7714,
      "step": 146500
    },
    {
      "epoch": 1.9554893379271814,
      "grad_norm": 0.24923543632030487,
      "learning_rate": 0.00013296992481203008,
      "loss": 2.7724,
      "step": 147000
    },
    {
      "epoch": 1.962140662205845,
      "grad_norm": 0.24022331833839417,
      "learning_rate": 0.00013171679197994987,
      "loss": 2.7723,
      "step": 147500
    },
    {
      "epoch": 1.9687919864845091,
      "grad_norm": 0.24990414083003998,
      "learning_rate": 0.00013046365914786968,
      "loss": 2.7698,
      "step": 148000
    },
    {
      "epoch": 1.9687919864845091,
      "eval_loss": 2.772564172744751,
      "eval_runtime": 30.0976,
      "eval_samples_per_second": 1661.263,
      "eval_steps_per_second": 12.991,
      "step": 148000
    },
    {
      "epoch": 1.9754433107631728,
      "grad_norm": 0.2763938307762146,
      "learning_rate": 0.00012921052631578947,
      "loss": 2.7707,
      "step": 148500
    },
    {
      "epoch": 1.982094635041837,
      "grad_norm": 0.23955732583999634,
      "learning_rate": 0.00012795989974937345,
      "loss": 2.7698,
      "step": 149000
    },
    {
      "epoch": 1.9887459593205006,
      "grad_norm": 0.2682046592235565,
      "learning_rate": 0.00012670676691729324,
      "loss": 2.7674,
      "step": 149500
    },
    {
      "epoch": 1.9953972835991647,
      "grad_norm": 0.24234500527381897,
      "learning_rate": 0.00012545363408521305,
      "loss": 2.7697,
      "step": 150000
    },
    {
      "epoch": 2.0020486078778283,
      "grad_norm": 0.23564977943897247,
      "learning_rate": 0.00012420050125313284,
      "loss": 2.767,
      "step": 150500
    },
    {
      "epoch": 2.0086999321564925,
      "grad_norm": 0.2337729036808014,
      "learning_rate": 0.0001229498746867168,
      "loss": 2.7562,
      "step": 151000
    },
    {
      "epoch": 2.015351256435156,
      "grad_norm": 0.23130370676517487,
      "learning_rate": 0.0001216967418546366,
      "loss": 2.7564,
      "step": 151500
    },
    {
      "epoch": 2.02200258071382,
      "grad_norm": 0.24449846148490906,
      "learning_rate": 0.0001204436090225564,
      "loss": 2.7526,
      "step": 152000
    },
    {
      "epoch": 2.02200258071382,
      "eval_loss": 2.7694013118743896,
      "eval_runtime": 30.0143,
      "eval_samples_per_second": 1665.872,
      "eval_steps_per_second": 13.027,
      "step": 152000
    },
    {
      "epoch": 2.028653904992484,
      "grad_norm": 0.2533405125141144,
      "learning_rate": 0.00011919298245614035,
      "loss": 2.7562,
      "step": 152500
    },
    {
      "epoch": 2.035305229271148,
      "grad_norm": 0.23571620881557465,
      "learning_rate": 0.00011793984962406015,
      "loss": 2.7542,
      "step": 153000
    },
    {
      "epoch": 2.0419565535498116,
      "grad_norm": 0.3163410425186157,
      "learning_rate": 0.00011668671679197995,
      "loss": 2.7565,
      "step": 153500
    },
    {
      "epoch": 2.0486078778284758,
      "grad_norm": 0.23361457884311676,
      "learning_rate": 0.00011543358395989975,
      "loss": 2.7548,
      "step": 154000
    },
    {
      "epoch": 2.0552592021071394,
      "grad_norm": 0.24648410081863403,
      "learning_rate": 0.00011418045112781956,
      "loss": 2.7567,
      "step": 154500
    },
    {
      "epoch": 2.0619105263858035,
      "grad_norm": 0.2533707320690155,
      "learning_rate": 0.00011292731829573935,
      "loss": 2.7539,
      "step": 155000
    },
    {
      "epoch": 2.068561850664467,
      "grad_norm": 0.24006447196006775,
      "learning_rate": 0.00011167418546365915,
      "loss": 2.7539,
      "step": 155500
    },
    {
      "epoch": 2.0752131749431313,
      "grad_norm": 0.24466724693775177,
      "learning_rate": 0.00011042105263157895,
      "loss": 2.7538,
      "step": 156000
    },
    {
      "epoch": 2.0752131749431313,
      "eval_loss": 2.7662193775177,
      "eval_runtime": 29.9883,
      "eval_samples_per_second": 1667.319,
      "eval_steps_per_second": 13.038,
      "step": 156000
    },
    {
      "epoch": 2.081864499221795,
      "grad_norm": 0.23374132812023163,
      "learning_rate": 0.0001091704260651629,
      "loss": 2.7543,
      "step": 156500
    },
    {
      "epoch": 2.088515823500459,
      "grad_norm": 0.2811450958251953,
      "learning_rate": 0.0001079172932330827,
      "loss": 2.7529,
      "step": 157000
    },
    {
      "epoch": 2.0951671477791227,
      "grad_norm": 0.2648716866970062,
      "learning_rate": 0.0001066641604010025,
      "loss": 2.7538,
      "step": 157500
    },
    {
      "epoch": 2.101818472057787,
      "grad_norm": 0.274554044008255,
      "learning_rate": 0.00010541102756892231,
      "loss": 2.7536,
      "step": 158000
    },
    {
      "epoch": 2.1084697963364505,
      "grad_norm": 0.24382613599300385,
      "learning_rate": 0.00010416040100250626,
      "loss": 2.7514,
      "step": 158500
    },
    {
      "epoch": 2.1151211206151146,
      "grad_norm": 0.24709804356098175,
      "learning_rate": 0.00010290726817042606,
      "loss": 2.7515,
      "step": 159000
    },
    {
      "epoch": 2.1217724448937783,
      "grad_norm": 0.24663788080215454,
      "learning_rate": 0.00010165413533834586,
      "loss": 2.7521,
      "step": 159500
    },
    {
      "epoch": 2.1284237691724424,
      "grad_norm": 0.25878405570983887,
      "learning_rate": 0.00010040100250626567,
      "loss": 2.7516,
      "step": 160000
    },
    {
      "epoch": 2.1284237691724424,
      "eval_loss": 2.7628180980682373,
      "eval_runtime": 29.9462,
      "eval_samples_per_second": 1669.66,
      "eval_steps_per_second": 13.057,
      "step": 160000
    },
    {
      "epoch": 2.135075093451106,
      "grad_norm": 0.2387077957391739,
      "learning_rate": 9.914786967418545e-05,
      "loss": 2.752,
      "step": 160500
    },
    {
      "epoch": 2.14172641772977,
      "grad_norm": 0.23918220400810242,
      "learning_rate": 9.789724310776943e-05,
      "loss": 2.7515,
      "step": 161000
    },
    {
      "epoch": 2.148377742008434,
      "grad_norm": 0.24144376814365387,
      "learning_rate": 9.664411027568923e-05,
      "loss": 2.7507,
      "step": 161500
    },
    {
      "epoch": 2.155029066287098,
      "grad_norm": 0.2401362657546997,
      "learning_rate": 9.539097744360902e-05,
      "loss": 2.7492,
      "step": 162000
    },
    {
      "epoch": 2.1616803905657616,
      "grad_norm": 0.23971018195152283,
      "learning_rate": 9.413784461152883e-05,
      "loss": 2.7511,
      "step": 162500
    },
    {
      "epoch": 2.1683317148444257,
      "grad_norm": 0.2409980446100235,
      "learning_rate": 9.288721804511279e-05,
      "loss": 2.7474,
      "step": 163000
    },
    {
      "epoch": 2.1749830391230893,
      "grad_norm": 0.24094301462173462,
      "learning_rate": 9.163408521303258e-05,
      "loss": 2.7461,
      "step": 163500
    },
    {
      "epoch": 2.1816343634017534,
      "grad_norm": 0.2313746064901352,
      "learning_rate": 9.038095238095238e-05,
      "loss": 2.7496,
      "step": 164000
    },
    {
      "epoch": 2.1816343634017534,
      "eval_loss": 2.7597875595092773,
      "eval_runtime": 29.9812,
      "eval_samples_per_second": 1667.711,
      "eval_steps_per_second": 13.041,
      "step": 164000
    },
    {
      "epoch": 2.188285687680417,
      "grad_norm": 0.22910639643669128,
      "learning_rate": 8.912781954887218e-05,
      "loss": 2.7483,
      "step": 164500
    },
    {
      "epoch": 2.194937011959081,
      "grad_norm": 0.2573256194591522,
      "learning_rate": 8.787719298245615e-05,
      "loss": 2.7471,
      "step": 165000
    },
    {
      "epoch": 2.201588336237745,
      "grad_norm": 0.2302512526512146,
      "learning_rate": 8.662406015037593e-05,
      "loss": 2.7476,
      "step": 165500
    },
    {
      "epoch": 2.208239660516409,
      "grad_norm": 0.22191384434700012,
      "learning_rate": 8.537092731829574e-05,
      "loss": 2.7448,
      "step": 166000
    },
    {
      "epoch": 2.2148909847950726,
      "grad_norm": 0.255772203207016,
      "learning_rate": 8.411779448621554e-05,
      "loss": 2.7492,
      "step": 166500
    },
    {
      "epoch": 2.2215423090737367,
      "grad_norm": Infinity,
      "learning_rate": 8.286466165413534e-05,
      "loss": 2.746,
      "step": 167000
    },
    {
      "epoch": 2.2281936333524004,
      "grad_norm": 0.2426752746105194,
      "learning_rate": 8.161403508771929e-05,
      "loss": 2.7483,
      "step": 167500
    },
    {
      "epoch": 2.2348449576310645,
      "grad_norm": 0.23800940811634064,
      "learning_rate": 8.03609022556391e-05,
      "loss": 2.7444,
      "step": 168000
    },
    {
      "epoch": 2.2348449576310645,
      "eval_loss": 2.756073236465454,
      "eval_runtime": 30.0224,
      "eval_samples_per_second": 1665.422,
      "eval_steps_per_second": 13.024,
      "step": 168000
    },
    {
      "epoch": 2.241496281909728,
      "grad_norm": 0.24526232481002808,
      "learning_rate": 7.91077694235589e-05,
      "loss": 2.7448,
      "step": 168500
    },
    {
      "epoch": 2.2481476061883923,
      "grad_norm": 0.2605174779891968,
      "learning_rate": 7.785463659147869e-05,
      "loss": 2.747,
      "step": 169000
    },
    {
      "epoch": 2.254798930467056,
      "grad_norm": 0.25014805793762207,
      "learning_rate": 7.660401002506266e-05,
      "loss": 2.7456,
      "step": 169500
    },
    {
      "epoch": 2.26145025474572,
      "grad_norm": 0.2410375326871872,
      "learning_rate": 7.535087719298246e-05,
      "loss": 2.7454,
      "step": 170000
    },
    {
      "epoch": 2.2681015790243837,
      "grad_norm": 0.2705070674419403,
      "learning_rate": 7.409774436090227e-05,
      "loss": 2.7437,
      "step": 170500
    },
    {
      "epoch": 2.274752903303048,
      "grad_norm": 0.2430289387702942,
      "learning_rate": 7.284461152882206e-05,
      "loss": 2.7417,
      "step": 171000
    },
    {
      "epoch": 2.2814042275817115,
      "grad_norm": 0.24290738999843597,
      "learning_rate": 7.159398496240602e-05,
      "loss": 2.7421,
      "step": 171500
    },
    {
      "epoch": 2.2880555518603756,
      "grad_norm": 0.26977822184562683,
      "learning_rate": 7.034085213032582e-05,
      "loss": 2.7425,
      "step": 172000
    },
    {
      "epoch": 2.2880555518603756,
      "eval_loss": 2.752851963043213,
      "eval_runtime": 30.0281,
      "eval_samples_per_second": 1665.108,
      "eval_steps_per_second": 13.021,
      "step": 172000
    },
    {
      "epoch": 2.2947068761390392,
      "grad_norm": 0.26513567566871643,
      "learning_rate": 6.908771929824561e-05,
      "loss": 2.7421,
      "step": 172500
    },
    {
      "epoch": 2.3013582004177033,
      "grad_norm": 0.24177446961402893,
      "learning_rate": 6.783458646616541e-05,
      "loss": 2.7438,
      "step": 173000
    },
    {
      "epoch": 2.308009524696367,
      "grad_norm": 0.2631429135799408,
      "learning_rate": 6.658395989974938e-05,
      "loss": 2.7451,
      "step": 173500
    },
    {
      "epoch": 2.314660848975031,
      "grad_norm": 0.24607358872890472,
      "learning_rate": 6.533082706766917e-05,
      "loss": 2.7411,
      "step": 174000
    },
    {
      "epoch": 2.3213121732536948,
      "grad_norm": 0.2534669041633606,
      "learning_rate": 6.407769423558897e-05,
      "loss": 2.7437,
      "step": 174500
    },
    {
      "epoch": 2.327963497532359,
      "grad_norm": 0.24702638387680054,
      "learning_rate": 6.282456140350877e-05,
      "loss": 2.7389,
      "step": 175000
    },
    {
      "epoch": 2.3346148218110225,
      "grad_norm": 0.23652830719947815,
      "learning_rate": 6.157142857142857e-05,
      "loss": 2.7418,
      "step": 175500
    },
    {
      "epoch": 2.3412661460896866,
      "grad_norm": 0.2508409917354584,
      "learning_rate": 6.031829573934837e-05,
      "loss": 2.7427,
      "step": 176000
    },
    {
      "epoch": 2.3412661460896866,
      "eval_loss": 2.749560832977295,
      "eval_runtime": 30.0381,
      "eval_samples_per_second": 1664.553,
      "eval_steps_per_second": 13.017,
      "step": 176000
    },
    {
      "epoch": 2.3479174703683503,
      "grad_norm": 0.25582143664360046,
      "learning_rate": 5.906766917293233e-05,
      "loss": 2.7412,
      "step": 176500
    },
    {
      "epoch": 2.3545687946470144,
      "grad_norm": 0.24532891809940338,
      "learning_rate": 5.7814536340852135e-05,
      "loss": 2.7387,
      "step": 177000
    },
    {
      "epoch": 2.361220118925678,
      "grad_norm": 0.25882452726364136,
      "learning_rate": 5.656140350877193e-05,
      "loss": 2.7375,
      "step": 177500
    },
    {
      "epoch": 2.367871443204342,
      "grad_norm": 0.2500089406967163,
      "learning_rate": 5.530827067669173e-05,
      "loss": 2.7394,
      "step": 178000
    },
    {
      "epoch": 2.374522767483006,
      "grad_norm": 0.2460080087184906,
      "learning_rate": 5.405764411027569e-05,
      "loss": 2.7393,
      "step": 178500
    },
    {
      "epoch": 2.38117409176167,
      "grad_norm": 0.26020172238349915,
      "learning_rate": 5.2804511278195485e-05,
      "loss": 2.7383,
      "step": 179000
    },
    {
      "epoch": 2.3878254160403336,
      "grad_norm": 0.268928200006485,
      "learning_rate": 5.155388471177945e-05,
      "loss": 2.7405,
      "step": 179500
    },
    {
      "epoch": 2.3944767403189973,
      "grad_norm": 0.2323552519083023,
      "learning_rate": 5.030075187969925e-05,
      "loss": 2.7366,
      "step": 180000
    },
    {
      "epoch": 2.3944767403189973,
      "eval_loss": 2.7466135025024414,
      "eval_runtime": 30.0441,
      "eval_samples_per_second": 1664.223,
      "eval_steps_per_second": 13.014,
      "step": 180000
    },
    {
      "epoch": 2.4011280645976614,
      "grad_norm": 0.25950369238853455,
      "learning_rate": 4.904761904761905e-05,
      "loss": 2.7335,
      "step": 180500
    },
    {
      "epoch": 2.4077793888763255,
      "grad_norm": 0.24064156413078308,
      "learning_rate": 4.779448621553885e-05,
      "loss": 2.7354,
      "step": 181000
    },
    {
      "epoch": 2.414430713154989,
      "grad_norm": 0.24320390820503235,
      "learning_rate": 4.6541353383458645e-05,
      "loss": 2.7353,
      "step": 181500
    },
    {
      "epoch": 2.421082037433653,
      "grad_norm": 0.23587962985038757,
      "learning_rate": 4.528822055137845e-05,
      "loss": 2.7347,
      "step": 182000
    },
    {
      "epoch": 2.427733361712317,
      "grad_norm": 0.26643654704093933,
      "learning_rate": 4.403508771929825e-05,
      "loss": 2.7328,
      "step": 182500
    },
    {
      "epoch": 2.434384685990981,
      "grad_norm": 0.2526921033859253,
      "learning_rate": 4.2781954887218046e-05,
      "loss": 2.7343,
      "step": 183000
    },
    {
      "epoch": 2.4410360102696447,
      "grad_norm": 0.23708386719226837,
      "learning_rate": 4.1531328320802e-05,
      "loss": 2.736,
      "step": 183500
    },
    {
      "epoch": 2.4476873345483083,
      "grad_norm": 0.2468584030866623,
      "learning_rate": 4.0278195488721805e-05,
      "loss": 2.7378,
      "step": 184000
    },
    {
      "epoch": 2.4476873345483083,
      "eval_loss": 2.7435405254364014,
      "eval_runtime": 30.0713,
      "eval_samples_per_second": 1662.716,
      "eval_steps_per_second": 13.002,
      "step": 184000
    },
    {
      "epoch": 2.4543386588269724,
      "grad_norm": 0.24403652548789978,
      "learning_rate": 3.90250626566416e-05,
      "loss": 2.7341,
      "step": 184500
    },
    {
      "epoch": 2.4609899831056365,
      "grad_norm": 0.2611154317855835,
      "learning_rate": 3.77719298245614e-05,
      "loss": 2.7353,
      "step": 185000
    },
    {
      "epoch": 2.4676413073843,
      "grad_norm": 0.23535333573818207,
      "learning_rate": 3.6521303258145366e-05,
      "loss": 2.7333,
      "step": 185500
    },
    {
      "epoch": 2.474292631662964,
      "grad_norm": 0.2573094964027405,
      "learning_rate": 3.526817042606516e-05,
      "loss": 2.7323,
      "step": 186000
    },
    {
      "epoch": 2.480943955941628,
      "grad_norm": 0.2303711175918579,
      "learning_rate": 3.4015037593984965e-05,
      "loss": 2.7326,
      "step": 186500
    },
    {
      "epoch": 2.487595280220292,
      "grad_norm": 0.24075402319431305,
      "learning_rate": 3.276190476190476e-05,
      "loss": 2.7303,
      "step": 187000
    },
    {
      "epoch": 2.4942466044989557,
      "grad_norm": 0.2416316270828247,
      "learning_rate": 3.151127819548872e-05,
      "loss": 2.7321,
      "step": 187500
    },
    {
      "epoch": 2.5008979287776194,
      "grad_norm": 0.2791690230369568,
      "learning_rate": 3.0258145363408523e-05,
      "loss": 2.7333,
      "step": 188000
    },
    {
      "epoch": 2.5008979287776194,
      "eval_loss": 2.7407469749450684,
      "eval_runtime": 30.0542,
      "eval_samples_per_second": 1663.661,
      "eval_steps_per_second": 13.01,
      "step": 188000
    },
    {
      "epoch": 2.5075492530562835,
      "grad_norm": 0.23976373672485352,
      "learning_rate": 2.9005012531328322e-05,
      "loss": 2.7274,
      "step": 188500
    },
    {
      "epoch": 2.5142005773349476,
      "grad_norm": 0.25464779138565063,
      "learning_rate": 2.775187969924812e-05,
      "loss": 2.732,
      "step": 189000
    },
    {
      "epoch": 2.5208519016136113,
      "grad_norm": 0.249029740691185,
      "learning_rate": 2.650125313283208e-05,
      "loss": 2.7304,
      "step": 189500
    },
    {
      "epoch": 2.527503225892275,
      "grad_norm": 0.23218198120594025,
      "learning_rate": 2.524812030075188e-05,
      "loss": 2.7313,
      "step": 190000
    },
    {
      "epoch": 2.534154550170939,
      "grad_norm": 0.23484788835048676,
      "learning_rate": 2.399498746867168e-05,
      "loss": 2.7305,
      "step": 190500
    },
    {
      "epoch": 2.540805874449603,
      "grad_norm": 0.24137817323207855,
      "learning_rate": 2.274185463659148e-05,
      "loss": 2.7285,
      "step": 191000
    },
    {
      "epoch": 2.547457198728267,
      "grad_norm": 0.27498745918273926,
      "learning_rate": 2.149122807017544e-05,
      "loss": 2.7272,
      "step": 191500
    },
    {
      "epoch": 2.5541085230069305,
      "grad_norm": 0.24690960347652435,
      "learning_rate": 2.023809523809524e-05,
      "loss": 2.7281,
      "step": 192000
    },
    {
      "epoch": 2.5541085230069305,
      "eval_loss": 2.7382993698120117,
      "eval_runtime": 30.0431,
      "eval_samples_per_second": 1664.274,
      "eval_steps_per_second": 13.015,
      "step": 192000
    },
    {
      "epoch": 2.5607598472855946,
      "grad_norm": 0.23559705913066864,
      "learning_rate": 1.898496240601504e-05,
      "loss": 2.7291,
      "step": 192500
    },
    {
      "epoch": 2.5674111715642587,
      "grad_norm": 0.24839429557323456,
      "learning_rate": 1.773182957393484e-05,
      "loss": 2.7302,
      "step": 193000
    },
    {
      "epoch": 2.5740624958429223,
      "grad_norm": 0.24253997206687927,
      "learning_rate": 1.64812030075188e-05,
      "loss": 2.7251,
      "step": 193500
    },
    {
      "epoch": 2.580713820121586,
      "grad_norm": 0.23015636205673218,
      "learning_rate": 1.5228070175438596e-05,
      "loss": 2.7293,
      "step": 194000
    },
    {
      "epoch": 2.58736514440025,
      "grad_norm": 0.24724365770816803,
      "learning_rate": 1.3974937343358395e-05,
      "loss": 2.7299,
      "step": 194500
    },
    {
      "epoch": 2.5940164686789142,
      "grad_norm": 0.2330317199230194,
      "learning_rate": 1.2721804511278196e-05,
      "loss": 2.7275,
      "step": 195000
    },
    {
      "epoch": 2.600667792957578,
      "grad_norm": 0.23111608624458313,
      "learning_rate": 1.1468671679197995e-05,
      "loss": 2.7244,
      "step": 195500
    },
    {
      "epoch": 2.6073191172362415,
      "grad_norm": 0.23404182493686676,
      "learning_rate": 1.0218045112781955e-05,
      "loss": 2.7282,
      "step": 196000
    },
    {
      "epoch": 2.6073191172362415,
      "eval_loss": 2.7361011505126953,
      "eval_runtime": 30.0462,
      "eval_samples_per_second": 1664.101,
      "eval_steps_per_second": 13.013,
      "step": 196000
    },
    {
      "epoch": 2.6139704415149057,
      "grad_norm": 0.24594572186470032,
      "learning_rate": 8.964912280701754e-06,
      "loss": 2.7244,
      "step": 196500
    },
    {
      "epoch": 2.6206217657935698,
      "grad_norm": 0.23829856514930725,
      "learning_rate": 7.711779448621555e-06,
      "loss": 2.7257,
      "step": 197000
    },
    {
      "epoch": 2.6272730900722334,
      "grad_norm": 0.2518227994441986,
      "learning_rate": 6.458646616541354e-06,
      "loss": 2.7224,
      "step": 197500
    },
    {
      "epoch": 2.633924414350897,
      "grad_norm": 0.23758499324321747,
      "learning_rate": 5.208020050125314e-06,
      "loss": 2.7264,
      "step": 198000
    },
    {
      "epoch": 2.640575738629561,
      "grad_norm": 0.24574699997901917,
      "learning_rate": 3.954887218045113e-06,
      "loss": 2.7234,
      "step": 198500
    },
    {
      "epoch": 2.6472270629082253,
      "grad_norm": 0.24698972702026367,
      "learning_rate": 2.701754385964912e-06,
      "loss": 2.7285,
      "step": 199000
    },
    {
      "epoch": 2.653878387186889,
      "grad_norm": 0.2339901626110077,
      "learning_rate": 1.4486215538847119e-06,
      "loss": 2.7232,
      "step": 199500
    },
    {
      "epoch": 2.6605297114655526,
      "grad_norm": 0.23487065732479095,
      "learning_rate": 1.9799498746867167e-07,
      "loss": 2.7241,
      "step": 200000
    },
    {
      "epoch": 2.6605297114655526,
      "eval_loss": 2.7347142696380615,
      "eval_runtime": 30.0773,
      "eval_samples_per_second": 1662.383,
      "eval_steps_per_second": 13.0,
      "step": 200000
    }
  ],
  "logging_steps": 500,
  "max_steps": 200000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 8000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
